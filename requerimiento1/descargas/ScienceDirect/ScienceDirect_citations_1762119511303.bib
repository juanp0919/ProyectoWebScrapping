@article{XIE2025102652,
title = {Deep learning for automatic vertebra analysis: A methodological survey of recent advances},
journal = {Computerized Medical Imaging and Graphics},
volume = {125},
pages = {102652},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102652},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001612},
author = {Zhuofan Xie and Zishan Lin and Enlong Sun and Fengyi Ding and Jie Qi and Shen Zhao},
keywords = {Automated vertebra analysis (AVA), Deep learning, Medical image analysis, Systematic review},
abstract = {Automated vertebra analysis (AVA), encompassing vertebra detection and segmentation, plays a critical role in computer-aided diagnosis, surgical planning, and postoperative evaluation in spine-related clinical workflows. Despite notable progress, AVA continues to face key challenges, including variations in the field of view (FOV), complex vertebral morphology, limited availability of high-quality annotated data, and performance degradation under domain shifts. Over the past decade, numerous studies have employed deep learning (DL) to tackle these issues, introducing advanced network architectures and innovative learning paradigms. However, the rapid evolution of these methods has not been comprehensively captured by existing surveys, resulting in a knowledge gap regarding the current state of the field. To address this, this paper presents an up-to-date review that systematically summarizes recent advances. The review begins by consolidating publicly available datasets and evaluation metrics to support standardized benchmarking. Recent DL-based AVA approaches are then analyzed from two methodological perspectives: network architecture improvement and learning strategies design. Finally, an examination of persistent technical barriers and emerging clinical needs that are shaping future research directions is provided. These include multimodal learning, domain generalization, and the integration of foundation models. As the most current survey in the field, this review provides a comprehensive and structured synthesis aimed at guiding future research toward the development of robust, generalizable, and clinically deployable AVA systems in the era of intelligent medical imaging.}
}
@article{NUTARELLI2025107011,
title = {Predicting the technological complexity of global cities based on unsupervised and supervised machine learning methods},
journal = {Journal of Economic Behavior & Organization},
volume = {234},
pages = {107011},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2025.107011},
url = {https://www.sciencedirect.com/science/article/pii/S0167268125001301},
author = {Federico Nutarelli and Samuel Edet and Giorgio Gnecco and Massimo Riccaboni},
keywords = {Innovation, Urban studies, Technological change, Artificial intelligence, Global cities},
abstract = {Analyzing and predicting innovation in global cities, i.e. cities with a high degree of economic integration into the world economy, can help identify emerging technologies and inform investment decisions that facilitate talent attraction and urban planning. In this context, the contribution of this paper is to analyze the technological complexity of global cities. We show how the combination of state-of-the-art network community detection and supervised machine learning can support local innovation and development policies by predicting the future competitiveness of global cities based on an up-to-date patent dataset. Network community detection with the Poisson stochastic block model is used as an unsupervised pre-processing step to find cities with similar innovation profiles and create homogeneous training sets that improve predictive power, interpretability and computational efficiency in a subsequent supervised learning task. The paper then compares the use of different supervised machine learning methods to predict the future competitiveness of global cities. Tree-based methods turn out to achieve better prediction performance than other supervised machine learning methods on various metrics based on the ground truth derived from historical patent production. The analytical method used in this paper can help policy makers identify technology sectors where global cities could focus their future investments and provide information on the temporal evolution of geographical patterns related to innovation.}
}
@article{REHMAN2024112111,
title = {Bioclimatic and remote sensing factors are better key indicators than local topography and soil: Vegetation composition variability in forests of Pakistan's Spin Ghar Mountain range},
journal = {Ecological Indicators},
volume = {163},
pages = {112111},
year = {2024},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2024.112111},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X24005685},
author = {Sabith Rehman and Zafar Iqbal and Rahmatullah Qureshi and Arshad Mahmood Khan and Mirza Faisal Qaseem and Manzer H. Siddiqui},
keywords = {Vegetation analysis, Diversity and distribution, Habitat complexity, Habitat fragmentation, Species extinction risk},
abstract = {The composition, structure and distribution of vegetation are influenced by diverse environmental factors. Such research inquiries provide the initial data for future conservation and management efforts. The study area of North Waziristan district, Khyber Pakhtunkhwa, Pakistan comprises diverse forests of the Spin Ghar Mountain Range (at the border areas of Pakistan and Afghanistan), and a highly remote, mountainous, and unexplored region. There was little information on the complex relationships that existed between the study area's ambient environment and vegetation. This study hypothesized that the varying environmental complexity in the study area and vegetation variety may be significantly correlated, and the ranking of leading influencing factors might enhance our ecological understanding. A total of 61 study sites comprising 183 transects (50 m each) were randomly selected to record the vegetation-environment data from January-2018 to December-2020 (3 years). Monte Carlo permutation testing, hierarchical clustering of study samples, indicator species analysis, and ordination were applied to assess the sampling data. The results indicated that there were a total of 391 vascular plant species which were further classified into seven significantly different (p < 0.05) plant assemblages, each comprising of a distinct species makeup. A variety of different environmental variables (topographic (06), bioclimatic (19), edaphic (09), remote sensing, and anthropogenic predictors (16)) were considered. Simple term effects testing results depicted the significant (p(adj) < 0.05) role of 39 variables initially, whereas, conditional term effects testing (with variance inflation factor (VIF) threshold value of < 10, and forward selecting variables that provided the most unique information) results highlighted the prominent role of eight (08) contributors. The results of the latter analysis ranked the mean temperature of the warmest quarter (Bio10) as the most influencing factor, followed by Normalized Difference Vegetation Index (NDVI), longitude, continuous heat insulation load index (CHILI), precipitation of the warmest quarter (Bio18), global human modification of the terrestrial systems (gHM), organic carbon density (OCD), and annual precipitation (Bio12). This study concluded that the vegetation variability in the study area was significantly correlated with the prevailing environment, and considered bioclimatic and remote sensing factors were better key indicators for any vegetation distribution when the study was conducted on a large spatial scale. Based on these results, the anticipated future variations in climate, particularly global warming, lengthy drought spells, and population explosion might remarkably lead to decline in local plant species richness and distribution. For the study area to guard its priceless biodiversity for future generations, careful and prompt conservation and management planning are required.}
}
@article{AYTAR2025100179,
title = {A synergistic multi-stage RAG architecture for boosting context relevance in data science literature},
journal = {Natural Language Processing Journal},
volume = {13},
pages = {100179},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100179},
url = {https://www.sciencedirect.com/science/article/pii/S294971912500055X},
author = {Ahmet Yasin Aytar and Kamer Kaya and Kemal Kılıç},
keywords = {Retrieval-Augmented Generation (RAG), Data science, Literature retrieval, Academic insights, Large Language Models (LLM)},
abstract = {Navigating the voluminous and rapidly evolving data science literature presents a significant bottleneck for researchers and practitioners. Standard Retrieval-Augmented Generation (RAG) systems often struggle with retrieving precisely relevant context from this dense academic corpus. This paper introduces a synergistic multi-stage RAG architecture specifically tailored to overcome these challenges. Our approach integrates structured document parsing (GROBID), domain-specific embedding fine-tuning derived from textbooks, semantic chunking for coherence, and proposes a novel ’Abstract First’ retrieval strategy that prioritizes concise, high-signal summaries. Through rigorous evaluation using the RAGAS framework and a custom data science query set, we demonstrate that this integrated architecture significantly boosts Context Relevance by over 15-fold compared to baseline RAG, surpassing configurations using only subsets of these enhancements. These findings underscore the critical importance of multi-stage optimization and highlight the surprising efficacy of the abstract-centric retrieval method for specialized academic domains, offering a validated pathway to more effective literature navigation in data science.}
}
@incollection{MOURTZIS2024465,
title = {15 - Outlook, trends, and future directions toward Industry 5.0},
editor = {Dimitris Mourtzis},
booktitle = {Manufacturing from Industry 4.0 to Industry 5.0},
publisher = {Elsevier},
pages = {465-492},
year = {2024},
isbn = {978-0-443-13924-6},
doi = {https://doi.org/10.1016/B978-0-443-13924-6.00015-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443139246000156},
author = {Dimitris Mourtzis},
keywords = {Computer in society, operations management, information systems, specific industry, network (computer science), computer systems organization, technology management, robotics, human-centered computing, computer science, sustainable development, operations research, management, computer security, manufacturing engineering, human–computer interaction, cognitive process, technological change, industrial organization, sustainability engineering, knowledge management, urban planning, manufacturing, mixed social research methods, control engineering},
abstract = {As artificial intelligence (AI) continues to transform various industries, including manufacturing, healthcare, and finance, the ethical implications of AI are becoming increasingly important. In this chapter an overview of AI ethics is provided, extending to the discussion on cornerstone aspects, among other being: (1) key ethical principles and issues, (2) governance and regulation, and (3) future directions. In particular, emphasis is given in the implications of AI ethics for Industry 5.0 and Society 5.0, which represent the integration of technology and society aiming toward a human-centered sustainable and resilient development. Further to that, a discussion on how ethical considerations in AI can contribute to the development of Industry 5.0 and Society 5.0 is conducted. The discussion follows a multifaceted context regarding the promotion of fairness, accountability, transparency, safety, and social responsibility of AI. In the closure of this chapter, and by extension this book, ongoing challenges and limitations of AI governance and regulation, as well as potential solutions and mitigations are discussed.}
}
@article{LI2024103484,
title = {Signing auditors’ experience gap and audit quality},
journal = {International Review of Economics & Finance},
volume = {95},
pages = {103484},
year = {2024},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2024.103484},
url = {https://www.sciencedirect.com/science/article/pii/S1059056024004763},
author = {Minghui Li and Xin Yang and Kerui Zhai},
keywords = {Audit team, Signing auditor, Auditor experience, Experience gap, Audit quality},
abstract = {This study investigates how interactions between signing auditors with different levels of experience affect audit outcomes. Using the unique data from China, we find that a higher experience gap between signing auditors is associated with higher audit quality, as indicated by lower absolute discretionary accruals and a smaller likelihood of restatements. Further analyses suggest that the positive association between signing auditors' experience gap and audit quality is more pronounced for client firms that are more complex, have weaker corporate governance and higher information asymmetry, are audited by smaller audit firms, and are more economically important to auditors. Our results are robust to alternative research designs, alternative measures of auditor experience and audit quality, and other sensitivity tests. We contribute to the literature on auditor experience and audit team diversity with implications for audit firms’ personnel assignment.}
}
@article{LI20243825,
title = {Survey and Prospect for Applying Knowledge Graph in Enterprise Risk Management},
journal = {Computers, Materials and Continua},
volume = {78},
number = {3},
pages = {3825-3865},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.046851},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824003618},
author = {Pengjun Li and Qixin Zhao and Yingmin Liu and Chao Zhong and Jinlong Wang and Zhihan Lyu},
keywords = {Knowledge graph, enterprise risk, risk identification, risk management, review},
abstract = {Enterprise risk management holds significant importance in fostering sustainable growth of businesses and in serving as a critical element for regulatory bodies to uphold market order. Amidst the challenges posed by intricate and unpredictable risk factors, knowledge graph technology is effectively driving risk management, leveraging its ability to associate and infer knowledge from diverse sources. This review aims to comprehensively summarize the construction techniques of enterprise risk knowledge graphs and their prominent applications across various business scenarios. Firstly, employing bibliometric methods, the aim is to uncover the developmental trends and current research hotspots within the domain of enterprise risk knowledge graphs. In the succeeding section, systematically delineate the technical methods for knowledge extraction and fusion in the standardized construction process of enterprise risk knowledge graphs. Objectively comparing and summarizing the strengths and weaknesses of each method, we provide recommendations for addressing the existing challenges in the construction process. Subsequently, categorizing the applied research of enterprise risk knowledge graphs based on research hotspots and risk category standards, and furnishing a detailed exposition on the applicability of technical routes and methods. Finally, the future research directions that still need to be explored in enterprise risk knowledge graphs were discussed, and relevant improvement suggestions were proposed. Practitioners and researchers can gain insights into the construction of technical theories and practical guidance of enterprise risk knowledge graphs based on this foundation.}
}
@article{LOHMAYER2026109384,
title = {Energy-based, geometric, and compositional formulation of fluid and plasma models},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {152},
pages = {109384},
year = {2026},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2025.109384},
url = {https://www.sciencedirect.com/science/article/pii/S1007570425007932},
author = {Markus Lohmayer and Michael Kraus and Sigrid Leyendecker},
keywords = {Bond graphs, Compositionality, Exterior calculus, GENERIC formalism, Graphical syntax, Magnetohydrodynamics, Metriplectic systems, Modeling language, Multiphysics, Navier-Stokes-Fourier fluid, Nonequilibrium thermodynamics, Port-Hamiltonian systems, Undirected wiring diagrams},
abstract = {Fluid dynamics plays a crucial role in various multiphysics applications, including energy systems, electronics cooling, and biomedical engineering. Developing models for complex, coupled systems can be challenging and time-consuming. In particular, ensuring the consistent integration of models from diverse physical domains requires meticulous attention. Considering the example of (electro-)magneto-hydrodynamics (on a fixed spatial domain and with linear polarization and magnetization), this article demonstrates how relatively complex models can be composed from simpler parts by means of a formal language for multiphysics modeling. The Exergetic Port-Hamiltonian Systems (EPHS) modeling language features a simple graphical syntax for expressing the energy-based interconnection of subsystems. This reduces cognitive load and facilitates communication, especially in multidisciplinary environments. As the example demonstrates, existing models can be easily integrated as subsystems of new models. Specifically, an ideal fluid model is used as a subsystem of a Navier-Stokes-Fourier fluid model, which in turn is reused as a subsystem of a magneto-hydrodynamics model. The energy-based, compositional approach simplifies understanding complex models, and it makes it easy to encapsulate, reuse, and replace their constituents. Moreover, structural properties of EPHS guarantee fundamental properties of thermodynamic systems, such as conservation of energy, non-negative entropy production, and Onsager reciprocal relations.}
}
@article{LI2024142589,
title = {Can the cumulative effect of technological resources promote green technology collaborative innovation in resource-based regions?},
journal = {Journal of Cleaner Production},
volume = {461},
pages = {142589},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.142589},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624020377},
author = {Yingming Li and Xiangjie Cao and Mingyue Wang},
keywords = {Green technology collaborative innovation, Enterprises participation, Patent collaboration network, Network evolution, Resource-based region, ERGM},
abstract = {Resource-based regions are encountering increasingly severe challenges in their green transformation and development. Urgent action is required from innovation entities to achieve more sustainable green technology innovation through Green technology collaborative innovation (GTCI). To enhance the driving mechanism of GTCI, this study categorizes technological resources into tangible and intangible categories and examines their cumulative effects on GTCI from the perspective of innovation entities. Using a network evolution perspective, this research builds multi-stage GTCI networks by utilizing green joint invention authorized patent data from 2000 to 2020, and empirically examines them using exponential random graph models. The study finds that the cumulative effect of intangible resources of technology can promote GTCI in resource-based areas, but it needs a certain period of quantitative change to trigger the qualitative change of the cumulative effect; the cumulative effect of technology tangible resources does not promote GTCI in resource-based regions and inhibits GTCI in some stages of development. This study contributes to the advancement of the resource-based view theory and broadens the research scope of the GTCI network. It also facilitates the establishment of a market-oriented green technology innovation system with enterprises as the primary focus, thereby promoting the optimized development of GTCI in resource-based regions.}
}
@article{SONG202515972,
title = {AI-driven advances in metal–organic frameworks: from data to design and applications},
journal = {Chemical Communications},
volume = {61},
number = {82},
pages = {15972-16001},
year = {2025},
issn = {1359-7345},
doi = {https://doi.org/10.1039/d5cc04220h},
url = {https://www.sciencedirect.com/science/article/pii/S1359734525021068},
author = {Yuhang Song and Jiakai Li and Dongzhi Chi and Zhengtao Xu and Jie Liu and Mingxi Chen and Ziyu Wang},
abstract = {Metal–organic frameworks (MOFs) are a versatile class of porous materials with unprecedented structural tunability, surface area, and application potential in areas such as gas storage, carbon capture, and biomedicine. However, their immense chemical design space poses significant challenges for conventional discovery and optimization methods. Recent advances in artificial intelligence (AI) and machine learning (ML) have introduced transformative capabilities to this field, enabling accurate property prediction, automated structure generation, and synthesis planning at scale. This review provides a comprehensive overview of AI-driven strategies for accelerating MOF research. It discusses key databases, deep learning architectures, generative models, and hybrid AI-simulation frameworks that have reshaped the design and screening of high-performance MOFs. Techniques such as graph neural networks and AL have enabled breakthroughs in structure–property prediction, while integration with robotics is advancing autonomous laboratories. Despite these advancements, challenges remain in data quality, model interpretability, and experimental validation. Future directions include physics-informed ML models, standardized data protocols, and deeper integration of AI with chemical robotics. By highlighting both opportunities and current limitations, this review aims to provide a roadmap for the next generation of AI-accelerated MOF innovation.}
}
@article{DATTA2024104060,
title = {Cybersecurity end-user compliance: Password management versus update compliance},
journal = {Information & Management},
volume = {61},
number = {8},
pages = {104060},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2024.104060},
url = {https://www.sciencedirect.com/science/article/pii/S0378720624001423},
author = {Pratim Milton Datta and Oliver Krancher},
keywords = {End-user compliance, Behavioral economics, Biases, Diligence, IT security knowledge, Social networking activity},
abstract = {In today's world, organizations rely on cybersecurity end-user compliance as an essential practical parameter. Yet cybersecurity compliance remains a challenge, and failures are commonplace. But why? In addressing this question, we argue that ISP compliance is neither too monolithic nor too granular a construct but needs respecification. We empirically investigate cybersecurity antecedents leading to (i) user protection-centric password management and (ii) system protection-centric update compliance dimensions. The results of our survey of 241 users show differentiating behavioral strands intertwined across different types of compliance, highlighting a unique interplay of attitudes, knowledge, and social factors as antecedents to password and update compliance.}
}
@article{MOHAMAD2026124398,
title = {Examining the factors influencing citizen adoption of e-government chatbot services in Jordan: A longitudinal survey study},
journal = {Technological Forecasting and Social Change},
volume = {222},
pages = {124398},
year = {2026},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124398},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525004299},
author = {Ibrahim Mohamad and Laurie Hughes and Ali Abdallah Alalwan and Tegwen Malik and Yogesh K. Dwivedi},
keywords = {Chatbot, Citizen, Adoption, UTAUT model, E-government adoption, Jordan},
abstract = {Many governments are focusing on adopting Artificial Intelligence (AI)-based chatbot technology to enhance work efficiency and improve e-government services. Jordan was among the first Middle Eastern countries to implement AI chatbots to offer various e-services to its citizens. While previous studies have examined the adoption of AI chatbots, they have not explored citizen adoption within the Jordanian context. This research investigates the key factors influencing citizen adoption of e-government chatbot services in Jordan by extending the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) theory with additional external variables. A longitudinal survey of 319 Jordanian citizens was conducted, with data collected at two different points using Structural equation modeling to test the hypotheses. Results demonstrate that attitude, performance expectancy, effort expectancy, social influence, hedonic motivation, facilitating conditions, self-efficacy, anthropomorphism, personal innovativeness, and trust all positively impacted Jordanian citizens' intentions to use e-government chatbot services, whilst anxiety had a negative effect. Behavioral intentions, facilitating conditions, synchronicity, active control, and ubiquitous connectivity, positively influenced usage behavior, which in turn significantly influenced satisfaction. Satisfaction also influenced citizens' future continuance usage intentions. This study offers valuable insights for enhancing e-government chatbot features to meet citizens' needs within a Middle Eastern context.}
}
@incollection{BRAGHIN2025871,
title = {Chapter 53 - Online Privacy},
editor = {John R. Vacca},
booktitle = {Computer and Information Security Handbook (Fourth Edition)},
publisher = {Morgan Kaufmann},
edition = {Fourth Edition},
pages = {871-890},
year = {2025},
isbn = {978-0-443-13223-0},
doi = {https://doi.org/10.1016/B978-0-443-13223-0.00053-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132230000539},
author = {Chiara Braghin and Marco Cremonini},
keywords = {Cookies, Data protection, Generative AI, Informed consent, Online privacy, Predictive technology, Regulations, Surveillance, Web tracking},
abstract = {Privacy is fading away from the online world, with powerful actors that have worked to invade everyone's privacy for commercial and surveillance purposes. However, limiting the analysis on the role of those actors is overly simplistic because the state of online privacy is the result of many different contributions and an historical trend. In this chapter, we analyze several facets of the lack of online privacy, some idiosyncrasies exhibited by privacy advocates, together with characteristics of the industry mostly responsible of massive data collecting. An issue not sufficiently debated is the asserted effectiveness of data-centered predictive technologies, which should be openly inquired. We also introduce the prevalent market-oriented assumption and individualistic approach at the base of online privacy. The regulatory approach to online privacy is also considered. EU's GDPR is commonly considered the reference case of modern privacy regulations, but its success hinders critical aspects that require a close examination, from the quirks of the institutional decision process, to the flaws of the informed consent principle. A glimpse on the likely problematic future is provided with a discussion on privacy related aspects of European Union, United Kingdom, and China's proposed generative AI policies. The last part of this chapter is dedicated to discuss some privacy technologies, their ambitious goals, the actual effectiveness, and the limitations, which often have been severely underestimated. There is no technical silver bullet for privacy and it seems highly unlikely that it could ever exist, because it is too multifaceted as a problem, often contradictory, strained between contrasting interests.}
}
@article{BERNARDES2025104570,
title = {Semantic meaning means a lot: Exploring the role of semantics in the development of a Big Five taxonomy},
journal = {Journal of Research in Personality},
volume = {115},
pages = {104570},
year = {2025},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2024.104570},
url = {https://www.sciencedirect.com/science/article/pii/S0092656624001181},
author = {Gabriel Bernardes and Beatriz Bozza and Marina Motta and Paulo Mattos and Ronald Fischer},
keywords = {Personality taxonomy, Big Five taxonomy, Language and personality, Lexical hypothesis, Lexical approach},
abstract = {Developing a Big Five adjective taxonomy in Brazilian Portuguese, we explored the effects of linguistic properties in our classification processes. The first two studies implement top-down (expert ratings) and bottom-up (self-ratings from a community sample; N = 500) strategies for taxonomy classification and validation. We identified a clear five-factor structure with 171 adjectives supporting the Big Five. Study 3 correlated frequency of use and the semantic dimensions of valence, arousal, and dominance to Big Five measures for each adjective. We found weak effects of frequency, but systematic effects of semantic dimensions with expert ratings and component loadings, that were congruent with differences and overlaps between the five traits. We discuss the potential role of linguistic effects on personality structure and assessment.}
}
@article{ISINGIZWE2024106631,
title = {Enhancing safety training engagement through immersive storytelling: A case study in the residential construction},
journal = {Safety Science},
volume = {179},
pages = {106631},
year = {2024},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2024.106631},
url = {https://www.sciencedirect.com/science/article/pii/S0925753524002212},
author = {Josiane Isingizwe and Ricardo Eiris and Ahmed {Jalil Al-Bayati}},
keywords = {Immersive storytelling, Residential construction, Safety training, Learning engagement, Fall hazards, Eye-tracking},
abstract = {Virtual safety training environments are increasingly utilized to support the development of safety knowledge and increase hazard identification skills in construction. One of the emerging techniques for virtual safety training is immersive storytelling. However, current studies have not explored how the inclusion or exclusion of storytelling within immersive safety training systems produces learning gains. Specifically, this study explores learning through the lens of engagement – behavioral, cognitive, and emotional. The residential construction industry was used as a case study to explore this research gap. Residential workers were assessed through a between-subject experimental design. Two safety training conditions were employed for this evaluation using a between-subject experiment – (1) immersive storytelling; and (2) immersive non-storytelling. The experimental comparison revealed that using immersive storytelling led to increases in behavioral learning and cognitive learning, allowing trainees to effectively identify openings and scaffold fall hazard categories. On the other hand, trainee emotional learning engagement did not change between immersive storytelling and immersive non-storytelling conditions. This study contributes to the existing body of knowledge by providing evidence on how using or not using storytelling can affect learning in the context of safety for fall hazards in residential construction. Practical implications for academicians and industry practitioners for the implementation of storytelling in immersive training systems are provided in the study.}
}
@incollection{REVURI2025,
title = {Artificial intelligence (AI) technologies and tools for accelerated software development},
series = {Advances in Computers},
publisher = {Elsevier},
year = {2025},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2025.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0065245825001111},
author = {Jaswanth Revuri and Rakesh Kumar Sakthivel and Gayathri Nagasubramanian},
keywords = {Artificial intelligence, Software development, Machine learning, Debugging, Software development life cycle (SDLC)},
abstract = {The rapid advancement of Artificial Intelligence (AI) is reshaping the field of software development, marking the beginning of a transformative era of automation and efficiency. This chapter provides a view of the shift to an AI-assisted approach to software development that moves beyond historical paradigms of development as we explore practices that utilize novel AI technologies. Exploring the use of AI technologies to automate processes can result in higher productivity and better collaboration, which create greater project efficiency. The chapter includes a thorough examination of certain key AI capabilities that automate aspects of coding and testing, such as automated code generation, bug detection, and test case generation. These artificial intelligence applications-electronic agents that don’t even require the presence of a developer-provide convenience and higher levels of quality, reliability and assurance. The overwhelming impact is improved productivity and collaboration through valuable AI technologies in the Software Development Lifecycle (SDLC) and ultimately improvement in every stage of the SDLC, such as idea generation, requirement gathering, design improvements and continuous deployment. This chapter finds that AI will drive collaboration where human creativity is utilized, aided by machine processing efficacies. Ultimately, the chapter provides a summative overview of the compelling promise of AI for automated software development and the changes that AI means for the software development industry. Developers who make use of these advancements can better situate themselves at the forefront of a developing technological revolution that will reshape the way that software is imagined, developed, and delivered.}
}
@article{BIBRI2025100628,
title = {AI and AI-powered digital twins for smart, green, and zero-energy buildings: A systematic review of leading-edge solutions for advancing environmental sustainability goals},
journal = {Environmental Science and Ecotechnology},
volume = {28},
pages = {100628},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100628},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425001061},
author = {Simon Elias Bibri and Jeffrey Huang},
keywords = {Artificial intelligence, Digital twins, Smart buildings, Green buildings, Zero-energy buildings, Environmental sustainability, Built environment, Sustainable smart cities},
abstract = {Buildings are among the largest contributors to global energy consumption and carbon emissions, making their transformation essential for advancing environmental sustainability goals. Innovative technologies such as artificial intelligence (AI) and digital twins (DTs) offer powerful tools for optimizing performance in smart, green, and zero-energy buildings. However, existing research remains fragmented—AI and AI-driven DT applications are often confined to isolated functions or specific building types—resulting in a limited, non-cohesive understanding of their collective potential in the built environment. This fragmentation, in turn, has hindered the development of integrated strategies that link building-level efficiencies with the broader environmental objectives of smart cities. To address these interrelated gaps, this study conducts a comprehensive systematic review of leading-edge AI and AI-powered DT solutions applied across smart, green, and zero-energy buildings. It aims to provide a holistic understanding of how these solutions enhance environmental performance through the analysis of key building-related indicators. By synthesizing, comparing, and evaluating recent research, it examines how AI and AI-powered DT technologies facilitate integrated, system-level strategies that promote environmentally sustainable smart practices across the built environment. The study reveals that AI enhances smart buildings by enabling dynamic energy optimization, occupant-centered environmental control, improved thermal comfort, renewable energy integration, and predictive system management. In green buildings, AI contributes to greater resource efficiency, minimizes construction and operational waste, promotes the use of sustainable materials, strengthens cost estimation and risk assessment processes, and supports adaptive design strategies. For zero-energy buildings, AI facilitates multi-objective optimization, advances explainable and transparent AI-driven control systems, supports performance benchmarking against net and nearly zero-energy standards, and enables renewable energy integration tailored to diverse climatic and regulatory contexts. Furthermore, AI-powered DTs enable real-time environmental monitoring, predictive analytics, anomaly detection, and adaptive operational strategies, thereby enhancing building performance, energy optimization, and resilience. At broader spatial scales, these technologies foster interconnected urban ecosystems, advancing environmental sustainability, sustainable development, and smart city initiatives. Building on these insights, this study introduces a novel integrated framework that positions AI and AI-driven DTs as systemic enablers of environmentally sustainable smart built and urban environments, emphasizing their cross-scale convergence in promoting carbon neutrality, circular economy principles, climate resilience, and regenerative urban strategies. The findings offer actionable pathways for advancing research agendas, inform practical strategies for building and urban system design, and provide evidence-based recommendations for policymakers committed to fostering more intelligent, sustainable, and resilient urban futures. This work establishes AI and AI-driven DTs as transformative catalysts for realizing the next generation of resource-efficient, carbon-neutral, and ecologically integrated urban ecosystems.}
}
@article{FAGEEH2025101996,
title = {The rise of chatbots in higher education: Exploring user profiles, motivations, and integration strategies},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101996},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101996},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125007247},
author = {Abdulaziz Fageeh},
keywords = {AI chatbots, Higher education, Student engagement, Personalized learning, Integration strategies, Activity theory, Systematic review, Mixed methods, Saudi Arabia},
abstract = {This mixed-methods study examines the incorporation of AI-powered chatbots in higher education, analyzing user profiles, motivations, and integration tactics. A systematic review of 45 studies, complemented by a survey of 86 graduate students in Saudi Arabian language and translation programs, grounded in Activity Theory, indicates that undergraduates are the predominant users, utilizing chatbots for skill enhancement, knowledge acquisition, and motivation improvement. Primary factors for adoption encompass tailored education, simulated human engagement, and secure learning settings. Although mostly supplementary instruments for academic assistance, writing, and speaking practice, chatbots are being incorporated into self-directed learning and online courses. Gamification demonstrates potential for improving motivation, although the effects of multimodal integration necessitate additional research. Qualitative analysis underscores student apprehensions about accuracy, depth of responses, and technical constraints, highlighting the necessity for continuous improvement and investigation into long-term effects and ethical considerations. The study highlights the significance of context-specific factors, especially within the Saudi Arabian educational framework, for the successful and fair integration of chatbots.}
}
@article{2024A6,
title = {Table of Contents},
journal = {American Journal of Kidney Diseases},
volume = {83},
number = {4, Supplement 2},
pages = {A6-A29},
year = {2024},
note = {National Kidney Foundation 2024 Spring Clinical Meeting Abstracts},
issn = {0272-6386},
doi = {https://doi.org/10.1053/S0272-6386(24)00588-2},
url = {https://www.sciencedirect.com/science/article/pii/S0272638624005882}
}
@article{FARHAN2025125963,
title = {RDG-TE: Link reliability-aware DRL-GNN-based traffic engineering in SDN},
journal = {Expert Systems with Applications},
volume = {265},
pages = {125963},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125963},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424028306},
author = {Muhammad Farhan and Nadir Shah and Lei Wang and Gabriel-Miro Muntean and Houbing Herbert Song},
keywords = {Software defined network, Graph Neural Network, Deep Reinforcement Learning, Traffic engineering},
abstract = {The existing advanced machine learning approaches based on Graph Neural Networks (GNN) for efficient traffic engineering (TE) in Software Defined Networking (SDN) overlook consideration of link reliability values. Link reliability is a very important parameter, directly linked to end-to-end delay for data packet transmission, and can be used to improve the delivery performance. This research article proposes two versions of RDG-TE, a novel model that integrates Deep Reinforcement Learning (DRL) and GNN in order to solve efficiently network TE problems by considering link reliability in both model training and reward computation. The proposed model enables improved performance by more accurately predicting the SDN network behavior in case of link failure. Testing results show that, in comparison to the closest state-of-art approach, our proposed approach reduces the number of disturbed flows by 24.19% and the hop count by 35.38%while also increases the reliable route prediction accuracy by 40.17%.}
}
@article{KHATRI2024100933,
title = {Student well-being in higher education: Scale development and validation with implications for management education},
journal = {The International Journal of Management Education},
volume = {22},
number = {1},
pages = {100933},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.100933},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724000041},
author = {Puja Khatri and Harshleen Kaur Duggal and Weng Marc Lim and Asha Thomas and Atul Shiva},
keywords = {Higher education, Management education, Student well-being, Scale development, Scale validation, SDG3},
abstract = {Student well-being (SWB) encompasses the physical, psychological, and social wellness of students, aspects increasingly at risk in the high-pressure environment of higher education. Marked by intense workloads, unmet expectations, and uncertainties around degree completion and employment, the higher education sector faces a growing challenge in maintaining and enhancing SWB. Current instruments for assessing SWB are limited in scope, failing to capture its multifaceted nature comprehensively. Addressing this gap, our research adopts a rigorous multi-study, multi-method, and multi-sample approach to develop and validate a multi-dimensional scale that effectively captures the nuances of SWB. This process encompassed five methodical stages: scale generation, scale purification, scale refinement, scale validation, and scale generalizability. The resulting SWB scale, encompassing five key dimensions—academic well-being, financial well-being, physical well-being, psychological resilience well-being, and relational well-being—provides a sophisticated tool for measuring and improving SWB in higher education contexts. Crucially, this paper extends beyond the scale development to explore the profound implications of this research for management education. By integrating SWB into management curricula and institutional cultures, this study underscores the potential for higher education to significantly contribute to Sustainable Development Goal 3: Good Health and Well-being. It highlights how nurturing SWB in management education can foster more resilient, empathetic, and socially responsible future leaders, addressing a critical need in contemporary business environments and society at large.}
}
@article{NG20241113,
title = {Megatrends affecting the world of work: Implications for human resource management},
journal = {Personnel Review},
volume = {54},
number = {5},
pages = {1113-1149},
year = {2024},
issn = {0048-3486},
doi = {https://doi.org/10.1108/PR-02-2025-0100},
url = {https://www.sciencedirect.com/science/article/pii/S0048348624000049},
author = {Eddy S. Ng and Pauline Stanton and Chidozie Umeh and Greg J. Bamber and Dianna Stone and Kimberly Lukaszewski and Sherry Aw and Sean Lyons and Linda Schweitzer and Shuang Ren and Mustafa F. Özbilgin and Arup Varma},
keywords = {Megatrends, Technological change, Artificial intelligence, Demographic shift, Globalization, Climate change, Populism, Future of work},
abstract = {Purpose
The purpose of the anthology is to explore how major societal shifts or “megatrends” are impacting the world of work and to provide guidance for human resource management (HRM) professionals.
Design/methodology/approach
The anthology adopts a varied approach encompassing literature reviews, empirical research and conceptual frameworks to offer informed perspectives on identifying and interpreting megatrends' impact on HRM.
Findings
The synthesis highlights several key impacts on the future of work: the transformative power of technological advancements, particularly AI and other new technologies; the challenges posed by globalization and shifting demographics; the lasting effects of the COVID-19 pandemic on work practices; the significant risks of climate change; the negative influence of populism and political polarization on diversity, equity and inclusion (DEI) initiatives; and the need for nuanced HRM approaches to address generational differences.
Research limitations/implications
There is inherent subjectivity in identifying and interpreting megatrends. Individual authors’ perspectives and biases might influence their analyses of megatrends and their recommendations for HRM. The analyses predominantly focus on Western contexts, limiting the generalizability of findings to other geographical regions and cultures.
Practical implications
The anthology encourages a more proactive, adaptable and inclusive approach to HRM, emphasizing the need for strategic foresight, investment in employee development and a focus on building organizational resilience in the face of significant societal changes.
Social implications
The anthology underscores the social responsibility of organizations and policymakers to mitigate negative social consequences arising from megatrends, promoting social justice, equity and the well-being of all members of society, particularly those most vulnerable to disruption. The findings highlight a need for societal adaptation and proactive measures to address potential inequities.
Originality/value
The anthology offers a comprehensive and insightful exploration of the significant transformations in the world of work, offering actionable guidance and laying the groundwork for future research into how HRM can successfully adapt to the evolving landscape.}
}
@incollection{IRFAN2025139,
title = {Chapter 8 - Energy efficiency solutions in the digitalized construction sector},
editor = {Ehsan Noroozinejad Farsangi and Mohammad Noori and T.Y Yang and Vasilis Sarhosis and Seyedali Mirjalili and Mirosław J. Skibniewski},
booktitle = {Digital Transformation in the Construction Industry},
publisher = {Woodhead Publishing},
pages = {139-164},
year = {2025},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-29861-5},
doi = {https://doi.org/10.1016/B978-0-443-29861-5.00008-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443298615000081},
author = {Muhammad Irfan and Muhammad Ali Musarat and Wesam Salah Alaloul and Maria Ghufran},
keywords = {Energy efficiency, digitalization, digitized construction sector, energy efficiency solutions, sustainable development.},
abstract = {Energy efficiency refers to the optimized utilization of energy by applying energy-efficient solutions. These solutions encompass various strategies, such as the integration of renewable energy sources with artificial intelligence (AI) and generative AI in construction, advancements in energy storage solutions for buildings, the use of AI for predictive maintenance and energy optimization, the incorporation of AI and building information modeling (BIM), the utilization of robotics, and the implementation of blockchain technology for transparent energy transactions. These energy-efficient solutions can potentially guide stakeholders in transforming the conventional construction industry into a digitized one. Given the significance of energy-efficient solutions in digitized construction, this chapter aims to analyze the current trends and opportunities for implementation in the construction sector. This analysis will consider the various procedures, tools, and technologies available to industry stakeholders.}
}
@article{CAMERON2024108564,
title = {DEXPI process: Standardizing interoperable information for process design and analysis},
journal = {Computers & Chemical Engineering},
volume = {182},
pages = {108564},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108564},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423004349},
author = {David B. Cameron and Wilhelm Otten and Heiner Temmen and Monica Hole and Gregor Tolksdorf},
keywords = {DEXPI, Digitalization, Interoperability, Process design, Standards},
abstract = {DEXPI Process is a proposed standard for modelling information about process design, as it is presented on block flow and process flow diagrams. It was developed by the DEXPI+ working group and builds upon the DEXPI (Data Exchange in the Process Industry) standard for piping and instrumentation diagrams. Digitalization is making increasing demands on the exchange of information in the process facility lifecycle. Industry 4.0 methods require shared terminology and knowledge models to exchange information. Standards, such as ISO15926, CFIHOS and DEXPI, try to address this need. All these focus on the physical plant items, as shown on a PID or 3D model. There is a lack of standards for early-phase, top-down process design. DEXPI Process fills this gap. This paper presents the development of DEXPI Process in the context of knowledge modelling of process systems and previews how the model is a foundation for applications of automated reasoning and decision support for design and operations.}
}
@article{HAGL2024101000,
title = {Change management interventions: Taking stock and moving forward},
journal = {Human Resource Management Review},
volume = {34},
number = {1},
pages = {101000},
year = {2024},
issn = {1053-4822},
doi = {https://doi.org/10.1016/j.hrmr.2023.101000},
url = {https://www.sciencedirect.com/science/article/pii/S1053482223000530},
author = {Christina Hagl and Rouven Kanitz and Katerina Gonzalez and Martin Hoegl},
keywords = {Change management interventions, Change implementation, Change support, Change leadership, Change management},
abstract = {Change management interventions (CMIs) are intentional activities that managers employ to facilitate planned organizational change by influencing employee receptivity to and adoption of that change. CMIs have been unclearly conceptualized and empirical insights on CMIs have become disjointed across research communities, limiting our understanding of the nature and effects CMIs can have. To address this shortcoming, we integrate and build on existing frameworks to provide an overview of the empirically studied CMI types, their mechanisms, and their outcomes. From our review of 119 empirical studies, we find that there are six overarching CMI types (and 14 sub-types): (1) communication (informing, framing, dialogic), (2) support (training, coaching, organizational change support), (3) involvement (consulting, co-creating, co-deciding), (4) reinforcement (rewards and goal-setting), (5) social influence (role modeling and peer exchange), and (6) coercion. Furthermore, based on our results, we encourage researchers to continue to strengthen an intervention-focused and context-sensitive approach to organizational change in the following underexplored areas: conceptualizing and measuring CMIs, bundles and interactions of CMIs, boundary conditions of CMIs, unintended consequences of CMIs, and the use of digital technology to enhance CMIs.}
}
@article{CASHEEKAR2024100632,
title = {A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions},
journal = {Computer Science Review},
volume = {52},
pages = {100632},
year = {2024},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100632},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000169},
author = {Avyay Casheekar and Archit Lahiri and Kanishk Rath and Kaushik Sanjay Prabhakar and Kathiravan Srinivasan},
keywords = {Computational intelligence, Artificial intelligence, Chatbots, Conversational agents, ChatGPT},
abstract = {This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI’s ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT’s applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT.}
}
@article{UPSHAW2024108725,
title = {Electrophysiological effects of smartphone notifications on cognitive control following a brief mindfulness induction},
journal = {Biological Psychology},
volume = {185},
pages = {108725},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108725},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123002454},
author = {Joshua D. Upshaw and Grant S. Shields and Matt R. Judah and Darya L. Zabelina},
keywords = {Theta/beta ratio, Spectral frequency, Mindfulness, Cognitive control, Reaction time, Smartphone, Notification},
abstract = {Smartphone use is nearly ubiquitous, with 93% of adults among economically developed countries, including the United States, Canada, Israel, and South Korea owning a smartphone (Taylor & Silver, 2019). Multiple studies have demonstrated the distracting effects of smartphone notifications on behavioral measures of cognition. Fewer studies have examined the effects of notifications on neural activity underlying higher-level cognitive processes or behavioral inductions to reduce smartphone-related distraction. Using EEG spectral frequency power densities, we assessed the effects of smartphone notifications (vs. control trials) on engagement of attentional shifting processes involved in cognitive control during a Navon Letter visual oddball task. Participants were randomly assigned to a brief mindfulness induction (N = 44) or a neutral narration control condition (N = 43). Overall, participants had lower theta-band power, but higher alpha- and beta-band power densities on target letter trials preceded by smartphone notifications. Additionally, participants in the mindfulness (vs. control) condition had a larger attention shifting oddball assessed via theta power density and theta/beta ratio (TBR) values—reflecting increased engagement of cognitive control—particularly on smartphone notification (vs. control) trials. Altogether, these results provide evidence supporting the idea that smartphone notifications can decrease activity of neural correlates of cognitive control, and offer the promise of a brief mindfulness induction to buffer against the effects of smartphone notifications on cognitive control. The findings indicate a need for further research on mindfulness inductiosn as a means to reduce potential distraction caused by smartphones.}
}
@article{K20252996,
title = {AI-Driven Multi-Modal Information Synthesis: Integrating PDF Querying, Speech Summarization, and Cross-Language Text Summarization},
journal = {Procedia Computer Science},
volume = {258},
pages = {2996-3018},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.559},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016631},
author = {Suresh Manic K and Ahmed-Al Balushi and Al-Bemani A.S. and Saleh {Al Araimi} and Balaji G and Uma Suresh and Asiya Najeeb},
keywords = {Artifical Intelligence (AI), PDF Question Answering System, Speech-to-Text Summarization, Multisource Text Summarization, Natural Language Processing (NLP)},
abstract = {This research presents an innovative AI-powered system designed to revolutionize information retrieval and summarization by integrating multiple data modalities. The system is composed of three key components: a PDF Question Answering System, Speech-to-Text Summarization, and Multi-Source Text Summarization with Cross-Language Translation capabilities. The PDF Question Answering System processes documents by segmenting them into 5000-word chunks and generating embeddings using the all-MiniLM-L6-v2 model. These embeddings are then stored in ChromaDB, a specialized vector database, enabling precise querying through similarity searches. The Speech-to-Text Summarization feature converts audio files or live streams into text using the OpenAI Whisper model. It then creates a summary of the text, which can be translated into different languages, making it easier for users to access the information. The Multi-Source Text Summarization and Translation module further broadens the system’s capabilities by processing content from various sources, including PDFs, YouTube videos, and websites. This content is summarized using the Gemma-7b-It model, with additional translation options available to the user. Test results showed that the system accurately converts speech to text, even in difficult audio conditions, with very few mistakes. It creates clear and concise summaries that keep the important details and processes tasks quickly. For example, it converts 5 minutes of audio into text in about 2 seconds and answers questions from PDF documents in less than 12 seconds. These results demonstrate the system’s ability to handle large amounts of data and different types of content efficiently, making it a flexible tool for users who need to collect and summarize information from multiple sources. It also supports multiple languages through its built-in translation feature.}
}
@article{DHAIGUDE2025100293,
title = {Supply chain integration and culture under globalization: A systematic review and global research agenda},
journal = {Research in Globalization},
volume = {11},
pages = {100293},
year = {2025},
issn = {2590-051X},
doi = {https://doi.org/10.1016/j.resglo.2025.100293},
url = {https://www.sciencedirect.com/science/article/pii/S2590051X25000267},
author = {Amol S. Dhaigude and Debmallya Chatterjee and Giridhar B Kamath},
keywords = {Supply chain integration, Culture, Cross-cultural supply chains, Global operations management, Systematic literature review, SPAR-4 SLR},
abstract = {Cultural peculiarities affect how corporations in global supply chains integrate, but unfortunately, there has been a lack of systematic documentation of this amalgamation. This study explores a complex global-level relationship among supply chain integration (SCI) and culture. This study synthesized current research from premier academic publications (A and A* levels) through text analysis, the SPAR-4 systematic literature review (SLR), and the theory, characteristics, context, and methodology(TCCM) framework to elucidate the intricacies of cross-cultural collaboration. This study proposes 60 research questions spread across the theoretical development, context, characteristics, and methodology to enhance the research on the amalgamation of SCI and culture at a global level. This study also proposes a research framework to guide future research on chaotic global supply networks. This study provides comprehensive knowledge of cross-cultural collaborative dynamics for practitioners and scholars, laying the groundwork for future empirical research and strategic management.}
}
@article{RATHER2023102088,
title = {Therapeutic efficacy and promise of stem cell-derived extracellular vesicles in Alzheimer’s disease and other aging-related disorders},
journal = {Ageing Research Reviews},
volume = {92},
pages = {102088},
year = {2023},
issn = {1568-1637},
doi = {https://doi.org/10.1016/j.arr.2023.102088},
url = {https://www.sciencedirect.com/science/article/pii/S1568163723002477},
author = {Hilal Ahmad Rather and Sameh Almousa and Suzanne Craft and Gagan Deep},
keywords = {Extracellular vesicles, Stem cell, Mesenchymal stem cell, Aging, Alzheimer’s disease},
abstract = {The term extracellular vesicles (EVs) refers to a variety of heterogeneous nanovesicles secreted by almost all cell types, primarily for intercellular communication and maintaining cellular homeostasis. The role of EVs has been widely reported in the genesis and progression of multiple pathological conditions, and these vesicles are suggested to serve as ‘liquid biopsies’. In addition to their use as biomarkers, EVs secreted by specific cell types, especially with stem cell properties, have shown promise as cell-free nanotherapeutics. Stem cell-derived EVs (SC-EVs) have been increasingly used as an attractive alternative to stem cell therapies and have been reported to promote regeneration of aging-associated tissue loss and function. SC-EVs treatment ameliorates brain and peripheral aging, reproductive dysfunctions and inhibits cellular senescence, thereby reversing several aging-related disorders and dysfunctions. The anti-aging therapeutic potential of SC-EVs depends on multiple factors, including the type of stem cells, the age of the source stem cells, and their physiological state. In this review, we briefly describe studies related to the promising effects of SC-EVs against various aging-related pathologies, and then we focus in-depth on the therapeutic benefits of SC-EVs against Alzheimer’s disease, one of the most devastating neurodegenerative diseases in elderly individuals. Numerous studies in transgenic mouse models have reported the usefulness of SC-EVs in targeting the pathological hallmarks of Alzheimer’s disease, including amyloid plaques, neurofibrillary tangles, and neuroinflammation, leading to improved neuronal protection, synaptic plasticity, and cognitive measures. Cell culture studies have further identified the underlying molecular mechanisms through which SC-EVs reduce amyloid beta (Aβ) levels or shift microglia phenotype from pro-inflammatory to anti-inflammatory state. Interestingly, multiple routes of administration, including nasal delivery, have confirmed that SC-EVs could cross the blood-brain barrier. Due to this, SC-EVs have also been tested to deliver specific therapeutic cargo molecule/s (e.g., neprilysin) to the brain. Despite these promises, several challenges related to quality control, scalability, and biodistribution remain, hindering the realization of the vast clinical promise of SC-EVs.}
}
@article{ITO2024105169,
title = {Understanding urban perception with visual data: A systematic review},
journal = {Cities},
volume = {152},
pages = {105169},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105169},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003834},
author = {Koichi Ito and Yuhao Kang and Ye Zhang and Fan Zhang and Filip Biljecki},
keywords = {Urban visual perception, Systematic review, Natural language processing},
abstract = {Visual characteristics of the built environment affect how people perceive and experience cities. For a long time, many studies have examined visual perception in cities. Such efforts have accelerated in recent years due to advancements in technologies and the proliferation of relevant data (e.g., street view imagery, geo-tagged photos, videos, virtual reality, and aerial imagery). There has not been a comprehensive systematic review paper on this topic to reveal an overarching set of research trends, limitations, and future research opportunities. Such omission is plausibly due to the difficulty in reviewing a large number of relevant papers on this popular topic. In this study, we utilized machine learning techniques (i.e., natural language processing and large language models) to semi-automate the review process and reviewed 393 relevant papers. Through the review, we found that these papers can be categorized into the physical aspects of cities: greenery and water, street design, building design, landscape, public space, and the city as a whole. We also revealed that many studies conducted quantitative analyses with a recent trend of increasingly utilizing big data and advanced technologies, such as combinations of street view imagery and deep learning models. Limitations and research gaps were also identified as follows: (1) a limited scope in terms of study areas, sample size, and attributes; (2) low quality of subjective and visual data; and (3) the need for more controlled and sophisticated methods to infer more closely examined impacts of visual features on human perceptions. We suggest that future studies utilize and contribute to open data and take advantage of existing data and technologies to examine the causality of visual features on human perception. The approach developed to accelerate this review proved to be accurate, efficient, and insightful. Considering its novelty, we also describe it to enable replications in the future.}
}
@article{LEE2024100649,
title = {Data literacy of principals in K–12 school contexts: A systematic review},
journal = {Educational Research Review},
volume = {45},
pages = {100649},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100649},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000587},
author = {Jihyun Lee and Dennis Alonzo and Kim Beswick and Cherry Zin Oo and Daniel W.J. Anson and Jan Michael Vincent Abril},
keywords = {Principals, Teachers, Data literacy, Data use, Indicators, Dimensions, Decision-making},
abstract = {This systematic review aims to clarify the concept of principals' data literacy and its various components. After examining 56 empirical studies, we have defined principals' data literacy and identified 63 specific indicators, organized into seven dimensions. Our findings highlight the complex tasks and responsibilities principals undertake to effectively lead with data. Although some data-related activities overlap between principals and teachers, the nature, scope, and purposes of data use differ between these roles. While teachers’ data literacy focuses on hands-on data creation, collection, and analysis, principals' data literacy revolves around leading their school communities and beyond. We argue that three of the seven dimensions—Dimension 3 (“Data use for fostering a data-driven culture”), Dimension 4 (“Data use for school improvement”), and Dimension 5 (“Data use for informing own practices”)—are particularly relevant to school leaders, thereby distinguishing principals' data literacy from that of teachers. We conclude by suggesting several practical implications based on our review, which could benefit the professional development of both school leaders and teachers at various career stages.}
}
@article{MERVIN2021474,
title = {Uncertainty quantification in drug design},
journal = {Drug Discovery Today},
volume = {26},
number = {2},
pages = {474-489},
year = {2021},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2020.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S1359644620305110},
author = {Lewis H. Mervin and Simon Johansson and Elizaveta Semenova and Kathryn A. Giblin and Ola Engkvist},
abstract = {Machine learning and artificial intelligence are increasingly being applied to the drug-design process as a result of the development of novel algorithms, growing access, the falling cost of computation and the development of novel technologies for generating chemically and biologically relevant data. There has been recent progress in fields such as molecular de novo generation, synthetic route prediction and, to some extent, property predictions. Despite this, most research in these fields has focused on improving the accuracy of the technologies, rather than on quantifying the uncertainty in the predictions. Uncertainty quantification will become a key component in autonomous decision making and will be crucial for integrating machine learning and chemistry automation to create an autonomous design–make–test–analyse cycle. This review covers the empirical, frequentist and Bayesian approaches to uncertainty quantification, and outlines how they can be used for drug design. We also outline the impact of uncertainty quantification on decision making.}
}
@article{TAMAYO202535,
title = {Bifidobacterium longum CECT 30763 improves depressive- and anxiety-like behavior in a social defeat mouse model through the immune and dopaminergic systems},
journal = {Brain, Behavior, and Immunity},
volume = {125},
pages = {35-57},
year = {2025},
issn = {0889-1591},
doi = {https://doi.org/10.1016/j.bbi.2024.12.028},
url = {https://www.sciencedirect.com/science/article/pii/S0889159124007578},
author = {M. Tamayo and A. Agusti and G.V. Molina-Mendoza and V. Rossini and C. Frances-Cuesta and V. Tolosa-Enguís and Y. Sanz},
keywords = {Gut-brain axis, Microbiota, , Stress, Depression},
abstract = {Adolescence is a crucial period marked by profound changes in the brain. Exposure to psychological stressors such as bullying, abuse or maltreatment during this developmental period may increase the risk of developing depression, anxiety and comorbid cardiometabolic conditions. Chronic psychological stress is associated with behavioral changes and disruption of the hypothalamic–pituitary–adrenal axis, leading to corticosterone overproduction in rodents and changes in both the immune system and the gut microbiome. Here, we demonstrate the ability of Bifidobacterium longum CECT 30763 (B. longum) to ameliorate adolescent depressive and anxiety-like behaviors in a chronic social defeat (CSD) mouse model. The mechanisms underlying this beneficial effect are related to the ability of B. longum to attenuate the inflammation and immune cell changes induced by CSD after the initial stress exposure through the induction of T regulatory cells with enduring effects that may prevent and mitigate the adverse consequences of repeated stress exposure on mental and cardiometabolic health. B. longum administration also normalized dopamine release, metabolism and signaling at the end of the intervention, which may secondarily contribute to the reversal of behavioral changes. The anti-inflammatory effects of B. longum could also explain its cardioprotective effects, which were reflected in an amelioration of the oxidative stress-induced damage in the heart and improved lipid metabolism in the liver. Overall, our findings suggest that B. longum regulates the links between the immune and dopaminergic systems from the gut to the brain, potentially underpinning its beneficial psychobiotic and physiological effects in CSD.}
}
@article{VANDENBROEK2024102411,
title = {When strategy is a dirty word: The role of visuals in sensegiving strategy to a skeptical audience},
journal = {Long Range Planning},
volume = {57},
number = {1},
pages = {102411},
year = {2024},
issn = {0024-6301},
doi = {https://doi.org/10.1016/j.lrp.2023.102411},
url = {https://www.sciencedirect.com/science/article/pii/S0024630123001188},
author = {Antonius {van den Broek} and Jonathan Gander},
keywords = {Sensegiving, Strategy presentations, Skepticism, Visual communication},
abstract = {When setting a new strategy for their firm, managers engage in a range of sensegiving activities designed to introduce the new direction and explain the reasons for the change. These communication events commonly involve the use of strategic management terms and concepts to explain and justify the prescribed strategy. Literature thus far assumes that audiences understand and agree that these terms and underlying concepts are appropriate and relevant. Yet such views fail to explain strategy sensegiving in contexts where audiences of strategy presentations are ignorant or skeptical towards strategy concepts and ideas. We examine sensegiving under such conditions by analyzing a manager introducing a new strategy in a creative agency which expressed skepticism towards the concepts and practice of strategizing. Using data from video recordings of a sequence of internal strategy presentations, we identify three strategies designed to overcome prejudice towards strategic thinking while at the same time encouraging its use: winning the right to lead, finding resonance, and enrolling the audience into the strategy. We further find how these three sensegiving strategies are supported by carefully crafted visuals to either emphasize or de-emphasize aspects of the strategy and its supporting rationale. Our findings extend the literature on the practice of strategy by illustrating how the visual supports sensegiving efforts to guide a firm's interpretation of a proposed new strategic direction.}
}
@article{2025iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {258},
pages = {iii-xxvi},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(25)01840-X},
url = {https://www.sciencedirect.com/science/article/pii/S187705092501840X}
}
@article{LIU2024100985,
title = {Thin-walled deployable composite structures: A review},
journal = {Progress in Aerospace Sciences},
volume = {146},
pages = {100985},
year = {2024},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2024.100985},
url = {https://www.sciencedirect.com/science/article/pii/S0376042124000113},
author = {Tian-Wei Liu and Jiang-Bo Bai and Nicholas Fantuzzi and Xiang Zhang},
keywords = {Deployable composite structure, Thin-walled, Boom, Tape-spring, Hinge, Reflector, Optimization},
abstract = {The elastic strain energy-driven thin-walled deployable composite structures, characterized by their integration of structure and functionality, have attracted considerable attention in the field of space applications. These structures utilize the stored strain energy accumulated during the folding process to achieve elastic deployment. Significant progress has been made in the understanding of deformation mechanisms, modeling, design, optimization, and applications of such structures based on existing research. This review critically discusses over 300 papers from the past few decades, providing a comprehensive exploration of the development of three representative types of deployable composite structures: deployable composite hinges, booms, and reflectors. Specifically, it starts by reviewing the structural design, functional mechanisms, theories, finite element modeling methods and experimental investigations for these three types of structures. It then introduces optimization design methods and their applications in deployable composite structures. Additionally, specific practical application cases of deployable composite structures are discussed. Finally, future challenges and prospects for deployable composite structures are outlined. This paper serves as a valuable reference and inspiration for the design and application of deployable composite structures. It is expected to promote further advancements in this field.}
}
@incollection{TAC2024432,
title = {4.18 - A Modeler׳s Guide to Soft Tissue Mechanics},
editor = {Vadim Silberschmidt},
booktitle = {Comprehensive Mechanics of Materials (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {432-451},
year = {2024},
isbn = {978-0-323-90647-0},
doi = {https://doi.org/10.1016/B978-0-323-90646-3.00053-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323906463000538},
author = {Vahidullah Tac and Adrian B. Tepole},
keywords = {Continuum damage mechanics, Data-driven material modeling., Fractional viscoelasticity, Growth and remodeling, Hyperelasticity, Hyper-viscoelasticity, Mechanobiology, Multiscale modeling, Reactive mixtures, Tissue biomechanics},
abstract = {Soft tissue mechanical behavior and its change with age, physiological adaption, and disease, are key to our health and survival. Soft tissues are divided in four main categories, epithelial, muscle, connective, and nervous system tissues. Different types of tissues have unique composition and microstruture to perform their specific functions. Musculoskeletal and connective soft tissues, in particular, have evolved to address important mechano-physiological needs. All soft tissues, whether or not their primary function is mechanical in nature, show extreme mechanics, with large deformation, nonlinear stress-strain stiffening, various modes of energy dissipation such as viscoelasticity and damage, and, most remarkably, show the ability to adapt to external stimulus through growth and remodeling. This chapter outlines the essential theoretical frameworks for modeling the complex behavior of soft tissue. The role of data-driven tools as well as the soft tissues that have received increasing attention in recent years are also discussed.}
}
@article{DAVIS2025102833,
title = {Shaping extra-role security behaviors through employee-agent relations: A dual-channel motivational perspective},
journal = {International Journal of Information Management},
volume = {80},
pages = {102833},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102833},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000811},
author = {Joshua M. Davis and Deepti Agrawal and Obi Ogbanufe},
keywords = {Extra-role security behaviors, Social exchange theory, Identity theory, Leader-member exchange, User-IS exchange},
abstract = {Organizational information security performance increasingly depends on employees’ extra-role security behaviors (ERBs), which go beyond the scope of formal organizational prescription and control. At the same time, however, the literature suggests ERBs are largely unresponsive to traditional outline-and-control approaches to behavioral security. Instead, this stream finds that ERBs are primarily cultivated through social interactions with other organizational agents, namely the IS department and the direct supervisor. While important progress has been made in explicating the social nature of ERBs and the organizational agents that shape it, little is currently understood about the attributes of these employee-agent relationships that give rise to their influence on ERB enactment. Tied to this void, review of the literature reveals two separate and fundamentally different explanations of relational influence in this context which, according to theory, are associated with different relational attributes. Responding to these gaps, the current study presents a mixed-method examination of the relational antecedents of ERB enactment. We first theoretically develop and quantitatively examine a dual-channel model of socially motivated ERB enactment that highlights two co-existing motivational channels—an exchange-based channel rooted in norms of reciprocity and an identity-based channel rooted in self-verification. Then, applying the findings from quantitative examination of the dual-channel model, we qualitatively examine the specific attributes of these employee-agent relationships that promote ERB enactment. In doing so, this study makes multiple contributions to the literature including unification of prior work in this stream and introduction of detailed profiles of effective employee-agent relationships in this context.}
}
@article{BARWEY2025118072,
title = {Mesh-based super-resolution of fluid flows with multiscale graph neural networks},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {443},
pages = {118072},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118072},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525003445},
author = {Shivam Barwey and Pinaki Pal and Saumil Patel and Riccardo Balin and Bethany Lusch and Venkatram Vishwanath and Romit Maulik and Ramesh Balakrishnan},
keywords = {Graph neural networks, Super-resolution, Fluid dynamics, Taylor–green vortex, Backward-facing step, Deep learning},
abstract = {A graph neural network (GNN) approach is introduced in this work which enables mesh-based three-dimensional super-resolution of fluid flows. In this framework, the GNN is designed to operate not on the full mesh-based field at once, but on localized meshes of elements (or cells) directly. To facilitate mesh-based GNN representations in a manner similar to spectral (or finite) element discretizations, a baseline GNN layer (termed a message passing layer, which updates local node properties) is modified to account for synchronization of coincident graph nodes, rendering compatibility with commonly used element-based mesh connectivities. The architecture is multiscale in nature, and is comprised of a combination of coarse-scale and fine-scale message passing layer sequences (termed processors) separated by a graph unpooling layer. The coarse-scale processor embeds a query element (alongside a set number of neighboring coarse elements) into a single latent graph representation using coarse-scale synchronized message passing over the element neighborhood, and the fine-scale processor leverages additional message passing operations on this latent graph to correct for interpolation errors. Demonstration studies are performed using hexahedral mesh-based data from Taylor–Green Vortex and backward-facing step flow simulations at Reynolds numbers of 1600 and 3200. Through analysis of both global and local errors, the results ultimately show how the GNN is able to produce accurate super-resolved fields compared to targets in both coarse-scale and multiscale model configurations. Reconstruction errors for fixed architectures were found to increase in proportion to the Reynolds number. Geometry extrapolation studies on a separate cavity flow configuration show promising cross-mesh capabilities of the super-resolution strategy.}
}
@article{CORLATESCU2024108154,
title = {The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108154},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108154},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000219},
author = {Dragos-Georgian Corlatescu and Micah Watanabe and Stefan Ruseti and Mihai Dascalu and Danielle S. McNamara},
keywords = {Natural language processing, Reading comprehension, Automated model of comprehension, ChatGPT, Large language models},
abstract = {Modeling reading comprehension processes is a critical task for Learning Analytics, as accurate models of the reading process can be used to match students to texts, identify appropriate interventions, and predict learning outcomes. This paper introduces an improved version of the Automated Model of Comprehension, namely version 4.0. AMoC has its roots in two theoretical models of the comprehension process (i.e., the Construction-Integration model and the Landscape model), and the new version leverages state-of-the-art Large Language models, more specifically ChatGPT, to have a better contextualization of the text and a simplified construction of the underlying graph model. Besides showcasing the usage of the model, the study introduces three in-depth psychological validations that argue for the model's adequacy in modeling reading comprehension. In these studies, we demonstrated that AMoC is in line with the theoretical background proposed by the Construction-Integration and Landscape models, and it is better at replicating results from previous human psychological experiments than its predecessor. Thus, AMoC v4.0 can be further used as an educational tool to, for example, help teachers design better learning materials personalized for student profiles. Additionally, we release the code from AMoC v4.0 as open source in a Google Collab Notebook and a GitHub repository.}
}
@article{XUE202369,
title = {A Review on the Security of the Ethereum-Based DeFi Ecosystem},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {139},
number = {1},
pages = {69-101},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.031488},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223000978},
author = {Yue Xue and Dunqiu Fan and Shen Su and Jialu Fu and Ning Hu and Wenmao Liu and Zhihong Tian},
keywords = {Blockchain, smart contract, decentralized finance, DeFi, security},
abstract = {Decentralized finance (DeFi) is a general term for a series of financial products and services. It is based on blockchain technology and has attracted people’s attention because of its open, transparent, and intermediary free. Among them, the DeFi ecosystem based on Ethereum-based blockchains attracts the most attention. However, the current decentralized financial system built on the Ethereum architecture has been exposed to many smart contract vulnerabilities during the last few years. Herein, we believe it is time to improve the understanding of the prevailing Ethereum-based DeFi ecosystem security issues. To that end, we investigate the Ethereum-based DeFi security issues: 1) inherited from the real-world financial system, which can be solved by macro-control; 2) induced by the problems of blockchain architecture, which require a better blockchain platform; 3) caused by DeFi invented applications, which should be focused on during the project development. Based on that, we further discuss the current solutions and potential directions of DeFi security. According to our research, we could provide a comprehensive vision to the research community for the improvement of Ethereum-based DeFi ecosystem security.}
}
@article{JAYAGOPAL2025111992,
title = {A multi-task domain-adapted model to predict chemotherapy response from mutations in recurrently altered cancer genes},
journal = {iScience},
volume = {28},
number = {3},
pages = {111992},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.111992},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225002524},
author = {Aishwarya Jayagopal and Robert J. Walsh and Krishna Kumar Hariprasannan and Ragunathan Mariappan and Debabrata Mahapatra and Patrick William Jaynes and Diana Lim and David Shao {Peng Tan} and Tuan Zea Tan and Jason J. Pitt and Anand D. Jeyasekharan and Vaibhav Rajan},
keywords = {Biocomputational method, Genomic analysis, Pharmacoinformatics, Cancer, Machine learning},
abstract = {Summary
Next-generation sequencing (NGS) is increasingly utilized in oncological practice; however, only a minority of patients benefit from targeted therapy. Developing drug response prediction (DRP) models is important for the “untargetable” majority. Prior DRP models typically use whole-transcriptome and whole-exome sequencing data, which are clinically unavailable. We aim to develop a DRP model toward the repurposing of chemotherapy, requiring only information from clinical-grade NGS (cNGS) panels of restricted gene sets. Data sparsity and limited patient drug response information make this challenging. We firstly show that existing DRPs perform equally with whole-exome versus cNGS (∼300 genes) data. Drug IDentifier (DruID) is then described, a DRP model for restricted gene sets using transfer learning, variant annotations, domain-invariant representation learning, and multi-task learning. DruID outperformed state-of-the-art DRP methods on pan-cancer data and showed robust response classification on two real-world clinical datasets, representing a step toward a clinically applicable DRP tool.}
}
@article{JAIPRAKASH2025110194,
title = {Exploring text-to-image generation models: Applications and cloud resource utilization},
journal = {Computers and Electrical Engineering},
volume = {123},
pages = {110194},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2025.110194},
url = {https://www.sciencedirect.com/science/article/pii/S0045790625001375},
author = {Sahani Pooja Jaiprakash and Choudhary Shyam Prakash},
keywords = {Text-to-image generation, VAE, GAN, StackGAN, Diffusion model, Cloud resouce utilization, Edge-cloud computing},
abstract = {Generating images from text presents a significant challenge in computer vision. Moreover, manually acquiring images from multiple perspectives for object or product generation is a resource-intensive and expensive endeavor. However, recent breakthroughs in deep learning and artificial intelligence have opened doors to creating new images from diverse data sources, and cloud resources play a pivotal role in alleviating the resource-intensive nature of this endeavor. As a result, substantial research efforts have been directed toward advancing image generation techniques, yielding impressive results. This paper aims to provide a comprehensive overview of existing image generation methods, offering insights into this evolving field of text-to-image generation. It traces the historical development of this technology. It examines the key models that have shaped its evolution, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Conditional GANs (CGANs), StackGAN, Transformers, and diffusion models. The paper offers insights into the functioning of text-to-image generation within the GAN architecture, elucidating the mechanisms behind transforming textual descriptions into visual content. Additionally, the integration of text-to-image generation with cloud and edge-cloud computing highlights the synergistic potential of these technologies while addressing the challenges and considerations associated with cloud infrastructure. The paper concludes by surveying the diverse applications of text-to-image generation across various domains, such as art, e-commerce, entertainment, and education. It also discusses the evaluation metrics commonly used in assessing the quality of generated images and the challenges that exist both within the methods and in their application across different domains. This review offers a comprehensive overview of the capabilities and limitations of text-to-image generation. Also, we have introduced a new HiResGAN model using a single generator/discriminator pair of networks to produce high-resolution 256 × 256 images from textual descriptions. We illustrate the efficacy of our model in producing high-resolution images based on contextually rich text descriptions that are visually plausible and semantically consistent through a series of experiments and analyses.}
}
@article{LIU2026107910,
title = {Singular Value Decomposition-based lightweight LSTM for time series forecasting},
journal = {Future Generation Computer Systems},
volume = {174},
pages = {107910},
year = {2026},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107910},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25002055},
author = {Changwei Liu and Hao Ren and Guoqiang Li and Haojie Ren and Xiaojun Liang and Chunhua Yang and Weihua Gui},
keywords = {Long–short-term memory, LSTM lightweight, Singular Value Decomposition, Model compression},
abstract = {Long–short-term memory (LSTM) neural networks are known for their exceptional performance in various domains, particularly in handling time series data and managing long-term dependencies. However, deploying LSTM often faces challenges due to limitations in memory and computational resources, especially in edge computing and real-time processing scenarios. To maximize the advantages of LSTM in resource-constrained environments, this paper presents a lightweight LSTM method that uses weight matrix decomposition. Specifically, it employs Singular Value Decomposition (SVD) to decompose the weight matrices within the LSTM Cell and fully connected layers. Then, an optimization method is addressed to enable the efficient development of a lightweight model by dynamically assessing and enhancing storage and computational efficiency through adjustments of the learning rate and weight parameters. The experimental results indicate that this method reduces the parameters of the LSTM model by 45%, compresses the model size to 45% of its original size, and maintains prediction accuracy without decline. It means that the proposed method based on weight matrix decomposition allows LSTM to operate with less computational power and memory, making them more feasible for deploying resource-constrained devices.}
}
@article{HOU2025108171,
title = {SSCLMix: A self-supervised contrastive learning-based data mixing augmentation method},
journal = {Neural Networks},
volume = {192},
pages = {108171},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.108171},
url = {https://www.sciencedirect.com/science/article/pii/S0893608025010512},
author = {Juntao Hou and Yingyue Zhou and Jiamin Qin and Juan Zhang and Xiaoxia Li and Shaobing Gao and Liming Wen and Li Wang and Junfei Guo},
keywords = {Convolutional neural networks, Data mixing augmentation, Deep learning, Medical image segmentation,},
abstract = {Due to the privacy and scarcity of medical data, deep learning (DL)-based medical image segmentation methods often face challenges of insufficient training data samples and imbalanced training data. These challenges may lead segmentation models to fail in fully learning critical lesion features, thereby degrading model segmentation performance. In the field of medical image processing, data mixing augmentation based on region dropout and mixing regularization is one effective approach to address this problem. However, existing data mixing enhancement methods face challenges such as loss of image structural information and feature misalignment, resulting in inconsistent quality of mixed samples and further hindering the improvement of segmentation model performance. To solve these problems, we propose a self-supervised contrastive learning-based image mixing method (SSCLMix), which contains two steps. First, it classifies the training samples based on the image structural similarity for subsequent image mixing. Second, it uses dual-encoder contrastive learning and a cross-self-attention mechanism for cross-sample modeling to generate mixed images. Additionally, to enhance the quality of mixed images, we introduce a dual- spatial feature perception residual module (DSFPR), which adopts global structural information perception to reduce the destruction of edge textures and regional information. Experimental results for seven medical image segmentation tasks show that, compared with existing data augmentation methods, our method can generate higher-quality mixed samples, thereby bringing more significant improvements to segmentation model metrics. At the same time, it ranks in the upper-middle range in terms of computational efficiency and has certain practicality.}
}
@article{SHIAU2025,
title = {Exploring Core Knowledge in Mobile Payment Research},
journal = {Journal of Organizational and End User Computing},
volume = {37},
number = {1},
year = {2025},
issn = {1546-2234},
doi = {https://doi.org/10.4018/JOEUC.379684},
url = {https://www.sciencedirect.com/science/article/pii/S1546223425000292},
author = {Wen-Lung Shiau and Chia-Hsing Shih and Chien-Liang Lin and Shan-Ze Jiang and Yogesh K. Dwivedi and Wen-Pin Yu and Kuanchin Chen},
keywords = {Co-Citation Analysis, Core Knowledge, Digital Banking, Mobile Money, Mobile Payment, Trust},
abstract = {ABSTRACT
This study investigates the intellectual core of mobile payment (MP) research through citation analysis, co-citation analysis, cluster analysis, and multidimensional scaling (MDS), based on 111 highly cited articles published between January 1996 and December 2023 in the Web of Science (WoS) database. The analysis reveals 13 core knowledge clusters: (1) mobile money, (2) trust in mobile banking, (3) risk factors in digital banking, (4) service quality, (5) UTAUT-based decision frameworks, (6) beliefs, (7) IT adoption decision-making, (8) trust, (9) perceived value, (10) compatibility, (11) relative advantage, (12) social influence, and (13) intention to use and continued use of information systems. These clusters reflect the evolution of MP research from foundational theories to practical, user-oriented applications. By mapping key themes and identifying influential research directions, this study offers valuable insights for scholars and practitioners, contributing to a deeper understanding of the field and providing a structured basis for future research.}
}
@article{MORCIANO2025100862,
title = {Trending applications of Phase Change Materials in sustainable thermal engineering: An up-to-date review},
journal = {Energy Conversion and Management: X},
volume = {25},
pages = {100862},
year = {2025},
issn = {2590-1745},
doi = {https://doi.org/10.1016/j.ecmx.2024.100862},
url = {https://www.sciencedirect.com/science/article/pii/S2590174524003404},
author = {Matteo Morciano and Matteo Fasano and Eliodoro Chiavazzo and Luigi Mongibello},
keywords = {Phase change materials, Energy storage, Sustainable thermal management, Solar thermal energy, Smart textiles},
abstract = {The on-going search for increasingly sustainable and efficient thermal energy management across a wide range of sectors leads to continuous exploration of innovative solutions. In this context, phase change materials (PCMs) have emerged as key solutions for thermal energy storage and reuse, offering versatility in addressing contemporary energy challenges. Through this review, we offer a comprehensive critical analysis of the latest developments in PCMs-based technology and their emerging applications within energy systems. First, the conducted investigation highlights the most important drivers stimulating the use of PCMs, namely, the miniaturization of electronic devices, the fluctuating nature of renewable energy sources, and the urge to design smart buildings and textiles. Here, we therefore discuss the integration of PCMs into electronic systems characterized by high heat fluxes, lithium-ion batteries, solar energy systems (including photovoltaic, desalination systems), building materials and textiles to offer wearable solutions for enhanced thermal comfort. Outlining around 100 various cases, PCMs emerge as particularly suitable to ensure optimal operating temperature ranges, to extend lifespan of the devices and ultimately to improve overall system energy efficiency. Beyond potential, challenges such as material leakage, long-term durability, and cost-effectiveness are discussed. By focusing on literature post-2022, the proposed review aims to condense the latest numerical and experimental research findings, spotlight emerging trends, and identify challenges to promote broader and long-term adoption of PCM-based systems. By providing a holistic perspective on PCM applications, we emphasize their potential in achieving sustainable and efficient energy management and provide insights to encourage future cross-disciplinary research and innovation.}
}
@article{LO2024102435,
title = {Understanding momentary engagement in university students: Exploring the interaction between competence and value beliefs on emotions and cognitive engagement – A multilevel investigation},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102435},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102435},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000281},
author = {Meng-Ting Lo},
keywords = {Momentary engagement, Achievement emotions, Cognitive engagement, Situated competence and value beliefs, Experience sampling method},
abstract = {Using an intensive longitudinal design, this study investigated the predictive role of and interaction between competence beliefs and task value in relation to four achievement emotions (enthusiasm, excitement, anxiety, and irritation) as well as cognitive engagement. Data were collected using an experience sampling method to capture the momentary experiences of 81 university students over 14 days. Using a multilevel modeling approach, the study disentangled variations between and within individuals across learning situations. The results indicated that associations between competence and value beliefs and emotions were primarily observed at the situational level. Both competence and value beliefs played important roles in predicting cognitive engagement. In addition, high competence beliefs acted as a buffer, mitigating the positive association between opportunity cost and anxiety and reducing the negative impact of low intrinsic value on irritation. Positive value beliefs emerged as instrumental in fostering cognitive engagement, particularly in situations characterized by limited competence beliefs.
Educational relevance statement
The motivation and engagement displayed by university students in diverse learning events offer valuable insights into their dedication and academic involvement in pursuing their degrees. This study highlights the importance of perceiving both high competence beliefs and intrinsic value, which results in stronger associations with enthusiasm and excitement during learning. Conversely, high opportunity cost is linked to greater anxiety, but high competence beliefs act as a protective factor, mitigating this effect. High competence beliefs also counteract the negative impact of low intrinsic value on irritation. Value beliefs, particularly importance and intrinsic value, have a compensatory effect on cognitive engagement. Positive value beliefs play a crucial role in driving cognitive engagement, especially when competence beliefs are lacking. Gaining insight into changes within individuals and variations between students enables educators to effectively tailor instructional strategies and provide support, which in turn fosters students' motivation and engagement.}
}
@article{XIAO2024e37238,
title = {RETRACTED: The promises and challenges of AI-based chatbots in language education through the lens of learner emotions},
journal = {Heliyon},
volume = {10},
number = {18},
pages = {e37238},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e37238},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024132690},
author = {Yuehai Xiao and Tianyu Zhang and Jingyi He},
abstract = {This article has been retracted: please see Elsevier policy on article withdrawal (https://www.elsevier.com/about/policies-and-standards/article-withdrawal). This article has been retracted at the request of the Editor-in-Chief. Post-publication, the journal identified references that are irrelevant to the article. The authors were asked to comment upon the presence of these references in their work but were unable to satisfactorily address the reason for the references. Consequently, the editor no longer has confidence in the integrity and the findings of the article and has decided to retract it. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process. The authors disagree with retraction and dispute the grounds for it.}
}
@article{ZAHRA2024122172,
title = {Current advances in imaging spectroscopy and its state-of-the-art applications},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122172},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122172},
url = {https://www.sciencedirect.com/science/article/pii/S095741742302674X},
author = {Anam Zahra and Rizwan Qureshi and Muhammad Sajjad and Ferhat Sadak and Mehmood Nawaz and Haris Ahmad Khan and Muhammad Uzair},
keywords = {Imaging spectroscopy, Hyperspectral imaging, Image processing, Computer vision, Remote sensing, Deep learning},
abstract = {Imaging spectroscopy integrates traditional computer vision and spectroscopy into a single system and has gained widespread acceptance as a non-destructive scientific instrument for a wide range of applications. The current state of imaging spectroscopy spans diverse applications including but not limited to air-borne and ground-based computer vision systems. This paper presents the current state of research and industrial applications including precision agriculture, material classification, medical science, forensic science, face recognition and document image analysis, environment monitoring, and remote sensing, which can be aided through imaging spectroscopy. In this regard, we further discuss a comprehensive list of applications of imaging spectroscopy, pre-processing techniques, and spectral image acquisition systems. Likewise, publicly available databases and current software tools for spectral data analysis are also documented in this review. This review paper, therefore, could potentially serve as a reference and roadmap for people looking for literature, databases, applications, and tools to undertake additional research in imaging spectroscopy.}
}
@article{RAPP2025103471,
title = {How do people react to ChatGPT's unpredictable behavior? Anthropomorphism, uncanniness, and fear of AI: A qualitative study on individuals’ perceptions and understandings of LLMs’ nonsensical hallucinations},
journal = {International Journal of Human-Computer Studies},
volume = {198},
pages = {103471},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103471},
url = {https://www.sciencedirect.com/science/article/pii/S107158192500028X},
author = {Amon Rapp and Chiara {Di Lodovico} and Luigi {Di Caro}},
keywords = {AI, Generative AI, LLM, Anthropomorphizing, Humanness, Uncanny valley},
abstract = {Large Language Models (LLMs) have shown impressive capabilities in producing texts of quality and fluency that are similar to those created by humans. Despite their increasing use, however, the broader population's experience of many aspects of interaction with LLMs remains underexplored. This study investigates how diverse individuals perceive and account for “nonsensical hallucinations”, namely, an LLM's unpredictable and meaningless behavior provided as a response to a user's request. We asked 20 participants to interact with ChatGPT 3.5 and experience its hallucinations. Through semi-structured interviews, we found that participants with a computer science background or consistent previous use of LLMs interpret unpredictable nonsensical responses as an error, while novices perceive them as model's autonomous behaviors. Moreover, we discovered that such responses produce an abrupt modification of participants’ perceptions and understandings of the LLM's nature. From a soothing and polite entity, ChatGPT becomes either an obscure and unfamiliar “alien”, or a human-like being potentially hostile to humankind, making also emerge unsettling feelings, which may unveil an underlying fear of Artificial Intelligence. The study contributes to literature on how people react to the unfamiliarity of a technology that may be perceived as alien and yet extremely human-like, generating “uncanny effects,” as well as to research on the anthropomorphizing of technology.}
}
@article{ZHENG2025113524,
title = {Comprehensive survey of large models-driving intelligent decision making},
journal = {Applied Soft Computing},
volume = {181},
pages = {113524},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113524},
url = {https://www.sciencedirect.com/science/article/pii/S156849462500835X},
author = {Yuanhang Zheng and Tong Wu and Xiangyu Xiao and Zeshui Xu},
keywords = {Intelligent decision making, Large models, Survey, Interaction, Multi-modal information, Interpretability},
abstract = {In recent years, intelligent decision making has become a national strategic level to attach great importance to the focus of the fields, in medicine, business, manufacturing, agriculture, etc. Exemplified by breakthroughs such as GPT-4, LLaMA, Deepseek, and multimodal systems like AlphaFold, large models have catalyzed a paradigm shift in artificial intelligence—from perceptual tasks to complex decision-making scenarios. This paper presents a comprehensive survey on large models (LMs)-driving intelligent decision making, where the main contributions are as follows: 1) innovatively give a definition of LM-driving intelligent decision making, and establish a novel multi-role functional framework distinguishing LMs as data synthesizers (preparers), contextual reasoners (facilitators), and ethical validators (reflectors). 2) cross-disciplinary bibliometric analysis reveals the current research landscape in this field, demonstrating a wide range of interests within the community. 3) conduct a profound and comprehensive analysis of key components and applications of LMs-driving intelligent decision making, and deeply analyze the advantages, limitations, and challenges associated with this approach while also suggesting future research directions. Furthermore, we recommend three priority research directions: 1) Develop reasoning-enhanced LMs overcoming parameter limits via non-parametric activation. 2) Create interpretable LMs mirroring human decision processes (intuition vs. systematic thought) through problem-solving transparency. 3) Combine fuzzy/probabilistic methods with Transformers for real-world adaptability and adaptive evaluation frameworks. This work advances both theoretical understanding through its interdisciplinary perspective and offers concrete implementation blueprints for industry practitioners navigating LM adoption in decision-critical contexts.}
}
@incollection{MAXWELL2026335,
title = {Chapter 14 - Improving deep learning models},
editor = {Aaron E. Maxwell and Christopher A. Ramezan and Yaqian He},
booktitle = {Supervised Learning in Remote Sensing and Geospatial Science},
publisher = {Elsevier},
pages = {335-363},
year = {2026},
isbn = {978-0-443-29306-1},
doi = {https://doi.org/10.1016/B978-0-443-29306-1.00002-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443293061000028},
author = {Aaron E. Maxwell and Christopher A. Ramezan and Yaqian He},
keywords = {Deep learning, loss metrics, training, data augmentation, generalization, overfitting, learning rate finder},
abstract = {Methods to potentially improve the predictions generated by a deep learning (DL) model, reduce overfitting, and improve model generalization are our focus. We discuss input training data considerations, including means to augment the training data and determine an appropriate mini-batch size. Alternative loss metrics that combat issues of class imbalance and/or allow for prioritizing difficult-to-predict samples or classes are explored, including focal losses (FLs), region-based losses (i.e., Dice and Tversky loss), and the unified FL framework. Useful architectural modifications and associated considerations are described including a review of methods discussed in prior chapters (e.g., batch normalization, branching, atrous convolution, and residual and deep connections), squeeze and excitation modules, attention gates, and deep supervision. Selecting an appropriate learning rate and augmenting this hyperparameter during the training process, and additional augmentations of the training loop, such as applying gradient accumulation and transfer learning, are discussed and suggestions are provided. Applying techniques to research and applied mapping and modeling is science, tradecraft, and art. Our goal is to aid you in improving your DL models and DL associated experimentation and workflows.}
}
@article{ALLALCHERIF2025123906,
title = {Stepping out of the innovation race to embrace outnovation: Fostering well-being and responsible consumption through sustainability, simplicity, authenticity, and nostalgia},
journal = {Technological Forecasting and Social Change},
volume = {210},
pages = {123906},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123906},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524007042},
author = {Oihab Allal-Chérif and José Fernando Gallego-Nicholls and Agustin Carrilero-Castillo and Francisco Javier {Sendra Garcia}},
keywords = {Outnovation, Innovation, Sustainability, Simplicity, Authenticity, Nostalgia, Excellence},
abstract = {This article theorizes and characterizes the concept of “outnovation” as an alternative or a complement to innovation within the framework of grounded theory. Outnovation consists of stepping out of the unrelenting innovation race and removing all unnecessary innovations from a product, focusing instead on sustainability, simplicity, authenticity, and nostalgia. After presenting the dangers and limits of innovative strategies and disasters resulting from poorly mastered innovations, the research studies four different cases, which examples demonstrate that not innovating or suppressing innovations is not synonymous with bankruptcy. At a time when customers are looking for more sustainable products and when many economists advocate degrowth and less unbridled consumption, companies are looking for new forms of differentiation and value creation. Outnovating is a way of getting out of the vicious circle of endless innovation and meeting United Nations' Sustainable Development Goals.}
}
@article{XU2025101370,
title = {Toward large reasoning models: A survey of reinforced reasoning with large language models},
journal = {Patterns},
volume = {6},
number = {10},
pages = {101370},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101370},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925002181},
author = {Fengli Xu and Qianyue Hao and Chenyang Shao and Zefang Zong and Yu Li and Jingwei Wang and Yunke Zhang and Jingyi Wang and Xiaochong Lan and Jiahui Gong and Tianjian Ouyang and Fanjin Meng and Yuwei Yan and Qinglong Yang and Yiwen Song and Sijian Ren and Xinyuan Hu and Jie Feng and Chen Gao and Yong Li},
keywords = {large language model, LLM, LLM reasoning, reinforcement learning, neural scaling law},
abstract = {Summary
Language has long been an essential tool for human reasoning. The rise of large language models (LLMs) has led to research on their application in complex reasoning tasks. Researchers are exploring the concept of “thought,” which represents intermediate reasoning steps, allowing LLMs to emulate humanlike reasoning processes. Recent work has applied reinforcement learning (RL) to train LLMs by searching for high-quality reasoning trajectories through trial-and-error exploration. In parallel, studies also demonstrate that allowing LLMs to “think” with longer chains of intermediate tokens at test time can also substantially improve reasoning accuracy. The combination of training and test-time advancements outlines a path toward large reasoning models. This survey reviews recent progress in LLM reasoning. It covers foundational concepts behind LLMs and the key technical components that contribute to the development of large reasoning models, and it highlights popular open-source projects for building these models. The survey concludes by discussing ongoing challenges and future research directions in this field.}
}
@article{LEI2023110491,
title = {Prior knowledge-embedded meta-transfer learning for few-shot fault diagnosis under variable operating conditions},
journal = {Mechanical Systems and Signal Processing},
volume = {200},
pages = {110491},
year = {2023},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2023.110491},
url = {https://www.sciencedirect.com/science/article/pii/S0888327023003990},
author = {Zihao Lei and Ping Zhang and Yuejian Chen and Ke Feng and Guangrui Wen and Zheng Liu and Ruqiang Yan and Xuefeng Chen and Chunsheng Yang},
keywords = {Intelligent fault diagnosis, Prior knowledge embedding, Few-shot learning, Meta-transfer learning, Variable operating conditions},
abstract = {In recent years, intelligent fault diagnosis based on deep learning has achieved vigorous development thanks to its powerful feature representation ability. However, scarcity of high-quality data, especially samples under severe fault states, and variable operating conditions have limited the industrial application of intelligent fault diagnosis. To alleviate this predicament, a novel prior knowledge-embedded meta-transfer learning (PKEMTL) is proposed for few-shot fault diagnosis with limited training data and scarce test data. The method focuses on the problem of few-shot fault diagnosis under variable operating conditions to improve adaptability. Different from traditional models, the PKEMTL employs a metric-based meta-learning framework and embeds prior knowledge to enable cross-task learning under variable operating conditions. Specifically, order tracking is firstly introduced as preliminary prior information for data augmentation, and then the augmented data are divided into a series of meta-tasks. Secondly, the meta-tasks are performed by lightweight multiscale feature encoding to obtain high-level feature representations. Next, the meta-learning module based on diagnostic knowledge embedding guides the model to acquire meta-knowledge of speed generalization by constructing the self-supervised task to embed additional prior knowledge into the meta-training process. The generalization performance of the model is further improved by adaptive information fusion learning as a comprehensive decision-making module. Two case studies under variable operating conditions are implemented to validate the effectiveness and superiority of the proposed few-shot fault diagnosis method.}
}
@article{AKKEM2024107881,
title = {A comprehensive review of synthetic data generation in smart farming by using variational autoencoder and generative adversarial network},
journal = {Engineering Applications of Artificial Intelligence},
volume = {131},
pages = {107881},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624000393},
author = {Yaganteeswarudu Akkem and Saroj Kumar Biswas and Aruna Varanasi},
keywords = {Variational autoencoders, Generative adversarial networks, Smart farming},
abstract = {In this study, we propose the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) to generate synthetic data for crop recommendation (CR). CR is critical in agriculture, assisting farmers in making informed decisions about crop cultivation, considering factors like soil conditions, weather patterns etc. Unfortunately, the availability of labeled data for CR is often limited, posing a significant challenge in training accurate recommendation models. VAEs and GANs are employed to create synthetic data that closely mirrors real-world crop data. VAEs are utilized to extract latent representation from the input data, enabling the generation of new samples with similar characteristics. GANs play a crucial role in generating data by training a generator network to produce synthetic samples that closely resemble real data, while a discriminator network distinguishes between genuine and synthetic data. The generated synthetic data serves as a valuable resource to prepare datasets for CR, enhancing the performance of recommendation models. Our research explores the effectiveness of VAEs and GANs in producing high-quality synthetic CR data, facilitating improved training and evaluation of recommendation systems. This paper presents the architecture and training process of the proposed models and evaluates the quality and utility of the generated synthetic data using various experiments, including visualizations such as heatmaps, scatter plots, cumulative sum per feature plots, and distribution per feature plots. The results of this study hold the potential to make a significant contribution to the field of agriculture by providing a reliable and abundant source of training data for CR systems.}
}
@article{DASGUPTA2025117425,
title = {Conditional score-based diffusion models for solving inverse elasticity problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {433},
pages = {117425},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.117425},
url = {https://www.sciencedirect.com/science/article/pii/S0045782524006807},
author = {Agnimitra Dasgupta and Harisankar Ramaswamy and Javier Murgoitio-Esandi and Ken Y. Foo and Runze Li and Qifa Zhou and Brendan F. Kennedy and Assad A. Oberai},
keywords = {Conditional generative models, Inverse problems, Bayesian inference, Diffusion-based modeling, Uncertainty quantification, Elastography},
abstract = {We propose a framework to perform Bayesian inference using conditional score-based diffusion models to solve a class of inverse problems in mechanics involving the inference of a specimen’s spatially varying material properties from noisy measurements of its mechanical response to loading. Conditional score-based diffusion models are generative models that learn to approximate the score function of a conditional distribution using samples from the joint distribution. More specifically, the score functions corresponding to multiple realizations of the measurement are approximated using a single neural network, the so-called score network, which is subsequently used to sample the posterior distribution using an appropriate Markov chain Monte Carlo scheme based on Langevin dynamics. Training the score network only requires simulating the forward model. Hence, the proposed approach can accommodate black-box forward models and complex measurement noise. Moreover, once the score network has been trained, it can be re-used to solve the inverse problem for different realizations of the measurements. We demonstrate the efficacy of the proposed approach on a suite of high-dimensional inverse problems in mechanics that involve inferring heterogeneous material properties from noisy measurements. Some examples we consider involve synthetic data, while others include data collected from actual elastography experiments. Further, our applications demonstrate that the proposed approach can handle different measurement modalities, complex patterns in the inferred quantities, non-Gaussian and non-additive noise models, and nonlinear black-box forward models. The results show that the proposed framework can solve large-scale physics-based inverse problems efficiently.}
}
@article{ZHANG2025252,
title = {Digital twin-driven staged error prediction and compensation framework for the whole process of robotic machining},
journal = {Journal of Manufacturing Systems},
volume = {83},
pages = {252-283},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525002365},
author = {Teng Zhang and Fangyu Peng and Zhao Yang and Xiaowei Tang and Jiangmiao Yuan and Rong Yan},
keywords = {Robotic machining, Error prediction and compensation, Staged strategies, Digital twins},
abstract = {Robotic machining has become another important machining paradigm after CNC machine tools. However, robot error has always been an important constraint in its progress towards high quality demand scenarios due to characteristics such as weak rigidity and pose dependence. Numerous scholars have carried out rich work around errors in robotic machining systems, and these studies have achieved excellent results in robot localization, trajectory continuous motion, and machining operations. However, due to the complexity of the robot machining system, the robot error has differentiated performance at different stages, and it is difficult to guarantee the global accuracy of the robot by focusing on and controlling a certain kind of error in a discrete manner. For this reason, a digital twin-driven staged error prediction and compensation framework for the whole robot machining process is constructed. In this framework, the whole process of robot machining is divided into three stages with significant differences: point planning, trajectory planning and material removal. And the error prediction function block in each stage is constructed for the error characteristics (distribution skew, error step, spatial-temporal coupling). For error compensation, a staged error compensation strategy is constructed from three aspects: offline point position, robot body and external three-axis platform, respectively. The constructed system was case-validated in the robotic machining of curved parts. All stages of the error prediction models show high prediction accuracy, and the excellent performance of the staged prediction models is verified by comparing with the classical prediction models. For the error compensation, the designed system is utilized to ensure that the robotic machining system provides a double guarantee on the robot end and the machining quality, the point position absolute error is controlled at 0.109 mm, the orientation error is controlled at 0.028°, the trajectory position error is controlled at 0.067 mm, the orientation error is controlled at 0.031°, and the final part machining error is controlled at 0.036 mm, which is almost approximates the repeatable positioning accuracy of the robot. The proposed framework realizes the system-level sensing and control of the robot machining system error, and provides a unified system framework for the subsequent research of related unit methods, which is conducive to promoting the development of robot machining to high-quality requirement scenarios.}
}
@article{LIM2026115745,
title = {Theory and theory development: Guidelines for establishing theoretical gaps, foundations, contributions, and implications},
journal = {Journal of Business Research},
volume = {202},
pages = {115745},
year = {2026},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115745},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325005685},
author = {Weng Marc Lim},
keywords = {Theory, Concept theory, Relationship theory, Typology theory, Framework (or model) theory, Integrated (or hybrid) theory, Theoretical gap, Theoretical problematization, Theoretical contribution, Theoretical novelty, Theoretical interestingness, Theoretical generalizability, Theoretical adaptation, Theoretical modification, Theoretical extension, New theoretical development},
abstract = {Theory guides the acquisition and advancement of knowledge. Despite its importance, developing and refining theories remains a formidable task, given the inadequate clarity, inherent confusion, and compounding complexity faced by scholars in theory development. In response, this article offers clear, coherent, and constructive guidelines to tackle these challenges in theory development. Adopting the 3Es involving the author’s expertise, experience, and exposure, this guide offers a sequential approach to addressing theoretical gaps, theoretical foundations, theoretical contributions, and theoretical implications. This all-inclusive, accessible, and actionable resource seeks to benefit a diverse range of stakeholders, including both emerging and established scholars, which, in turn, contributes to ensuring the effective development of theories and, by extension, the return on value of these theories for funders, institutions, and, most importantly, the target beneficiaries (e.g., consumers, firms, society at large) of well-developed, theory-informed research.}
}
@article{RUCHAWAPOL2022154324,
title = {A review on computational approaches that support the researches on traditional Chinese medicines (TCM) against COVID-19},
journal = {Phytomedicine},
volume = {104},
pages = {154324},
year = {2022},
issn = {0944-7113},
doi = {https://doi.org/10.1016/j.phymed.2022.154324},
url = {https://www.sciencedirect.com/science/article/pii/S0944711322004032},
author = {Chattarin Ruchawapol and Wen-Wei Fu and Hong-Xi Xu},
keywords = {Computational approaches, Traditional Chinese Medicine (TCM), Structure-based approach, Knowledge-mining, Network-based approach},
abstract = {Background
COVID-19 highly caused contagious infections and massive deaths worldwide as well as unprecedentedly disrupting global economies and societies, and the urgent development of new antiviral medications are required. Medicinal herbs are promising resources for the discovery of prophylactic candidate against COVID-19. Considerable amounts of experimental efforts have been made on vaccines and direct-acting antiviral agents (DAAs), but neither of them was fast and fully developed.
Purpose
This study examined the computational approaches that have played a significant role in drug discovery and development against COVID-19, and these computational methods and tools will be helpful for the discovery of lead compounds from phytochemicals and understanding the molecular mechanism of action of TCM in the prevention and control of the other diseases.
Methods
A search conducting in scientific databases (PubMed, Science Direct, ResearchGate, Google Scholar, and Web of Science) found a total of 2172 articles, which were retrieved via web interface of the following websites. After applying some inclusion and exclusion criteria and full-text screening, only 292 articles were collected as eligible articles.
Results
In this review, we highlight three main categories of computational approaches including structure-based, knowledge-mining (artificial intelligence) and network-based approaches. The most commonly used database, molecular docking tool, and MD simulation software include TCMSP, AutoDock Vina, and GROMACS, respectively. Network-based approaches were mainly provided to help readers understanding the complex mechanisms of multiple TCM ingredients, targets, diseases, and networks.
Conclusion
Computational approaches have been broadly applied to the research of phytochemicals and TCM against COVID-19, and played a significant role in drug discovery and development in terms of the financial and time saving.}
}
@article{VALASIADIS2024112727,
title = {Wide-characterization of high and low dry matter kiwifruit through spatiotemporal multi-omic approach},
journal = {Postharvest Biology and Technology},
volume = {209},
pages = {112727},
year = {2024},
issn = {0925-5214},
doi = {https://doi.org/10.1016/j.postharvbio.2023.112727},
url = {https://www.sciencedirect.com/science/article/pii/S092552142300488X},
author = {Dimitrios Valasiadis and Marios Georgios Kollaros and Michail Michailidis and Chrysanthi Polychroniadou and Georgia Tanou and Christos Bazakos and Athanassios Molassiotis},
keywords = {Dry matter, Gene expression, Kiwifruit ripening, Non-destructive, Primary metabolites, 1-MCP},
abstract = {Despite the widespread use of dry matter content (DMC) as an indicator of kiwifruit quality, the physiological and molecular impact of DMC in fruit ripening remains unknown. Herein, the post-harvest physiological, metabolomic, and transcriptomic influence of DMC status on the pericarp and placenta tissue of ‘Hayward’ kiwifruit at harvest and at the onset of post-cold ripening was investigated. A segregation strategy based on DMC in commercially harvested kiwifruit was achieved with near-infrared spectroscopy for the estimation of DMC in individual fruits. Additionally, kiwifruits with distinct DMC levels were treated with 1-methylcyclopropene (1-MCP) and systematically monitored for ripening changes (20 °C) at various intervals after cold storage (0 °C). Following 90 and 120 days of cold exposure, high DMC kiwifruit generally exhibited superior physiological characteristics, such as increased pericarp and placenta firmness, and soluble solid and starch contents compared to low DMC kiwifruit, regardless of the 1-MCP application. Evidence is also presented for 1-MCP delaying the ripening of low-DMC fruit to the level of the untreated high-DMC kiwifruit. An accumulation of primary metabolites, particularly sugars and polyphenolic compounds, such as catechin, chlorogenic acid and procyanidin B1/B2 was evidenced in the high DMC group. At harvest, gene expression analysis revealed minor differences between DMC groups, with beta-amylase being the highest up-regulated gene in high DMC kiwifruit. Moreover, the gene expression patterns between DMC groups became more distinct after cold storage. Genes related to starch biosynthesis (i.e., glucose-1-phosphate adenyltransferase), water movement (i.e., aquaporin), polyphenolic biosynthesis (i.e., chalcone synthase) and lipid metabolism (i.e., diacylglycerol acyltransferase) showed strong variations between low and high DMC. Interestingly, the placenta tissue displayed almost 4 times more than DMC-affected differentially expressed genes compared to the pericarp, highlighting the key role of the placenta in kiwifruit ripening, notably following 1-MCP treatment. This study provides insights into the tissue-specific ripening response between kiwifruit with distinct DMC, as well as the gene expression influenced by an interaction of 1-MCP and DMC level, thereby helping develop postharvest programs aimed at improving kiwifruit quality traits.}
}
@article{FAN2024100082,
title = {A survey of emerging applications of diffusion probabilistic models in MRI},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100082},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100082},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000353},
author = {Yuheng Fan and Hanxi Liao and Shiqi Huang and Yimin Luo and Huazhu Fu and Haikun Qi},
keywords = {Diffusion probabilistic models, Score based generative modeling, MRI},
abstract = {Diffusion probabilistic models (DPMs) which employ explicit likelihood characterization and a gradual sampling process to synthesize data, have gained increasing research interest. Despite their huge computational burdens due to the large number of steps involved during sampling, DPMs are widely appreciated in various medical imaging tasks for their high-quality and diversity of generation. Magnetic resonance imaging (MRI) is an important medical imaging modality with excellent soft tissue contrast and superb spatial resolution, which possesses unique opportunities for DPMs. Although there is a recent surge of studies exploring DPMs in MRI, a survey paper of DPMs specifically designed for MRI applications is still lacking. This review article aims to help researchers in the MRI community to grasp the advances of DPMs in different applications. We first introduce the theory of two dominant kinds of DPMs, categorized according to whether the diffusion time step is discrete or continuous, and then provide a comprehensive review of emerging DPMs in MRI, including reconstruction, image generation, image translation, segmentation, anomaly detection, and further research topics. Finally, we discuss the general limitations as well as limitations specific to the MRI tasks of DPMs and point out potential areas that are worth further exploration.}
}
@article{SEO2025,
title = {Impact of Perception of Intelligent Information Technology (IIT) on IIT-Based Policy Decision-Making in the Public Sector:},
journal = {Journal of Organizational and End User Computing},
volume = {37},
number = {1},
year = {2025},
issn = {1546-2234},
doi = {https://doi.org/10.4018/JOEUC.379768},
url = {https://www.sciencedirect.com/science/article/pii/S1546223425000309},
author = {HyungJun Seo and HyoungSuk Lee and Fu-Sheng Tsai},
keywords = {Artificial Intelligence, Digital Government, Digital Transformation, Intelligent Information Technology (IIT), Policy Decision Making, Social Capital},
abstract = {ABSTRACT
Many governments have adopted information intelligent technology (IIT) policies to enhance efficiency and responsiveness. This study examines key factors influencing IIT-based decision making in Korean central and local governments. The research model includes perceived usefulness and risk of IIT, leaders’ and peers’ IIT, and social capital as moderators. Using quota sampling, regression analysis reveals that perceived usefulness, perceived risk, and leaders’ IIT positively affect decision making. While bonding social capital has no moderating effect, bridging social capital enhances the impact of peers’ IIT but weakens the effects of perceived risk and leaders’ IIT. These findings highlight the role of personal perception, social influence, and social capital in IIT adoption, offering insights for future digital governance research.}
}
@article{WEI2026103049,
title = {Cooperative supervision of livestreaming e-commerce based on stochastic evolutionary game and overconfidence},
journal = {Technology in Society},
volume = {84},
pages = {103049},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103049},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002398},
author = {Xiaochao Wei and Qiping She},
keywords = {Livestreaming e-commerce, Cooperative supervision, Streamer type, Overconfidence, Evolutionary game},
abstract = {The rapid development of livestreaming e-commerce has been accompanied by an increasing number of misleading marketing behaviors (MIBs) that require adequate regulations. To reveal the impact of irrational behavior (overconfidence) and to explore effective supervision strategies tailored to different types of streamers. We have classified streamers into brand-affiliated streamers and professional streamers (including internet celebrity streamers and ordinary streamers), then four types overconfidence are identified and integrated into a stochastic evolutionary game framework to investigate the regulatory effectiveness. The findings indicate that platform overconfidence positively affects supervision, while overconfidence among streamers and consumers has the opposite effect. For brand-affiliate streamers, the reputation mechanism exerts the most significant regulatory influence and should be heightened; additionally, enhancing platform penalties proves effective in cases of streamer overconfidence, whereas reducing supervision costs works better in other scenarios. Regarding professional streamers, a combination of platform penalties and incentive mechanisms leads to more stable and effective regulatory outcomes, especially in cases of streamer or consumer overconfidence. Furthermore, for internet celebrity streamers, the reputation mechanism serves as a beneficial supplement; for ordinary streamers, reducing regulatory costs proves to be more effective. Therefore, this study provides insights for classified and tiered regulation policy formulation regarding livestreaming e-commerce and provides a new perspective for supervision research by integrating overconfidence and evolutionary games.}
}
@article{CHEN2025116702,
title = {Modelling of lithium-ion battery electrode calendering: A critical review},
journal = {Journal of Energy Storage},
volume = {123},
pages = {116702},
year = {2025},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2025.116702},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X2501415X},
author = {Jiashen Chen and Maryam Asachi and Ali Hassanpour and Meisam Babaie and Masoud Jabbari},
keywords = {Lithium-ion batteries, Electrode calendering, Numerical modelling, Machine learning, Electrode microstructure, Battery performance},
abstract = {Lithium-ion Batteries (LIBs) are central to modern energy storage, with growing demands for improved performance, safety, and cost efficiency. Electrode calendering, a critical step in LIBs manufacturing, significantly influences the microstructure and electrochemical properties of electrodes. This review explores advances in the modelling of the calendering process over the past few years, focusing on empirical, numerical, and machine learning approaches. Empirical models, though computationally efficient, are limited by oversimplification, while numerical methods, such as Discrete Element Method (DEM) and Finite Element Method (FEM), offer more detailed insights into the structural evolution during calendering but require intensive computational resources. The growing application of machine learning introduces novel data-driven methods for optimising the process by effectively handling multiscale phenomena and high-dimensional data. A comparative analysis of these modelling strategies highlights the need for hybrid approaches that integrate empirical, numerical, and data-driven models to accurately predict electrode behaviour and optimise calendering conditions. Future research should aim to bridge the gap between computational accuracy and practical application to improve the performance and cost-efficiency of LIBs manufacturing.}
}
@article{SEPULVEDAOVIEDO2025100942,
title = {A review of operational factors affecting photovoltaic system performance},
journal = {Energy Conversion and Management: X},
volume = {26},
pages = {100942},
year = {2025},
issn = {2590-1745},
doi = {https://doi.org/10.1016/j.ecmx.2025.100942},
url = {https://www.sciencedirect.com/science/article/pii/S2590174525000741},
author = {Edgar Hernando Sepúlveda-Oviedo},
keywords = {Performance evaluation, Degradation, Efficiency, Tilt angle, Photovoltaic (PV)},
abstract = {The reduction in manufacturing costs of photovoltaic (PV) systems has driven significant growth in the PV industry. This expansion has shifted the current challenge from constructing new PV systems to maximizing the performance and longevity of installed PV modules. PV performance is influenced by two major categories of factors: environmental and operational. While environmental factors, such as dust and temperature, have been extensively studied, operational factors — critical for optimizing system efficiency — have not received the same level of attention. This study analyzes 102 articles focusing on operational factors such as PV technology, tilt and orientation angles, surface properties, height, and component aging, while also examining their interaction with environmental factors, particularly dust. In addition, the study compiles a set of standardized metrics aimed at quantifying efficiency losses and enabling consistent comparisons across studies. Finally, this review outlines a roadmap identifying key research gaps and provides recommendations for improving PV system performance. This roadmap offers valuable insights for researchers, engineers, and policymakers to better understand and address the operational factors that influence the efficiency and lifespan of PV systems.}
}
@article{PENG2024199,
title = {A narrative review of Environmentally Oriented Anti-consumption: Definitions, dimensions, and research framework},
journal = {Sustainable Production and Consumption},
volume = {51},
pages = {199-221},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352550924001933},
author = {Feiyan Peng and Anhua Long and Juan Chen and Khloe Qi Kang},
keywords = {Anti-consumption, Environmental concerns, Environmentally Oriented Anti-consumption, Sustainable development, Policy enlightenment},
abstract = {In the context of political uncertainty, environmental degradation, and resource scarcity, significant changes in individual consumption attitudes underscore the necessity of sustainability and anti-consumption research. Environmentally-oriented anti-consumption (EOA) represents a pivotal research direction that integrates these elements. Utilizing the PRISMA method, we conducted a comprehensive analysis of 428 articles. Our findings indicate that while qualitative methods have traditionally been favored, quantitative research is rapidly increasing. However, the dimensions, measurements, and frameworks employed in quantitative research remain fragmented, signaling a need for further refinement in EOA studies. To advance the theoretical framework of EOA, we rigorously selected and systematically analyzed 36 articles. Following identification, refinement, and expert validation, we proposed a comprehensive taxonomy categorizing EOA into seven major types, each with various sub-dimensions and measurement items. Furthermore, we developed a framework to measure the antecedents and consequences of EOA, incorporating motivational explanatory mechanisms. Our research provides a more precise definition and scope of EOA, thereby enhancing academic understanding. It offers novel tools for businesses and policymakers to implement sustainable practices, positioning on target groups through classification and dimensional measurement. This study aligns policies, marketing, and consumer behavior with sustainability goals, promoting societal development and addressing challenges in evolving social and environmental contexts.}
}
@article{VELDHUIS2025100708,
title = {Critical Artificial Intelligence literacy: A scoping review and framework synthesis},
journal = {International Journal of Child-Computer Interaction},
volume = {43},
pages = {100708},
year = {2025},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100708},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000771},
author = {Annemiek Veldhuis and Priscilla Y. Lo and Sadhbh Kenny and Alissa N. Antle},
keywords = {Artificial intelligence, Critical literacy, AI ethics, AI literacy, Computational empowerment, Literature review},
abstract = {The proliferation of Artificial Intelligence (AI) in everyday life raises concerns for children, other marginalized groups, and the general public. As new AI implementations continue to emerge, it is crucial to enable children to engage critically with AI. Critical literacy objectives and practices can encourage children to question, critique, and transform the social, political, cultural, and ethical implications of AI. As an initial step towards critical AI education, we conducted a 10-year scoping review to identify publications reporting on activities that engage children, between the ages of 5 and 18, to address the critical implications of AI. Our review identifies a wide range of participants, content, and pedagogical approaches. Through framework synthesis guided by an established critical literacy model, we examine the critical literacy learning objectives embedded in the reported activities and propose a critical AI literacy framework. This paper outlines future opportunities for critical AI literacies in the field of child–computer interaction including inspiring new learning activities, encouraging inclusive perspectives, and supporting pragmatic curriculum integration.}
}
@article{THOMAS2024121823,
title = {Leaf traits of Central-European beech (Fagus sylvatica) and oaks (Quercus petraea/robur): Effects of severe drought and long-term dynamics},
journal = {Forest Ecology and Management},
volume = {559},
pages = {121823},
year = {2024},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2024.121823},
url = {https://www.sciencedirect.com/science/article/pii/S037811272400135X},
author = {Frank M. Thomas and Sebastian Preusser and Bernhard Backes and Willy Werner},
keywords = {Climatic water balance, Compositional Nutrient Diagnosis, Drought stress, Leaf morphology, Nutrient concentration, Summer drought},
abstract = {In 2018—2020, Central-European forests suffered from extremely hot and dry summers. We used data from long-term forest monitoring of six stands of European beech (Fagus sylvatica) and two stands of oak (Quercus petraea/Q. robur) growing on different geological substrates in the climatically uniform state of Saarland (south-western Germany) for analyzing leaf traits of the period 2004—2021. We aimed at detecting overall effects of the drought on foliar morphology, nutrient concentrations, and injury, and long-term alterations in these traits. Across sites, drought resulted in a decrease in leaf size and specific leaf area (SLA) and increased fruiting in the beech and a decrease in the foliar nitrogen (N) concentrations in both tree genera. During drought, foliar calcium and manganese concentrations were lower and potassium (K) concentrations higher across the beech stands, whereas in the oak stands, drought led to a reduction in the foliar phosphorus (P) and magnesium (Mg) concentrations. High rates of anthropogenic N deposition during recent decades have resulted in high foliar N concentrations and low to deficient concentrations of P and, in the beech, of Mg. However, a significant (negative) long-term trend in leaf traits across the study sites was only found for the K concentration and necroses of the beech leaves. Foliar N correlated positively with SLA in the beech and with leaf size in the oak but was not related to herbivory. Chlorosis was the only leaf trait that, in the beech, correlated (negatively) with the climatic water balance. We conclude that even severe drought during three consecutive years does not seem to critically affect the nutrient supply to the two most important deciduous forest tree genera of Central Europe. In the beech, a decrease in leaf size and SLA might be used as an early indication of severe drought stress effects in regular monitoring programs.}
}
@article{SELVARAJ2025100925,
title = {Exploring the sources and routes of micro- and nanoplastics from dental products and materials: their impact on human health - a systematic review},
journal = {Next Research},
volume = {2},
number = {4},
pages = {100925},
year = {2025},
issn = {3050-4759},
doi = {https://doi.org/10.1016/j.nexres.2025.100925},
url = {https://www.sciencedirect.com/science/article/pii/S3050475925007924},
author = {Vidhya Selvaraj and R. Saravanan and N. Raj Vikram and Uma revathi Gopalakrishnan and Ramsamy M},
keywords = {Dental materials, Microplastics, Nanoplastics, Human health, Environmental pollution},
abstract = {Plastic pollution has emerged as a critical environmental and public health concern, extending beyond macroplastics to include microplastics (MPs; <5 mm) and nanoplastics (NPs; <1 µm). Dental products, including composites, aligners, impression materials, and toothpaste, represent a direct and underrecognized source of MPs and NPs due to their polymer-based composition and prolonged intraoral use. This systematic review aimed to explore the origins, release mechanisms, exposure pathways and health effects of MPs and NPs associated with dental materials. A total of 23 studies published between 2000 and 2025 were included following a comprehensive search across seven databases using PRISMA guidelines. Both in vitro and in vivo evidence indicated that dental materials release MPs and NPs through mechanical abrasion, thermal degradation and biofilm-mediated degradation. Exposure occurs via ingestion, inhalation and dermal absorption particularly in dental professionals and patients undergoing long-term treatments. MPs/NPs have been linked to gastrointestinal inflammation, respiratory dysfunction, immune disruption, neurotoxicity and even genotoxic and teratogenic outcomes. Materials such as resin composites, clear aligners and polishing agents were identified as major contributors with particle sizes ranging from several micrometers down to the nanoscale. Biofilm formation, enzymatic degradation and intraoral pH fluctuations were key mechanisms accelerating polymer fragmentation. Furthermore, improper disposal and wastewater discharge from dental settings contribute to environmental microplastic pollution with MPs acting as vectors for toxic pollutants and bioaccumulating in aquatic organisms. The review highlights an urgent need for biodegradable dental materials, enhanced occupational safety, improved waste filtration systems and regulatory guidelines to mitigate both human and ecological risks. A collaborative approach among dental practitioners, manufacturers and policymakers is necessary to address this overlooked source of plastic exposure and to promote sustainable and safe dental practices.}
}
@article{ZHONG2025130791,
title = {A comprehensive methodological review of human mobility simulation and modelling: Current trends, challenges, and future directions},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {674},
pages = {130791},
year = {2025},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2025.130791},
url = {https://www.sciencedirect.com/science/article/pii/S0378437125004431},
author = {Zhihua Zhong and Hongzeng Zhang and Jun’ichi Ozaki and Yang Zhou and Xinjie Zhao and Daniel Dan and Chaofan Wang},
keywords = {Human mobility simulation and modelling, Transport system, Deep learning, Agent-based model},
abstract = {Human mobility, reflecting the behaviour and movement patterns of individuals or groups in space, presents intricate characteristics and impacts various dimensions of urban life. Having increasingly caught the attention of disciplinary scholars, this field has evolved into a confused mixture of various modelling theories and methodologies, creating challenges in selecting appropriate methods when dealing with data with different structures and applications with varying scales of observation and scenarios. Moreover, disruptive techniques such as big data and artificial intelligence have tremendously revolutionised the traditional research paradigms in human mobility simulation and modelling. To scrutinise the various emerging methods, this study comprehensively reviews state-of-the-art research in the field, particularly focusing on research over the past decades. Here, we holistically collect, classify, and summarise existing methodologies into two categories: data-driven vs. mechanism-driven. These methods are organised following key clues, including modelling focus (aggregated flow vs. individual trajectory), typical application scenarios (regular vs. irregular), and model complexity (simple vs. complex), and are presented chronologically. Notably, deep learning (DL), agent-based model (ABM), and their combinations are emphasised as the most cutting-edge directions. We also reveal the future trends and opportunities for model evolution, transitioning from single-model, single-modality, and single-agent to multi-model, multi-modality, and multi-agent systems. Meanwhile, challenges in data ethics and bias, and models’ scalability, predictability, interpretability, and verifiability should be addressed in the future. The discoveries will serve as a reference for scholars and practitioners in the field, contributing to a systematic methodological framework that clarifies the complex research landscape and establishes a baseline for future model development.}
}
@article{XIE2024123022,
title = {A joint learning method with consistency-aware for low-resolution facial expression recognition},
journal = {Expert Systems with Applications},
volume = {244},
pages = {123022},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.123022},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423035248},
author = {Yuanlun Xie and Wenhong Tian and Liang Song and Ruini Xue and Zhiyuan Zha and Bihan Wen},
keywords = {Facial expression recognition, Image super-resolution, Deep learning, High-level vision task},
abstract = {Existing facial expression recognition (FER) methods are mainly devoted to learning discriminative features from high-resolution images. However, when applied to low-resolution images, their performance drops rapidly. This paper proposes a unified learning framework (namely SR-FER) by cascading the image super-resolution (SR) task and FER task to alleviate the low-resolution challenge. It effectively feeds back expression-related information from the FER network to the SR network, and returns the quality-enhanced expression images via a SR network. Specifically, a multi-stage attention-aware consistency loss module is introduced to help the SR network achieve discriminative feature restoration guided by attention information. Furthermore, a prediction consistency loss module is also developed to encourage the SR network to restore discriminative features by reducing the difference in prediction information between the restored and original normal-resolution images. Therefore, more accurate results are obtained by performing FER on the restored images. We conduct extensive experiments to demonstrate that the proposed low-resolution FER solution can help SR methods restore features favorable for FER while maintaining acceptable FER performance in various resolution degradation scenarios. The proposed method effectively improves the FER challenge under resolution degradation conditions, which is of good reference value for real-world applications.}
}
@article{WANG2024104004,
title = {Travel photography is important to me! The impact of merchants' photo editing behavior on destination clothes rental intention},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {104004},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.104004},
url = {https://www.sciencedirect.com/science/article/pii/S096969892400300X},
author = {Yuchen Wang and Rui Guo},
keywords = {Travel photography, Photo editing, Clothes rental intention, Social comparison, Destination marketing},
abstract = {The rise of travel selfies has fueled the development of destination clothes rental programs, yet there is scant research on this phenomenon. Therefore, this study, grounded in social comparison theory, constructs a model of the complex influence mechanism of merchants' photo editing behavior on tourist clothes rental intention. By employing a mixed-method approach that includes grounded theory and scenario experiments, this study verifies the proposed mechanism. The findings are as follows: first, finely editing photos, as opposed to roughly editing ones, are more likely to inspire tourist clothes rental intention. Second, the differential impact of photo editing behavior on tourist clothes rental intention is less pronounced in arriving at tourism destinations than in social media contexts. Third, cultural factors and individual differences, such as collectivism, face consciousness, and social comparison orientation, moderate the main effects. Fourth, considering tourists' comparative mindset, finely editing photos, compared to roughly editing ones, are more likely to stimulate state appearance comparison, leading to varying degrees of mutability, and ultimately affecting clothes rental intentions. This study contributes to the understanding of how photo editing influences tourist project participation behavior, providing valuable insights for marketers in the destination clothing rental industry.}
}
@article{YAN2025101729,
title = {Scientometric analysis of emerging trends and research landscape of ERNIE Bot's potentials as an educational tool: A mixed method study of a large language model},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101729},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101729},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125004577},
author = {Yang Yan and Bosede Iyiade Edwards and Mageswaran Sanmugam},
keywords = {Generative AI, AI in education, Scientometric analysis, Bibliometric analysis, ERNIE Bot, PRISMA model},
abstract = {This paper presents findings from a mixed-method analysis of a generative AI tool, ERNIE Bot's research status and role in education based on research from 2019–May 2025. Leveraging scientometric analysis, the study explored a combination of bibliometric and discourse analyses to uncover trends and language use. Using the PRISMA model, 147 publications from Scopus database were analyzed and insights from CiteSpace and VOSviewer were combined with thematic analysis. Findings indicate that Chinese researchers, and China-based funding bodies are the most prominent in ERNIE-bot-related research with all the top 5 countries concentrated in the global north. Top themes include ‘Natural Language Model’, ‘Semantics’, and ‘Human’. Topmost publishers were Applied Sciences (Switzerland), IEEE Access and PLOS ONE with top average citations by Sensors (12.67 citations/publication). The study confirms Bradford and Price laws. ERNIE Bot's application in education has attracted notable attention, with 22.4 % of the analyzed studies focusing on this area, highlighting its strong potential in personalized learning and human-computer interaction. Findings from discourse analysis shows that it’s Chinese origin is often framed as a symbol of contextual leadership and basis for positioning ERNIE Bot as a key player in China's technological competition with global models like ChatGPT. ERNIE Bot's strengths in Chinese language processing and innovations are also highlighted regarding power relations and knowledge hierarchies. However, ERNIE Bot lags global counterparts in overall competitiveness; limitations in data diversity, political censorship, and accessibility further restricts its global applicability. Future research should explore ERNIE Bot's knowledge base, its educational potentials, especially in adaptive learning systems and the significance of contextual leadership as an educational technology.}
}
@article{ABADIE2024304,
title = {Impact of carbon offset perceptions on greenwashing: Revealing intentions and strategies through an experimental approach},
journal = {Industrial Marketing Management},
volume = {117},
pages = {304-320},
year = {2024},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0019850124000014},
author = {Amelie Abadie and Soumyadeb Chowdhury and Sachin Kumar Mangla and Shaily Malik},
keywords = {Carbon offset, Greenwashing, Agency theory, Revealed preferences, Experiment},
abstract = {Organizations operating in the Business-to-Business (B2B) ecosystem across the globe are committed to net zero initiatives to achieve sustainability across business processes. In this context, carbon carbon credits have emerged as a carbon offsetting mechanism to help organizations invest in low-carbon initiatives. However, existing studies are yet to examine whether carbon offsetting practices will influence the sustainability behavior of B2B organizations and whether it could lead to greenwashing propensity. In this vein, we adopt agency and revealed pereferences theories to conduct two experiments with B2B small and medium-sized enterprises (SMEs) managers operating in the UK process intensive sectors to reveal that affordability of carbon credits can motivate managers to engage in sustainable attitudes and practices. We also found that organizations willing to buy carbon credits at high price to are likely to engage in high greenwashing propensity. Considering these novel findings, we provide recommendations that will help organizations to become more responsible in their carbon offesteing investments, and for policy makers to adopt stringent assessment of such investments and carbon disclosures made by firms.}
}
@incollection{MAXWELL2026365,
title = {Chapter 15 - Current trends and frontiers},
editor = {Aaron E. Maxwell and Christopher A. Ramezan and Yaqian He},
booktitle = {Supervised Learning in Remote Sensing and Geospatial Science},
publisher = {Elsevier},
pages = {365-399},
year = {2026},
isbn = {978-0-443-29306-1},
doi = {https://doi.org/10.1016/B978-0-443-29306-1.00016-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443293061000168},
author = {Aaron E. Maxwell and Christopher A. Ramezan and Yaqian He},
keywords = {Data cubes, cloud computing, high performance computing, transformers, self-attention, vision transformer, SegFormer, semi-supervised learning, self-training, co-training, generative adversarial networks, autoencoders, denoising autoencoders, variational autoencoders, foundation models, Segment Anything},
abstract = {We offer a survey of current trends and recent developments in geospatial science and remote sensing relating to supervised learning. We begin with a discussion of advancements in sensors and data availability followed by modern means to store and interact with data including analysis ready data products, data cubes, and cloud computing. We then discuss the key characteristics of transformer-based architectures, including the multihead attention mechanism, and how these architectures have been adapted for image and computer vision tasks: scene labeling and semantic segmentation. Means to incorporate unlabeled data via semi-supervised learning are discussed including feature extraction, self-training, co-training, and generative AI methods. We end with an introduction to characteristics of foundation models and their application to geospatial and remotely sensed data.}
}
@article{MUSTERT2025106217,
title = {The European Data Protection Board - a (non)consensual and (un)accountable role?},
journal = {Computer Law & Security Review},
volume = {59},
pages = {106217},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106217},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000896},
author = {Lisette Mustert and Cristiana Santos},
keywords = {European Data Protection Board, Guidance, Soft law, Coherence, Accountability, Completely independent supervision},
abstract = {The European Data Protection Board (EDPB) aims to ensure consistent enforcement of data protection laws across the EU through the adoption of guidelines and opinions. However, two challenges have been identified. First, the EDPB’s proactive engagement in issuing guidance is sometimes inconsistent, which can lead to discrepancies in the application of data protection laws across the EU, particularly as national Data Protection Authorities (DPAs) issue their own guidelines, creating a fragmented landscape. Second, uncertainty remains regarding the consistency of the EDPB’s guidance due to its non-binding nature, which leads to varying interpretations of the GDPR. These challenges raise concerns about the EDPB’s ability to ensure compliance with its mandate. This paper examines whether the EDPB is sufficiently independent when drafting guidance and whether it can be held accountable through political, legal, administrative, or social oversight. This paper argues that while the EDPB should maintain complete independence to fully utilize its technical expertise, it should still be subject to ex post accountability mechanisms. However, certain forms of accountability pose a risk to the Board’s independence. A comparative analysis highlights both horizontal and vertical misalignments between EDPB and national guidelines, suggesting that the EDPB’s role in providing cohesive guidance could be strengthened.}
}
@article{TAO2024361,
title = {Research of Preventive Maintenance Plans for Wind Power Equipment Based on Maintenance Knowledge Fusion Large Model},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {29},
pages = {361-366},
year = {2024},
note = {7th IFAC Conference on Engine and Powertrain Control, Simulation and Modeling E-COSM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.11.171},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324023127},
author = {Laifa Tao and Shangyu Li and Qixuan Huang and Zhengduo Zhao and Xuanyuan Su and Kaixin Jin},
keywords = {Fault prediction and health management, Wind power equipment, Large language models, Preventive maintenance, Supervised fine-tuning, Prompt learning},
abstract = {As an important energy equipment, wind power equipment have a wide range of applications worldwide. But its high equipment maintenance costs seriously affect the profits of wind power generation enterprises. Fault prediction and health management technology, as key technologies for optimizing maintenance methods and reducing maintenance costs, are of great significance for reduce the failure rate of wind power equipment, reduce maintenance costs, and promote the rapid development of the clean energy industry to generate excellent preventive maintenance plans for wind power equipment. However, the current development of wind power equipment maintenance plans heavily relies on expert experience and lacks reliable explanatory support. In this case, we propose a preventive maintenance plan generation method for wind power equipment based on maintenance knowledge fusion large model. Our solution generation process no longer relies on expert experience, but relies on the reasoning ability of the latest artificial intelligence technology large language model. We fine tune the pretrained base large model using data and knowledge from wind power equipment fault manuals and maintenance manuals, and design reasonable question and answer prompts to achieve intelligent generation of wind power equipment preventive maintenance plans. Finally, the effectiveness of the above method was verified through the manual materials of UP77 and UP82 fan equipment.}
}
@article{ROWE2025101474,
title = {Integrating computational and experimental advances in bone multiscale mechanics},
journal = {Progress in Materials Science},
volume = {153},
pages = {101474},
year = {2025},
issn = {0079-6425},
doi = {https://doi.org/10.1016/j.pmatsci.2025.101474},
url = {https://www.sciencedirect.com/science/article/pii/S0079642525000490},
author = {James Rowe and Sabrina Shen and Amadeus C.S. {de Alcântara} and Munir S. Skaf and Daniele Dini and Nicholas M. Harrison and Ulrich Hansen and Markus J. Buehler and Richard L. Abel},
abstract = {Decades of bone research have revealed the intricate hierarchical structures in bone, from the nanoscale building blocks of collagen and mineral to the complex micro-architecture and macro-geometry. Multiscale architecture confers bones their incredible toughness and strength that enables us to move through our daily lives. However, childhood and adult diseases can cause bone fragility and subsequent fractures, leading to disability, and mortality. A foundational understanding of bone mechanics across disparate scales is critical to improve the diagnosis and management of such diseases. At present, we have limited knowledge of how macroscale deformations that occur during everyday movement are transferred down to the nanoscale in order to resist fracture, especially due to historic limitations in measuring nanoscale mechanics experimentally. Recent advances in both experimental and computational tools are equipping researchers to probe the nanoscale for the first time. Here we provide a timely review of existing and next-generation experimental and computational tools and offer new perspectives on how to leverage the strengths of each approach to overcome the limitations of others. We focus on bone structure ranging from atomistic phenomena to microscale mineralized fibril interactions to build a bottom-up understanding of continuum bone mechanics and accelerate research towards impactful clinical translation.}
}
@article{WAQAS2024123893,
title = {Exploring Multiple Instance Learning (MIL): A brief survey},
journal = {Expert Systems with Applications},
volume = {250},
pages = {123893},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123893},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424007590},
author = {Muhammad Waqas and Syed Umaid Ahmed and Muhammad Atif Tahir and Jia Wu and Rizwan Qureshi},
keywords = {Multiple Instance Learning (MIL), Multi-Instance Learning(MIL), SUpervised MIL, Unsupervised MIL, Bag and Instance Classification, Review, MIL Applications},
abstract = {Multiple Instance Learning (MIL) is a learning paradigm, where training instances are arranged in sets, called bags, and only bag-level labels are available during training. This learning paradigm has been successfully applied in various real-world scenarios, including medical image analysis, object detection, image classification, drug activity prediction, and many others. This survey paper presents a comprehensive analysis of MIL, highlighting its significance, recent advancements, methodologies, applications, and evolving trends across diverse domains. The survey begins by explaining the core principles that form the basis of MIL and how it differs from traditional learning approaches. This sets the foundation for comprehending the distinct challenges and techniques of solving MIL problems. Next, we discuss how supervised learning algorithms are tailored to support MIL and combine this discussion with a review of seminal MIL algorithms as well as the latest innovations that incorporate neural networks, deep learning architectures, and attention techniques. This comprehensive analysis helps to understand the strengths, limitations, and adaptability of these methods across diverse data modalities, complexities, and applications. In summary, this survey paper provides an essential resource for researchers, practitioners, and enthusiasts seeking a comprehensive understanding of Multiple Instance Learning. It covers foundational concepts, traditional methods, recent advancements, and future directions. By providing a holistic view of MIL’s dynamic landscape, this paper aims to inspire further innovation and exploration in this ever-evolving field.}
}
@article{CANTEROGAMITO2023102673,
title = {The influence of China in AI governance through standardisation},
journal = {Telecommunications Policy},
volume = {47},
number = {10},
pages = {102673},
year = {2023},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2023.102673},
url = {https://www.sciencedirect.com/science/article/pii/S0308596123001842},
author = {Marta {Cantero Gamito}},
abstract = {Artificial intelligence systems (AIS) are subject to technical standardisation. Technical standards are primarily developed within standard developing organisations (SDOs) traditionally operating under consensus-based, community- and largely industry-driven processes. Governments are increasingly interested in technical standards’ development, accentuating the political dimension of standardisation. This article explores the contribution of technical standardisation to the governance of artificial intelligence (AI) and asks whose views are being implemented in the development of non-state rules for AI. The article, based on empirical research, focuses on the changing governance structure of the International Telecommunications Union (ITU). Overall, the discussion offers an overview of the existing geopolitics in AI-related standardisation and contributes to the scholarship on AI and digital governance by exploring the role of technical standardisation as a tool in AI governance. The research finds an increasing Chinese representation in international standardisation and argues that the political use of standardisation can lead to China establishing its own vision of digital governance. Consequently, the article suggest that China is using participation in recognised SDOs to legitimate its vision for digital governance calling for a re-examination of standardisation considering its implications for democracy and the protection of human rights.}
}
@article{SIEVI2025105093,
title = {(How) Should security authorities counter false information on social media in crises? A democracy-theoretical and ethical reflection},
journal = {International Journal of Disaster Risk Reduction},
volume = {116},
pages = {105093},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.105093},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924008550},
author = {Luzia Sievi and Maria Pawelec},
keywords = {Disinformation, Fake news, Security authority, Crisis communication, Debunking, Disaster ethics},
abstract = {False information on social media accompanies most crises and exacerbates their complexity and consequences. If security authorities and organisations (SAO) want to ensure security in crises, they must therefore curb the spread of false information. However, in liberal democracies, state authorities, but also aid organisations taking on state tasks have a special responsibility to ensure that they do not unjustifiably impair public communication and citizens' constitutionally protected rights when combating false information. (How) Should SAO therefore react to false information? Which ethical questions and value conflicts arise? More concretely, how can SAO implement countermeasures without harming pluralist deliberation and violating democratic principles or values constitutive to their self-understanding? This paper assesses these questions, combining both descriptive and normative ethics and focusing on values such as liberty, autonomy, neutrality, privacy, non-discrimination, and security. It ethically evaluates four countermeasures for SAO to combat false information: Media literacy trainings, social media monitoring, preventive and reactive crisis communication, and community management. It also draws on various methods of qualitative social science research and evidence from the relevant scientific literature to uncover underlying values and value conflicts when it comes to SAO's reactions to false information on social media, and to contextualize the presented ethical considerations with regard to SAO's daily work and challenges. The paper contributes disaster, security, and media ethics and, more practically, to more effective and ethically informed strategies for democratic actors responding to disinformation and misinformation on social media.}
}
@article{LASTAUSKAS2024106918,
title = {Labor market policies in high- and low-interest rate environments: Evidence from the euro area},
journal = {Economic Modelling},
volume = {141},
pages = {106918},
year = {2024},
issn = {0264-9993},
doi = {https://doi.org/10.1016/j.econmod.2024.106918},
url = {https://www.sciencedirect.com/science/article/pii/S026499932400275X},
author = {Povilas Lastauskas and Julius Stakėnas},
keywords = {Labor market policies, Non-linear responses, Mallow’s  criterion, Average local projections, Low and high interest rate environments},
abstract = {Do labor market policies initiated in periods of loose monetary policy yield different outcomes from those introduced when monetary tightening prevails? Using data from 11 euro-area members up to 2010 – and extending to 17 countries up to 2020 – we analyze three labor market policies: replacement rates, spending on active labor market policies (ALMPs), and employment protection. We find that these policies deliver different macroeconomic outcomes in low- and high-interest rate environments. In particular, ALMPs reduce unemployment if implemented under a loose monetary policy but not otherwise, whereas higher employment protection delivers expansionary effects under a tight monetary policy. These findings highlight that the effectiveness of labor market policies is significantly influenced by the monetary policy environment, emphasizing the need for coordinated policy design. Methodologically, we contribute by proposing to average local projections using Mallow’s Cp criterion, allowing for inferences that are robust to mis-specification and accommodate non-linearities.}
}
@article{PICCOLI2024101835,
title = {Digital transformation requires digital resource primacy: Clarification and future research directions},
journal = {The Journal of Strategic Information Systems},
volume = {33},
number = {2},
pages = {101835},
year = {2024},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2024.101835},
url = {https://www.sciencedirect.com/science/article/pii/S0963868724000179},
author = {Gabriele Piccoli and Varun Grover and Joaquin Rodriguez},
keywords = {Digital transformation, IT-enabled transformation, Digital ontology, Digital organization, Digital resources},
abstract = {Responding to recent calls, this essay offers a commentary on the framing and definition of organizational digital transformation. We focus on the unique ontology of digital transformation and delineate it from neighboring concepts.Our contention is that, despite its volume, current research remains unclear about how the digital transformation of organizations differs from their IT-enabled transformation. We advocate definitional precision to foster knowledge accumulation and to enable scholars to pursue important research questions that are unique to digital transformation. Our perspective, grounded in the notion of digital resources, defines digital transformation as the metamorphosis of an IT-enabled organization into a digital organization – one with a specific digital architecture and design principles.A key departure from previous conceptualization is that we characterize digital transformation as a change in digital technology architecture rather than a change from digital technology use. Our paper achieves the following: describes the constructs underpinning this formulation, digital resources and digital organization; justifies their use; and describes what research directions the new perspective promotes. With sound definitions of key constructs, Information Systems scholars have the unprecedented opportunity to lead the way in digital “x” research, making our discipline the reference point for the burgeoning “digital research” literature in related business fields.}
}
@article{MA2025124125,
title = {Fighting fake news in the age of generative AI: Strategic insights from multi-stakeholder interactions},
journal = {Technological Forecasting and Social Change},
volume = {216},
pages = {124125},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124125},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525001568},
author = {Rui Ma and Xueqing Wang and Guo-Rui Yang},
keywords = {Artificial intelligence (AI)-generated fake news, Fake news governance, Adaptive governance theory, User-generated content (UGC) platform, Opinion leader, Public opinion monitor agency (POMA)},
abstract = {The advancements in algorithm technology have led to a proliferation of artificial intelligence-generated fake news, resulting in significant social harm. Promoting multi-stakeholder engagement in fake news governance is beneficial for establishing a robust information ecosystem. The primary stakeholders, including the government at the policy-making end, user-generated content platforms at the algorithm development end, and opinion leaders at the news dissemination end, possess varying degrees of initiative and roles in governance. The main objective of this study is to investigate the evolutionary process of behaviors among multi-stakeholders in fake news governance and their influencing factors under different news environments. This study constructs an evolutionary game model to identify the conditions for the realization of five models of fake news governance. Stakeholders' behaviors in different states are affected by external factors, such as news environment, penalties, and incentives, as well as internal factors, such as governance capability deficiencies and platform algorithm reliability. The research findings expand the boundary of adaptive governance theory by revealing the mechanisms of stakeholder collaboration and the interaction between stakeholders and the news environment in fake news governance. These insights offer valuable guidance for advancing the transformation and enhancement of fake news governance models.}
}
@article{SHONUBI2025100971,
title = {Innovation challenges of digital transformation: Transitioning legacy to the future},
journal = {Sustainable Futures},
volume = {10},
pages = {100971},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.100971},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825005350},
author = {Ololade A. Shonubi},
keywords = {Digital transformation, Innovation challenges, Legacy systems, Emerging digital technologies, Organisational innovation, Process innovation, Product innovation, Service innovation, Asia, Africa, AI, IOT, I4.0, Data Analytics, Cloud Computing},
abstract = {Considering rapid technological advancement and global competitive pressures, organisations are seeking alternatives to traditional business models through digital transformation initiatives. Legacy systems were not isolated from this change, where reliance on emerging technologies such as AI has become imperative for organisational survival. A related challenge is "innovation integration", which refers to the simultaneous adoption of organisational innovation, process innovation, and product/service innovation during digital transitions. Accordingly, this research examines innovation challenges faced by enterprises transitioning from legacy systems to digital futures by empirically testing relationships between emerging technology integration and multiple innovation types across Asian and African contexts using structural equation modelling with quantitative data from managers across two continents. Emerging technology integration demonstrated significant positive relationships with organisational innovation, process innovation, and product/service innovation across both continents. Regional variations influenced innovation capabilities, with African enterprises showing superior process innovation adaptability despite digital infrastructure limitations. Gender differences significantly impacted product and service innovation perceptions amongst managers. Results contribute to academia by enriching digital transformation and innovation management research in emerging economies. Findings contribute to policy and practice by providing strategic insights to enterprise leaders, policymakers, and technology developers regarding innovation strategy, digital capability development, and resource allocation for organisations navigating complex digital transformation challenges whilst leveraging regional innovation strengths and competitive advantages.}
}
@article{LIU2025120968,
title = {Intelligent decision and planning for unmanned surface vehicle: A review of machine learning techniques},
journal = {Ocean Engineering},
volume = {327},
pages = {120968},
year = {2025},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2025.120968},
url = {https://www.sciencedirect.com/science/article/pii/S002980182500681X},
author = {Zongyang Liu and Qin Zhang and Xianbo Xiang and Shaolong Yang and Yi Huang and Yanji Zhu},
keywords = {USV, Machine learning, Mission planning, Dynamic decision, Path planning},
abstract = {With the increasing demand for unmanned surface vehicles (USVs) in fields such as marine environmental monitoring, resource exploration, and emergency rescue, the development of intelligent decision and planning technologies has become critical. However, the complexity and dynamic nature of marine environments pose significant challenges to traditional methods in practical applications. In recent years, the rapid advancement of machine learning (ML) has offered novel solutions for the intelligent decision and planning of USVs. This paper systematically reviews the research progress in USV decision and planning based on ML. First, it reviews the classification of USV autonomy levels and the historical development of ML in unmanned marine systems. Then, the paper proposes and elaborates on the “ML-MDP” framework (a ML-based Mission planning, Dynamic decision, and Path planning framework) for USVs, analyzing the latest research outcomes in these areas and explores the suitability of various ML algorithms in addressing these challenges. Finally, the paper analyzes the challenges faced by ML in USV applications and its future development directions. This review aims to provide a valuable reference for researchers in related fields, highlighting the potential of ML in marine unmanned systems and promoting advancements in USV intelligence.}
}
@article{ZHU2024110268,
title = {Threshold-based earthquake early warning for high-speed railways using deep learning},
journal = {Reliability Engineering & System Safety},
volume = {250},
pages = {110268},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.110268},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024003405},
author = {Jingbao Zhu and Wentao Sun and Shanyou Li and Kunpeng Yao and Jindong Song},
keywords = {Earthquake early warning, High-speed railway, Deep learning, Magnitude, Peak ground acceleration, Accuracy of alert},
abstract = {Earthquakes are disasters that threaten the operational safety of high-speed railways. To obtain reliable alerts for the earthquake monitoring and early warning systems of high-speed railways, based on magnitude and peak ground acceleration (PGA) thresholds (M = 5.5 and PGA = 40 cm/s2), an earthquake early warning (EEW) method for high-speed railways using deep learning is proposed. And the application of deep learning method in EEW for high-speed railway is explored. We design a single-station deep learning network architecture (named the CT architecture) by combining convolutional neural and transformer networks, and with that architecture, we train two separate models (CT-M and CT-PGA models) using the strong motion data recorded from the Kyoshin Network in Japan, which are used to predict whether the magnitude and PGA exceed the thresholds for issuing an alert. To verify the robustness of the method, we apply it to the M7.3 earthquake and M7.4 earthquake off the coast of Fukushima in 2021–2022. Results show that within 10 s after P-wave arrival, the accuracy of the alert reaches 90 %, and the average observed lead time reaches 18 s. The proposed method displays potential application on EEW systems for high-speed railways.}
}
@article{NANDI2023123550,
title = {Development of long-acting injectable suspensions by continuous antisolvent crystallization: An integrated bottom-up process},
journal = {International Journal of Pharmaceutics},
volume = {648},
pages = {123550},
year = {2023},
issn = {0378-5173},
doi = {https://doi.org/10.1016/j.ijpharm.2023.123550},
url = {https://www.sciencedirect.com/science/article/pii/S0378517323009717},
author = {Snehashis Nandi and Luis Padrela and Lidia Tajber and Alain Collas},
keywords = {Itraconazole, Microsuspension, Continuous antisolvent crystallization, Microchannel reactor, Dissolution, LAI},
abstract = {Our present work elucidated the operational feasibility of direct generation and stabilization of long-acting injectable (LAI) suspensions of a practically insoluble drug, itraconazole (ITZ), by combining continuous liquid antisolvent crystallization with downstream processing (i.e., centrifugal filtration and reconstitution). A novel microchannel reactor-based bottom-up crystallization setup was assembled and optimized for the continuous production of micro-suspension. Based upon the solvent screening and solubility study, N-methyl pyrrolidone (NMP) was selected as the optimal solvent and an impinging jet Y-shaped microchannel reactor (MCR) was selected as the fluidic device to provide a reproducible homogenous mixing environment. Operating parameters such as solvent to antisolvent ratio (S/AS), total jet liquid flow rates (TFRs), ITZ feed solution concentration and the maturation time in spiral tubing were tailored to 1:9 v/v, 50 mL/min, 10 g/100 g solution, and 96 h, respectively. Vitamin E TPGS (0.5% w/w) was found to be the most suitable excipient to stabilize ITZ particles amongst 14 commonly used stabilizers screened. The effect of scaling up from 25 mL to 15 L was evaluated effectively with in situ monitoring of particle size distribution (PSD) and solid-state form. Thereafter, the suspension was subjected to centrifugal filtration to remove excess solvent and increase ITZ solid fraction. As an alternative, an even more concentrated wet pellet was reconstituted with an aqueous solution of 0.5% w/w Vitamin E TPGS as resuspending agent. The ITZ LAI suspension (of 300 mg/mL solid concentration) has the optimal PSD with a D10 of 1.1 ± 0.3 µm, a D50 of 3.53 ± 0.4 µm and a D90 of 6.5 ± 0.8 µm, corroborated by scanning electron microscopy (SEM), as remained stable after 548 days of storage at 25 °C. Finally, in vitro release methods using Dialyzer, dialysis membrane sac were investigated for evaluation of dissolution of ITZ LAI suspensions. The framework presented in this manuscript provides a useful guidance for development of LAI suspensions by an integrated bottom-up approach using ITZ as model API.}
}
@article{WEI2026104437,
title = {Can large language models replace human experts in knowledge construction? A comparative analysis from the perspectives of information quality, information perception, and information load},
journal = {Information Processing & Management},
volume = {63},
number = {2, Part B},
pages = {104437},
year = {2026},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104437},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325003784},
author = {Jingzhu Wei and Zhipeng Chen},
keywords = {Large language models, Knowledge construction, Human-computer interaction, Text analysis},
abstract = {This study evaluates how large language models support knowledge construction by comparing Dense and Mixture of Experts architectures with human expert texts across six dimensions: Intrinsic Information Quality, Contextual Information Quality, Representational Information Quality, Linguistic Affinity, Structural Clarity, and Information Load. Using 2028 questions and 6084 responses, we compute composite indicators and estimate hierarchical regressions. MoE attains the highest Representational Information Quality in 89.69 % overall, rising to 95.72 % in closed domains, and the highest Linguistic Affinity in 65.30 %, but incurs high Information Load in 81.71 %. Dense leads Structural Clarity in 72.87 % and yields stable yet conservative expression. Human experts maintain low Information Load in 77.42 %. Regressions show that complexity increases representational expressiveness and load but weakens contextual alignment, while specificity increases affinity, structure, and load. Both model types lag behind the human standard on Intrinsic Information Quality and Contextual Information Quality. Findings support task aligned model selection and hybrid workflows.}
}
@article{202584,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {5},
number = {1},
pages = {84-90},
year = {2025},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(25)00007-5},
url = {https://www.sciencedirect.com/science/article/pii/S2667102625000075}
}
@article{COSCIA2025104397,
title = {APIARY: An API-based automatic rule generator for yara to enhance malware detection},
journal = {Computers & Security},
volume = {153},
pages = {104397},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104397},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825000860},
author = {Antonio Coscia and Roberto Lorusso and Antonio Maci and Giuseppe Urbano},
keywords = {API, Intrusion detection and prevention, Malware detection, Security tool, YARA rule},
abstract = {Cyber threats, primarily malware, have increased with rapid technological advancements in various fields. This growing complexity requires sophisticated and automated malware detection tools because traditional methods cannot keep up with the sheer volume of threats and their evolution. Detection mechanisms that are resilient against evolved malware behaviors, which are typically described by application programming interface (API) functions, are essential for real-time system protection. This paper presents APIARY, an innovative API-based Automatic Rule generator for the YARA tool, designed to enhance malware identification through customized signatures based on peculiar API-based patterns. It discovers distinctive APIs that distinguish malware from goodware, regardless of input data coming from dynamic and static analyses of Windows-like executable files. The algorithm assigns relevance scores to each variable and discards less significant features to identify critical malware indicators. In addition, the generation process optimizes the identified malware model categories to increase the detection rate while minimizing the number of rules produced. The experimental results obtained on nine datasets sourced from the literature demonstrate the potential of APIARY to automatically produce highly effective YARA rules in a short time. Moreover, the rules generated outperform those obtained using alternative state-of-the-art algorithms in terms of detection performance. Lastly, unlike competitors, the proposed procedure does not rely on additional malware analysis data, such as network connection attempts or API parameters, achieving a more streamlined and efficient detection process.}
}
@article{AMMARULLAH2025110518,
title = {A review of enhanced total hip prosthesis design and material bearing combination to accommodate Muslim prayer (Salat) movements: Biomechanical, biotribological, and biological perspectives},
journal = {Tribology International},
volume = {205},
pages = {110518},
year = {2025},
issn = {0301-679X},
doi = {https://doi.org/10.1016/j.triboint.2025.110518},
url = {https://www.sciencedirect.com/science/article/pii/S0301679X25000131},
author = {Muhammad Imam Ammarullah and Muhammad Kozin and Mohamad Izzur Maula and M. {Danny Pratama Lamura} and Hasyid Ahmad Wicaksono and Athanasius Priharyoto Bayuseno and Jamari Jamari and Muhammad Hanif Ramlee},
keywords = {Total hip prosthesis, Design, Bearing, Muslim prayer (Salat)},
abstract = {Total hip prostheses have greatly improved mobility and quality of life for patients with hip disorders. However, the unique biomechanical demands of Muslim prayer (Salat), involving complex, repetitive movements, pose challenges for standard designs. This review highlights advancements in prosthesis design, emphasizing dual mobility bearings for enhanced stability and range of motion, and Ceramic-on-Polymer (CoP) bearings for durability and reduced wear. By addressing biomechanical, biotribological, and biological factors, these innovations optimize prosthetic performance, meeting the functional and cultural needs of Muslim patients while ensuring long-term durability and satisfaction.}
}
@article{ZHOU2025100102,
title = {Democratizing AI Through Model Fusion: A Comprehensive Review and Future Directions},
journal = {Nexus},
pages = {100102},
year = {2025},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2025.100102},
url = {https://www.sciencedirect.com/science/article/pii/S295016012500049X},
author = {Qi Zhou and Yiming Zhang and Yanggan Gu and Yuanyi Wang and Zhijie Sang and Zhaoyi Yan and Zhen Li and Shengyu Zhang and Fei Wu and Hongxia Yang},
keywords = {Decentralized AI, Large Language Models, Model Fusion},
abstract = {Rapid advancement of Large Language Models is fundamentally constrained by the structural limits of centralized training, characterized by high costs and resource monopolization. Model fusion provides a scalable, resource-efficient alternative for integrating specialized models into a unified system, despite facing challenges related to compatibility and alignment. This review systematically analyzes the current landscape of fusion, classifying methodologies into parameter-level merging and knowledge distillation-based fusion. We focus on cutting-edge techniques that resolve challenges in model heterogeneity, semantic alignment, and scalability, highlighting frameworks like InfiFusion, InfiGFusion, and InfiFPO, which demonstrate significant performance gains and unprecedented efficiency. Finally, we summarize applications in fields like Medical AI and delineate key future directions.}
}
@article{ZHANG2024103140,
title = {Media opinion divergence and stock returns: Evidence from China},
journal = {International Review of Financial Analysis},
volume = {93},
pages = {103140},
year = {2024},
issn = {1057-5219},
doi = {https://doi.org/10.1016/j.irfa.2024.103140},
url = {https://www.sciencedirect.com/science/article/pii/S1057521924000723},
author = {Zuochao Zhang and John W. Goodell and Dehua Shen and Oumaima Lahmar},
keywords = {Media opinion divergence, Textual analysis, Latent Dirichlet Allocation, Generative probabilistic modeling},
abstract = {We construct a proxy for media opinion divergence using Latent Dirichlet Allocation. With this proxy, we investigate the impact of media opinion divergence on Chinese stocks. Findings indicate that higher media opinion divergence results in higher stock returns, but leads to lower future stock returns, consistent with Miller (1987). Additionally, we similarly explore the impact of divergence between traditional media and new media on stock returns, obtaining similar results. Findings are robust to controlling for firm characteristics and the number of news articles. Our study provides valuable insights into how the media can influence investor opinions and in turn the stock market in the digital media era.}
}
@article{BUJA2024104944,
title = {Pathobiology of myocardial and cardiomyocyte injury in ischemic heart disease: Perspective from seventy years of cell injury research},
journal = {Experimental and Molecular Pathology},
volume = {140},
pages = {104944},
year = {2024},
issn = {0014-4800},
doi = {https://doi.org/10.1016/j.yexmp.2024.104944},
url = {https://www.sciencedirect.com/science/article/pii/S0014480024000649},
author = {L. Maximilian Buja},
keywords = {Cardiomyocyte, Myocardial ischemia, Calcium measurements, Pathology, Reperfusion, Conditioning, Oncosis, Apoptosis, Autophagy},
abstract = {This review presents a perspective on the pathobiology of acute myocardial infarction, a major manifestation of ischemic heart disease, and related mechanisms of ischemic and toxic cardiomyocyte injury, based on advances and insights that have accrued over the last seventy years, including my sixty years of involvement in the field as a physician-scientist-pathologist. This analysis is based on integration of my research within the broader context of research in the field. A particular focus has been on direct measurements in cardiomyocytes of electrolyte content by electron probe X-ray microanalysis (EPXMA) and Ca2+ fluxes by fura-2 microspectrofluorometry. These studies established that increased intracellular Ca2+ develops at a transitional stage in the progression of cardiomyocyte injury in association with ATP depletion, other electrolyte alterations, altered cell volume regulation, and altered membrane phospholipid composition. Subsequent increase in total calcium with mitochondrial calcium accumulation can occur. These alterations are characteristic of oncosis, which is an initial pre-lethal state of cell injury with cell swelling due to cell membrane dysfunction in ATP depleted cells; oncosis rapidly progresses to necrosis/necroptosis with physical disruption of the cell membrane, unless the adverse stimulus is rapidly reversed. The observed sequential changes fit a three-stage model of membrane injury leading to irreversible cell injury. The data establish oncosis as the primary mode of cardiomyocyte injury in evolving myocardial infarcts. Oncosis also has been documented to be the typical form of non-ischemic cell injury due to toxins. Cardiomyocytes with less energy impairment have the capability of undergoing apoptosis and autophagic death as well as oncosis, as is seen in pathological remodeling in chronic heart failure. Work is ongoing to apply the insights from experimental studies to better understand and ameliorate myocardial ischemia and reperfusion injury in patients. The perspective and insights in this review are derived from basic principles of pathology, an integrative discipline focused on mechanisms of disease affecting the cell, the organizing unit of living organisms.}
}
@article{MARTINEZPANDIANI2025100317,
title = {‘Toxic’ memes: A survey of computational perspectives on the detection and explanation of meme toxicities},
journal = {Online Social Networks and Media},
volume = {47},
pages = {100317},
year = {2025},
issn = {2468-6964},
doi = {https://doi.org/10.1016/j.osnem.2025.100317},
url = {https://www.sciencedirect.com/science/article/pii/S2468696425000187},
author = {Delfina S. {Martinez Pandiani} and Erik {Tjong Kim Sang} and Davide Ceolin},
keywords = {Internet memes, Toxicity, Information quality, Multimodal discourse},
abstract = {Internet memes are multimodal, highly shareable cultural units that condense complex messages into compact forms of communication, making them a powerful vehicle for information spread. Increasingly, they are used to propagate hateful, extremist, or otherwise ‘toxic’ narratives, symbols, and messages. Research on computational methods for meme toxicity analysis has expanded significantly over the past five years. However, existing surveys cover only studies published until 2022, resulting in inconsistent terminology and overlooked trends. This survey bridges that gap by systematically reviewing content-based computational approaches to toxic meme analysis, incorporating key developments up to early 2024. Using the PRISMA methodology, we extend the scope of prior analyses, resulting in a threefold increase in the number of reviewed works. This study makes four key contributions. First, we expand the coverage of computational research on toxic memes, reviewing 158 content-based studies, including 119 newly analyzed papers, and identifying over 30 datasets while examining their labeling methodologies. Second, we address the lack of clear definitions of meme toxicity in computational research by introducing a new taxonomy that categorizes different toxicity types, providing a more structured foundation for future studies. Third, we observe that existing content-based studies implicitly focus on three key dimensions of meme toxicity—target, intent, and conveyance tactics. We formalize this perspective by introducing a structured framework that models how these dimensions are computationally analyzed across studies. Finally, we examine emerging trends and challenges, including advancements in cross-modal reasoning, the integration of expert and cultural knowledge, the increasing demand for automatic toxicity explanations, the challenges of handling meme toxicity in low-resource languages, and the rising role of generative AI in both analyzing and generating ‘toxic’ memes.}
}
@article{GRUENBICHLER20251473,
title = {Exploring AI frontiers: Insights from Austria’s Industrial Sector on Enhancing Control Functions},
journal = {Procedia Computer Science},
volume = {253},
pages = {1473-1484},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.209},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002170},
author = {Rudolf Gruenbichler and Alexander Sitter and Thomas Fenzl},
keywords = {Artificial Intelligence, Controlling, Management Accounting, Application, Knowledge Acquisition, Industry, Implementation barriers},
abstract = {Industrial companies have their own controlling departments that provide information for corporate management. These activities can also be supported by artificial intelligence in the future. In an in-depth interview study of eleven controllers from internationally operating large industrial companies in Austria, the current status of the use of artificial intelligence technologies in the controlling environment is surveyed and the barriers to implementation are analyzed. Furthermore, it is investigated how controllers prepare themselves in this new area, which information channels are used and which information is processed in which form in order to use artificial intelligence in controlling. The results show that the implementation barriers are located at different levels, namely employee, organizational and resource levels. Furthermore, we found that personal, web-based and institutional channels are used to acquire knowledge, with exchange with other companies being the most popular. For the preparation and distribution of content, application examples are preferred, which are made available via video tutorials.}
}