@article{HUO2024,
title = {Generative Artificial Intelligence in Business Higher Education:},
journal = {Journal of Global Information Management},
volume = {32},
number = {1},
year = {2024},
issn = {1062-7375},
doi = {https://doi.org/10.4018/JGIM.364093},
url = {https://www.sciencedirect.com/science/article/pii/S1062737524000416},
author = {Xuenan Huo and Keng Leng Siau},
keywords = {Generative Artificial Intelligence, Agentic Artificial Intelligence, Artificial General Intelligence, Focus Group Study, Qualitative Research, Business Higher Education},
abstract = {ABSTRACT
This research investigates the opportunities and challenges of integrating generative artificial intelligence (GenAI) into business higher education, drawing insights from an asynchronous focus group research study with doctoral students who serve dual roles as both learners and educators. Key opportunities identified through thematic analysis include knowledge acquisition, intelligent co-ideation, supportive augmentation, and personalized learning. Challenges identified include AI trustworthiness, cognitive dependency, human value, policy and instruction, assessment integrity, and identity management. This study clarifies GenAI’s specific role in business education and provides practical insights for effectively integrating GenAI to enhance learning outcomes and address emerging challenges. An analysis theory on the opportunities and challenges of GenAI on business higher education is developed and described in the paper. The potential impact of Agentic Artificial Intelligence (autonomous AI agents) and Artificial General Intelligence (AGI) on education is also discussed.}
}
@article{HEROLD2025101012,
title = {Brave new procurement deals: An experimental study of how generative artificial intelligence reshapes buyer–supplier negotiations},
journal = {Journal of Purchasing and Supply Management},
volume = {31},
number = {4},
pages = {101012},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101012},
url = {https://www.sciencedirect.com/science/article/pii/S1478409225000214},
author = {Silke Herold and Jonas Heller and Frank Rozemeijer and Dominik Mahr},
keywords = {Artificial intelligence, Chatbots, Negotiation},
abstract = {The technological breakthrough of artificial intelligence (AI) is impacting buyer-supplier negotiations, which are increasingly moving toward human-to-machine negotiations using AI-based chatbots. While the first AI-powered negotiation solutions are currently being used by procurement professionals to negotiate for non-critical spend items, which is an example of structural influence, the behavioral influence of AI-based chatbots (i.e., on negotiation approach) remains unknown. It is unclear in which behavioral settings these chatbots deliver value to the buying firm in terms of economic, psychological, and relational outcomes. To fill this gap, we conduct three experiments in buyer–supplier negotiation settings, two in a lab-setting with undergraduate business students and one online experiment with professional negotiators. In our interactive simulations, participants play the role of the supplier, while a ChatGPT-based custom-trained chatbot acts as the buyer. We find that when the chatbot deploys a competitive, as compared to a collaborative, negotiation approach, it will achieve a higher price discount, better payment terms, and a quicker negotiation. However, suppliers trust a collaboratively prompted, as compared to a competitively prompted, chatbot more and demonstrate higher outcome satisfaction, as well as a stronger desire for future interaction. A text analysis of the chat interactions indicates a higher level of similarity when a competitively prompted chatbot is employed, which implies that suppliers also use more insistent and intimidating language, thereby matching the chatbot's negotiation approach to a greater degree. While the negotiation approach is a significant influencing factor, we do not find significant evidence that item type, in our case non-critical or bottleneck, matters, which indicates that AI-based chatbots can be effective in various buyer–supplier settings.}
}
@article{PARK20242355,
title = {Has generative artificial intelligence solved inverse materials design?},
journal = {Matter},
volume = {7},
number = {7},
pages = {2355-2367},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
author = {Hyunsoo Park and Zhenzhu Li and Aron Walsh},
abstract = {Summary
The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.}
}
@article{LV2023208,
title = {Generative artificial intelligence in the metaverse era},
journal = {Cognitive Robotics},
volume = {3},
pages = {208-217},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000198},
author = {Zhihan Lv},
abstract = {Generative artificial intelligence (AI) is a form of AI that can autonomously generate new content, such as text, images, audio, and video. Generative AI provides innovative approaches for content production in the metaverse, filling gaps in the development of the metaverse. Products such as ChatGPT have the potential to enhance the search experience, reshape information generation and presentation methods, and become new entry points for online traffic. This is expected to significantly impact traditional search engine products, accelerating industry innovation and upgrading. This paper presents an overview of the technologies and prospective applications of generative AI in the breakthrough of metaverse technology and offers insights for increasing the effectiveness of generative AI in creating creative content.}
}
@article{WAISBERG20251,
title = {Generative artificial intelligence in ophthalmology},
journal = {Survey of Ophthalmology},
volume = {70},
number = {1},
pages = {1-11},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000444},
author = {Ethan Waisberg and Joshua Ong and Sharif Amit Kamran and Mouayad Masalkhi and Phani Paladugu and Nasif Zaman and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning},
abstract = {Generative artificial intelligence (AI) has revolutionized medicine over the past several years. A generative adversarial network (GAN) is a deep learning framework that has become a powerful technique in medicine, particularly in ophthalmology for image analysis. In this paper we review the current ophthalmic literature involving GANs, and highlight key contributions in the field. We briefly touch on ChatGPT, another application of generative AI, and its potential in ophthalmology. We also explore the potential uses for GANs in ocular imaging, with a specific emphasis on 3 primary domains: image enhancement, disease identification, and generating of synthetic data. PubMed, Ovid MEDLINE, Google Scholar were searched from inception to October 30, 2022, to identify applications of GAN in ophthalmology. A total of 40 papers were included in this review. We cover various applications of GANs in ophthalmic-related imaging including optical coherence tomography, orbital magnetic resonance imaging, fundus photography, and ultrasound; however, we also highlight several challenges that resulted in the generation of inaccurate and atypical results during certain iterations. Finally, we examine future directions and considerations for generative AI in ophthalmology.}
}
@article{CHARLES2025177508,
title = {AI in action: Changes to student perceptions when using generative artificial intelligence for the creation of a multimedia project-based assessment},
journal = {European Journal of Pharmacology},
volume = {998},
pages = {177508},
year = {2025},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2025.177508},
url = {https://www.sciencedirect.com/science/article/pii/S0014299925002626},
author = {Kellie A. Charles and Arsalan Yousuf and Han Chow Chua and Slade Matthews and Joanna Harnett and Tina Hinton},
keywords = {Science education, Pharmacology education, Artificial intelligence, AI, ChatGPT},
abstract = {Introduction
New modes of assessments are needed to evaluate of the authenticity of student learning in an artificial intelligence (AI) world. In mid-2023, we piloted a new assessment type; a collaborative group multimedia assessment with AI allowance. The aim of the research study was to explore the experiences of students using AI in a multimedia assessment. We further aimed to determine whether these use cases changed student perceptions of the ways AI can be used in learning and assessment.
Methods
Students enrolled in a capstone Pharmacology interdisciplinary unit (n = 40) were included in an exploratory, qualitative case study methodology. Thematic analysis using an AI role-based conceptual framework was used to explore student perceptions of AI use prior to and during their projects from logbooks documenting the assessment process.
Results
AI was initially perceived by students as having a personal tutor-style role, which aligned with the taxonomy with AI acting as an Arbiter (49 %), Oracle (41 %) and Quant (10 %). In contrast to their earlier perceptions, AI was only used in a limited manner in the early stages of assessment in the idea generation in the role as an Oracle (86 %) or in data analytic purposes as a Quant (14 %), (n = 14 cases in 5 groups). No student group used AI to generate written text for the final assessment.
Discussion
Tension between perceived and actual use of AI is indicative of the uncertainty faced by students with the allowance of AI within assessments. Clear guidance for educators and students about how to assess the AI-supported learning process is needed to ensure the integrity of the assessment system.}
}
@article{DEMIREL2025101127,
title = {Late gadolinium enhancement cardiovascular magnetic resonance with generative artificial intelligence},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101127},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2024.101127},
url = {https://www.sciencedirect.com/science/article/pii/S1097664724011542},
author = {Omer Burak Demirel and Fahime Ghanbari and Christopher W. Hoeger and Connie W. Tsao and Adele Carty and Long H. Ngo and Patrick Pierce and Scott Johnson and Kathryn Arcand and Jordan Street and Jennifer Rodriguez and Tess E. Wallace and Kelvin Chow and Warren J. Manning and Reza Nezafat},
keywords = {Late gadolinium enhancement, Highly accelerated, Deep learning},
abstract = {ABSTRACT
Background
Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging enables imaging of scar/fibrosis and is a cornerstone of most CMR imaging protocols. CMR imaging can benefit from image acceleration; however, image acceleration in LGE remains challenging due to its limited signal-to-noise ratio. In this study, we sought to evaluate a rapid two-dimensional (2D) LGE imaging protocol using a generative artificial intelligence (AI) algorithm with inline reconstruction.
Methods
A generative AI-based image enhancement was used to improve the sharpness of 2D LGE images acquired with low spatial resolution in the phase-encode direction. The generative AI model is an image enhancement technique built on the enhanced super-resolution generative adversarial network. The model was trained using balanced steady-state free-precession cine images, readily used for LGE without additional training. The model was implemented inline, allowing the reconstruction of images on the scanner console. We prospectively enrolled 100 patients (55 ± 14 years, 72 males) referred for clinical CMR at 3T. We collected three sets of LGE images in each subject, with in-plane spatial resolutions of 1.5 × 1.5-3-6 mm2. The generative AI model enhanced in-plane resolution to 1.5 × 1.5 mm2 from the low-resolution counterparts. Images were compared using a blur metric, quantifying the perceived image sharpness (0 = sharpest, 1 = blurriest). LGE image sharpness (using a 5-point scale) was assessed by three independent readers.
Results
The scan times for the three imaging sets were 15 ± 3, 9 ± 2, and 6 ± 1 s, with inline generative AI-based images reconstructed time of ∼37 ms. The generative AI-based model improved visual image sharpness, resulting in lower blur metric compared to low-resolution counterparts (AI-enhanced from 1.5 × 3 mm2 resolution: 0.3 ± 0.03 vs 0.35 ± 0.03, P < 0.01). Meanwhile, AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images showed similar blur metric (0.30 ± 0.03 vs 0.31 ± 0.03, P = 1.0) Additionally, there was an overall 18% improvement in image sharpness between AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images in the subjective blurriness score (P < 0.01).
Conclusion
The generative AI-based model enhances the image quality of 2D LGE images while reducing the scan time and preserving imaging sharpness. Further evaluation in a large cohort is needed to assess the clinical utility of AI-enhanced LGE images for scar evaluation, as this proof-of-concept study does not provide evidence of an impact on diagnosis.}
}
@article{VASAVADA2025S48,
title = {A NOVEL WEB APPLICATION UTILIZING GENERATIVE ARTIFICIAL INTELLIGENCE TO ENHANCE ENDOSCOPY EDUCATION FOR GASTROENTEROLOGY FELLOWS},
journal = {Gastrointestinal Endoscopy},
volume = {101},
number = {5, Supplement },
pages = {S48},
year = {2025},
note = {ASGE Abstracts - DDW 2025},
issn = {0016-5107},
doi = {https://doi.org/10.1016/j.gie.2025.03.088},
url = {https://www.sciencedirect.com/science/article/pii/S0016510725002573},
author = {Shaleen Vasavada and Theresa H. Nguyen and Scott Larson}
}
@article{RODMAN2025689,
title = {Is generative artificial intelligence capable of clinical reasoning?},
journal = {The Lancet},
volume = {405},
number = {10480},
pages = {689},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625003484},
author = {Adam Rodman and Eric J Topol}
}
@article{SAENKHUM2023101066,
title = {Generative artificial intelligence and second language writing},
journal = {Journal of Second Language Writing},
volume = {62},
pages = {101066},
year = {2023},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2023.101066},
url = {https://www.sciencedirect.com/science/article/pii/S1060374323001042},
author = {Tanita Saenkhum and Soo Hyon Kim}
}
@article{LIU2023798,
title = {Generative artificial intelligence and its applications in materials science: Current situation and future perspectives},
journal = {Journal of Materiomics},
volume = {9},
number = {4},
pages = {798-816},
year = {2023},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352847823000771},
author = {Yue Liu and Zhengwei Yang and Zhenyao Yu and Zitu Liu and Dahui Liu and Hailong Lin and Mingqing Li and Shuchang Ma and Maxim Avdeev and Siqi Shi},
keywords = {Machine learning, Artificial intelligence, Generative artificial intelligence, Materials science, Novel materials discovery, Deep learning},
abstract = {Generative Artificial Intelligence (GAI) is attracting the increasing attention of materials community for its excellent capability of generating required contents. With the introduction of Prompt paradigm and reinforcement learning from human feedback (RLHF), GAI shifts from the task-specific to general pattern gradually, enabling to tackle multiple complicated tasks involved in resolving the structure-activity relationships. Here, we review the development status of GAI comprehensively and analyze pros and cons of various generative models in the view of methodology. The applications of task-specific generative models involving materials inverse design and data augmentation are also dissected. Taking ChatGPT as an example, we explore the potential applications of general GAI in generating multiple materials content, solving differential equation as well as querying materials FAQs. Furthermore, we summarize six challenges encountered for the use of GAI in materials science and provide the corresponding solutions. This work paves the way for providing effective and explainable materials data generation and analysis approaches to accelerate the materials research and development.}
}
@article{JOWSEY2023971,
title = {Medical education empowered by generative artificial intelligence large language models},
journal = {Trends in Molecular Medicine},
volume = {29},
number = {12},
pages = {971-973},
year = {2023},
issn = {1471-4914},
doi = {https://doi.org/10.1016/j.molmed.2023.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1471491423002113},
author = {Tanisha Jowsey and Jessica Stokes-Parish and Rachelle Singleton and Michael Todorovic},
keywords = {artificial intelligence, large language model, machine learning, education},
abstract = {Generative artificial intelligence (GAI) large language models (LLMs), like ChatGPT, have become the world’s fastest growing applications. Here, we provide useful strategies for educators in medical and health science (M&HS) to integrate GAI-LLMs into learning and teaching practice, ultimately enhancing students’ digital capability.}
}
@article{RAWLINSON2025,
title = {Generative Artificial Intelligence to Automate the Adaptation of Excel Health Economic Models and Word Technical Reports},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S109830152502399X},
author = {William Rawlinson and Siguroli Teitsson and Tim Reason and Bill Malcolm and Andy Gimblett and Sven L. Klijn},
keywords = {artificial intelligence, large language models},
abstract = {Objectives
In health economics and outcomes research (HEOR), many repetitive tasks could be performed by large language models (LLMs), including adapting Excel-based health economic models and associated Word technical reports to a new setting. However, it is vital to develop robust methods so that the LLM delivers at least human-level accuracy.
Methods
We developed LLM-based pipelines to automate parameter value adaptations for Excel-based models and subsequent reporting of the model results. Chain-of-thought prompting, ensemble shuffling, and task decomposition were used to enhance the accuracy of the LLM-generated content. We tested the pipelines by adapting 3 Excel-based models (2 cost-effectiveness models [CEMs] and 1 budget impact model [BIM]) and their associated technical reports. The quality of reporting was evaluated by 2 expert health economists.
Results
The accuracy of parameter value adaptations was 100% (147 of 147), 100% (207 of 207), and 98.7% (158 of 160) for the 2 CEMs and 1 budget impact model, respectively. The parameter value adaptations were performed without human intervention in 195 seconds, 245 seconds, and 189 seconds. For parameter value adaptations, the application programming interface costs associated with running the pipeline were $13.36, $6.48, and $2.65. The accuracy of report adaptations was 94.4% (17 of 18), 100% (54 of 54), and 95.1% (39 of 41), respectively. The report adaptations were performed in 128 seconds, 336 seconds, and 286 seconds. For report adaptations, the application programming interface costs associated with running the pipeline were $1.53, $4.24, and $4.05.
Conclusions
LLM-based toolchains have the potential to accurately and rapidly perform routine adaptations of Excel-based CEMs and technical reports at a low cost. This could expedite health technology assessments and improve patient access to new treatments.}
}
@incollection{MUKHUTY202537,
title = {Chapter 3 - Industry 5.0 era of digital supply chain: A generative artificial intelligence (GenAI) action model for workforce engagement},
editor = {Syed Abdul Rehman Khan and Adnan Ahmed Sheikh and Jyri Vilko and Sajid Nazir and Mahmood Ali and Marko Torkkeli},
booktitle = {Technological Innovations and Industry 5.0},
publisher = {Elsevier},
pages = {37-53},
year = {2025},
series = {Developments and Advances in the Supply Chain Industry},
isbn = {978-0-443-33813-7},
doi = {https://doi.org/10.1016/B978-0-443-33813-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443338137000038},
author = {Sumona Mukhuty and Robert Dixon and Arvind Upadhyay},
keywords = {Generative artificial intelligence, Industry 4.0, Industry 5.0, Productivity enhancement, Supply chains},
abstract = {Industry 5.0 advocates triangulating the technology-centric emphasis of Industry 4.0 with human-centricity and sustainability. The focus is on creating an inclusive work environment facilitating human-machine reconciliation leading to “sustainable social welfare.” Within this context, the advent and accessibility of generative artificial intelligence (GenAI) have been received with equal measures of excitement and existential dread. This is a major disruptive digital technology that has begun to shake the equilibrium and stability of business survival and job security. Yet, the potential of GenAI in enhancing efficiency is revolutionary, spanning all sectors, including supply chains. Organizational success within the Industry 5.0 context is heavily dependent on the appropriate skills and capabilities. However, the rapid advancement and adoption of GenAI has left organizations with severe knowledge and skills gaps. In this study, we conduct a succinct review of GenAI’s impact on supply chains. Thereafter we draw upon strategic management theories and organizational change theories to develop an organizational GenAI action model to enable supply chain organizations to transition workers from a state of “unconscious GenAI incompetence” to “conscious GenAI competence,” working through the five stages of the model: getting urgent, exploration, formulation, iteration, and embedding. We will predominantly draw upon high-impact peer-reviewed articles, complemented by relevant gray literature, including the European Commission publications, in developing this review and conceptual model. We will close by highlighting the model’s applicability and future research directions.}
}
@article{YASSIN2025102284,
title = {Evaluating a generative artificial intelligence accuracy in providing medication instructions from smartphone images},
journal = {Journal of the American Pharmacists Association},
volume = {65},
number = {1},
pages = {102284},
year = {2025},
issn = {1544-3191},
doi = {https://doi.org/10.1016/j.japh.2024.102284},
url = {https://www.sciencedirect.com/science/article/pii/S1544319124003157},
author = {Yusef Yassin and Thien Nguyen and Krishna Panchal and Katharine Getchell and Timothy Aungst},
abstract = {Background
The Food and Drug Administration mandates patient labeling materials like the Medication Guide (MG) and Instructions for Use (IFU) to support appropriate medication use. However, challenges such as low health literacy and difficulties navigating these materials may lead to incorrect medication usage, resulting in therapy failure or adverse outcomes. The rise of generative AI, presents an opportunity to provide scalable, personalized patient education through image recognition and text generation.
Objective
This study aimed to evaluate the accuracy and safety of medication instructions generated by ChatGPT based on user-provided drug images, compared to the manufacturer's standard instructions.
Methods
Images of 12 medications requiring multiple steps for administration were uploaded to ChatGPT's image recognition function. ChatGPT's responses were compared to the official IFU and MG using text classifiers, Count Vectorization (CountVec), and Term Frequency-Inverse Document Frequency (TF-IDF). The clinical accuracy was further evaluated by independent pharmacists to determine if ChatGPT responses were valid for patient instruction.
Results
ChatGPT correctly identified all medications and generated patient instructions. CountVec outperformed TF-IDF in text similarity analysis, with an average similarity score of 76%. However, clinical evaluation revealed significant gaps in the instructions, particularly for complex administration routes, where ChatGPT's guidance lacked essential details, leading to lower clinical accuracy scores.
Conclusion
While ChatGPT shows promise in generating patient-friendly medication instructions, its effectiveness varies based on the complexity of the medication. The findings underscore the need for further refinement and clinical oversight to ensure the safety and accuracy of AI-generated medical guidance, particularly for medications with complex administration processes.}
}
@article{HIDAYATULLAH2025100213,
title = {Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling},
journal = {Neuroscience Informatics},
volume = {5},
number = {3},
pages = {100213},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000287},
author = {Hafidz Ihsan Hidayatullah and Muhammad Taufiq Saifullah and Muhammad Thesa Ghozali and Ayesha Aziz},
keywords = {Artificial intelligence, Communal pharmacy, Social intention, Procreative AI, Technology acceptance},
abstract = {Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ2=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.}
}
@incollection{SMITH2026421,
title = {Chapter 16 - Generative artificial intelligence for research translation in environmental toxicology and the ethical considerations∗},
editor = {Zhoumeng Lin and Wei-Chun Chou},
booktitle = {Machine Learning and Artificial Intelligence in Toxicology and Environmental Health},
publisher = {Academic Press},
pages = {421-432},
year = {2026},
isbn = {978-0-443-30010-3},
doi = {https://doi.org/10.1016/B978-0-443-30010-3.00013-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300103000131},
author = {Ted Smith},
keywords = {Artificial intelligence (AI), ChatGPT, Environmental health, Generative AI, Large language model (LLM), Plain language summaries (PLS), Prompt development},
abstract = {This chapter explores the potential of generative artificial intelligence (AI) for increasing the accessibility of the toxicological research published for the scientific community for nonspecialist audiences who may need this information for a wide range of important purposes. Translating and summarizing, in plain language, the specialized terminology, intricate statistical models, and interdisciplinary knowledge inherent in this field presents significant challenges which have historically been addressed with human intermediaries and their associated cost and time. Freely available chat-enabled large language models offer the ability to automatically generate a range of cost-effective plain language summaries. These capabilities are accompanied by several limitations such as oversimplification and the risk of inaccuracies which must be considered. Also considered are the ethical considerations such as the need to emphasize transparency, cultural sensitivities, and mitigation of bias in generative AI outputs. The importance of human quality assurance in maintaining scientific accuracy, context, and public trust is critical to responsible applications of this approach. By advocating for a balanced approach that leverages AI's scalability while preserving scientific rigor, this chapter promotes the thoughtful integration of AI in environmental toxicology research translation, ultimately envisioning its role in enhancing public understanding, informing policy, and fostering equitable access to scientific knowledge. An illustrative case exercise provides a step-by-step process for creating these summaries.}
}
@article{DORTAGONZALEZ2024102187,
title = {Generative artificial intelligence usage by researchers at work: Effects of gender, career stage, type of workplace, and perceived barriers},
journal = {Telematics and Informatics},
volume = {94},
pages = {102187},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102187},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000911},
author = {Pablo Dorta-González and Alexis Jorge López-Puig and María Isabel Dorta-González and Sara M. González-Betancor},
keywords = {Artificial intelligence, Use of AI by researchers in the workplace, Challenges in implementing AI, Gender imbalance},
abstract = {The integration of generative artificial intelligence technology into research environments has become increasingly common in recent years, representing a significant shift in the way researchers approach their work. This paper seeks to explore the factors underlying the frequency of use of generative AI amongst researchers in their professional environments. As survey data may be influenced by a bias towards scientists interested in AI, potentially skewing the results towards the perspectives of these researchers, this study uses a regression model to isolate the impact of specific factors such as gender, career stage, type of workplace, and perceived barriers to using AI technology on the frequency of use of generative AI. It also controls for other relevant variables such as direct involvement in AI research or development, collaboration with AI companies, geographic location, and scientific discipline. Our results show that researchers who face barriers to AI adoption experience an 11 % increase in tool use, while those who cite insufficient training resources experience an 8 % decrease. Female researchers experience a 7 % decrease in AI tool usage compared to men, while advanced career researchers experience a significant 19 % decrease. Researchers associated with government advisory groups are 45 % more likely to use AI tools frequently than those in government roles. Researchers in for-profit companies show an increase of 19 %, while those in medical research institutions and hospitals show an increase of 16 % and 15 %, respectively. This paper contributes to a deeper understanding of the mechanisms driving the use of generative AI tools amongst researchers, with valuable implications for both academia and industry.}
}
@article{PREIKSAITIS2023,
title = {Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48785},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000697},
author = {Carl Preiksaitis and Christian Rose},
keywords = {medical education, artificial intelligence, ChatGPT, Bard, AI, educator, scoping, review, learner, generative},
abstract = {Background
Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications.
Objective
This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration.
Methods
We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data.
Results
Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions.
Conclusions
The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.}
}
@article{PERES2023269,
title = {On ChatGPT and beyond: How generative artificial intelligence may affect research, teaching, and practice},
journal = {International Journal of Research in Marketing},
volume = {40},
number = {2},
pages = {269-275},
year = {2023},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167811623000162},
author = {Renana Peres and Martin Schreier and David Schweidel and Alina Sorescu},
keywords = {ChatGPT, Generative AI, Artificial intelligence, LLMs},
abstract = {How does ChatGPT, and other forms of Generative Artificial Intelligence (GenAI) affect the way we have been conducting—and evaluating—academic research, teaching, and business practice? What are the implications for the theory and practice of marketing? What are the opportunities and threats, and what are some interesting avenues for future research? This editorial aims to kick off an initial discussion and stimulate research that will help us better understand how the marketing field can fully exploit the potential of GenAI and effectively cope with its challenges.}
}
@article{WEN2025101010,
title = {Generative artificial intelligence for enzyme design: Recent advances in models and applications},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {52},
pages = {101010},
year = {2025},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2025.101010},
url = {https://www.sciencedirect.com/science/article/pii/S2452223625000148},
author = {Shuixiu Wen and Wen Zheng and Uwe T. Bornscheuer and Shuke Wu},
keywords = {artificial intelligence, biocatalysis, enzyme design, generative models},
abstract = {Enzyme catalysis is a key enabling technology for green and sustainable production of chemicals. Developing suitable enzymes is at the heart of this technology, which is currently changing by Artificial Intelligence (AI) such as machine learning. AI-based methods were used for enzyme discovery and design. We review the recent advances in generative AI models for enzyme design, with a particular focus on those that have been validated by experiments. Furthermore, we discuss the applications of the enzymes designed by generative AI, including artificial luciferases, non-heme iron (II)-dependent oxygenases, and P450 enzymes. We provide our opinions on several current issues encountered in computational enzyme design. With the fast development of new generative models in enzymes and the implementation of these models by the research community, we believe that the precise design of efficient enzymes with new catalytic functions and/or potential industrial applications will be a mature method in the near future.}
}
@article{AHMED20241975,
title = {Generative Artificial Intelligence Tools in Gastroenterology Training},
journal = {Clinical Gastroenterology and Hepatology},
volume = {22},
number = {10},
pages = {1975-1978},
year = {2024},
issn = {1542-3565},
doi = {https://doi.org/10.1016/j.cgh.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1542356524006001},
author = {Tasnim Ahmed and Loren G. Rabinowitz and Adam Rodman and Tyler M. Berzin}
}
@article{ABUMALLOH2024104128,
title = {Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms},
journal = {Computers in Industry},
volume = {161},
pages = {104128},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000563},
author = {Rabab Ali Abumalloh and Mehrbakhsh Nilashi and Keng Boon Ooi and Garry Wei Han Tan and Hing Kai Chan},
keywords = {Generative AI models, ChatGPT, Citizen Data science, Retail firms, Industrial growth, Industrial and innovation},
abstract = {Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.}
}
@article{CHAUHAN20241406,
title = {The Impact of Generative Artificial Intelligence in Scientific Content Synthesis for Authors},
journal = {The American Journal of Pathology},
volume = {194},
number = {8},
pages = {1406-1408},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002001},
author = {Chhavi Chauhan}
}
@article{RODLER2024S947,
title = {A0193 - Exploring the efficiency of generative artificial intelligence in rapidly and accurately producing patient information for urological malignancy treatments aligned with the latest EAU guidelines},
journal = {European Urology},
volume = {85},
pages = {S947-S948},
year = {2024},
note = {Abstracts EAU24 - 39th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/S0302-2838(24)00773-5},
url = {https://www.sciencedirect.com/science/article/pii/S0302283824007735},
author = {S. Rodler and L.S. Ramacciotti and E. Checcucci and P. {De Backer} and I.R. Belenchon and M. Taraktin and S. Pulliatti and A. Veccia and P. Piazza and L. Baekelandt and K-F. Kowalewski and J.G. Rivas and A.L. Abreu and I.S. Gill and G.E. Cacciamani}
}
@article{ROBINSON2025212,
title = {Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {307},
pages = {212-220},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.12.059},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000216},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines},
keywords = {AI, Artificial intelligence, ChatGPT, Generative AI, Large language models},
abstract = {Artificial intelligence (AI) is rapidly being used in medicine due to its advanced capabilities in image and video recognition, clinical decision support, surgical education, and administrative task automation. Large language models such as OpenAI’s Generative Pretrained Transformer (GPT)-4 and Google’s Bard have particularly revolutionized text generation, offering substantial benefits for the academic surgeon, including aiding in manuscript and grant writing. However, integrating AI into academic surgery necessitates addressing ethical concerns such as bias, transparency, and intellectual property. This paper provides guidelines and recommendations based on current literature around the opportunities and ethical challenges of AI in academic surgery. We discuss the underlying mechanisms of large language models, their potential biases, and the importance of responsible usage. Furthermore, we explore the ethical implications of AI in clinical documentation, highlighting improved efficiency and necessary privacy concerns. This review also addresses the critical issue of intellectual property dilemmas posed by AI-generated innovations in university settings. Finally, we propose guidelines for the responsible adoption of AI in academic and clinical environments, stressing the need for transparency, ethical training, and robust governance frameworks to ensure AI enhances, rather than undermines, academic integrity and patient care.}
}
@article{YANG2025,
title = {Reinforcement learning-based generative artificial intelligence for novel pesticide design},
journal = {Journal of Advanced Research},
year = {2025},
issn = {2090-1232},
doi = {https://doi.org/10.1016/j.jare.2025.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S2090123225001286},
author = {Ruoqi Yang and Biao Li and Jin Dong and Zhuomei Cai and Hongyan Lin and Fan Wang and Guangfu Yang},
keywords = {Generative model, Reinforcement learning, Pesticide design, 4-hydroxyphenylpyruvate dioxygenase},
abstract = {Introduction
Pesticides play a pivotal role in ensuring food security, and the development of green pesticides is an inevitable trend in global agricultural progress. Although deep learning-based generative models have revolutionized de novo drug design in pharmaceutical research, their application in pesticide research and development remains unexplored.
Objectives
This study aims to pioneer the application of generative artificial intelligence to pesticide design by proposing a reinforcement learning-based framework for obtaining pesticide-like molecules with high binding affinity.
Methods
This framework comprises two key components: PestiGen-G, which systematically explores the pesticide-like chemical space using a character-based generative model coupled with the REINFORCE algorithm; and PestiGen-S, which combines a fragment-based generative model with the Monte Carlo Tree Search algorithm to generate molecules that stably bind to the specific target protein.
Results
Experimental results show that the molecules generated by PestiGen have superior pesticide-likeness and binding affinity compared to those generated by existing methods. In addition, we employ an active learning strategy to reduce the false-positive rate of the generated molecules. Finally, through collaboration with domain experts, we successfully designed a novel 4-hydroxyphenylpyruvate dioxygenase inhibitor (YH23768) with favorable enzyme inhibition and herbicidal potency.
Conclusion
This proof-of-concept study highlights the utility of PestiGen as a valuable tool for pesticide design. The web server based on the model is freely available at https://dpai.ccnu.edu.cn/PestiGen/.}
}
@article{HALL2024100256,
title = {Generative Artificial Intelligence, Large Language Models, and JID Innovations},
journal = {JID Innovations},
volume = {4},
number = {2},
pages = {100256},
year = {2024},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100256},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000018},
author = {Russell P. Hall}
}
@article{AWIDI2024100226,
title = {Comparing expert tutor evaluation of reflective essays with marking by generative artificial intelligence (AI) tool},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100226},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000274},
author = {Isaiah T. Awidi}
}
@article{KOKABI2025100619,
title = {Ionic Cell Microscopy: A new modality for visualizing cells using microfluidic impedance cytometry and generative artificial intelligence},
journal = {Biosensors and Bioelectronics: X},
volume = {24},
pages = {100619},
year = {2025},
issn = {2590-1370},
doi = {https://doi.org/10.1016/j.biosx.2025.100619},
url = {https://www.sciencedirect.com/science/article/pii/S2590137025000469},
author = {Mahtab Kokabi and Gulam M. Rather and Mehdi Javanmard},
keywords = {Cancer imaging, Impedance cytometry, Microfluidic device, Label-free diagnostics, Generative AI},
abstract = {This study introduces a novel approach to cancer cell imaging by integrating microfluidic sensor technology with artificial intelligence (AI). We developed a custom microfluidic device with polydimethylsiloxane (PDMS) microchannels and integrated electrodes to capture electrical impedance data. The device was fabricated using photolithography, electron beam evaporation, and lift-off techniques. Instead of traditional imaging methods, electrical impedance signals were used to reconstruct cell images. A generative AI model with eight hidden layers processed 191 impedance values to accurately reconstruct the shapes of cancer cells and control beads. Our approach successfully reconstructed images of MDA-MB-231 breast cancer cells, HeLa cells, and beads, achieving 91 % accuracy on the test dataset. Validation using the Structural Similarity Index (SSI) and Mean Structural Similarity Index (MSSIM) produced scores of 0.97 for breast cancer cells and 0.93 for beads, confirming the high precision of this method. This label-free, impedance-based imaging offers a promising solution for cancer diagnostics by accurately reconstructing cell shapes and distinguishing cell types, particularly in point-of-care applications.}
}
@article{KRUIDERING2024224,
title = {Can Generative Artificial Intelligence (AI) Reliably Score Open-Ended Questions (OEQs) in the Assessment of Medical Knowledge},
journal = {The Journal of Pharmacology and Experimental Therapeutics},
volume = {389},
pages = {224},
year = {2024},
issn = {0022-3565},
doi = {https://doi.org/10.1124/jpet.224.126248},
url = {https://www.sciencedirect.com/science/article/pii/S002235652417454X},
author = {Marieke Kruidering and Bao Bao Truongb and Kumiko Endo and Doreen M. Olvet and Tracy B. Fulton and Jeffrey B. Bird and Judith Brenner and Joanne M. Willey},
abstract = {Abstract ID 126248 Poster Board 224 Purpose: The objective of this study is to establish the accuracy of generative artificial intelligence (AI) when scoring medical student exam questions in an open-ended format (OEQ) compared to a faculty content expert. Background: Despite the numerous benefits to including OEQs in assessment of medical knowledge1,2, only 39% of US allopathic medical schools use them3. Faculty report that the biggest barrier is the time it takes to grade student responses1,2. Natural language processing has been explored to automate scoring of clinical reasoning4, but no study has evaluated the use of generative AI to score OEQ responses in the pre-clerkship curriculum. Methods: OEQ responses from two questions administered at the Zucker School of Medicine (ZSOM) and the University of California at San Francisco School of Medicine (UCSF) were used for the current study5. Responses from 54 students per site were analyzed. Content experts scored the responses using an analytic (ZSOM) or holistic rubric (UCSF). Questions, rubrics, and student responses were fed into the GPT-4 model via the Med2Lab platform. Once finalized, scores for each student’s response were generated. Cohen’s weighted kappa (kw) was used to evaluate inter-rater reliability (IRR) between the content expert and generative AI scores, with kw scores between 0.60 and 0.80 being considered substantial6. Prompt engineering was employed for question 1 (analytic rubric) to evaluate its impact on IRR. Results: IRR between the content expert and generative AI scores was substantial using the analytic rubric (question 1: kw = 0.71; question 2: kw = 0.63) and the holistic rubric (question 1: kw = 0.66; question 2: kw = 0.68). IRR for question 1 (analytic rubric) was initially kw = 0.61 but was increased to kw = 0.71 after adjustments with prompt engineering and re-run in GPT-4. Conclusions: Generative AI can score OEQs with substantial reliability. With the potential to alleviate grading burden, AI scoring will allow medical schools to broadly implement OEQs for assessment.}
}
@article{TOROUS2025683,
title = {Assessing generative artificial intelligence for mental health},
journal = {The Lancet},
volume = {406},
number = {10504},
pages = {683},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)01237-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625012371},
author = {John Torous and Eric J Topol}
}
@article{ZHAO2024191,
title = {Employees’ perception of generative artificial intelligence and the dark side of work outcomes},
journal = {Journal of Hospitality and Tourism Management},
volume = {61},
pages = {191-199},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1447677024001207},
author = {Hairong Zhao and Bocong Yuan and Yang Song},
keywords = {, , },
abstract = {Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.}
}
@article{CHO2025101418,
title = {Exploring international students' perceptions of adopting generative artificial intelligence (GenAI) technologies in learning},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101418},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101418},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125001457},
author = {Changwhan Cho and Duke Ofosu-Anim},
abstract = {This study explores international students' perceptions of GenAI technologies in higher education, focusing on how gender and age influence their willingness to adopt. A survey of 122 international graduate students from a private university in South Korea showed that the students are generally familiar with GenAI and its uses in learning. However, its usage varied in frequency. The study also finds that male students are more likely to use GenAI than female students. Additionally, the study revealed age-related differences in the willingness of international students to adopt GenAI, with younger students showing more interest and willingness than older students. However, despite the differences in interest levels in adopting GenAI among genders and ages, the study revealed that overall, there is a general willingness among international students to learn and apply GenAI technologies to their studies. The South Korean education system can be reformed to accommodate the emerging and growing relevance of GenAI in education by developing ethical capacities that will enhance learning while addressing students’ concerns.}
}
@article{MOUSSA2025202990,
title = {Validation of a generative artificial intelligence tool for the critical appraisal of articles on the epidemiology of mental health: Its application in the Middle East and North Africa},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
number = {2},
pages = {202990},
year = {2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.202990},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325001843},
author = {Cheima Moussa and Sarah Altayyar and Marion Vergonjeanne and Thibaut Gelle and Pierre-Marie Preux},
keywords = {Artificial intelligence, ChatGPT, Critical appraisal, Mental health, MENA},
abstract = {Mental health disorders have a high disability-adjusted life years in the Middle East and North Africa. This rise has led to a surge in related publications, prompting researchers to use AI tools like ChatGPT to reduce time spent on routine tasks. Our study aimed to validate an AI-assisted critical appraisal (CA) tool by comparing it with human raters. We developed customized GPT models using ChatGPT-4. These models were tailored to evaluate studies using the Newcastle-Ottawa Scale (NOS) or the Jadad Scale in one model, while another model evaluated STROBE or CONSORT guidelines. Our results showed a moderate to good agreement between human CA and our GPTs for the NOS for cohort, case control and cross-sectional studies and for the Jadad scale, with an ICC of 0.68 [95 %CI: 0.24–0.82], 0.69 [95 %CI: 0.31–0.88], 0.76 [95 %CI: 0.47–0.90] and 0.84 [95 %CI: 0.57–0.94] respectively. There was also a moderate to substantial agreement between the two methods for STROBE in cross sectional, cohort, case control studies, and for CONSORT in trial design, with a K of 0.63 [95 %CI: 0.56–0.70], 0.57 [95 %CI: 0.47–0.66], 0.48 [95 %CI: 0.38–0.50] and 0.70 [95 %CI: 0.63–0.77] respectively. Our custom GPT models produced hallucinations in 6.5 % and 4.9 % of cases, respectively. Human raters took an average of 19.6 ± 4.3 min per article, whereas our customized GPTs took only 1.4. ChatGPT could be a useful tool for handling repetitive tasks yet its effective application relies on the critical expertise of researchers.}
}
@article{NEVIERE2024S474,
title = {MSR184 Leveraging Generative Artificial Intelligence for Assessing the Quality of Network Meta-Analysis: Methodological Considerations and Early Findings},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S474-S475},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2418},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052811},
author = {A Nevière and G Friedrich and K Papadimitropoulou and P {Le Nouveau} and A Gauthier}
}
@incollection{SZABO2025239,
title = {Chapter 16 - Acceptance and commitment training in applied behavior analysis: Competency-based training with generative artificial intelligence},
editor = {Henry S. Roane and Joel E. Ringdahl and Terry S. Falcomata and William E. Sullivan},
booktitle = {Clinical and Organizational Applications of Applied Behavior Analysis (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {239-253},
year = {2025},
series = {Practical Resources for the Mental Health Professional},
isbn = {978-0-443-22365-5},
doi = {https://doi.org/10.1016/B978-0-443-22365-5.00027-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223655000275},
author = {Thomas G. Szabo and Michael J. Cameron and Zimeng Ma and Ziyao Yang and Zhixin Yao},
keywords = {Acceptance and commitment training, Applied behavior analysis, Artificial intelligence, Autism, Genertive AI},
abstract = {Many have returned to a question that Skinner asked toward the end of his career, why are we not acting to save the world (Skinner, 1987). At least two recent papers (Dixon et al., 2018; Rehfeldt & Tyndall, 2021) have posited that we can make substantial progress by furthering research on derived stimulus relations and making use of acceptance and commitment training (ACTr; Szabo, 2023; Szabo et al., 2019b; Tarbox et al., 2020). We enthusiastically endorse these recommendations, but we offer (a) a caveat and (b) solutions that are not at not new in principle but which we propose can be accomplished with surprisingly novel approaches. In this chapter, we offer a brief outline of ACTr in ABA, caveats to using ACTr, and strategies for training BCBAs to the level of competence and sensitivity to scope of practice required. Specifically, we introduce the concept of programmed instruction in ACTr using generative artificial intelligence (GenAI) and provide examples of GenAI as it is used in medical research. Finally, we offer a list of recommendations to researchers and practitioners interested in pursuing this approach to realizing Skinner’s dream.}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{ASHRAF2024,
title = {Search Engines and Generative Artificial Intelligence Integration: Public Health Risks and Recommendations to Safeguard Consumers Online},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/53086},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000504},
author = {Amir Reza Ashraf and Tim Ken Mackey and András Fittler},
keywords = {generative artificial intelligence, artificial intelligence, comparative assessment, search engines, online pharmacies, patient safety, generative, safety, search engine, search, searches, searching, website, websites, Google, Bing, retrieval, information seeking, illegal, pharmacy, pharmacies, risk, risks, consumer, consumers, customer, customers, recommendation, recommendations, vendor, vendors, substance use, substance abuse, controlled substances, controlled substance, drug, drugs, pharmaceutic, pharmaceutics, pharmaceuticals, pharmaceutical, medication, medications},
abstract = {Background
The online pharmacy market is growing, with legitimate online pharmacies offering advantages such as convenience and accessibility. However, this increased demand has attracted malicious actors into this space, leading to the proliferation of illegal vendors that use deceptive techniques to rank higher in search results and pose serious public health risks by dispensing substandard or falsified medicines. Search engine providers have started integrating generative artificial intelligence (AI) into search engine interfaces, which could revolutionize search by delivering more personalized results through a user-friendly experience. However, improper integration of these new technologies carries potential risks and could further exacerbate the risks posed by illicit online pharmacies by inadvertently directing users to illegal vendors.
Objective
The role of generative AI integration in reshaping search engine results, particularly related to online pharmacies, has not yet been studied. Our objective was to identify, determine the prevalence of, and characterize illegal online pharmacy recommendations within the AI-generated search results and recommendations.
Methods
We conducted a comparative assessment of AI-generated recommendations from Google’s Search Generative Experience (SGE) and Microsoft Bing’s Chat, focusing on popular and well-known medicines representing multiple therapeutic categories including controlled substances. Websites were individually examined to determine legitimacy, and known illegal vendors were identified by cross-referencing with the National Association of Boards of Pharmacy and LegitScript databases.
Results
Of the 262 websites recommended in the AI-generated search results, 47.33% (124/262) belonged to active online pharmacies, with 31.29% (82/262) leading to legitimate ones. However, 19.04% (24/126) of Bing Chat’s and 13.23% (18/136) of Google SGE’s recommendations directed users to illegal vendors, including for controlled substances. The proportion of illegal pharmacies varied by drug and search engine. A significant difference was observed in the distribution of illegal websites between search engines. The prevalence of links leading to illegal online pharmacies selling prescription medications was significantly higher (P=.001) in Bing Chat (21/86, 24%) compared to Google SGE (6/92, 6%). Regarding the suggestions for controlled substances, suggestions generated by Google led to a significantly higher number of rogue sellers (12/44, 27%; P=.02) compared to Bing (3/40, 7%).
Conclusions
While the integration of generative AI into search engines offers promising potential, it also poses significant risks. This is the first study to shed light on the vulnerabilities within these platforms while highlighting the potential public health implications associated with their inadvertent promotion of illegal pharmacies. We found a concerning proportion of AI-generated recommendations that led to illegal online pharmacies, which could not only potentially increase their traffic but also further exacerbate existing public health risks. Rigorous oversight and proper safeguards are urgently needed in generative search to mitigate consumer risks, making sure to actively guide users to verified pharmacies and prioritize legitimate sources while excluding illegal vendors from recommendations.}
}
@article{KADHIM2025100895,
title = {Application of generative artificial intelligence to utilize unstructured clinical data for acceleration of inflammatory bowel disease research},
journal = {Med},
pages = {100895},
year = {2025},
issn = {2666-6340},
doi = {https://doi.org/10.1016/j.medj.2025.100895},
url = {https://www.sciencedirect.com/science/article/pii/S2666634025003228},
author = {Alex Z. Kadhim and Zachary Green and Iman Nazari and Jonathan Baker and Michael George and Ashley Heinson and Bhumita Vadgama and Matt Stammers and Christopher M. Kipps and R. Mark Beattie and James J. Ashton and Sarah Ennis},
keywords = {inflammatory bowel disease, Crohn’s disease, ulcerative colitis, AI, large language models, electronic health records, histology, imaging, FAIR data},
abstract = {Summary
Background
Inflammatory bowel disease (IBD) research is a dynamic field. However, the growing volume of electronic health records (EHRs) and research data presents significant challenges. Traditional methods for structuring unstructured EHRs are labor-intensive and lack scalability. Large language models (LLMs) may present a solution, however, their usefulness in data standardization in the context of IBD remains unknown. We sought to evaluate LLMs in structuring free-text histology and radiology reports from IBD patients (n = 32,041), compare their performance to manual clinician curation, and assess the usefulness of fine-tuning and retrieval-augmented generation (RAG).
Methods
We developed an IBD-specialized LLM-based framework utilizing structured prompt engineering and fine-tuning. Free-text reports from two independent sites were manually curated and processed using various LLMs (n = 120).
Findings
Overall, Llama 3.3 achieved the highest F1 scores for histology and imaging (1.00 ± 0 and 0.85 ± 0.29, respectively) in extracting findings and anatomical regions, surpassing other models in structured data generation. Fine-tuning improved the performance of the smaller Llama 3.1 8B model for imaging reports (0.70 ± 0.46 vs. 0.82 ± 0.35), enabling better extraction with reduced computational requirements.
Conclusions
Our findings demonstrate the feasibility of LLM-based automated structuring of IBD-related medical records. Unstructured data from free-text reports can be reliably converted into standardized ontologies with location, severity, and qualifiers. These advancements enable scalable, privacy-compliant AI-driven solutions for data standardization.
Funding
The Institute for Life Sciences, University of Southampton, the NIHR Southampton BRC, and EPSRC (EP/Y01720X/1).}
}
@article{ESMAEILI2024127676,
title = {Enhancing digital rock analysis through generative artificial intelligence: Diffusion models},
journal = {Neurocomputing},
volume = {587},
pages = {127676},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127676},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004478},
author = {Mohammad Esmaeili},
keywords = {Diffusion Models, Generative Artificial Intelligence, Computer Vision, Digital Rock Analysis, Single Image Super-Resolution},
abstract = {Within the realm of computer vision, the landscape has been significantly reshaped by the abundance of extensive and diverse datasets, leading to remarkable breakthroughs in image processing. These advancements have reverberated across a wide spectrum of applications, catalyzing transformative outcomes. However, in stark contrast, the field of digital rock analysis finds itself grappling with a conspicuous dearth of data, a challenge that casts a formidable shadow over the effective deployment of computer vision techniques for rock image analysis. In response to this pressing issue, this paper presents a pioneering methodology designed to surmount the hurdles posed by data limitation in the realm of digital rock analysis. At the core of this innovative approach lies the fusion of artificially generated digital rock images, created using a state-of-the-art diffusion model, with their authentic counterparts. This fusion is guided by the overarching objective of augmenting the efficacy of various digital rock analysis applications. This integration endeavors to bridge the gap between the limited available data and the substantial demands of the digital rock analysis domain. The practical significance and potential of this integrated approach are vividly demonstrated through a series of concrete implementations. These include, but are by no means limited to, enhancing image quality to facilitate clearer visualization of intricate rock structures and refining the estimation of petrophysical properties with increased accuracy.}
}
@article{ZHAO2025108654,
title = {“Positive” or “Threatened”? The impact of the features in generative artificial intelligence on continued behavior},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108654},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001013},
author = {Li Zhao and Yun Xu and Sheng-kai Zhou},
keywords = {Artificial intelligence generated content (AIGC), Positive awe, Threatened awe, Continued usage intention},
abstract = {Artificial intelligence technologies have empowered marketers with advanced tools and insights, fostering unparalleled efficiency and personalization decision-making. To provide marketers with targeted and actionable guidance, this study investigated the behavioral mechanisms underlying the adoption of artificial intelligence-generated content (AIGC) technology. Specifically, it examined the influence of AIGC features (accuracy, competence, anthropomorphism, and interactivity) and the distinct psychological mechanisms of awe on users' behavioral intentions. A mixed-methods approach was employed, combining quantitative data (N = 860) with qualitative research (user reviews). The analysis revealed that the awe experience significantly influences AIGC users' preferences to continue using the technology. Positive awe had a significant positive effect, while threatened awe had a comparatively weaker negative effect. The four features (accuracy, competence, anthropomorphism, and interactivity) of AIGC contribute significantly to its users' continued usage intention. Notably, positive awe induced by competence, anthropomorphism, and interactivity significantly outweighed threatened awe, with the exception of accuracy. The findings reveal that the unique features of AIGC not only evoke users’ perceived awe but also strengthen their intentions to continue using the technology.}
}
@article{KANAPARTHY2025,
title = {Real-World Evidence Synthesis of Digital Scribes Using Ambient Listening and Generative Artificial Intelligence for Clinician Documentation Workflows: Rapid Review},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/76743},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000808},
author = {Naga Sasidhar Kanaparthy and Yenny Villuendas-Rey and Tolulope Bakare and Zihan Diao and Mark Iscoe and Andrew Loza and Donald Wright and Conrad Safranek and Isaac V Faustino and Alexandria Brackett and Edward R Melnick and R Andrew Taylor},
keywords = {digital scribes, artificial intelligence in medicine, clinical documentation, speech recognition software, patient-clinician communication},
abstract = {Background
As physicians spend up to twice as much time on electronic health record tasks as on direct patient care, digital scribes have emerged as a promising solution to restore patient-clinician communication and reduce documentation burden—making it essential to study their real-world impact on clinical workflows, efficiency, and satisfaction.
Objective
This study aimed to synthesize evidence on clinician efficiency, user satisfaction, quality, and practical barriers associated with the use of digital scribes using ambient listening and generative artificial intelligence (AI) in real-world clinical settings.
Methods
A rapid review was conducted to evaluate the real-world evidence of digital scribes using ambient listening and generative AI in clinical practice from 2014 to 2024. Data were collected from Ovid MEDLINE, Embase, Web of Science–Core Collection, Cochrane CENTRAL and Reviews, and PubMed Central. Predefined eligibility criteria focused on studies addressing clinical implementation, excluding those centered solely on technical development or model validation. The findings of each study were synthesized and analyzed through the QUEST human evaluation framework for quality and safety and the Systems Engineering Initiative for Patient Safety (SEIPS) 3.0 model to assess integration into clinicians’ workflows and experience.
Results
Of the 1450 studies identified, 6 met the inclusion criteria. These studies included an observational study, a case report, a peer-matched cohort study, and survey-based assessments conducted across academic health systems, community settings, and outpatient practices. The major themes noted were as follows: (1) they decreased self-reported documentation times, with associated increased length of notes; (2) physician burnout measured using standardized scales was unaffected, but physician engagement improved; (3) physician productivity, assessed via billing metrics, was unchanged; and (4) the studies fell short when compared to standardized frameworks.
Conclusions
Digital scribes show promise in reducing documentation burden and enhancing clinician satisfaction, thereby supporting workflow efficiency. However, the currently available evidence is sparse. Future real-world, multifaceted studies are needed before AI scribes can be recommended unequivocally.}
}
@article{DIEN2023108595,
title = {Generative artificial intelligence in publishing - Reflection and discussion},
journal = {Biological Psychology},
volume = {181},
pages = {108595},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108595},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001126},
author = {Joseph Dien and Thomas Ritz},
keywords = {Plagiarism, Large Language Models, ChatGPT, Artificial Intelligence, Academic Misconduct}
}
@article{DIEN2023108621,
title = {Editorial: Generative artificial intelligence as a plagiarism problem},
journal = {Biological Psychology},
volume = {181},
pages = {108621},
year = {2023},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2023.108621},
url = {https://www.sciencedirect.com/science/article/pii/S0301051123001382},
author = {Joseph Dien},
keywords = {Plagiarism, Large language models, ChatGPT, Artificial intelligence, Academic misconduct},
abstract = {There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology, the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved.}
}
@article{BOSCO2025,
title = {Designing a Multimodal and Culturally Relevant Alzheimer Disease and Related Dementia Generative Artificial Intelligence Tool for Black American Informal Caregivers: Cognitive Walk-Through Usability Study},
journal = {JMIR Aging},
volume = {8},
year = {2025},
issn = {2561-7605},
doi = {https://doi.org/10.2196/60566},
url = {https://www.sciencedirect.com/science/article/pii/S2561760525000027},
author = {Cristina Bosco and Ege Otenen and John {Osorio Torres} and Vivian Nguyen and Darshil Chheda and Xinran Peng and Nenette M Jessup and Anna K Himes and Bianca Cureton and Yvonne Lu and Carl V Hill and Hugh C Hendrie and Priscilla A Barnes and Patrick C Shih},
keywords = {multimodality, artificial intelligence, AI, generative AI, usability, black, African American, cultural, Alzheimer's, dementia, caregivers, mobile app, interaction, cognition, user opinion, geriatrics, smartphone, mHealth, digital health, aging},
abstract = {Background
Many members of Black American communities, faced with the high prevalence of Alzheimer disease and related dementias (ADRD) within their demographic, find themselves taking on the role of informal caregivers. Despite being the primary individuals responsible for the care of individuals with ADRD, these caregivers often lack sufficient knowledge about ADRD-related health literacy and feel ill-prepared for their caregiving responsibilities. Generative AI has become a new promising technological innovation in the health care domain, particularly for improving health literacy; however, some generative AI developments might lead to increased bias and potential harm toward Black American communities. Therefore, rigorous development of generative AI tools to support the Black American community is needed.
Objective
The goal of this study is to test Lola, a multimodal mobile app, which, by relying on generative AI, facilitates access to ADRD-related health information by enabling speech and text as inputs and providing auditory, textual, and visual outputs.
Methods
To test our mobile app, we used the cognitive walk-through methodology, and we recruited 15 informal ADRD caregivers who were older than 50 years and part of the Black American community living within the region. We asked them to perform 3 tasks on the mobile app (ie, searching for an article on brain health, searching for local events, and finally, searching for opportunities to participate in scientific research in their area), then we recorded their opinions and impressions. The main aspects to be evaluated were the mobile app’s usability, accessibility, cultural relevance, and adoption.
Results
Our findings highlight the users’ need for a system that enables interaction with different modalities, the need for a system that can provide personalized and culturally and contextually relevant information, and the role of community and physical spaces in increasing the use of Lola.
Conclusions
Our study shows that, when designing for Black American older adults, a multimodal interaction with the generative AI system can allow individuals to choose their own interaction way and style based upon their interaction preferences and external constraints. This flexibility of interaction modes can guarantee an inclusive and engaging generative AI experience.}
}
@article{MESSER2024100056,
title = {Co-creating art with generative artificial intelligence: Implications for artworks and artists},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100056},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000161},
author = {Uwe Messer},
keywords = {Art, Authenticity, Generative AI, Human-AI-Collaboration},
abstract = {Synthetic visual art is becoming a commodity due to generative artificial intelligence (AI). The trend of using AI for co-creation will not spare artists’ creative processes, and it is important to understand how the use of generative AI at different stages of the creative process affects both the evaluation of the artist and the result of the human-machine collaboration (i.e., the visual artifact). In three experiments (N = 560), this research explores how the evaluation of artworks is transformed by the revelation that the artist collaborated with AI at different stages of the creative process. The results show that co-created art is less liked and recognized, especially when AI was used in the implementation stage. While co-created art is perceived as more novel, it lacks creative authenticity, which exerts a dominant influence. The results also show that artists’ perceptions suffer from the co-creation process, and that artists who co-create are less admired because they are perceived as less authentic. Two boundary conditions are identified. The negative effect can be mitigated by disclosing the level of artist involvement in co-creation with AI (e.g., by training the algorithm on a curated set of images vs. simply prompting an off-the-shelf AI image generator). In the context of art that is perceived as commercially motivated (e.g., stock images), the effect is also diminished. This research has important implications for the literature on human-AI-collaboration, research on authenticity, and the ongoing policy debate regarding the transparency of algorithmic presence.}
}
@article{STERPETTI2025388,
title = {Letter Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {388-389},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001325},
author = {Antonio V. Sterpetti}
}
@article{MILES2024S478,
title = {MSR201 Optimising Performance of Generative Artificial Intelligence (GenAI) in Systematic Literature Review (SLR) Screening Using PICOS Criteria},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S478},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2435},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524052987},
author = {G Miles and L Giles and B.C. Kerr and B Norman and GC Sibbring}
}
@article{DUONG2025910,
title = {Exploring the role of generative artificial intelligence (ChatGPT) adoption in digital social entrepreneurship: a serial mediation model},
journal = {Social Enterprise Journal},
volume = {21},
number = {5},
pages = {910-936},
year = {2025},
issn = {1750-8614},
doi = {https://doi.org/10.1108/SEJ-03-2024-0029},
url = {https://www.sciencedirect.com/science/article/pii/S1750861425000106},
author = {Cong Doanh Duong and Thanh Hieu Nguyen and Minh Hoa Nguyen and Ngoc Su Dang and Anh Trong Vu and Ngoc Diep Do},
keywords = {GenAI (ChatGPT) adoption in social entrepreneurship, Perceived feasibility, Perceived desirability, Intention toward digital social entrepreneurship},
abstract = {Purpose
Using an integrated framework of the Entrepreneurial Event Model and the Stimulus–Organism–Response theory, this study aims to investigate how artificial intelligence (AI)-driven stimulus [Generative AI (ChatGPT) adoption in digital social entrepreneurship] affects individuals’ cognitive processes (perceived feasibility and perceived desirability), which subsequently influence their behavioral intentions (digital social entrepreneurial intention).
Design/methodology/approach
This research used a stratified sampling method to survey 986 higher education students in Vietnam. Hypotheses were tested using structural equation modeling.
Findings
The results indicate that GenAI (ChatGPT) adoption in digital social entrepreneurship significantly enhances both perceived feasibility and perceived desirability. These cognitive perceptions are positively associated with intentions to engage in digital social entrepreneurship. In addition, this study finds that GenAI (ChatGPT) adoption in digital social entrepreneurship poses a serial indirect effect on digital social entrepreneurial intention through a perceived feasibility–perceived desirability path.
Practical implications
The findings provide actionable recommendations for aspiring students (potential future entrepreneurs), educators and policymakers to foster the use of AI technologies in promoting digital social entrepreneurship.
Originality/value
This study offers substantial theoretical contributions by merging the Entrepreneurial Event Model and the Stimulus–Organism–Response framework. Thus, it advances the extant understanding of the cognitive mechanisms driving digital social entrepreneurial decision-making in the context of AI adoption. This research addresses a critical gap and establishes a foundation for future theoretical advancements in digital social entrepreneurship and AI integration.}
}
@article{LEE20241318,
title = {Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {8},
pages = {1318-1320},
year = {2024},
note = {Focus on Global Radiology},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S1546144024001303},
author = {Christoph I. Lee and Jonathan H. Chen and Marc D. Kohli and Andrew D. Smith and Joshua M. Liao}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@article{CHAUHAN20241802,
title = {The Impact of Generative Artificial Intelligence on the External Review of Scientific Manuscripts and Editorial Peer Review Processes},
journal = {The American Journal of Pathology},
volume = {194},
number = {10},
pages = {1802-1806},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024002864},
author = {Chhavi Chauhan and George Currie}
}
@article{MESKO2023,
title = {The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48392},
url = {https://www.sciencedirect.com/science/article/pii/S143888712300465X},
author = {Bertalan Mesko},
keywords = {artificial intelligence, digital health, future, technology, ChatGPT, medical practice, large language model, language model, generative, conversational agent, conversation agents, chatbot, generated text, computer generated, medical education, continuing education, professional development, curriculum, curricula},
abstract = {In November 2022, OpenAI publicly launched its large language model (LLM), ChatGPT, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using generative artificial intelligence (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the ChatGPT revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.}
}
@article{NA2025103614,
title = {1376 Virtual H&E Staining Using Generative Artificial Intelligence: A Novel Technique for Digital Transformation of Unstained Pathology Slides},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103614},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032926},
author = {Sei Na and Dawoon Na and Kyoungsook Park and SangYong Song and Byullee Park and Hyung Kyung Kim}
}
@article{LEE2025104317,
title = {Readability, quality and accuracy of generative artificial intelligence chatbots for commonly asked questions about labor epidurals: a comparison of ChatGPT and Bard},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104317},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104317},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003297},
author = {D. Lee and M. Brown and J. Hammond and M. Zakowski},
keywords = {Labor analgesia, Epidural, Pregnancy, Generative Artificial Intelligence, Patient educational materials},
abstract = {Introduction
Over 90% of pregnant women and 76% expectant fathers search for pregnancy health information. We examined readability, accuracy and quality of answers to common obstetric anesthesia questions from the popular generative artificial intelligence (AI) chatbots ChatGPT and Bard.
Methods
Twenty questions for generative AI chatbots were derived from frequently asked questions based on professional society, hospital and consumer websites. ChatGPT and Bard were queried in November 2023. Answers were graded for accuracy by four obstetric anesthesiologists. Quality was measured using Patient Education Materials Assessment Tool for Print (PEMAT). Readability was measured using six readability indices. Accuracy, quality and readability were compared using independent t-test.
Results
Bard readability scores were high school level, significantly easier than ChatGPT’s college level by all scoring metrics (P <0.001). Bard had significantly longer answers (P <0.001), yet with similar accuracy of Bard (85% ± 10) and ChatGPT (87% ± 14) (P=0.5). PEMAT understandability scores were no statistically significantly different (P=0.06). Actionability by PEMAT scores for Bard was significantly higher (22% vs. 9%) than ChatGPT (P=0.007)
Conclusion
Answers to questions about “labor epidurals” should be accurate, high quality, and easy to read. Bard at high school reading level, was well above the goal 4th to 6th grade level suggested for patient materials. Consumers, health care providers, hospitals and governmental agencies should be aware of the quality of information generated by chatbots. Chatbots should meet the standards for readability and understandability of health-related questions, to aid public understanding and enhance shared decision-making.}
}
@article{DAUNGSUPAWONG2024361,
title = {Generative Artificial Intelligence in Dental Licensing Examinations: Comment},
journal = {International Dental Journal},
volume = {74},
number = {2},
pages = {361},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2024.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0020653924000431},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@article{FIJACKO2024100584,
title = {Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses},
journal = {Resuscitation Plus},
volume = {18},
pages = {100584},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100584},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000353},
author = {Nino Fijačko and Ruth Masterson Creber and Benjamin S. Abella and Primož Kocbek and Špela Metličar and Robert Greif and Gregor Štiglic},
keywords = {Emergency medicine, European Resuscitation Council, Congress, Bibliometrics analysis, Generative artificial intelligence},
abstract = {Aims
The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade.
Methods
In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics.
Results
From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence.
Conclusion
This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.}
}
@incollection{BEHESHTI2025333,
title = {Chapter 13 - Exploring the convergence of Internet of things and big data technologies in the age of generative artificial intelligence},
editor = {Mohamed Adel Serhani and Yang Xu and Zakaria Maamar},
booktitle = {Empowering IoT with Big Data Analytics},
publisher = {Academic Press},
pages = {333-354},
year = {2025},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-21640-4},
doi = {https://doi.org/10.1016/B978-0-443-21640-4.00004-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216404000041},
author = {Amin Beheshti and Wathiq Mansoor},
keywords = {Internet of things (IoT), Big data analytics, Generative artificial intelligence (AI), Data curation},
abstract = {The Internet of things (IoT) has transformed the way we interact with the physical world, generating an unprecedented volume of data. In modern enterprises, the convergence of IoT, big data, and generative artificial intelligence (GAI) is reshaping the landscape of digital solutions. This chapter explores this convergence, shedding light on emerging solutions, software architectures, and challenges and opportunities in the age of GAI. We explore the complexities of effectively using IoT-generated data, emphasizing the challenges of gathering, organizing, curating, and processing these data for meaningful insights. We highlight the importance of linking analytical, cognitive, and GAI to enable the development of self-evolving systems capable of learning from extensive data streams and making instant data-driven decisions and predictions. This synergy between IoT, big data, and AI can transform various industries by enhancing automation, augmentation, and improvement of their processes.}
}
@article{AZIZOGLU2025162359,
title = {Generative Artificial Intelligence Accuracy in Interpreting Forest Plots in Pediatric Surgery Meta-analyses: A Perspective From Pediatric Surgery Meta-analysis Study Group (PESMA)},
journal = {Journal of Pediatric Surgery},
volume = {60},
number = {7},
pages = {162359},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162359},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825002040},
author = {Mustafa Azizoglu and Maria Escolino and Tahsin Onat Kamci and Sergey Klyuev and Sonia {Perez Bertolez} and Toni Risteski and Ismael Elhalaby and Nitinkumar Borkar and Ciro Esposito and Mehmet Hanifi Okur and Martin Lacher and Annika Mutanen and Sameh Shehata and Fabio Chiarenza and Mark Davenport}
}
@article{RAY20231457,
title = {Generative Artificial Intelligence (AI) and Medical Ethics: A Symbiotic Dance for the Future},
journal = {Journal of Oral and Maxillofacial Surgery},
volume = {81},
number = {12},
pages = {1457-1459},
year = {2023},
issn = {0278-2391},
doi = {https://doi.org/10.1016/j.joms.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278239123011588},
author = {Partha Pratim Ray}
}
@article{WHEATLEY2024102942,
title = {Comparing generative artificial intelligence tools to voice assistants using reference interactions},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {5},
pages = {102942},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102942},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324001034},
author = {Amanda Wheatley and Sandy Hervieux},
keywords = {Artificial intelligence, Voice assistants, Generative AI, Reference},
abstract = {This study investigates the ability of voice assistants and generative AI tools to respond to reference questions traditionally received by academic librarians. The authors created a sample of 25 questions based on queries received on the virtual reference service at their institution. They then created a rubric to evaluate the quality of the answers that the AI powered tools provided. The authors determined that the tools understand reference questions well and provide relevant answers but that the quality of the references provided, and the accuracy of the answers can be lacking. They suggest that more research needs to be done to understand the place of AI powered tools in reference services.}
}
@article{RAPP2025103375,
title = {How do people experience the images created by generative artificial intelligence? An exploration of people's perceptions, appraisals, and emotions related to a Gen-AI text-to-image model and its creations},
journal = {International Journal of Human-Computer Studies},
volume = {193},
pages = {103375},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103375},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001587},
author = {Amon Rapp and Chiara {Di Lodovico} and Federico Torrielli and Luigi {Di Caro}},
keywords = {AI, Generative AI, Stable diffusion, User experience, Anthropomorphising, Humanness, Uncanny valley},
abstract = {Generative Artificial Intelligence (Gen-AI) has rapidly advanced in recent years, potentially producing enormous impacts on industries, societies, and individuals in the near future. In particular, Gen-AI text-to-image models allow people to easily create high-quality images possibly revolutionizing human creative practices. Despite their increasing use, however, the broader population's perceptions and understandings of Gen-AI-generated images remain understudied in the Human-Computer Interaction (HCI) community. This study investigates how individuals, including those unfamiliar with Gen-AI, perceive Gen-AI text-to-image (Stable Diffusion) outputs. Study findings reveal that participants appraise Gen-AI images based on their technical quality and fidelity in representing a subject, often experiencing them as either prototypical or strange: these experiences may raise awareness of societal biases and evoke unsettling feelings that extend to the Gen-AI itself. The study also uncovers several “relational” strategies that participants employ to cope with concerns related to Gen-AI, contributing to the understanding of reactions to uncanny technology and the (de)humanization of intelligent agents. Moreover, the study offers design suggestions on how to use the anthropomorphizing of the text-to-image model as design material, and the Gen-AI images as support for critical design sessions.}
}
@article{LENGUYEN2024138836,
title = {Generative artificial intelligence and optimisation framework for concrete mixture design with low cost and embodied carbon dioxide},
journal = {Construction and Building Materials},
volume = {451},
pages = {138836},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.138836},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824039783},
author = {Khuong {Le Nguyen} and Minhaz Uddin and Thong M. Pham},
keywords = {Concrete mixture design, Machine learning approach, Generative AI, Compressive strength prediction, Multi-objective optimisation},
abstract = {This research presents a generative Artificial Intelligence (AI) and design framework that integrates machine learning (ML) and optimisation methodologies to discover new concrete mixture designs. Unlike traditional ML models that predict based on existing data, this framework innovatively generates new concrete mix designs that meet specific requirements such as strength, cost-efficiency, and reduced embodied CO2. To propose a powerful and reliable generative AI model, several advanced ML algorithms were considered, e.g., CatBoost, XGBoost, and LGBM. These models were trained on a unique dataset consisting of 4,936 data points collected from five different batching plants and have not been published yet. Bayesian Optimisation was employed to fine-tune model hyperparameters, resulting in the most effective models attaining R2 values of 0.94 and 0.89 for raw and grouped data, respectively. To verify the trained generative AI model, a case study was conducted, in which the model was requested to provide designs of a mix with pre-determined strength and optimised cost and embodied CO2. The mix designs generated by the framework were successfully validated through experimental tests, corroborating the predictive outcomes. The research culminated in the development of a web application, a tool crafted to streamline the concrete mixture design and optimisation process. This generative AI design framework can be applied to many other aspects of material design and engineering problems.}
}
@article{VLACHOPOULOS2024120,
title = {Generative artificial intelligence tools in scientific writing: entering a brave new world?},
journal = {Hellenic Journal of Cardiology},
volume = {77},
pages = {120-121},
year = {2024},
issn = {1109-9666},
doi = {https://doi.org/10.1016/j.hjc.2024.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S1109966624001180},
author = {Charalambos Vlachopoulos and Alexios Antonopoulos and Dimitrios Terentes-Printzios}
}
@article{MOTOKI2025106904,
title = {Assessing political bias and value misalignment in generative artificial intelligence},
journal = {Journal of Economic Behavior & Organization},
volume = {234},
pages = {106904},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2025.106904},
url = {https://www.sciencedirect.com/science/article/pii/S0167268125000241},
author = {Fabio Y.S. Motoki and Valdemar {Pinho Neto} and Victor Rangel},
keywords = {Generative AI, Societal values, Large language models, Multimodal, AI governance},
abstract = {Our analysis reveals a concerning misalignment of values between ChatGPT and the average American. We also show that ChatGPT displays political leanings when generating text and images, but the degree and direction of skew depend on the theme. Notably, ChatGPT repeatedly refused to generate content representing certain mainstream perspectives, citing concerns over misinformation and bias. As generative AI systems like ChatGPT become ubiquitous, such misalignment with societal norms poses risks of distorting public discourse. Without proper safeguards, these systems threaten to exacerbate societal divides and depart from principles that underpin free societies.}
}
@article{LIU2024124511,
title = {Generative artificial intelligence and data augmentation for prognostic and health management: Taxonomy, progress, and prospects},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124511},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124511},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013782},
author = {Shen Liu and Jinglong Chen and Yong Feng and Zongliang Xie and Tongyang Pan and Jingsong Xie},
keywords = {Fault diagnosis, Generative artificial intelligence, Data augmentation, Data generation, Prognostics and health management},
abstract = {Intelligent fault diagnosis, detection, and prognostics (DDP) for complex equipment prognostics and health management (PHM) have achieved remarkable breakthroughs. Equipment in industrial scenarios often operates in normal conditions, resulting in missing anomalies, limited failures, and incomplete degradation paths. Thus the limited information on the state of the equipment collected from sensor readings severely hinders the cognitive capabilities of discriminative artificial intelligence (AI) for PHM. Data augmentation and generation (DA&G) techniques, represented by generative AI, have shown great promise in overcoming the limitations of PHM application scenarios. Research on DA&G has yielded significant achievements, but a comprehensive review in the mechanical field is still lacking. To this end, this paper provides a comprehensive review of DA&G techniques aimed at solving the DDP problems, which are divided into three categories insights of data, mechanism, and features. The data-based randomized approach applies controlled randomness for augmentation. The mechanism-based domain-specific techniques advocate for exploring relationships between the physical entity and monitoring data for generating by reasoned inference. The feature-based generative model aims to identify the latent space of data and subsequently resample it. Finally, the paper explores strategies for evaluating DA&G and provides a deep insight into the challenges and opportunities of DA&G techniques.}
}
@article{DAS2025102546,
title = {Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer’s genetic and immune landscape},
journal = {Molecular Therapy Nucleic Acids},
volume = {36},
number = {2},
pages = {102546},
year = {2025},
issn = {2162-2531},
doi = {https://doi.org/10.1016/j.omtn.2025.102546},
url = {https://www.sciencedirect.com/science/article/pii/S2162253125001003},
author = {Arpita Das and Manojit Bhattacharya and Ali Saber Abdelhameed and Sang-Soo Lee and Chiranjib Chakraborty},
keywords = {Bioinformatics, GenAI, single-cell analysis, Alzheimer’s disease, genetic and immune landscape},
abstract = {The research aims to understand Alzheimer’s genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer’s disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8+ T cells (33.42%) and naive T cells (45.95%). The single-cell study found that effector memory T cells have two subsets. It also found that the macrophage population has started to spread and dendritic cells have decreased in Alzheimer’s patients. The single-cell gene expression study reveals the top ten highly expressed genes (NDUFV2, CAT, MRPS34, PBX3, THOC2, CCDC57, PBXIP1, SDHAF3, PPP4C, and MAP3K8). The clonal frequency indicates that CD8+ T and naive T cell populations show the highest clonal frequency in healthy and AD individuals and are further noted them in the clonotype cell proportion study. Following our GenAI and single-cell profiling strategy, future studies will help in quickly understanding the genetic and immune basis of many diseases.}
}
@article{KAPLAN2025106080,
title = {New generative artificial intelligence model: ScholarGPT’s performance on dental avulsion},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106080},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106080},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002977},
author = {Taibe Tokgöz Kaplan},
keywords = {Artificial intelligence, ChatGPT, Dental avulsion, Gemini, Large Language Models, ScholarGPT},
abstract = {Background
This study aims to evaluate the performance of ScholarGPT, a Large Language Model (LLM) developed for academic purposes, on questions related to dental avulsion. In addition, to analyze and compare it with the results of the previous study evaluating the performance of ChatGPT and Gemini.
Method
A total of 22 technical questions (11 multiple-choice questions (MCQs), 11 true/false (T/F)) were posed to the ScholarGPT. ScholarGPT responses were assessed using a modified Global Quality Scale (GQS). Responses were randomized using an online randomizer (www.randomizer.org) before scoring. A single researcher carried out the assessments at three different times, two weeks apart, and a new randomization was performed before each scoring.
Results
When the answers given by ScholarGPT according to the question groups were analyzed by the Mann-Whitney U test, the mean value was found to be 4.64 for MCQ questions and 4.82 for T/F questions. ScholarGPT provided similarly high-quality and consistent answers in both question types (p = 0.590). When the performance of ScholarGPT was compared with Gemini and ChatGPT via the Friedman test, the mean score of ScholarGPT responses was significantly higher than both ChatGPT and Gemini (mean difference with Gemini = 0.75; mean difference with ChatGPT = 1.62, p < 0.001). ScholarGPT produced statistically significantly more consistent and higher-quality responses than ChatGPT and Gemini.
Conclusion
ScholarGPT showed high performance on technical questions related to dental avulsion and produced more consistent and higher-quality answers than ChatGPT and Gemini. According to the findings, LLMs based on academic databases can provide more accurate and reliable information. In the future, through the development of LLMs specific to the branches of dentistry, artificial intelligence systems can produce higher quality and consistent information.}
}
@article{BRITOZERON2025570,
title = {POS0311 SARCOIDOSIS AS A SYSTEMIC DISEASE: IDENTIFYING PATTERNS OF MULTIORGAN-SPECIFIC INVOLVEMENT AND EPIDEMIOLOGICAL PROFILING THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE-DRIVEN CLUSTERING},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {570-571},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.698},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725017315},
author = {P. Brito-Zerón and A. Flores-Chávez and C. Feijoo-Masso and G. Policarpo-Torres and R. {Gómez de la Torre} and B. Escalante and J.M. Lopez-Dupla and C. Soler-i-Ferrer and E. Fonseca-Aizpuru and A. González-García and J.C. Herranz-Pérez and S. {GARCÍA MORILLO} and A. Alguacil and Á. {Robles Marhuenda} and M. Bonet and M.V. Villalba-García and A.J. Chamorro and B. {De Miguel-Campo} and M.G. {CRUZ CAPARROS} and M. {Akasbi Montalvo} and A. Mayer-Fuentes and M. Ramos-Casals},
keywords = {Registries, Artificial Intelligence, Prognostic factors, Epidemiology, Comorbidities},
abstract = {Background:
Sarcoidosis is a heterogeneous granulomatous disease characterized by a wide range of clinical manifestations stemming from multiple organ involvement. While clustering techniques offer a robust method for uncovering these patterns, traditional approaches may fail to fully capture the complexity of multisystem diseases like sarcoidosis. Leveraging generative artificial intelligence (AI) offers a unique opportunity to improve data analysis and interpretation in complex systemic settings, providing novel insights into multifaceted disease patterns and guiding both hypothesis generation and clinical decision-making.
Objectives:
This study aimed to identify distinct clusters of organ involvement in patients with sarcoidosis, assess their corresponding epidemiological characteristics, and highlight the benefits of AI-driven methodologies in handling complex multisystem data—underscoring the feasibility and advantages of advanced AI-based approaches for systemic phenotypes in this heterogeneous disease.
Methods:
We conducted an AI-assisted analysis to identify organ-involvement clusters in a dataset of 2,187 anonymized sarcoidosis patients (Spanish National Registry SarcoGEAS, all fulfilling the 1999 ATS/ERS/WASOG criteria). Organ involvement was retrospectively determined in each patient at the time of diagnosis using the 2014 WASOG organ assessment instrument. Clustering was carried out via the k-means algorithm in Python's scikit-learn library (version 1.0.2). The optimal number of clusters was determined using the elbow method, supported by silhouette scores to evaluate cluster quality. Statistical comparisons (ANOVA, Kruskal-Wallis, and Chi-square tests—using exact tests for low-frequency data) were applied to characterize cluster differences. Significance was set at p < 0.05, ensuring rigorous evaluation of epidemiological and clinical distinctions. The analysis was conducted in a secure computational environment using generative AI (via OpenAI's GPT-4 model) using Python (version 3.9) with essential libraries including pandas (1.4.3) for data manipulation, numpy (1.21.5) for numerical computations, and matplotlib (3.5.1) and seaborn (0.11.2) for visualizations. Data processing and analysis workflows adhered to GDPR standards to ensure patient privacy. All patient data were anonymized prior to analysis, and no identifiable information was accessed at any point. Code modularity and reproducibility were prioritized, with all scripts managed in version control systems (e.g., Git) to enable transparency.
Results:
The cohort comprised 2,187 patients, with a female predominance (61.4%), a mean age at diagnosis of 48.6 years (range: 5-95), and a majority identifying as White (88%). Cluster quality analysis identified 5 as the optimal number of clusters potential; an additional clinically significant cluster (hepatic-splenic) was manually identified and confirmed post hoc through statistical validation. Ultimately, we defined six distinct clusters of systemic involvement: the lymphadenopathic cluster (Cluster 1, characterized by 100% lymphadenopathy), the pulmonary cluster (Cluster 2, characterized by 100% lung involvement and co-occurring 100% lymphadenopathy), the cutaneous cluster (Cluster 3, 100% of cutaneous involvement), the ocular cluster (Cluster 4, 100% ocular involvement), the hepato-splenic cluster (Cluster 5, defined by 100% hepatic and splenic involvement), and the multisystemic cluster (Cluster 6, exhibiting generalized, but not predominant, organ involvement). Each cluster demonstrated statistically significant epidemiological differences (Figure 1). For age, the lymphadenopathic cluster had the highest mean (51.7 years), whereas the cutaneous cluster had the lowest (42.9 years) (p = 0.00056). For sex, the proportion of females ranged from 49.0% in the hepato-splenic cluster to 65.9% in the ocular cluster (p = 0.000017). For ethnicity, the proportion of White patients ranged from 81.4% in the ocular cluster to 94.6% in the lymphadenopathic cluster (p = 0.00135).
Conclusion:
This generative AI-driven clustering study successfully identified six distinct patterns of systemic involvement in sarcoidosis, offering a deeper understanding of the disease's heterogeneity. Each cluster exhibited specific epidemiological profiles: cutaneous cluster was associated with the youngest age at sarcoidosis diagnosis, lymphadenopathic cluster with the oldest age and the highest frequency of White patients, ocular cluster with the highest frequency of women and highest frequency of non-White patients, and the hepato-splenic cluster with the highest rate of men. The significant epidemiological disparities among clusters underscore the disease's variability and offer a framework for refined patient stratification.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{LEE2024102846,
title = {Generating TRIZ-inspired guidelines for eco-design using Generative Artificial Intelligence},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102846},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102846},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004944},
author = {C.K.M. Lee and Jingying Liang and K.L. Yung and K.L. Keung},
keywords = {Eco-design, TRIZ, Large Language Models, Generative AI},
abstract = {Environmental considerations are emerging as stimuli for innovation during the eco-design ideation process. Integrating TRIZ (Teoriya Resheniya Izobretatelskikh Zadatch─Theory of Inventive Problem Solving) methodology into eco-design offers a structured problem-solving approach to address sustainability challenges. However, developing innovative designs requires expertise in TRIZ concepts and access to resources, which makes it a time-consuming process and can limit its application for eco-design innovation quickly. This study leverages the analytical and generative capabilities of large language models (LLMs) to enhance the TRIZ methodology and automate the ideation process in eco-design. An intelligent tool, “Eco-innovate Assistant,” is designed to provide users with eco-innovative solutions with design sketches. Its effectiveness is validated and evaluated through comparative studies. The findings demonstrate the potential of LLMs in automating design processes, catalyzing a transformation in AI-driven innovation and ideation in eco-design.}
}
@article{BRITOZERON20252097,
title = {ABS0885 COMPLEMENT CONSUMPTION PATTERNS AS AN EARLY PREDICTOR OF SYSTEMIC SJÖGREN DISEASE: GENERATIVE ARTIFICIAL INTELLIGENCE-ASSISTED ANALYSIS USING STRATIFIED CROSS-VALIDATION GENERALIZABILITY MODELS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2097-2098},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1702},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037550},
author = {P. Brito-Zerón and A. Flores-Chávez and L.T. {Delgado Garcia} and I.F. Horváth and R. Priori and H. Bootsma and B. Armagan and V. Manfrè and S. Praprotnik and G. Hernandez-Molina and R. {Pereira da Costa} and R. Gerli and M. Rischmueller and Y. Suzuki and R. Solans-Laqué and S. Pasoto and E. Skoglund and I. Sanchez-Berna and A. Alunno and V. {Fernandes Moça Trevisani} and V. Valim and S. {Melchor Díaz} and B. {Maure Noia} and E. Fonseca-Aizpuru and H. Nakamura and L.D. Miguel and M. Vázquez and M. {Akasbi Montalvo} and G. Policarpo-Torres and B. {De Miguel-Campo} and A. Szántó and A. Gattamelata and A. Vissink and L. Quartuccio and L. Kiliç and K. Perdan-Pirkmajer and V.C. Romão and E. Bartoloni and S. Downie-Doyle and Y. Fujisawa and M. Ramos-Casals},
keywords = {Validation, Artificial Intelligence},
abstract = {Background:
Complement consumption, characterized by decreased C3 and/or C4 levels, is a hallmark of immune complex-mediated inflammation and vascular involvement in patients with systemic autoimmune diseases. In patients with Sjögren Disease (SjD), hypocomplementemia at diagnosis has been mainly linked to an increased risk of lymphoma. By analysing the relationship between complement consumption profiles and systemic activity in the largest international cohort, we aim to refine early prognostic paradigms and inform tailored clinical surveillance strategies in SjD, thereby addressing a critical gap in precision medicine for this complex autoimmune disease.
Objectives:
The objectives of this study were to identify and classify complement consumption patterns, investigate their association with an early phenotype consisting of systemic activity across ESSDAI domains while adjusting for age and gender, and explore how cross-validation techniques may validate the predictive accuracy and generalizability of developed models.
Methods:
This study analyzed data from the International Sjögren Big Data Registry. Patients were categorized into four distinct groups according to their complement consumption patterns (isolated low C3, isolated low C4, combined low C3 and C4, and normal C3 and C4 levels). We used Chi-square tests to evaluate univariate associations, and Kruskal-Wallis H-test and Mann-Whitney U test to investigate significant differences with respect to systemic activity (mean ESSDAI score and DAS categories). Multivariable logistic regression models were developed to analyze associations between complement patterns and ESSDAI domains, adjusting for age and gender. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated. A five-fold stratified cross-validation was carried out to rigorously evaluate the models' generalizability, with the Area Under the Curve (AUC) serving as the primary performance metric. Generative Artificial Intelligence (AI) (ChatGPT-4o model) was used within a secure offline environment to automate anonymized data recoding and statistical scripting. Python libraries, including pandas, statsmodels, and scikit-learn, were integral for data processing, model development, and cross-validation.
Results:
Complement values determined at diagnosis were available in 13,710 patients. Stratification according to the 4 complement consumption patterns identified that 79.58% of patients had normal levels of C3 and C4, 7.42% exhibited isolated low C3, 6.90% showed isolated low C4, and 6.09% presented combined low C3 and C4 levels. Combined low C3-C4 levels exhibited the highest mean ESSDAI score (11.41), follwed by isolated low C3, isolated low C4 and normocomplementemia (mean ESSDAI score of 9.26, 7.39, and 5.66, respectively) (Figure 1); Kruskal-Wallis H-test revealed a highly significant difference between the groups (p<0.001), as well as pairwise comparisons using the Mann-Whitney U test (p<0.001). The Chi-square test revealed significant differences in the distribution of DAS categories across the C3-C4 combined groups (χ2=476.41, p<0.001) (Figure 2). However, multivariate logistic regression confirmed significant associations in only three domains. For the pulmonary domain, combined low C3 and C4 levels were associated with the highest odds of activity (OR: 3.12, 95% CI: 2.50–3.91, p < 0.001; AUC: 0.591). In the biological domain, isolated low C3 strongly correlated with activity (OR: 2.45, 95% CI: 1.98–3.03, p < 0.001; AUC: 0.580). For constitutional symptoms, isolated low C3 was associated with the highest activity frequency (18.54%), whereas normal complement levels showed the lowest frequency (11.06%, OR: 0.56, 95% CI: 0.48–0.67, p < 0.001; AUC: 0.563). After adjusting for epidemiological factors, sex and age emerged as influential variables: men had higher odds of constitutional activity (OR 1.24, 95% CI: 1.02–1.52, p = 0.03), while older age had a protective effect, reducing systemic activity by about 1% per year (OR: 0.99, 95% CI: 0.99–1.00, p = 0.0003). The AUC values obtained after running the five-fold stratified cross-validation generalizability models ranged between 0.56 and 0.59, indicating modest ability to discriminate between active and inactive states.
Conclusion:
This study demonstrates that complement consumption patterns are strongly associated with baseline systemic activity in SjD, highlighting their potential as early prognostic markers. While complement patterns provide valuable insights for risk stratification, the current predictive models exhibit modest discriminatory ability (AUC values between 0.5 and 0.6), suggesting that complement patterns are relevant but insufficient alone as predictors to improve clinical applicability. The nuanced influence of epidemiological factors—such as the protective effect of age and the increased susceptibility of men to systemic disease—adds complexity to our understanding of early systemic Sjögren.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{BAGENAL20241118,
title = {Generative artificial intelligence and scientific publishing: urgent questions, difficult answers},
journal = {The Lancet},
volume = {403},
number = {10432},
pages = {1118-1120},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)00416-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624004161},
author = {Jessamy Bagenal}
}
@article{BRUNTON2025102110,
title = {Using generative artificial intelligence to enhance the performance of disadvantaged students in secondary education},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {102110},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.102110},
url = {https://www.sciencedirect.com/science/article/pii/S259029112500840X},
author = {Ryan J. Brunton and Soukaina Rhazzafe and Raymond Moodley and Stefan Kuhn and Fabio Caraffini and Sara Wilford and Rachel Higginbottom and Simon Colreavy-Donnelly and Mario Gongora},
keywords = {Disadvantaged pupils, Pupil premium, Feedback, Education, Large language models, Artificial intelligence, Generative AI},
abstract = {We show that generative AI can support disadvantaged students, improve grades, and help close the attainment gap between pupil premium (PP) and students with special education needs (SEN). It can also alleviate teacher workload, especially for PP and SEN students, by minimising marking and feedback time, enabling better lesson planning and interventions, which can enhance teacher retention and staffing. We focus on disadvantaged students with SEN and low-income families and use AI for personalised feedback and lesson planning in arts and humanities. This enables school leaders and parents to view the qualitative and quantitative student progress. The results of this study demonstrate the potential of using AI-based systems to help close the attainment gap between disadvantaged students and their peers. The intervention given to these pupils would have been an unreasonable demand on the current teacher workload in the UK.}
}
@article{GLYNN2024596,
title = {Suspected undeclared use of generative artificial intelligence},
journal = {Intelligent Pharmacy},
volume = {2},
number = {5},
pages = {596-597},
year = {2024},
issn = {2949-866X},
doi = {https://doi.org/10.1016/j.ipha.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949866X24000492},
author = {Alex Glynn},
keywords = {Generative artificial intelligence, Transparency, Accountability},
abstract = {In a recent article in Intelligent Pharmacy, a portion of the text appears to have been generated by a generative artificial intelligence (AI) system. The usage of AI is not documented in the article. If AI was used, therefore, the article is in violation of the journal's policy on generative AI use and declaration.}
}
@article{DHAWAN202447,
title = {Generative artificial intelligence in surgery: balancing innovation with ethical challenges},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {90},
pages = {47-48},
year = {2024},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2024.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1748681524000731},
author = {Ravi Dhawan and Akshay Nair and Denys Shay}
}
@article{HYUNBAEK2023102030,
title = {Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence},
journal = {Telematics and Informatics},
volume = {83},
pages = {102030},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102030},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000941},
author = {Tae {Hyun Baek} and Minseong Kim},
keywords = {ChatGPT, Generative artificial intelligence (AI), Uses and gratifications theory, Creepiness, Trust, Continuance intention},
abstract = {Few studies have examined user motivations to use generative artificial intelligence (AI). This research aims to address this gap by examining how user motivations for ChatGPT usage affect perceived creepiness, trust, and the intention to continue using AI chatbot technology. The findings of an online survey (N = 421) reveal a negative relationship between personalization and creepiness, while task efficiency and social interaction are positively associated with creepiness. Increased levels of creepiness, in turn, result in decreased continuance intention. Furthermore, task efficiency and personalization have a positive impact on trust, leading to increased continuance intention. The results contribute to the field of human–computer interaction by investigating the motivations for utilizing generative AI chatbots and advancing our comprehension of AI creepiness, trust, and continuance intention. The practical ramifications of this research can inform the design of user interfaces and the development of features for generative AI chatbots.}
}
@article{HIROSAWA2025,
title = {Utility of Generative Artificial Intelligence for Japanese Medical Interview Training: Randomized Crossover Pilot Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/77332},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000996},
author = {Takanobu Hirosawa and Masashi Yokose and Tetsu Sakamoto and Yukinori Harada and Kazuki Tokumasu and Kazuya Mizuta and Taro Shimizu},
keywords = {artificial intelligence, generative artificial intelligence, medical interview training, mock patient, simulation education},
abstract = {Background
The medical interview remains a cornerstone of clinical training. There is growing interest in applying generative artificial intelligence (AI) in medical education, including medical interview training. However, its utility in culturally and linguistically specific contexts, including Japanese, remains underexplored. This study investigated the utility of generative AI for Japanese medical interview training.
Objective
This pilot study aimed to evaluate the utility of generative AI as a tool for medical interview training by comparing its performance with that of traditional face-to-face training methods using a simulated patient.
Methods
We conducted a randomized crossover pilot study involving 20 postgraduate year 1‐2 physicians from a university hospital. Participants were randomly allocated into 2 groups. Group A began with an AI-based station on a case involving abdominal pain, followed by a traditional station with a standardized patient presenting chest pain. Group B followed the reverse order, starting with the traditional station for abdominal pain and subsequently within the AI-based station for the chest pain scenario. In the AI-based stations, participants interacted with a GPT-configured platform that simulated patient behaviors. GPTs are customizable versions of ChatGPT adapted for specific purposes. The traditional stations involved face-to-face interviews with a simulated patient. Both groups used identical, standardized case scenarios to ensure uniformity. Two independent evaluators, blinded to the study conditions, assessed participants’ performances using 6 defined metrics: patient care and communication, history taking, physical examination, accuracy and clarity of transcription, clinical reasoning, and patient management. A 6-point Likert scale was used for scoring. The discrepancy between the evaluators was resolved through discussion. To ensure cultural and linguistic authenticity, all interviews and evaluations were conducted in Japanese.
Results
AI-based stations scored lower across most categories, particularly in patient care and communication, than traditional stations (4.48 vs 4.95; P=.009). However, AI-based stations demonstrated comparable performance in clinical reasoning, with a nonsignificant difference (4.43 vs 4.85; P=.10).
Conclusions
The comparable performance of generative AI in clinical reasoning highlights its potential as a complementary tool in medical interview training. One of its main advantages lies in enabling self-learning, allowing trainees to independently practice interviews without the need for simulated patients. Nonetheless, the lower scores in patient care and communication underline the importance of maintaining traditional methods that capture the nuances of human interaction. These findings support the adoption of hybrid training models that combine generative AI with conventional approaches to enhance the overall effectiveness of medical interview training in Japan.
Trial Registration
UMIN-CTR UMIN000053747; https://center6.umin.ac.jp/cgi-open-bin/ctr_e/ctr_view.cgi?recptno=R000061336}
}
@article{PATEL2024105791,
title = {Generative artificial intelligence versus clinicians: Who diagnoses multiple sclerosis faster and with greater accuracy?},
journal = {Multiple Sclerosis and Related Disorders},
volume = {90},
pages = {105791},
year = {2024},
issn = {2211-0348},
doi = {https://doi.org/10.1016/j.msard.2024.105791},
url = {https://www.sciencedirect.com/science/article/pii/S2211034824003687},
author = {Mahi A. Patel and Francisco Villalobos and Kevin Shan and Lauren M. Tardo and Lindsay A. Horton and Peter V. Sguigna and Kyle M. Blackburn and Shanan B. Munoz and Tatum M. Moog and Alexander D. Smith and Katy W. Burgess and Morgan McCreary and Darin T. Okuda},
keywords = {Multiple sclerosis, Artificial intelligence, ChatGPT, Diagnosis, Generative AI},
abstract = {Background
Those receiving the diagnosis of multiple sclerosis (MS) over the next ten years will predominantly be part of Generation Z (Gen Z). Recent observations within our clinic suggest that younger people with MS utilize online generative artificial intelligence (AI) platforms for personalized medical advice prior to their first visit with a specialist in neuroimmunology. The use of such platforms is anticipated to increase given the technology driven nature, desire for instant communication, and cost-conscious nature of Gen Z. Our objective was to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in individuals earlier than their clinical timeline, and to assess if the accuracy differed based on age, sex, and race/ethnicity.
Methods
People with MS between 18 and 59 years of age were studied. The clinical timeline for people diagnosed with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). Chats were conducted using both actual and derivatives of their age, sex, and race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was estimated for time to diagnosis, clustered by subject. The p-value testing for differences in time to diagnosis was accomplished using a general Wilcoxon test. Logistic regression (subject-specific intercept) was used to capture intra-subject correlation to test the accuracy prior to and after the inclusion of MRI data.
Results
The study cohort included 100 unique people with MS. Of those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a total of 529 people that represented digital simulations of the original cohort of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing for 629 scripted conversations to be analyzed. The estimated median time to diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no difference in the diagnostic accuracy between ages and by race/ethnicity prior to the inclusion of MRI data. However, prior to including the MRI data, males had a 47% less likely chance of a correct diagnosis relative to females (p=0.05). Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 4.0-fold greater for Gen Z participants, relative to non-Gen Z participants (p=0.01) with the diagnostic accuracy being 68% less in males relative to females (p=0.009), and 75% less for White subjects, relative to non-White subjects (p=0.0004).
Conclusion
Although generative AI platforms enable rapid information access and are not principally designed for use in healthcare, an increase in use by Gen Z is anticipated. However, the obtained responses may not be generalizable to all users and bias may exist in select groups.}
}
@article{WINNIFRITH2024102794,
title = {Generative artificial intelligence for de novo protein design},
journal = {Current Opinion in Structural Biology},
volume = {86},
pages = {102794},
year = {2024},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2024.102794},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X24000216},
author = {Adam Winnifrith and Carlos Outeiral and Brian L. Hie},
abstract = {Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called ‘de novo’ design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example, in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.}
}
@article{MATSUBARA2025172,
title = {Research misconduct: Use of generative artificial intelligence in writing may lower the threshold},
journal = {European Journal of Obstetrics & Gynecology and Reproductive Biology},
volume = {304},
pages = {172-173},
year = {2025},
issn = {0301-2115},
doi = {https://doi.org/10.1016/j.ejogrb.2024.11.038},
url = {https://www.sciencedirect.com/science/article/pii/S030121152400650X},
author = {Shigeki Matsubara and Daisuke Matsubara}
}
@article{DINAPOLI2024S2935,
title = {1871: Generative artificial intelligence for toxicity detection in radiotherapy},
journal = {Radiotherapy and Oncology},
volume = {194},
pages = {S2935-S2936},
year = {2024},
note = {ESTRO 2024, 3-7 May 2024, Glasgow, UK},
issn = {0167-8140},
doi = {https://doi.org/10.1016/S0167-8140(24)02186-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167814024021868},
author = {Nicola Dinapoli and Francesco Esposito and Martina D'Antoni and Vito Lanzotti and Luca Tagliaferri and Mariangela Massaccesi and Francesco Miccichè and Vincenzo Valentini and Maria Antonietta Gambacorta}
}
@article{CHAN2025102733,
title = {Generative artificial intelligence in a VUCA world: the ‘Lived Experiences’ of Southeast Asian teachers’ use of AI in higher education},
journal = {International Journal of Educational Research},
volume = {133},
pages = {102733},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102733},
url = {https://www.sciencedirect.com/science/article/pii/S088303552500206X},
author = {Nee Nee Chan and Richard Peter Bailey and Mabel Hwee Joo Tan and Genevieve Flores Dipolog and Garry Wei Han Tan and Saeid Motevalli and Nadia Samsudin and Chin Siang Ang},
keywords = {ChatGPT, Hermeneutic phenomenology, VUCA model, Educational quality, AI policy guidelines},
abstract = {This study explores how generative intelligence (GenAI) is used in teaching and learning, assessments, and research at Southeast Asian (SEA) universities. Using hermeneutic phenomenology as the philosophical underpinning and research methodology, SEA teachers’ ‘lived experiences’ of using ChatGPT and other GenAI tools were uncovered. 38 teachers from 10 SEA countries participated in 11 focus group interviews over five months. Three themes emerged: Learning Anew; Disequilibrium and Lack of Rootedness; and Ambiguity about New Norms, New Practices. It was found that teachers work with GenAI in deeply personal, fragmented, and continuously evolving ways. GenAI took the form of novel work companions, enhancing the efficiency and effectiveness of some work practices. It also was a disruptor to old habits of thinking, behaviour and practices. Teachers were in a state of disequilibrium in this new world beset by VUCA (volatility, uncertainty, complexity, and ambiguity). Some felt overwhelmed and ‘at breaking point’. A lack of rootedness in teachers’ beliefs and practices emerged. Teachers were generally against the notions of plagiarism and academic integrity held by students who believed the ends justified the means. However, with new ways of teaching, learning and assessment, many teachers recognised their beliefs and practices would have to change. Thus, in the absence of detailed AI guidelines, they called for the urgent need to establish boundaries and teach AI literacy to promote innovative and responsible use. In this VUCA world, more targeted change management training for teachers and students was strongly needed.}
}
@article{MUNIR2025102439,
title = {Pharmacy meets AI: Effect of a drug information activity on student perceptions of generative artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {10},
pages = {102439},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102439},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725001601},
author = {Faria Munir and Heather Ipema and Rahul Nohria and Divita Singh},
keywords = {ChatGPT, Artificial intelligence, Drug information, Student perceptions, Generative artificial intelligence, Large language model, Health professional student, Health professional education},
abstract = {Objective
The current study assessed pharmacy students' perceptions about generative AI before and after participation in a ChatGPT-based drug information activity.
Methods
In 2024, students at three colleges of pharmacy completed a baseline and post-activity survey on their perceptions of ChatGPT including its reliability, usefulness, and impact on academic performance and critical thinking. The survey was modified from the TAME-ChatGPT assessment and used a 5-point Likert scale. After the baseline survey, students answered clinically relevant drug information questions on their own using primary or tertiary resources and compared their answers with ChatGPT responses. Independent t-test samples were used to compare baseline and post-activity surveys.
Results
A total of 227 students completed the pre-survey and 203 students completed the post-survey. Students' concerns about the reliability of ChatGPT increased after completing the drug information activity (pre-survey: 3.57 ± 0.96; post-survey: 3.88 ± 1.11; p = 0.002). Students' concerns about reliance on ChatGPT and prevention of critical thinking increased (pre-survey: 3.30 ± 1.34; post-survey: 3.57 ± 1.21; p = 0.031). The following areas decreased after the activity: enthusiasm about ChatGPT as learning and research tool (pre-survey: 3.60 ± 1.02; post-survey: 3.32 ± 1.18; p = 0.008), viewing ChatGPT as an important tool for academic success (pre-survey: 3.40 ± 1.13; post-survey: 3.12 ± 1.23; p = 0.015), and concern regarding being accused of plagiarism when using ChatGPT(pre-survey: 4.12 ± 0.96; post-survey: 3.91 ± 1.10; p = 0.031). Open-ended responses revealed that students largely perceived ChatGPT as unreliable for drug information, citing concerns about accuracy and outdated content. However, some students noted its potential usefulness for non-clinical tasks such as generating ideas, organizing content, or providing general overviews.
Conclusion
After a hands-on ChatGPT-based drug information activity, pharmacy students reported increased concerns about reliability and over-reliance on artificial intelligence-based technology. The results of this study may encourage pharmacy educators to implement classroom activities for active exploration of the benefits and challenges of generative AI.
Contribution to literature
Limited published data describes pharmacy student perceptions of artificial intelligence platforms as a drug information source. There is even less literature with pre- and post-data after implementing an activity in which students gain hands-on experience critiquing an artificial intelligence platform response. Therefore, this study was conducted to evaluate student perceptions after using ChatGPT in the classroom and comparing its performance to their own responses based on information from primary and tertiary literature. The results demonstrate that despite enthusiasm before using ChatGPT, concerns for reliability and hindering thinking increased after a observing the limitations of its performance in answering drug information questions.}
}
@article{LI2025112349,
title = {Generative artificial intelligence-based framework for bridging lifecycle gaps in semiconductor HVAC systems},
journal = {Journal of Building Engineering},
volume = {105},
pages = {112349},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112349},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225005868},
author = {Yanlin Li and Chi-Yun Liu and Hsiao-Ping Ni and Fermodelie Paul and Wai Oswald Chong and Jui-Sheng Chou},
keywords = {HVAC system performance, Semiconductor manufacturing facility, HVAC equipment degradation prediction, AI-Driven models, Advanced building systems},
abstract = {The production of modern semiconductor chips is susceptible to variations in air temperature, humidity, and quality, mainly as chip dimensions shrink to smaller than atmospheric dust particles. Heating, ventilation, and air-conditioning (HVAC) systems are critical in this context, given their role in stabilizing these environmental factors. Gaps in Design and Construction (D&C) can critically undermine the reliability, performance, quality, and lifespan of HVAC systems during their Operation and Maintenance (O&M) stages. Current studies illustrate how existing models predicted performance degradation and how the Design, Construction, Operations, and Maintenance (DCOM) gap arises. Despite the substantial implications for Semiconductor Manufacturing Facilities (SMFs), research on HVAC performance degradation remains limited, particularly in capturing and quantifying degradation-related patterns. Compared to other types of buildings, the renovation and transformation of high-end manufacturing facilities are more frequent, and customized design and equipment also lead to model application issues, such as data limitations and incompatibility. This paper aims to propose a novel HVAC system degradation prediction model utilizing Generative Adversarial Networks (GAN) and Informer algorithms based on the building characteristics and operation mode of semiconductor facilities to overcome the limitations of data scarcity and long-term prediction, evaluate the comprehensive impact of the gap between D&C and O&M stages on HVAC systems. By integrating data augmentation, this model reduces data dependency and can handle incomplete, inconsistent, or discrete data for early prediction in operation, bridging the gap between D&C and O&M stages, and improving the overall efficiency and effectiveness of facility operation and maintenance. In addition to SMFs, the proposed model exhibits considerable application potential in other high-precision building types due to the structural variability.}
}
@article{LIM2025105306,
title = {Development and implementation of a generative artificial intelligence-enhanced simulation to enhance problem-solving skills for pre-service teachers},
journal = {Computers & Education},
volume = {232},
pages = {105306},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105306},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000740},
author = {Jieun Lim and Unggi Lee and Junbo Koh and Yeil Jeong and Yunseo Lee and Gyuri Byun and Haewon Jung and Yoonsun Jang and Sanghyeok Lee and Jewoong Moon},
keywords = {Generative AI, Virtual simulation, Teacher education, Problem-based learning, Design-based research},
abstract = {Effective teachers should be equipped to solve complex problems across diverse instructional and learning contexts. However, many teacher training programs struggle to bridge the gap between theoretical knowledge to real-world applications. The current study tackles this challenge by developing a generative artificial intelligence (GenAI)-enhanced simulation to improve preservice teachers’ problem-solving abilities. Using design-based research (DBR), we created a virtual environment that integrates problem-based learning (PBL) with GenAI technology. The simulation was rigorously refined through expert review and usability testing before being implemented in a teacher training program. We evaluated its effectiveness by comparing three groups: (1) a text-based scenario, (2) a rule-based simulation, and (3) a GenAI-enhanced simulation. Pre- and post-test results showed significant improvements in problem-solving skills for both the rule-based and GenAI-enhanced simulation groups compared to the text-based scenario group. Notably, qualitative findings revealed that students reported heightened realism and immersion in the GenAI-enhanced simulation, attributing this to more dynamic interactions with AI agents that helped them better contextualize PBL and increased their motivation. Our study findings contribute design principles for developing GenAI-enhanced simulations in teacher education, offering promising insights into leveraging AI technology to create more engaging and effective training experiences.}
}
@article{KSHETRI2024102760,
title = {The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models},
journal = {Telecommunications Policy},
volume = {48},
number = {5},
pages = {102760},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000570},
author = {Nir Kshetri},
keywords = {Academic industry, ChatGPT, Generative artificial intelligence, Institutional theory, Large language models, Theorization},
abstract = {This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.}
}
@article{MAY2024155,
title = {Would Uro_Chat, a Newly Developed Generative Artificial Intelligence Large Language Model, Have Successfully Passed the In-Service Assessment Questions of the European Board of Urology in 2022?},
journal = {European Urology Oncology},
volume = {7},
number = {1},
pages = {155-156},
year = {2024},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2023.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2588931123001785},
author = {Matthias May and Katharina Körner-Riffard and Martin Marszalek and Klaus Eredics}
}
@article{HUESO2023309,
title = {Is Generative Artificial Intelligence the Next Step Toward a Personalized Hemodialysis?},
journal = {Revista de Investigación Clínica},
volume = {75},
number = {6},
pages = {309-317},
year = {2023},
issn = {0034-8376},
doi = {https://doi.org/10.24875/RIC.23000162},
url = {https://www.sciencedirect.com/science/article/pii/S0034837625001597},
author = {Miguel Hueso and Rafael Álvarez and David Marí and Vicent Ribas-Ripoll and Karim Lekadir and Alfredo Vellido},
keywords = {Personalized hemodialysis, Artificial intelligence, Natural language processing, Large Language Models},
abstract = {ABSTRACT
Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI’s chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients’ lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients’ engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients’ care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists’ collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients’ quality of life. (REV INVEST CLIN. 2023;75(6):309-17)}
}
@article{CHENG2024899,
title = {Principles and challenges of generative artificial intelligence detection},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {4},
pages = {899-901},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S000709122400415X},
author = {Kunming Cheng and Wanqing Li and Nan Zhang and Xiaojun Liu and Haiyang Wu},
keywords = {academic publishing, artificial intelligence, ChatGPT, detection, generative AI, peer review}
}
@article{XU2024e32364,
title = {Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32364},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32364},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024083956},
author = {Rui Xu and Zhong Wang},
keywords = {ChatGPT, Healthcare, Digital media, Applications, Opportunities, Challenges, Digital health, Generative artificial intelligence, Large language models, Artificial intelligence generated content},
abstract = {Introduction
The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges.
Methods
This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the sub-categories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers.
Results
This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics.
Conclusions
The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs’ economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.}
}
@article{WOBST2025115571,
title = {Avoiding algorithm errors in textual analysis: A guide to selecting software, and a research agenda toward generative artificial intelligence},
journal = {Journal of Business Research},
volume = {199},
pages = {115571},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115571},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325003947},
author = {Janice Wobst and Rainer Lueg},
keywords = {Generative AI, Large language models, Textual analysis, Software selection, Algorithm error, Validity, Reliability, Value-based management},
abstract = {The use of textual analysis is expanding in organizational research, yet software packages vary in their compatibility with complex constructs. This study helps researchers select suitable tools by focusing on phrase-based dictionary methods. We empirically evaluate four software packages—LIWC, DICTION, CAT Scanner, and a custom Python tool—using the complex construct of value-based management as a test case. The analysis shows that software from the same methodological family produces highly consistent results, while popular but mismatched tools yield significant errors such as miscounted phrases. Based on this, we develop a structured selection guideline that links construct features with software capabilities. The framework enhances construct validity, supports methodological transparency, and is applicable across disciplines. Finally, we position the approach as a bridge to AI-enabled textual analysis, including prompt-based workflows, reinforcing the continued need for theory-grounded construct design.}
}
@article{TRAN2024104079,
title = {Visual narratives in nursing education: A generative artificial intelligence approach},
journal = {Nurse Education in Practice},
volume = {79},
pages = {104079},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104079},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324002087},
author = {Linh Duc Tran and Neo Tung and Eugene Tordecilla Macalinga and Arthur Tang and Brigitte Woo and Wilson Tam},
keywords = {Nursing education, Visual narrative, Generative artificial intelligence, DALL-E},
abstract = {Aim
The aim of this paper is to investigate the incorporation of visual narratives, such as comics and graphics, into nursing education using Generative Artificial Intelligence (GAI) models like DALL-E.
Background
Visual narratives serve as a powerful method for communicating intricate concepts in nursing education. Despite their advantages, challenges in creating effective educational comics persist due to the need for expertise in graphic design and the associated time and resource constraints.
Design
This study examines existing literature that highlights the efficacy of visual narratives in education and demonstrates the potential of GAI models, specifically DALL-E, in creating visual narratives for nursing education.
Methods
We analyze the potential of GAI models, specifically DALL-E, to create visual narratives for educational purposes. This was demonstrated through illustrative examples addressing sensitive topics, illustrating research methodology and designing recruitment posters for clinical trials. Additionally, we discussed the necessity of reviewing and editing the text generated by DALL-E to ensure its accuracy and relevance in educational contexts. The method also considered legal concerns related to copyright and ownership of the generated content, highlighting the evolving legal landscape in this domain.
Results
The study found that GAI, specifically DALL-E, has significant potential to bridge the gap in creating visual narratives for nursing education. While offering cost-effectiveness and accessibility, GAI tools require careful consideration of challenges such as text-related errors, misinterpretation of user prompts and legal concerns.
Conclusions
GAI models like DALL-E offer promising solutions for enhancing visual storytelling in nursing education. However, their effective integration requires a collaborative approach, where educators engage with these tools as co-pilots, leveraging their capabilities while mitigating potential drawbacks. By doing so, educators can harness the full potential of GAI to enrich the educational experience for learners through compelling visual narratives.}
}
@article{COLBRAN2023105008,
title = {Generative artificial intelligence in Journal of Biological Chemistry},
journal = {Journal of Biological Chemistry},
volume = {299},
number = {8},
pages = {105008},
year = {2023},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2023.105008},
url = {https://www.sciencedirect.com/science/article/pii/S0021925823020367},
author = {Roger J. Colbran and Alex Toker}
}
@article{KSHETRI2024102716,
title = {Generative artificial intelligence in marketing: Applications, opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {75},
pages = {102716},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102716},
url = {https://www.sciencedirect.com/science/article/pii/S026840122300097X},
author = {Nir Kshetri and Yogesh K. Dwivedi and Thomas H. Davenport and Niki Panteli},
keywords = {ChatGPT, Customer engagement, Customer experience, Generative AI, Personalization},
abstract = {While all functional areas in organizations are benefiting from the recent development in generative artificial intelligence (GAI), marketing has been particularly affected positively by this breakthrough innovation. However, scholars have not paid attention to the transformative impacts GAI has on marketing activities. This editorial article aims to fill this void. It outlines the current state of generative artificial intelligence in marketing. The article discusses the facilitators and barriers for the use of generative artificial intelligence in marketing. It highlights the effectiveness of insights generated by GAI in personalizing content and offerings and argues that marketing content generated by GAI is likely to be more personally relevant than that produced by earlier generations of digital technologies. The article explains how higher efficiency and productivity of marketing activities can be achieved by using GAI to create marketing content. It also describes the roles of insights and marketing content generated by GAI to improve the sales lead generation process. Implications for research, practice and policy are also discussed.}
}
@article{GUO2024102408,
title = {Letter to the editor “A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing”},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102408},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102408},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000471},
author = {Dongke Guo and Yonghua Fu and Zhongxin Zhu}
}
@article{OCHIENG2024102710,
title = {Potential application of generative artificial intelligence and machine learning algorithm in oil and gas sector: Benefits and future prospects},
journal = {Technology in Society},
volume = {79},
pages = {102710},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102710},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002586},
author = {Edward G. Ochieng and Diana Ominde and Tarila Zuofa},
keywords = {Generative artificial intelligence, Machine learning algorithm, Value chain operations, Oil and gas, Productivity performance, Risk management},
abstract = {With the rapid advancement of technology and societies, the global energy sector now acknowledges that by integrating contemporary digital technologies into their operations and capabilities, can improve their competitive advantage and innovation performance and processes. Moreover, energy operators are also facing a significant undertaking: how to best use and secure large amounts of data that promote sustainable productivity performance and minimise potential threats in the oil and gas value chain and project operations. In view of the foregoing, various facets like Generative Artificial Intelligence (GAI) and Machine Learning Algorithms (MLA) are increasingly gaining popularity within oil and gas sector operations. Thus, we explored how GAI and ML algorithms can enhance oil and gas value chain productivity performance. The Principal Component Analysis (PCA) was employed to identify significant GAI and MLA variables influencing performance in the oil and gas value chain, while Structural Equation Modelling (SEM) was used to test regression equations related to their application. The study found that risk portfolios and profiles can be appraised throughout the value chain by effectively utilising GAI and ML algorithms in upstream, midstream and downstream undertakings. While these findings are noteworthy and have significant implications for current practice, the paper advocates that an array of digital technologies beyond GAI and ML can still be examined during future studies to demonstrate a holistic perspective on how digital transformation can be achieved across the energy sector value and project operations.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{WALTERS2024S626,
title = {SA62 Evaluating Generative Artificial Intelligence (GenAI) in Health Technology Assessment (HTA) Content Generation: A Proof-of-Concept Using Canadian Agency for Drugs and Technologies in Health (CADTH) Reimbursement Dossier Forms},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S626},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3143},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524060066},
author = {J. Walters and I. Guerra and K. Rtveladze and J. Joseph and R. Shankar and T. Wiemken and P.A. Dubé and T.C. Woodward}
}
@article{KOHNKE2023100156,
title = {Exploring generative artificial intelligence preparedness among university language instructors: A case study},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100156},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000358},
author = {Lucas Kohnke and Benjamin Luke Moorhouse and Di Zou},
keywords = {Artificial intelligence, AI, Generative AI, University language instructors, Higher education, English},
abstract = {The integration of generative artificial intelligence (AI) in English language teaching presents opportunities and challenges for instructors. This study explores the attitudes of higher education English language instructors towards generative AI tools, their intentions to use them and the institutional support and professional development necessary to teach and learn with them. As the field continues to evolve rapidly, it is essential to comprehend the readiness of front-line language instructors. This qualitative interpretive study seeks to identify the digital competencies and pedagogical knowledge required to implement generative AI in education and provide guidance for the design of professional development programmes that address the challenges and concerns associated with adopting AI. Drawing on semi-structured interviews with twelve instructors at a higher education institution in Hong Kong, the findings reveal the significance of familiarity and confidence with using AI-driven teaching tools, the challenges and concerns language instructors face and the need for tailored support and professional development. The study offers ten practical implications to cultivate language instructors’ digital competencies, pedagogical knowledge and positive attitudes towards integrating AI to enhance their students’ learning experiences.}
}