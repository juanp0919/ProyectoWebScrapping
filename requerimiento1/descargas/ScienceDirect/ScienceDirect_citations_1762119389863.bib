@article{BUSCH2025100213,
title = {The early wave of ChatGPT research: A review and future agenda},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {6},
pages = {100213},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000970},
author = {Peter André Busch and Geir Inge Hausvik and Jeppe Agger Nielsen},
keywords = {Generative AI, Conversational AI, ChatGPT, Literature review},
abstract = {Researchers and practitioners are increasingly engaged in discussions about the hopes and fears of artificial intelligence (AI). In this article, we critically examine the early scholarly response to one prominent form of generative and conversational AI: ChatGPT. The launch of ChatGPT has sparked a surge in research, resulting in a fast-growing but fragmented body of literature. Against this backdrop, we undertook a systematic literature review of 192 empirical articles about ChatGPT to examine, synthesize, and evaluate the foci and gaps in this early wave of research to capture the dominating and immediate scholarly reactions to ChatGPT's release. Our analytical focus covered the following main aspects: perspectives on the purpose, usage, attitudes, and impacts of ChatGPT, as well as the theories and methods scholars apply in studying ChatGPT. Most studies in our sample focus on performance tests of ChatGPT, highlighting its strengths in remembering, understanding, and analyzing content, while revealing limitations in its capacity to generate novel ideas and its hallucination habit. Although the initial wave of ChatGPT research has generated valuable first insights, much of this early research remains a-theoretical, descriptive, and narrowly scoped, with limited attention to broader social, ethical, and institutional implications. These patterns reflect both the rapid publication pace and the early stage of scholarly engagement with this emerging technology. In response, we propose a conceptual model that maps key focus areas of ChatGPT research and suggest ways of strengthening ChatGPT research by proposing a research agenda aimed at advancing more theoretically informed, contextually grounded, and socially responsive studies of generative and conversational AI.}
}
@article{HOGSTEDT2025741535,
title = {Automated computer vision based individual salmon (Salmo salar) breathing rate estimation (SaBRE) for improved state observability},
journal = {Aquaculture},
volume = {595},
pages = {741535},
year = {2025},
issn = {0044-8486},
doi = {https://doi.org/10.1016/j.aquaculture.2024.741535},
url = {https://www.sciencedirect.com/science/article/pii/S0044848624009967},
author = {Espen Berntzen Høgstedt and Christian Schellewald and Rudolf Mester and Annette Stahl},
keywords = {Computer vision, Deep learning, Respiration frequency, Atlantic salmon, Fish welfare, Aquaculture},
abstract = {Salmon farming plays an important role in the Norwegian food industry, supplying a large portion of the world's salmon. Despite its economic importance, salmon farming faces unique biological challenges impacting the health and welfare of the fish. These factors limit the growth of salmon and the full economic potential of salmon farms, highlighting the need for advanced techniques in aquaculture to enhance productivity and sustainability. A key technical challenge is the unavailability of effective monitoring tools, leading to greater difficulties assessing the condition of salmon in water compared to the assessment of the animal stock on land-based farms. To improve the observability of salmon farms, we designed and created a computer-vision based approach for salmon breathing rate estimation (SaBRE), which allows the automatic monitoring of the respiration frequency of each individual salmon in a group of fish, seamlessly covering the entire workflow from video-stream input to the final data output (end-to-end). We thoroughly evaluated the capabilities of our method in two ways. Firstly, we performed a quantitative analysis of the constituent modules of SaBRE, revealing that all modules were highly accurate, including a salmon re-identification module that achieved an accuracy of 99.51 %. Secondly, we analyzed data from a salmon experiment with SaBRE, demonstrating that our algorithm provides high-quality respiration frequency information that can be compared with other types of experimental data to infer biological relationships. For the fish in our experiment, we observed that the ranking of the respiration frequencies in individual salmon remains relatively unchanged both in the short term and over longer periods (i.e., a salmon with a high breathing rate consistently remains among those with the highest rates, regardless of changes in the environment). Furthermore, a significant negative correlation (Pearson correlation coefficients with r values between −0.61 and −0.90 and p values below 0.01) was observed between our algorithm's estimated respiration frequency and the dissolved oxygen (dO2) content in the water. In addition, the average breathing rate of the salmon was observed to increase in response to incidents potentially causing stress.}
}
@article{CHEN2025113881,
title = {Super-sparse-sampling high-resolution photoacoustic microscopy boosted by generative diffusion priors},
journal = {Optics & Laser Technology},
volume = {192},
pages = {113881},
year = {2025},
issn = {0030-3992},
doi = {https://doi.org/10.1016/j.optlastec.2025.113881},
url = {https://www.sciencedirect.com/science/article/pii/S0030399225014720},
author = {Yanhan Chen and Yubin Cao and Guolin Liu and Yiguang Wang and Siyi Cao and Weiliang Yuan and Teng Lian and Qiegen Liu and Xianlin Song},
keywords = {Photoacoustic microscopy, Super-sparse sampling, Diffusion model, Sparse reconstruction},
abstract = {Photoacoustic Microscopy (PAM) is a non-invasive hybrid biomedical imaging technology that combines the advantages of optics and acoustics to provide high-resolution biological tissue information at the submicron scale. Conventional PAM suffers from slow imaging speeds during high-resolution imaging due to the limitations of the laser pulse repetition rate. Although extending the sampling step size (i.e., sparse sampling) can enhance imaging speed and alleviate data collection demands, it might compromise image quality by causing distortions or the loss of fine details. This study presents an enhanced method based on the mean-reverting diffusion model for sparse-sampling high-resolution reconstruction in PAM to address the problem. The model captures prior knowledge of the data distribution by simulating the degradation process from a fully-sampled image to a sparsely-sampled image contaminated with Gaussian noise (mean state). The learned prior is then utilized to iteratively reconstruct a fully-sampled image from the sparsely-sampled one. The results indicate that the IR-SDE method achieves high-resolution sparse-sampling reconstruction for mouse in vivo blood vessel experimental data compared with the Richardson-Lucy deconvolution method (RL Deconv) and CycleGAN method. Under super-sparse sampling (sampling ratios of about 0.4 %), the IR-SDE method reaches an SSIM of 0.742 and a PSNR of 24.22 dB using only about 0.4 % of the fully-sampled pixels, improving 0.597 (∼412 %) in SSIM and 11.51 dB (∼91 %) in PSNR, compared to U-Net method. Even in the case of reconstructing sparsely-sampled PAM images obtained from real-world scenarios without prior training or extensive trainable data, the proposed method still demonstrates satisfactory reconstruction performance. The proposed method is anticipated to improve reconstruction speed and imaging speed, achieving high-resolution reconstruction at super-sparse sampling.}
}
@article{XU2025101227,
title = {The development and validation of a scale on student AI literacy in L2 writing: A domain-specific perspective},
journal = {Journal of Second Language Writing},
volume = {69},
pages = {101227},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101227},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000529},
author = {Linlin Xu and Lu Zhang and Ling Ou and Di Wang},
keywords = {Student AI literacy, Domain-specific AI literacy, L2 writing, Scale development},
abstract = {Artificial Intelligence (AI) is transforming the educational landscape, especially in second language (L2) writing, reshaping how students approach the learning and practice of L2 writing. This shift has highlighted the importance of student AI literacy, which enables students to harness the power of AI tools and navigate the complexities of L2 writing more effectively and responsibly. Despite its significance, research on student AI literacy in L2 writing remains scarce, and there is a notable absence of instruments to measure, diagnose and track its development among L2 student writers. Heeding the call for developing psychometrically validated scales tailored to specific domains or disciplines, this study aims to develop and validate the L2 Writing-Student AI Literacy Scale (L2W-SAILS) for teachers and students to operationalise and assess student AI literacy in L2 writing. Building on relevant seminal works, this study proposed a four-dimension AI literacy framework, including ‘understanding’, ‘use’, ‘evaluation’, and ‘ethics’. Guided by this framework, a 22-item self-reported questionnaire on student AI literacy was developed and validated through exploratory and confirmatory factor analysis involving respectively 435 and 350 Chinese university students. The results confirm that the L2W-SAILS is a reliable measurement scale for assessing student AI literacy in L2 writing, and the proposed four-dimension model is a robust representation of student AI literacy. The findings also contribute to a pedagogical framework that informs AI-assisted teaching and learning of L2 writing.}
}
@article{KAUSHIK2026106302,
title = {Conceptual similarity as aggregation over feature sets in geometric spaces},
journal = {Cognition},
volume = {266},
pages = {106302},
year = {2026},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2025.106302},
url = {https://www.sciencedirect.com/science/article/pii/S0010027725002422},
author = {Karthikeya Kaushik and Bill D. Thompson},
keywords = {Concepts, Similarity, Distributional semantics},
abstract = {Understanding how people judge whether two concepts are similar is a fundamental problem in cognitive science, with implications for theories of learning and reasoning. Human judgments of conceptual similarity often conflict with basic metric assumptions, leading to effects such as judgment asymmetry and violations of the triangle inequality. Classical models of conceptual structure explained these effects via set-based logic applied to manually constructed feature-set representations of concepts. Modern geometric models of conceptual structure offer a scalable, data-driven alternative, but struggle to capture judgment asymmetries via metric-based similarity measures. Here we introduce a modeling framework that combines the merits of these two approaches. Our approach represents concepts as sets of high-dimensional feature embeddings extracted from geometric models via natural language descriptions (e.g. has legs, likes coffee). We present a similarity function appropriate to this setting and show how it can account for classic judgment effects. We evaluate the predictions of this approach against human judgment in two studies: (1) a behavioral study of human similarity judgments among abstract concepts (world countries), and (2) the Nelson free word association dataset. We also formalize a link between our approach and Tversky’s classic Contrast Model. Our model outperforms alternatives and establishes a generally-applicable framework that integrates classic and contemporary approaches to conceptual structure.}
}
@article{UZOCHUKWU2025104888,
title = {Impact of vitamin E and selenium supplementation on growth, reproductive performance, and oxidative stress in dexamethasone-stressed Japanese quail cocks: Vitamin E & selenium in stressed quail cocks},
journal = {Poultry Science},
volume = {104},
number = {3},
pages = {104888},
year = {2025},
issn = {0032-5791},
doi = {https://doi.org/10.1016/j.psj.2025.104888},
url = {https://www.sciencedirect.com/science/article/pii/S0032579125001257},
author = {Ifeanyi Emmanuel Uzochukwu and Luke Chukwudi Ali and Bright Chigozie Amaefule and Chisom C. Okeke and Charles Onochie Osita and Ndubuisi Samuel Machebe and Vesela Yancheva and Dóra Somogyi and Krisztián Nyeste},
keywords = {Dexamethasone-induced stress, Oxidative stress response, Antioxidants, Micronutrient supplementation, Japanese quail reproduction},
abstract = {This study investigated the effects of dietary vitamin E (VE) and selenium (Se) supplementation on body weight changes, blood profile, and semen quality in Dexamethasone (DEX)-stressed Japanese quails. One hundred and five 10-week-old quail cocks were acclimated and divided into five treatment groups: negative control – G1, DEX-treated (20 mgL−1 of drinking water) – G2, DEX + VE (180 mg kg diet−1) – G3; DEX + Se (0.3 mg kg diet−1) – G4; and DEX + VE (180 mg kg diet−1) + Se (0.3 mg kg diet−1) – G5. The birds received their respective treatments over 21 days, and various performance, hematological, and semen quality parameters were measured. Results indicated that DEX treatment significantly reduced weight gain (WG) and feed intake (P < 0.05). Supplementation with VE and Se, individually and combined, ameliorated these effects, with groups G3, G4, and G5 showing similar WG to the control. Hematological analysis revealed significant increases (P < 0.05) in packed cell volume, hemoglobin, and white blood cell count in DEX-treated groups compared to G1. Treatment did not affect blood glucose and cholesterol levels (P ≥ 0.05). Plasma antioxidant assays showed elevated superoxide dismutase and catalase functions and reduced malondialdehyde levels in G3, G4, and G5 compared to G2, indicating reduced oxidative stress. No marked differences were seen in the plasma glutathione peroxidase activities across groups. Sperm motility was impaired in the DEX-only group but improved (P < 0.05) with antioxidant supplementation. In conclusion, dietary VE and Se effectively mitigated the negative impacts of DEX-induced stress on growth, antioxidant status, and spermatozoa motility in Japanese quail cocks. VE and Se supplementation could be beneficial in enhancing the welfare and productivity of poultry under stress.}
}
@article{DAGATA2023101603,
title = {Easy come, easy go: Short-term land-use dynamics vis à vis regional economic downturns},
journal = {Socio-Economic Planning Sciences},
volume = {88},
pages = {101603},
year = {2023},
issn = {0038-0121},
doi = {https://doi.org/10.1016/j.seps.2023.101603},
url = {https://www.sciencedirect.com/science/article/pii/S0038012123001039},
author = {Alessia D'Agata and Leonardo Salvatore Alaimo and Pavel Cudlín and Luca Salvati},
keywords = {Metropolitan cycle, Sprawl, Indicators, Partial least square regression, Mediterranean Europe},
abstract = {The present study postulates distinctive land-use dynamics along the economic cycle, and tests against diverging trends over time of urban and non-urban land-uses with characteristic economic potential. Short-term land-use changes over seven time windows encompassing the last three decades (1992–2020) were investigated in metropolitan Athens (Greece), a mono-centric region experiencing complex economic downturns. Based on diachronic land-use maps with homogeneous spatial resolution and nomenclature derived from ESA Climate Change Initiative (ESA-CCI), a change detection analysis was run considering mean patch size, distance from downtown, and specific entropy-based metrics of landscape diversification (Shannon-Wiener H’ diversity index and Pielou J evenness index). Results of a canonical correlation analysis document differential intensity and spatial direction of change during expansions and recessions associated with distinctive socio-demographic profiles. Metropolitan growth followed a radio-centric (land-saving) model during economic expansions with intense urbanization of fringe land. A more dispersed settlement model – reflecting urban sprawl – was associated with economic stagnations, involving land at progressively distant locations from downtown. Landscape diversification was higher under stagnations and lower during expansions.}
}
@article{YAN2025114498,
title = {An explainable framework for assisting the detection of AI-generated textual content},
journal = {Decision Support Systems},
volume = {196},
pages = {114498},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114498},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625000995},
author = {Sen Yan and Zhiyi Wang and David Dobolyi},
keywords = {Generative AI (GenAI), AI-generated content (AIGC), Large language model (LLM), AIGC detection, Deep learning, Explainable AI (XAI)},
abstract = {The recent development of generative AI (GenAI) algorithms has allowed machines to create new content in a realistic way, driving the spread of AI-generated content (AIGC) on the Internet. However, generative AI models and AIGC have exacerbated several societal challenges such as security threats (e.g., misinformation), trust issues, ethical concerns, and intellectual property regulation, calling for effective detection methods and a better understanding of AI-generated vs. human-written content. In this paper, we focus on AI-generated texts produced by large language models (LLMs) and extend prior detection methods by proposing a novel framework that combines semantic information and linguistic features. Based on potential semantic and linguistic differences in AI vs. human writing, we design our Semantic-Linguistic-Detector (SemLinDetector) framework by integrating a transformer-based semantic encoder and a linguistic encoder with parallel linguistic representations. By comparing a series of benchmark models on datasets collected from various LLMs and human writers in multiple domains, our experiments show that the proposed detection framework outperforms other benchmarks in a consistent and robust manner. Moreover, our model interpretability analysis showcases our framework's potential to help understand the reasoning behind prediction outcomes and identify patterns of differences in AI-generated and human-written content. Our research adds to the growing space of GenAI by proposing an effective and responsible detection system to address the risks and challenges of GenAI, offering implications for researchers and practitioners to better understand and regulate AIGC.}
}
@article{KLIMCZAK2024102745,
title = {Equivalent sentiment measures for cross-language analysis of corporate communications},
journal = {MethodsX},
volume = {12},
pages = {102745},
year = {2024},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2024.102745},
url = {https://www.sciencedirect.com/science/article/pii/S2215016124001985},
author = {Karol Marek Klimczak and Jan Makary Fryczak and Dominika Hadro and Justyna Fijałkowska},
keywords = {Business communication, Financial reporting, Textual analysis, Text mining, Python},
abstract = {This paper presents a technique for sentiment measurement in many languages. The method allows researchers to efficiently analyze corporate documents, management reports, and financial statements using python. When the texts are written in many languages, the method extracts equivalent cross-linguistic sentiment features that can be used for statistical analysis or machine learning. We use Open Multilingual WordNet, a large lexicon organizing words into semantic groups, as the knowledge base about word equivalence in more than 200 languages. We experiment with a parallel English-French corpus and find that our senitment measures across the two languages are comparable. The method produces a consistent classification of positive and negative texts in two languages, and sentiment measure values correlate. The paper provides a detailed account of the method and python code, So that it can be applied to other languages, text mining, quantitative communication studies, and management research.•Method to create equivalent sentiment measures in multiple languages•Based on established lexicons and WordNet•Validated for English and French}
}
@article{DUY2024101945,
title = {Assessing potential to improve sandfish (Holothuria scabra) culture in Vietnam using supplemental seaweed feeding},
journal = {Aquaculture Reports},
volume = {35},
pages = {101945},
year = {2024},
issn = {2352-5134},
doi = {https://doi.org/10.1016/j.aqrep.2024.101945},
url = {https://www.sciencedirect.com/science/article/pii/S2352513424000334},
author = {Nguyen Dinh Quang Duy and Mai Nhu Thuy and Monal M. Lal and Paul C. Southgate},
keywords = {Sea cucumber, Supplemental feeding, Seaweed, Short-cropping, Vietnam},
abstract = {This study assessed potential improvement of sandfish (Holothuria scabra) culture using supplemental feeding with seaweed to explore its potential to support short-cropping. Three phased experiments evaluated juvenile growth and survival performance by: offering two types of seaweed-based supplemental feeds (Sargassum sp. and Gracilaria verrucosa) both processed by fermentation and pulverisation (Experiment 1); evaluating three stocking densities (25, 35 and 45 individuals per m2) using the best-performing diet from Experiment 1 (Experiment 2); and upscaling to commercial-level culture in three 400 m2 earthen ponds (Experiment 3). Fermented diets were prepared using a probiotic mixture (Saccharomyces boulardii, Lactobacillus acidophilus and Bacillus subtilis) added to ground, dried seaweed; while the pulverised diets were offered as a ground powder (350–450 µm particle sizes). Sandfish offered fermented Sargassum and Gracilaria reached 35.0% and 29.7% heavier mean final weights (18.18 ± 0.19 g and 16.81 ± 0.08 g, respectively), compared to their pulverised equivalents (11.82 ± 1.09 g across both seaweed species, p < 0.05) after 84 days of culture. Similar trends in growth rate (AGR and SGR) were evident. Fermented Sargassum sp. was therefore selected for subsequent experiments. During Experiment 2 the lowest density tested of 25 ind./m2 yielded the highest weight gain after 84 days, with juveniles 29.2% and 44.0% heavier respectively (final weight=18.20 ± 1.31 g), cf. 35 and 45 ind./m2, respectively (final weights=12.90 ± 0.71 and 10.20 ± 0.70 g, respectively). Growth at 25 ind./m2 was 15.7% faster (SGR=2.61 ± 0.09 g/day) compared to 35 ind./m2 (SGR=2.20 ± 0.07 g/day), and 26.5% faster relative to 45 ind./m2 (SGR=1.92±0.10 g/day). Sandfish grown in earthen ponds during Experiment 3 attained a final mean weight of 241.21 ± 0.84 g after 180 days. Final mean weights, weight gained and SGR (1.76 ± 0.06%/day) were not significantly different between ponds (p > 0.05). Valuable new information has been generated for further development of supplemental feeding of sandfish, and results here demonstrate high technical feasibility to support short cropping, with optimisation of this culture model required.}
}
@article{LI2026384,
title = {A comprehensive review of remaining useful life prediction methods for lithium-ion batteries: Models, trends, and engineering applications},
journal = {Journal of Energy Chemistry},
volume = {112},
pages = {384-414},
year = {2026},
issn = {2095-4956},
doi = {https://doi.org/10.1016/j.jechem.2025.08.056},
url = {https://www.sciencedirect.com/science/article/pii/S2095495625007168},
author = {Yang Li and Haotian Shi and Shunli Wang and Qi Huang and Chunmei Liu and Shiliang Nie and Xianyi Jia and Tao Luo},
keywords = {Lithium-ion batteries, Remaining useful life, Model-driven approach, Data-driven approach, Hybrid approach},
abstract = {Under complex working conditions, accurate prediction of the remaining useful life (RUL) of lithium-ion batteries is of great significance to ensure the stable operation of energy storage systems, the safe driving of electric vehicles, and the continuous power supply of electronic devices. This paper systematically describes the RUL prediction methods of lithium-ion batteries and comprehensively summarizes the development status and future trends in this field. First, the battery degradation mechanisms and lightweight data acquisition are analyzed. Secondly, a systematic classification model is constructed for the more widely used lithium battery RUL prediction methods, and the application characteristics and implementation limitations of different methods are analyzed in detail. An innovative classification framework for hybrid methods is proposed based on the depth of physical-data interaction. Then, collaborative modelling of calendar ageing and cyclic ageing is discussed, revealing their coupled effects and corresponding RUL prediction methods. Finally, the technical bottlenecks faced by the current RUL prediction of lithium batteries are identified, potential solutions are proposed, and the future development trends are outlined.}
}
@article{MORA202347,
title = {Models of plate tectonics with the Lattice Boltzmann Method},
journal = {Artificial Intelligence in Geosciences},
volume = {4},
pages = {47-58},
year = {2023},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2023.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666544123000199},
author = {Peter Mora and Gabriele Morra and David A. Yuen},
keywords = {Lattice Boltzmann Method, Mantle convection simulation, Plate tectonics simulation, Nonlinear rheology, Extreme plasticity},
abstract = {Modern geodynamics is based on the study of a large set of models, with the variation of many parameters, whose analysis in the future will require Machine Learning to be analyzed. We introduce here for the first time how a formulation of the Lattice Boltzmann Method capable of modeling plate tectonics, with the introduction of plastic non-linear rheology, is able to reproduce the breaking of the upper boundary layer of the convecting mantle in plates. Numerical simulation of the earth’s mantle and lithospheric plates is a challenging task for traditional methods of numerical solution to partial differential equations (PDE’s) due to the need to model sharp and large viscosity contrasts, temperature dependent viscosity and highly nonlinear rheologies. Nonlinear rheologies such as plastic or dislocation creep are important in giving mantle convection a past history. We present a thermal Lattice Boltzmann Method (LBM) as an alternative to PDE-based solutions for simulating time-dependent mantle dynamics, and demonstrate that the LBM is capable of modeling an extremely nonlinear plastic rheology. This nonlinear rheology leads to the emergence plate tectonic like behavior and history from a two layer viscosity model. These results demonstrate that the LBM offers a means to study the effect of highly nonlinear rheologies on earth and exoplanet dynamics and evolution.}
}
@article{MASUDA2023677,
title = {Plasma lipoprotein subclass variation in middle-aged and older adults: Sex-stratified distributions and associations with health status and cardiometabolic risk factors},
journal = {Journal of Clinical Lipidology},
volume = {17},
number = {5},
pages = {677-687},
year = {2023},
issn = {1933-2874},
doi = {https://doi.org/10.1016/j.jacl.2023.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1933287423002155},
author = {Reika Masuda and Julien Wist and Samantha Lodge and Torben Kimhofer and Michael Hunter and Jennie Hui and John P. Beilby and John R. Burnett and Girish Dwivedi and Markus P. Schlaich and Sze-How Bong and Ruey Leng Loo and Elaine Holmes and Jeremy K. Nicholson and Bu B. Yeap},
keywords = {Nuclear magnetic resonance spectroscopy, Lipoproteins, Cholesterol, Triglycerides, Apolipoproteins, Diabetes, Cardiovascular disease},
abstract = {BACKGROUND
Circulating lipids and lipoproteins mediate cardiovascular risk, however routine plasma lipid biochemistry provides limited information on pro-atherogenic remnant particles.
OBJECTIVE
We analysed plasma lipoprotein subclasses including very low-density and intermediate-density lipoprotein (VLDL and IDL); and assessed their associations with health and cardiometabolic risk.
METHODS
From 1,976 community-dwelling adults aged 45–67 years, 114/1071 women (10.6%) and 153/905 men (16.9%) were categorised as very healthy. Fasting plasma lipoprotein profiles comprising 112 parameters were measured using 1H nuclear magnetic resonance (NMR) spectroscopy, and associations with health status and cardiometabolic risk factors examined.
RESULTS
HDL cholesterol was higher, and IDL and VLDL cholesterol and triglycerides lower, in very healthy women compared to other women, and women compared to men. IDL and VLDL cholesterol and triglyceride were lower in very healthy men compared to other men. HDL cholesterol and apolipoprotein (apo) A-I were inversely, and IDL and VLDL cholesterol, apoB-100, and apoB-100/apoA-I ratio directly associated with body mass index (BMI) in women and men. In women, LDL, IDL and VLDL cholesterol increased with age. Women with diabetes and cardiovascular disease had higher cholesterol, triglycerides, phospholipids and free cholesterol across IDL and VLDL fractions, with similar trends for men with diabetes.
CONCLUSION
Lipoprotein subclasses and density fractions, and their lipid and apolipoprotein constituents, are differentially distributed by sex, health status and BMI. Very healthy women and men are distinguished by favorable lipoprotein profiles, particularly lower concentrations of VLDL and IDL, providing reference intervals for comparison with general populations and adults with cardiometabolic risk factors.}
}
@article{JHINJER2023158153,
title = {Nanosized ZIF-8 based odor adsorbing and antimicrobial finish for polyester fabrics},
journal = {Applied Surface Science},
volume = {639},
pages = {158153},
year = {2023},
issn = {0169-4332},
doi = {https://doi.org/10.1016/j.apsusc.2023.158153},
url = {https://www.sciencedirect.com/science/article/pii/S0169433223018330},
author = {Hardeep Singh Jhinjer and Manjeet Jassal and Ashwini K. Agrawal},
keywords = {Anti-odor, Malodor adsorption, Antibacterial, Multifunctional, Metal-organic frameworks (MOF), Nanoparticles},
abstract = {Effective odor control in textiles requires two approaches to be implemented simultaneously. One is the ability to adsorb body odors and volatile organic compounds (VOCs) present in the microclimate between the skin and the textile layer, and the other is the ability of the textile to kill and prevent the growth of odor-causing bacteria. However, most of the finishes use one of the two approaches, which lowers the efficacy of the finish. In this work, we have reported the use of Zeolitic Imidazolate Frameworks, viz. ZIF-8 nanoparticles (NPs), which, when applied to polyester fabrics, serve a dual purpose of both adsorbing the odor and imparting antimicrobial activity. ZIF-8 NPs with an average size of ∼60 nm were synthesized by a water-based procedure at ambient temperature and applied in small concentrations on PET fabric using a commercial binder. The ZIF-8 functionalized polyester fabric (ZIF-8@PET Fabric) was characterized for its morphology and functionality. The fabrics were found to adsorb high concentrations of three odor-causing model compounds, such as isovaleric acid, indole, and nonenal, and could effectively inhibit the bacterial growth of E. coli and S. aureus. Further, the fabric functionality was retained even after several wash cycles and could be reused repeatedly.}
}
@article{ZHANG2025118894,
title = {Integrated lipidomic and transcriptomics to explore the effects of ethyl acetate extract of Herpetospermum pedunculosum on nonalcoholic fatty liver disease in mice},
journal = {Journal of Ethnopharmacology},
volume = {337},
pages = {118894},
year = {2025},
issn = {0378-8741},
doi = {https://doi.org/10.1016/j.jep.2024.118894},
url = {https://www.sciencedirect.com/science/article/pii/S0378874124011930},
author = {Boyu Zhang and Cairong Han and Zhongrui Zhang and Akida Adiham and Rui Tan and Puyang Gong and Jian Gu},
keywords = {Nonalcoholic fatty liver disease, , Lipidome, Transcriptome, TGF-β signaling pathway, Sphingolipid metabolism},
abstract = {Ethnopharmacological relevance
Herpetospermum pedunculosum (Ser.) C.B. Clarke (HP), a traditional Tibetan medicine used to treat hepatobiliary diseases, was confirmed that lignans-enriched ethyl acetate extract of HP (EAHP) could alleviate the hepatic injury by modern pharmacological evidence. However, the effects and potential mechanisms of EAHP against nonalcoholic fatty liver disease (NAFLD) are still unknown.
Aim of the study
To reveal the effects of EAHP on NAFLD and explore the potential mechanisms from the perspective of lipidomics and transcriptomics.
Materials and methods
UPLC‒Q–TOF‒MS analysis was carried out to investigate the chemical components of EAHP. A Choline-deficient, L-amino acid defined, high fat diet (CDAHFD) was used to establish a NAFLD mouse model. The anti-NAFLD effects of various dosages of EAHP were evaluated by biochemical indexes and histological analysis. Hepatic lipidomic and transcriptomic analysis and multiple bioinformatics methods were used to screen biomarkers and signaling pathways. The levels of the corresponding genes were verified by qPCR.
Results
36 kinds of compounds were identified by UPLC‒Q–TOF‒MS analysis. Oral treatment with EAHP significantly decrease the liver index and the levels of ALT and AST in the serum. The measurements lipid content and Oil Red O staining results suggested that EAHP ameliorated lipid metabolism disorders by reducing the content of TG and LDL-C, increasing HDL-C in the liver. H&E staining and ELISA revealed that EAHP restored hepatic inflammatory infiltration and decrease the levels of IL-1β, IL-6, TNF-α, and increase IL-10 in the serum. Lipidomic analysis showed that EAHP could regulate CDAHFD-induced lipid metabolic disorder. The different lipid metabolites included TG, phosphatidyl choline (PC), diacylglycerol (DG), phosphatidylethanolamine (PE), phosphatidylinositol (PI), ceramide (Cer). Transcriptomic analysis revealed that Bmp8b, Nbl1, Rgma, Sphk1, Thbs1, and Ugt8a were important regulators, which were associated with TGF-β signaling pathway and sphingolipid metabolism. The expressions of above genes detected by were qPCR consistent with transcriptomic data.
Conclusions
The ameliorative effects of EAHP on NAFLD are potentially attributable to the regulation of sphingolipid metabolism and TGF-β signaling pathway, etc., which results in abnormal hepatic lipid metabolism and inflammatory response.}
}
@article{BAO2025100929,
title = {Cross-cultural attitudes toward generative AI in Art: Implications for sustainable creativity in the U.S., Japan, and China},
journal = {Sustainable Futures},
volume = {10},
pages = {100929},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.100929},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825004940},
author = {Suomiya Bao},
keywords = {Generative AI, Art, Attitude, Culture},
abstract = {This study investigates the perceptions and attitudes toward generative AI art across three major global economies: the United States, Japan, and China. As leaders in AI development, these countries exhibit distinct viewpoints regarding the integration of AI into the creative process. The investigation was conducted using an online questionnaire, which gathered responses from participants in the three countries. The survey consisted of questions that assessed participants’ experiences with AI tools, their views on AI-generated art in various forms, and their ethical concerns regarding its use. The results indicate that participants in China are generally more optimistic about the value of AI-generated art, prioritizing the quality of the final product over ethical concerns. In contrast, participants in the U.S. and Japan emphasize the importance of human creativity and express skepticism about AI art, primarily due to ethical concerns such as misinformation and intellectual property issues. While Chinese participants focus on data privacy and intellectual property protection, U.S. participants are more concerned with misinformation and fake content. Japan, despite having the least experience with AI tools, presents attitudes that often fall between the positions of the U.S. and China. This study provides valuable insights into cross-cultural differences in attitudes toward AI art, offering guidance for educators, policymakers, and AI developers on integrating AI into the art and design sectors in a sustainable, ethical, and culturally adaptive manner.}
}
@article{DUTTENHEFNER2025,
title = {Mevalonate pathway in pancreatic ductal adenocarcinoma: mechanisms driving metabolic and cellular plasticity},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000734},
author = {Jenna N. Duttenhefner and Katie M. Reindl},
keywords = {Mevalonic Acid, Metabolism Reprogramming, Pancreatic Ductal Carcinoma, Molecular Targeted Therapy, Lipid Metabolism, Protein Prenylation, Drug Therapy, Combination},
abstract = {The mevalonate pathway is crucial in the metabolic reprogramming of pancreatic ductal adenocarcinoma (PDAC), driving lipid biosynthesis, redox homeostasis, and oncogenic signaling to sustain tumor progression and therapeutic resistance. Its integration with Kirsten rat sarcoma viral oncogene homolog (KRAS)-driven signaling networks positions it as a cornerstone of PDAC biology and a compelling therapeutic target. The products of the pathway (sterols and isoprenoids) support key processes such as membrane biogenesis, protein prenylation, and immune evasion, facilitating tumor adaptation to the harsh microenvironment. Despite extensive research, therapeutic resistance and metabolic plasticity present considerable challenges in targeting this pathway. This review synthesizes current knowledge on the biochemical regulation of the mevalonate pathway in PDAC, its crosstalk with key oncogenic signaling networks, and emerging therapeutic strategies. In addition, we highlight critical knowledge gaps, including the complex regulatory crosstalk of the pathway with oncogenes, tumor suppressors, and nutrient-sensing pathways, and the mechanisms by which metabolic rewiring modulates tumor-immune interactions and therapy resistance. By integrating insights from pre-clinical and clinical studies, we highlighted promising novel combination therapies, including statins, bisphosphonates, and sterol regulatory element-binding protein (SREBP) inhibitors, as well as the potential for precision medicine approaches targeting mevalonate pathway vulnerabilities. Addressing these challenges may provide new avenues for improving therapeutic outcomes in PDAC.}
}
@article{NIU2025128368,
title = {LLM-Loc: Bootstrap single-image indoor localization with large language model},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128368},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128368},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425019876},
author = {Qun Niu and Tao Chen and Xing Zhang and Yifan Wang and Ning Liu},
keywords = {Area identification, Collaborative contour refinement, Contour similarity ranking},
abstract = {Visual indoor localization has gathered significant attention, mainly due to the ubiquity and distinctiveness of visual textures. However, visual texture-based approaches usually suffer from extensive site survey, a lack of generality to different sites and are prone to appearance changes, hindering their practical deployment. We propose LLM-Loc, which combines large language models (LLMs), ubiquitous scene texts and line segments for positioning, as texts and lines present more stable and robust spatial semantics. LLM-Loc comprises two stages: coarse area inference with scene texts and fine positioning with contour lines. To reduce the impact of text diversity and environmental noises on the area identification, we combine the reasoning capability of LLM and semantic priors for area inference. To reduce the impact of occlusion on contour extraction, we propose a collaborative contour refinement algorithm, where we leverage homograhy constraints and refine contour lines using images taken by others. Using the refined contour image, we propose a relative similarity ranking scheme and estimate fine user locations with orientation and map constraints. Extensive experimental results in different trial sites show LLM-Loc is accurate (mean localization errors 1.61 m and 1.34 m in the food plaza and shopping mall) and reduces positioning error at least by 39 %.}
}
@article{HUANG2025113691,
title = {Artificial intelligence artificial muscle of dielectric elastomers},
journal = {Materials & Design},
volume = {251},
pages = {113691},
year = {2025},
issn = {0264-1275},
doi = {https://doi.org/10.1016/j.matdes.2025.113691},
url = {https://www.sciencedirect.com/science/article/pii/S026412752500111X},
author = {Dongyang Huang and Jiaxuan Ma and Yubing Han and Chang Xue and Mengying Zhang and Weijia Wen and Sheng Sun and Jinbo Wu},
keywords = {Artificial muscle, Artificial intelligence, Dielectric elastomer, Material database, Data mining, Natural language processing},
abstract = {Artificial muscles (AMs), which encompass materials or devices capable of replicating the functions of natural muscles, have garnered significant attention in recent years, driven by the advent of various materials (advanced hydrogels, pneumatic AMs, dielectric elastomers, etc.) that exhibit exceptional properties and devices that demonstrate remarkable performance. The immense potential of AMs spans numerous industries and aspects of daily life, necessitating accelerated research efforts to meet the increasing demand. This article focuses on dielectric responsive elastomers, which are key materials within the field of AMs, highlighting advancements in theory, materials, and devices. To expedite the research and development of dielectric elastomer AM materials and beyond, we propose leveraging artificial intelligence tools to transform the artificial intelligence muscle research paradigm. Establishing an AM material database is highly valuable, as seemingly minor material data can be correlated with descriptors and target values via machine learning. Through material data mining integrating materials science and data science, we can predict potential breakthroughs in AM materials. A data-driven experimental research approach significantly reduces the number of experiments required for AM development, leading to cost savings and increased research efficiency.}
}
@article{MARTINEZMORENO2024100296,
title = {What motivates future teachers? The influence of Artificial Intelligence on student teachers' career choice},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100296},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100296},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000997},
author = {Judit Martínez-Moreno and Dominik Petko},
keywords = {AI, AIEd, Career choice, (D)FIT-Choice, Digital transformation, Student teachers, Motivations, Agency, Teacher education},
abstract = {Artificial Intelligence in Education (AIEd) is reshaping not only the educational landscape but also potentially influencing the motivations of aspiring teachers. This paper explores whether considerations related to AIEd play a role in student teachers' decision to become teachers. For this aim, the study introduces a new AI subscale within the (D)FIT-Choice scale's Social Utility Value (SUV) factor and validates its effectiveness with a sample of 183 student teachers. Descriptive statistics reveal high mean scores for traditional motivators like Intrinsic Value Teaching, while AI-related factors, although considered, exhibit lower influence. A noticeable disconnection exists between digital motivations and the aspiration to shape the future, suggesting a potential gap in student teachers' understanding of digitalization's future impact. An extreme group analysis reveals a subset of student teachers who significantly consider AI. This group also gives value to Job Security and Make a Social Contribution, suggesting an awareness of AI's societal and professional impacts. Based on these findings, it is recommended to put a focus on teacher education programs to ensure student teachers' understanding of the impact of AI on education and society.}
}
@article{ALMAZROUI2025100205,
title = {Ideological indoctrination of children during Crises: Non-Religious extremism in authoritarian regimes},
journal = {Child Protection and Practice},
volume = {6},
pages = {100205},
year = {2025},
issn = {2950-1938},
doi = {https://doi.org/10.1016/j.chipro.2025.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2950193825001135},
author = {Dr Karima Almazroui},
keywords = {, , , , , , },
abstract = {This article investigates the secular ideological indoctrination of children under authoritarian regimes during political and humanitarian crises, focusing on the Khmer Rouge in Cambodia, North Korea, and Maoist China. While much attention has been given to religious radicalization, this study highlights how non-religious regimes exploit education and child socialization to consolidate power. Using a comparative, interdisciplinary framework grounded in critical theory, developmental psychology, and human rights law, it explores how states manipulate curricula, emotional bonds, and youth institutions to reengineer identity, suppress dissent, and instill loyalty. Crises enable regimes to occupy moral and epistemic space left by collapsing institutions, reframing education as a tool of ideological purification. The study introduces the concept of affective captivity to capture the emotional restructuring of children's moral frameworks and links these practices to violations of the UN Convention on the Rights of the Child. It reframes indoctrination as a form of epistemic and structural violence with enduring psychological and civic consequences. By naming secular indoctrination as a form of non-religious extremism, the article contributes to authoritarian studies, child rights, and comparative education. It calls for enhanced legal recognition, critical curriculum safeguards, and post-crisis strategies to protect children's autonomy and psychosocial development.}
}
@article{SALMAN2025114714,
title = {Germany’s energy security strategy in times of turmoil: The role of AI-driven energy systems and environmental policy in the Russian gas exit},
journal = {Energy Policy},
volume = {205},
pages = {114714},
year = {2025},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2025.114714},
url = {https://www.sciencedirect.com/science/article/pii/S0301421525002216},
author = {Muhammad Salman},
keywords = {AI-Driven energy systems, Environmental policy, Geopolitical risks, Russian gas imports, Germany},
abstract = {The 2014 Crimea crisis and the 2022 Russia’s all-out war against Ukraine sent shockwaves across Europe and uncovered the continent's reliance on a key geopolitical adversary. Energy has become a central issue in this situation. European nations have committed to reducing their dependence on Russian fossil fuels. Meanwhile, Russia has restricted gas supplies to some countries and substantially decreased deliveries to others, and Germany found itself in the driver’s seat. This study explores the role of AI-driven energy systems and environmental policy (EPS) in shaping Germany’s response to Russian gas dependency in shifting geopolitical landscape (GPR). Using a battery of robust econometric methods, the findings reveal that AI and EPS significantly reduce Germany’s dependency on Russian gas in both the short and long run, with stronger effects observed over the long term. Geopolitical risk, although having limited direct effects, but its interaction with AI and EPS highlights the compounded benefits of integrated technological advancement and policy strategies in mitigating energy dependency in times of turmoil. Moreover, the interaction between AI, EPS, and the 2014 Crimea crisis (D2014) demonstrated that this crisis acted as a catalyst, accelerating structural changes in Germany's energy policies and diversification efforts. To test robustness, this study uses the 2014 Crimea crisis as an exogenous shock. The Synthetic Control Method (SCM) reveals a significant gap between actual and synthetic Germany’s gas imports, highlighting Germany’s efforts to address energy dependency through AI-driven energy management and policy measures. Policymakers should integrate AI technologies with targeted energy policies to enhance energy resilience and reduce dependency on geopolitical adversaries during times of crisis.}
}
@article{SADIQ2025107590,
title = {Organelle-targeted nanostructured lipid carriers: Strategic design, analytical validation, and translational insights for precision intracellular drug delivery},
journal = {Journal of Drug Delivery Science and Technology},
volume = {114},
pages = {107590},
year = {2025},
issn = {1773-2247},
doi = {https://doi.org/10.1016/j.jddst.2025.107590},
url = {https://www.sciencedirect.com/science/article/pii/S1773224725009931},
author = {Hannan Sadiq and Muneeb Ur Rahman and Habiba Akram and Ihtesham Ur Rehman and Rehan Ali and Rehan Khan},
keywords = {Nanostructured lipid carriers, Drug delivery systems, Organelle targeting, Intracellular membranes, Organelles/ drug effects},
abstract = {Precision intracellular drug delivery, enhanced payload capacity, physicochemical stability, and tunable release kinetics are the features offered by nanostructured lipid carriers (NLCs) as a next-generation drug delivery platform. Organelle-specific engineering and rational design of NLCs for targeted delivery to subcellular compartments, including the mitochondria, lysosomes, nucleus, endoplasmic reticulum (ER), and Golgi apparatus, are comprehensively discussed in this review. Strategic physicochemical modifications, such as particle size optimisation, surface functionalization with targeting ligands (e.g., TPP, TAT, NLS, KDEL), ceramide-mimetic components, and incorporation of pH or redox-responsive lipids, achieve organelle-specific localization, enabled by coupling chemistries like bio-orthogonal click reactions and EDC/NHS activation. High-resolution imaging modalities (CLSM, TEM, cryo-EM), co-localization quantification (Pearson's and Mander's coefficients), LC-MS/MS, FERT, FRAP, imaging flow cytometry, and differential scanning calorimetry (DSC) are used to validate targeting efficiency and formulation integrity analytically. Particle size, zeta potential, encapsulation efficiency, crystallinity, and release behavior are included in critical quality attributes (CQAs) that are optimised systematically using Design of Experiment (DoE) within a quality-by-design (QbD) framework. Physiologically based pharmacokinetics (PBPK) modelling and spatial lipidomics for assessing biodistribution and pharmacodynamic impact are used as preclinical translation, incorporating bioanalytical method validation. Endosomal entrapment, interspecies variability, and GMP-compliant challenges are the key translational and regulatory bottlenecks addressed in this review. Transformative potential for NLC-based precision medicine includes converging dual-organelle targeting, multi-stimuli responsiveness, emerging AI-guided design tools, and continuous manufacturing platforms. Redefining the landscape of intracellular therapeutics towards clinically viable organelle-targeted formulations through cutting-edge innovations is consolidated in this review.}
}
@article{HUANG2025102643,
title = {Generative AI outperforms humans in social media engagement: Evidence from GPT-4 and the FIIT model},
journal = {Public Relations Review},
volume = {51},
number = {5},
pages = {102643},
year = {2025},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2025.102643},
url = {https://www.sciencedirect.com/science/article/pii/S0363811125001055},
author = {Jiacheng Huang and Alvin Zhou},
keywords = {Social media engagement, AI, Generative AI, GPT, Brand communication, Public relations, Computational methods},
abstract = {This multi-study paper demonstrates that large language model-generated social media posts (via GPT-4) outperform human-written messages in driving digital engagement. Using a dataset of Fortune 500 Twitter posts, Study 1 introduces and validates the FIIT model – Fluency, Interactivity, Information, and Tone – a linguistic framework explaining why AI-optimized content attracts more likes, comments, and shares. Study 2 experimentally confirms that consumers prefer AI-generated posts, while Study 3 shows that even trained public relations professionals, despite FIIT instruction and monetary incentives, cannot match AI performance. Together, these studies provide large-scale, multi-method evidence that generative AI can outperform human communicators in measurable engagement outcomes. The paper advances computational grounded theory in strategic communication and discusses implications for public relations practice, research, and education in the era of generative AI.}
}
@article{YU2024e24289,
title = {RETRACTED: The application and challenges of ChatGPT in educational transformation: New demands for teachers' roles},
journal = {Heliyon},
volume = {10},
number = {2},
pages = {e24289},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24289},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024003207},
author = {Hao Yu},
abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/policies/article-withdrawal). This article has been retracted at the request of the Editors. Post-publication, an investigation conducted by Elsevier's Research Integrity & Publishing Ethics team on behalf of the journal identified references that are irrelevant to the article and a distinct lack of citations in large sections of the text. The author was asked to comment upon the references in their work but was unable to satisfactorily address the reason for the references. Additionally, there are concerns that the author appears to have used a Generative AI source in the writing process of the paper without disclosure, which is a breach of journal policy. Consequently, the editor no longer has confidence in the integrity and the findings of the article and has decided to retract it. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process. The author disagrees with retraction and disputes the grounds for it.}
}
@article{LI2025104365,
title = {Reliability evaluation of wind power systems by integrating granularity-related latin hypercube sampling with LSTM-based prediction},
journal = {Computers in Industry},
volume = {173},
pages = {104365},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2025.104365},
url = {https://www.sciencedirect.com/science/article/pii/S0166361525001307},
author = {Yonggang Li and Yaotong Su and Lei Xia and Yuanjin Zhang and Weinong Wu and Longjiang Li},
keywords = {Reliability, Wind power integration, Granularity, Latin hypercube sampling, Monte carlo method},
abstract = {When evaluating the reliability of a wind power system, it is imperative to undertake differentiated sampling and meticulously predict extensive datasets. Existing studies frequently constrain raw data within narrowly defined parameter spaces to enhance their statistical significance. However, such an approach may inadvertently engender overly optimistic reliability evaluations, neglecting rare yet crucial failure scenarios. Consequently, this oversight potentially underestimates systemic risks and undermines robustness. To date, the dichotomy between high data acquisition rates and the intrinsic characteristics of collected data remains inadequately addressed. Concurrently, an urgent requirement persists for developing precise data distribution models capable of comprehensively assessing wind power system reliability. In response, Long Short-Term Memory (LSTM) models are employed to bridge this research gap, enabling predictions of wind power generation through analyses of data at varying granularities. Subsequently, an Improved Latin Hypercube Sampling (ILHS) methodology is implemented to partition sampling intervals, integrating seamlessly with the Monte Carlo (MC) method for wind power data sampling. This reliability assessment model fully exploits the flexibility of the proposed sampling technique, enhancing the precision of sample probability distributions, interval segmentation, and data stratification. Empirical evidence demonstrates that the proposed algorithm exhibits superior predictive accuracy and enhanced statistical efficacy relative to conventional methodologies. Thus, it offers a robust and efficacious solution for assessing the reliability of wind power integration. This study evaluates the practical reliability of a local wind power integration system in Southwest China. Additionally, methods for discerning vulnerabilities are systematically applied to fortify critical power buses and augment overall system reliability.}
}
@article{KUANG2025104289,
title = {The incentive effects of experts: Evidence from an online mental health platform},
journal = {Information Processing & Management},
volume = {62},
number = {6},
pages = {104289},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104289},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325002304},
author = {Lini Kuang and Tingting Hou},
keywords = {Online mental health platform, Expert effect, Performance, Mediation analysis, Large language model},
abstract = {A prevalent form of online healthcare comprises hybrid support services, allowing help seekers to pose health-related questions, assess answers from various healthcare experts and ordinary supporters, and vote on the usefulness of answers they find most satisfactory. However, the impact of healthcare experts' engagement on the subsequent supporters' performance within this hybrid service remains unclear. While concerns persist that experts' involvement may diminish subsequent supporters' performance due to a reduced likelihood of recognition, there is a plausible scenario in which it fosters learning and competition, thereby improving performance of subsequent supporters. Leveraging data from a Chinese online mental health platform, we utilize the mediation effects model to investigate the impact of healthcare experts' engagement on the performance of subsequent supporters. Within our model, we focus on the mediating effects of the effort and quality of answers from these subsequent supporters. Our research findings indicate that the engagement of counselors can directly enhance the social recognition obtained by subsequent supporters and can also indirectly boost this recognition by increasing the effort put into their answers. However, the quality of the subsequent supporters' answers does not play a significant mediating role in this relationship. These results fill a gap in the literature on online health services and expert effects, offering valuable insights for online health platforms aiming to enhance the performance of supporters by involving healthcare experts.}
}
@article{LI2025,
title = {Trust or distrust? AIGC trustworthiness and an extended analysis within nomology framework},
journal = {Data Science and Management},
year = {2025},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2025.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666764925000499},
author = {Mingqian Li and Rong Du and Shizhong Ai and Richard A. Hunt and Jianing Xie},
keywords = {artificial intelligence (AI), artificial intelligence generated content (AIGC), nomology framework, trust, trustworthiness, grounded theory, text mining, sentiment analysis},
abstract = {Given the dizzying advancements in artificial intelligence (AI) applications such as ChatGPT and DeepSeek, AI-generated content (AIGC) has attracted considerable attention from scholars, practitioners, and policymakers, each of whom is grappling with fundamental issues involving individual, organizational, and even societal impacts, which are exciting and daunting. Central to the process of identifying and assessing the benefits and detriments of AIGC are critical issues involving reliability, intelligibility, desirability, and, perhaps most of all, trustworthiness. Although humans have generally accepted the reality that AI is destined to play a prominent role in our lives, we are still in the very early stages of determining how we feel about the complex relationships that emerge between people and AI. Management and organizational scholars play a key role in developing theories that demarcate and predict the evolving structure and content of these relationships. Towards that end, this study adopts a mixed-methods design to systematically examine perceptions of AIGC trustworthiness. We begin by employing grounded theory to develop a nomology framework that integrates the extroverted and introverted dimensions of human cognition. We then subject the interview corpus to text mining and sentiment analysis to distill targeted, evidence-based strategies for strengthening AIGC trustworthiness.}
}
@article{LI202564,
title = {Intelligent human-computer interactive training assistant system for rail systems},
journal = {High-speed Railway},
volume = {3},
number = {1},
pages = {64-77},
year = {2025},
issn = {2949-8678},
doi = {https://doi.org/10.1016/j.hspr.2025.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949867825000066},
author = {Yuexuan Li and Junhua Chen and Xiangyong Luo and Han Zheng},
keywords = {High-speed railway, Dispatch training assistance, Large language model, Human-computer interactive training assistant system, Reinforcement learning},
abstract = {In recent years, railway construction in China has developed vigorously. With continuous improvements in the high-speed railway network, the focus is gradually shifting from large-scale construction to large-scale operations. However, several challenges have emerged within the high-speed railway dispatching and command system, including the heavy workload faced by dispatchers, the difficulty of quantifying subjective expertise, and the need for effective training of professionals. Amid the growing application of artificial intelligence technologies in railway systems, this study leverages Large Language Model (LLM) technology. LLMs bring enhanced intelligence, predictive capabilities, robust memory, and adaptability to diverse real-world scenarios. This study proposes a human-computer interactive intelligent scheduling auxiliary training system built on LLM technology. The system offers capabilities including natural dialogue, knowledge reasoning, and human feedback learning. With broad applicability, the system is suitable for vocational education, guided inquiry, knowledge-based Q&A, and other training scenarios. Validation results demonstrate its effectiveness in auxiliary training, providing substantial support for educators, students, and dispatching personnel in colleges and professional settings.}
}
@article{KONDAMUDI20251081,
title = {Integrating Explainable AI with Enhanced Ensemble Models for Accurate and Transparent Fake News Detection in OSN’s},
journal = {Procedia Computer Science},
volume = {258},
pages = {1081-1090},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.343},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925014450},
author = {Medeswara rao Kondamudi and Somya ranjan Sahoo},
keywords = {Fake news Detection, Machine learning, Stack classifier, Ensembling Approaches, Explainable artificial Intelligence, Weak, Strong learner},
abstract = {Nowadays, identifying and mitigating fake news creates challenges, particularly due to the widespread dissemination of text-based content over internet sites, online social networking platforms, and emails. While conventional ways of detecting fake news can be quite successful, they frequently fall behind the latest tactics. The developments in machine learning and deep learning algorithms have greatly enhanced the performance of fake news-detecting frameworks. This work develops a reliable and understandable method to identify fake news efficiently by combining XAI with ensemble learning and employing different techniques to increase efficacy. Nevertheless, user dependability is hampered by these products’ opaque and black-box design. Explainable AI has surfaced in subsequent actions to improve people’s comprehension of artificial intelligence conclusions. We utilized four classifiers to perform testing and training: decision tree, support vector machine, and logistic regression, respectively. Three different fake news datasets were balanced and combined to lessen overfitting. Compared to individual classifiers, the Random Forest (RF)-based stacking ensemble approach yielded the greatest results, with 98% recall, 96% accuracy, and 96% F1-score. Using XAI’s interpretability, the approach explains its categorization facts, revealing unseen techniques for recognizing fake news.}
}
@article{CHEN2025106756,
title = {New-type infrastructure and corporate digital transformation: Evidence from a multimethod machine learning approach},
journal = {Finance Research Letters},
volume = {74},
pages = {106756},
year = {2025},
issn = {1544-6123},
doi = {https://doi.org/10.1016/j.frl.2025.106756},
url = {https://www.sciencedirect.com/science/article/pii/S1544612325000212},
author = {Chen Chen and Zhixin Xue},
keywords = {New-type infrastructure, Corporate digital transformation, Pre-trained language model, Causal forests, The normalization model},
abstract = {This study is an exploration of the impact of new-type infrastructure on corporate digital transformation. The results show that the construction of new-type infrastructure has played a major role in corporate digital transformation. The heterogeneity tests indicate that this positive effect is more significant with higher levels of urbanization and higher levels of human capital at the regional level, less efficient management of liquid assets and higher financing constraints at the firm level. The mechanism results suggest that the internal innovation incentives and the external governance environment are important mechanisms influencing the relationship between new-type infrastructure and corporate digital transformation.}
}
@article{WESTBY2024100101,
title = {How voice and helpfulness shape perceptions in human–agent teams},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {2},
pages = {100101},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000616},
author = {Samuel Westby and Richard J. Radke and Christoph Riedl and Brooke Foucault Welles},
keywords = {Human–agent interaction, Human–agent teams, Anthropomorphism, Perception, Voice assistants},
abstract = {Voice assistants are increasingly prevalent, from personal devices to team environments. This study explores how voice type and contribution quality influence human–agent team performance and perceptions of anthropomorphism, animacy, intelligence, and trustworthiness. By manipulating both, we reveal mechanisms of perception and clarify ambiguity in previous work. Our results show that the human resemblance of a voice assistant’s voice negatively interacts with the helpfulness of an agent’s contribution to flip its effect on perceived anthropomorphism and perceived animacy. This means human teammates interpret the agent’s contributions differently depending on its voice. Our study found no significant effect of voice on perceived intelligence, trustworthiness, or team performance. We find differences in these measures are caused by manipulating the helpfulness of an agent. These findings suggest that function matters more than form when designing agents for high-performing human–agent teams, but controlling perceptions of anthropomorphism and animacy can be unpredictable even with high human resemblance.}
}
@article{ISLAYEM2025101648,
title = {Enhancing medical digital twins within metaverse using blockchain, NFTs and LLMs},
journal = {Internet of Things},
volume = {32},
pages = {101648},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101648},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525001623},
author = {Ruba Islayem and Ahmad Musamih and Khaled Salah and Raja Jayaraman and Ibrar Yaqoob},
keywords = {Blockchain, Digital twins, Metaverse, NFTs, LLMs},
abstract = {Medical digital twins (MDTs) are rapidly emerging as transformative tools in healthcare. They provide virtual representations of medical devices and systems that facilitate real-time analysis and enhance decision-making. However, challenges such as secure data management, access control, and the lack of immersive and intelligent patient interactions limit their effectiveness. In this paper, we propose a solution integrating blockchain technology, Non-Fungible Tokens (NFTs), and Large Language Models (LLMs) within a metaverse environment to enhance MDT functionality. Blockchain and NFTs ensure secure ownership and access control, while the metaverse offers an engaging platform for user interaction. An LLM-powered non-player character (NPC) enables intelligent real-time user interactions and personalized insights. We develop two blockchain smart contracts for user registration, NFT ownership, and access control, and utilize decentralized InterPlanetary File System (IPFS) storage for the metaverse, MDT metadata, and interaction logs. We present the system architecture, sequence diagrams, and algorithms, along with the implementation and testing details. We conduct cost, security, and response time analyses to evaluate the smart contracts and LLM performance and compare our solution with existing approaches. We discuss practical implications, as well as challenges and limitations of the proposed solution. Finally, we explore the generalization of our system for various applications. The smart contract code and metaverse files are publicly available on GitHub.}
}
@article{ONSTWEDDER2024,
title = {Policy Guidance for Direct-to-Consumer Genetic Testing Services: Framework Development Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/47389},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400390X},
author = {Suzanne Maria Onstwedder and Marleen Elizabeth Jansen and Martina Cornelia Cornel and Tessel Rigter},
keywords = {genetic testing, direct-to-consumer testing, health policy, genetic privacy, online market, informed consent, public health genomics, policy decision, mHealth, mobile health, privacy},
abstract = {Background
The online offer of commercial genetic tests, also called direct-to-consumer genetic tests (DTC-GTs), enables citizens to gain insight into their health and disease risk based on their genetic profiles. DTC-GT offers often consist of a combination of services or aspects, including advertisements, information, DNA analysis, and medical or lifestyle advice. The risks and benefits of DTC-GT services have been debated and studied extensively, but instruments that assess DTC-GT services and aid policy are lacking. This leads to uncertainty among policy makers, law enforcers, and regulators on how to ensure and balance both public safety and autonomy and about the responsibilities these 3 parties have toward the public.
Objective
This study aimed to develop a framework that outlines aspects of DTC-GTs that lead to policy issues and to help provide policy guidance regarding DTC-GT services.
Methods
We performed 3 steps: (1) an integrative literature review to identify risks and benefits of DTC-GT services for consumers and society in Embase and Medline (January 2014-June 2022), (2) structuring benefits and risks in different steps of the consumer journey, and (3) development of a checklist for policy guidance.
Results
Potential risks and benefits of DTC-GT services were mapped from 134 papers and structured into 6 phases. In summary, these phases were called the consumer journey: (1) exposure, (2) pretest information, (3) DNA analysis, (4) data management, (5) posttest information, and (6) individual and societal impact. The checklist for evaluation of DTC-GT services consisted of 8 themes, covering 38 items that may raise policy issues in DTC-GT services. The themes included the following aspects: general service content, validity and quality assurance, potential data and privacy risks, scientific evidence and robustness, and quality of the provided information.
Conclusions
Both the consumer journey and the checklist break the DTC-GT offer down into key aspects that may impact and compromise individual and public health, safety, and autonomy. This framework helps policy makers, regulators, and law enforcers develop methods to interpret, assess, and act in the DTC-GT service market.}
}
@article{IMMADI2025107676,
title = {Agroecological practices in United States North Central dairy systems enhance omega-3 and phytonutrient levels in cow's milk},
journal = {Food Bioscience},
volume = {73},
pages = {107676},
year = {2025},
issn = {2212-4292},
doi = {https://doi.org/10.1016/j.fbio.2025.107676},
url = {https://www.sciencedirect.com/science/article/pii/S221242922501853X},
author = {Sree Bhavya Immadi and Muhammad Ahsin and Joseph Vinod Varre and Robert E. Ward and Allen Williams and Stephan {Van Vliet}},
keywords = {Pasture-fed, TMR (total mixed ration), Omega-3 fats, Phytonutrients, Milk, Metabolomics},
abstract = {This study evaluated the impact of agroecological (“regenerative”) practices on milk nutritional quality and soil health in a sample of U.S. North Central dairy systems. Five dairy farms employing rotational grazing and diverse forage feeding were compared to a conventional total mixed ration (C-TMR) control. Milk and forage were analyzed for fatty acids by gas chromatography and for phytonutrients by high-performance liquid chromatography–tandem mass spectrometry. Soil indicators included total organic carbon (SOC), microbial mass, fungi-to-bacteria ratio, and organic-to-inorganic nitrogen ratio. Milk from regenerative farms contained higher levels of omega-3 fatty acids: eicosapentaenoic acid (C20:5n3) was 122–144 % higher in regen farms 1 and 4, and docosapentaenoic acid (C22:5n3) was 800–1000 % higher in regen farms 1, 3, and 4 versus the control. Forages averaged 217 % more alpha-linolenic acid (C18:3n3), whereas the control feed contained 148 % more linoleic acid (C18:2n6). Milk from regenerative farms was also enriched in phytonutrients including p-cresol sulfate (117 %), hippuric acid (49.5 %), and catechol (48.5 %). Cluster analysis highlighted farm-level variation in compounds such as formononetin (20.6 % higher) and genkwanin (225 % higher). Soils from regenerative farm 1, which had the most plant diversity, showed elevated SOC (up to 420 mg/kg) and a balanced nitrogen ratio (1.0). Overall, regenerative practices—including rotational grazing and diverse forage feeding—appeared to enhance milk omega-3 fatty acid and phytonutrient profiles, alongside improved soil health indicators. Further research is needed to assess long-term impacts across a broader range of farms.}
}
@article{MUZANENHAMO2024102735,
title = {ChatGPT and accounting in African contexts: Amplifying epistemic injustice},
journal = {Critical Perspectives on Accounting},
volume = {99},
pages = {102735},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102735},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000340},
author = {Penelope Muzanenhamo and Sean Bradley Power},
keywords = {ChatGPT, Epistemic injustice, Large language models, Pluriversality, Accounting, Africa},
abstract = {Large Language Models (LLMs) such as ChatGPT are likely to amplify epistemic injustice through the lack of transparency and traceability of data sources. The unethical alienation of original knowledge producers from their intellectual products, which are repackaged by LLMs as artificial intelligence, conceals power asymmetries in the global knowledge production and dissemination system. As elaborated by Miranda Fricker (2010), Western White male actors traditionally dominate knowledge production; therefore, ChatGPT and other LLMs are inclined to reproduce patriarchal perspectives as universal understandings of the World. Our commentary applies this logic to accounting practice and research in Africa, and asserts that epistemic injustice, resulting from colonization and racism, means that ontological and epistemological approaches situated in the accounting needs and experiences of African communities are missing from or poorly articulated by ChatGPT and other LLMs. If LLMs are to attain legitimacy as (ethical) sources of knowledge, regulation must be enforced to ensure transparency—as a foundation for promoting pluriversality and eliminating epistemic injustice.}
}
@article{POURBEHZADI2024114308,
title = {Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring},
journal = {Decision Support Systems},
volume = {186},
pages = {114308},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114308},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624001416},
author = {Motahareh Pourbehzadi and Giti Javidi and C. Jordan Howell and Eden Kamar and Ehsan Sheybani},
keywords = {Cybersecurity, CVE, CVSS, Machine learning, Situational awareness},
abstract = {The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity.}
}
@article{CHEN2025131230,
title = {Knowledge graph and large language model integration with focus on educational applications: A survey},
journal = {Neurocomputing},
volume = {654},
pages = {131230},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131230},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019022},
author = {Guanyu Chen and Tao Song and Quanyu Wang and Zheng Ma and Jun Hu and Qi Li and Chunming Wu},
keywords = {Knowledge graph, Large language model, Educational application, Retrieval augmented generation, Pre-training},
abstract = {In recent years, artificial intelligence (AI) technology has made significant advancements, particularly in the areas of large language models (LLMs) and knowledge graphs (KGs). KGs excel at structured knowledge representation and reasoning, offering interpretability; however, they are costly to construct, have limited coverage, and lack natural language processing capabilities. Conversely, LLMs possess powerful language understanding and generation abilities, but they rely heavily on vast amounts of data, are prone to “hallucinations," and lack interpretability. The integration of these two approaches is an inevitable trend for achieving stronger and more reliable AI applications, and has become a hot topic of research. Simultaneously, the combination of LLMs and KGs perfectly aligns with the pressing needs of the education field for precise reasoning and personalized services, addressing the shortcomings of traditional teaching methods and providing support for intelligent education. In light of this, this paper undertakes work in the following three key areas. Firstly, the concepts and technologies of both LLMs and KGs, along with their applications in education, are introduced. On this basis, the paper then delves into a discussion of the methods for integrating LLMs and KGs, and reviews related research progress. Finally, the paper focuses on specific educational scenarios, such as intelligent tutoring systems, intelligent learning companions, and intelligent evaluation systems, to explore the collaborative application of LLMs and KGs. The aim of this paper is to provide researchers in the field with a systematic understanding of LLMs and KGs, and to offer valuable references for future AI-driven educational innovation.}
}
@article{PAN2025114022,
title = {Interpretable photovoltaic power modeling via Kolmogorov-Arnold network and timeGAN hybrid architecture with regime-aware data augmentation},
journal = {Solar Energy},
volume = {302},
pages = {114022},
year = {2025},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2025.114022},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X25007856},
author = {Yuqiao Pan and Zhaocai Wang and Zuowen Tan and Zhihua Zhu},
keywords = {Transformer-KAN, Photovoltaic power generation prediction, Collaborative data analysis, TimeGAN, Interpretable analysis},
abstract = {The variable and stochastic nature of photovoltaic (PV) power generation poses significant challenges to its large-scale integration into power grids, limiting the full exploitation of solar energy as a clean power source. To address this issue, this study proposes a hybrid modeling framework that synergistically combines data preprocessing, feature expansion, and advanced deep learning architectures. First, the integrate Variational Autoencoder (VAE) is used for feature selection and dimensionality reduction, followed by seasonal and diurnal pattern division. The Ordering Points to Identify the Clustering Structure (OPTICS) algorithm is employed to identify intrinsic operational regimes, while TimeGAN is adopted to augment data diversity through synthetic generation of temporal features. The core innovation resides in the adoption of a dual-model architecture. For the first time, this architecture integrates the Transformer with the Kolmogorov-Arnold Network (KAN) to establish a hybrid framework. Comparative experiments involving ten benchmark models, including five standalone deep learning models and their KAN-enhanced variants, demonstrate the superiority of the proposed approach. The Transformer-KAN hybrid achieves 29.51 % and 12.0 % reductions in RMSE and MAE respectively compared to the standalone Transformer, while maintaining computational efficiency. This study provides an interpretable artificial intelligence solution for PV modeling that can effectively support renewable energy utilization optimization.}
}
@article{2024134,
title = {Guide for Authors},
journal = {Intelligent Medicine},
volume = {4},
number = {2},
pages = {134-140},
year = {2024},
issn = {2667-1026},
doi = {https://doi.org/10.1016/S2667-1026(24)00028-7},
url = {https://www.sciencedirect.com/science/article/pii/S2667102624000287}
}
@article{XIN2024104669,
title = {Acupuncture Provides Short-Term Functional Improvements and Pain Relief for Patients After Knee Replacement Surgery: A Systematic Review and Meta-analysis},
journal = {The Journal of Pain},
volume = {25},
number = {12},
pages = {104669},
year = {2024},
issn = {1526-5900},
doi = {https://doi.org/10.1016/j.jpain.2024.104669},
url = {https://www.sciencedirect.com/science/article/pii/S1526590024006254},
author = {Wang Xin and Yu Miao and Mei Yu and Xie Xing and Xu Ying-ying and Zhang Yan and Li Dai and Huang Hongshi and Yin Yu and Wang Jian-quan and Li Bao-hua},
keywords = {Acupuncture, knee replacement, postoperative pain, range of motion, meta-analysis},
abstract = {The impact of acupuncture on knee function and pain intensity following knee replacement remains controversial. Therefore, we categorized the postsurgery recovery period into 3 phases: short-term (≤2 weeks), intermediate-term (2 weeks–3 months), and long-term (>3 months), and then assessed the effectiveness of acupuncture in improving function and alleviating pain at different stages following knee replacement. This meta-analysis included randomized controlled trials that compared acupuncture intervention with either no treatment or a sham group after knee replacement. Six databases were searched from inception to December 31, 2023, including PubMed, Embase, Cochrane Central Register of Controlled Trials, Web of Science, and 2 Chinese databases (Chinese National Knowledge Infrastructure and WanFang Data). A total of 23 studies comprising 1,464 participants were included. Significant improvement of active range of motion was observed on day 7 and week 2 after operation. Lower pain intensity at rest was noted in patients receiving acupuncture in short-term periods after operation (12 hours, day 1, day 2, day 5, and week 2). A reduction in pain intensity during movement with acupuncture was observed on postoperative day 1 and day 7. Auricular acupuncture did not show not significant effectiveness in improving range of motion and pain intensity. For conventional acupuncture, the combination of distal and local point selection was found to be the most effective. Early application of acupuncture, in conjunction with physical therapy, starting before postoperative day 1 or day 2, was recommended. Further high-quality researches are warranted to validate the findings in this meta-analysis.
Perspective
This article demonstrates that acupuncture has short-term effects (≤2 weeks) on improving active range of motion and reducing pain during rest and during movement following knee replacement surgery. The findings support the early application of acupuncture in hospital settings after knee replacement.
Registration ID
The study was registered on PROSPERO (CRD42024503479).}
}
@incollection{SAMANT2026321,
title = {Chapter 13 - Artificial intelligence and personalized medication using nanodots},
editor = {Bhupendra G. Prajapati and Devesh U. Kapoor and Nemat Ali},
booktitle = {Nanodots for Cancer Diagnosis and Treatment},
publisher = {Academic Press},
pages = {321-346},
year = {2026},
isbn = {978-0-443-27511-1},
doi = {https://doi.org/10.1016/B978-0-443-27511-1.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443275111000017},
author = {Sheetal Sadguru Samant and Devesh U. Kapoor},
keywords = {Artificial intelligence, cancer, deep learning, machine learning, nanodots, nanomedicine, personalized medication, targeted drug delivery},
abstract = {The convergence of artificial intelligence (AI) and nanotechnology has paved the way for a paradigm shift in personalized cancer treatment. Nanodots (NDs) are tiny particles engineered to target specific cancer cells that can be designed to deliver precise medication, thereby reducing harm to healthy cells and minimizing side effects. AI algorithms can analyze vast amounts of data to identify optimal dosing regimens, predict patient outcomes, and detect potential side effects. This synergy enables real-time monitoring, adaptive treatment strategies, and enhanced patient outcomes. AI-driven NDs can be programmed to release medication in response to specific biological triggers, thus ensuring targeted and efficient treatment. Moreover, AI-powered analytics facilitate the identification of predictive biomarkers, thereby enabling early detection and intervention. By harnessing the strengths of AI and nanotechnology, we can revolutionize cancer treatment, thus making it more precise, effective, and patient-centric. The potential benefits of this technology are vast, including improved treatment outcomes, reduced healthcare costs, and enhanced quality of life for cancer patients. This chapter explores the innovative application of AI-powered NDs in cancer therapy, thereby enabling tailored approaches to combat this complex and multifaceted disease. This chapter showcases innovative research that could revolutionize cancer treatment.}
}
@article{TOLEDOESILVA2025139890,
title = {Cell wall polysaccharides from macauba pulp (Acrocomia aculeata L.): Fractionation and characterization of their chemical and rheological properties},
journal = {International Journal of Biological Macromolecules},
volume = {298},
pages = {139890},
year = {2025},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2025.139890},
url = {https://www.sciencedirect.com/science/article/pii/S0141813025004398},
author = {Sérgio Henrique {Toledo e Silva} and Stephanie Bader-Mittermaier and Lidiane Bataglia Silva and Carlos Augusto Colombo and Roseli Aparecida Ferrari and Peter Eisner},
keywords = {Bocaiuva, By-products, Gums},
abstract = {Macauba fruit pulp (Acrocomia aculeata) is an emerging oil source. After de-oiling, the macauba pulp meal (MPM) offers a dietary fiber content of 40–50 %, which mainly comprises cell wall polysaccharides (CWP). The present work aimed to assess the potential of MPM as an innovative source of sustainable food polysaccharides. To this end, the macauba CWP were fractionated into water-soluble galactoglucomannans (21.7 %), calcium- and ester-bound pectins (3.4 %), loosely-bound xyloglucans (27.6 %), strongly-bound xylans (6.5 %), and a cellulose-rich fraction (39.3 %). The galactoglucomannans produced shear-thinning aqueous dispersions with an increase in consistency index from 3.03·10−2 to 3.58·101 Pa·sn by increasing the concentration from 1.0 to 5.0 %. The galactoglucomannans dispersions showed semi-dilute behavior, evidenced by relaxation times ranging from 1.24·10−2 to 1.17 s for concentrations from 2.5 to 10.0 %. Macauba pectins and xyloglucans showed weak gel behavior, with an increase in yield stress from 3.20·10−1 to 1.04·102 Pa and from 7.01·10−2 to 1.35·102 Pa for dispersions at 2.5 to 10.0 %, respectively. 2.5 to 5 times higher concentration of macauba polysaccharides is needed to obtain rheological behavior similar to guar and xanthan gum. The thickening and gelling properties of macauba CWP highlight their potential as thickeners and stabilizers for the food industry.}
}
@article{2025A11,
title = {Guidelines for Authors},
journal = {Journal of Endodontics},
volume = {51},
number = {7},
pages = {A11-A18},
year = {2025},
issn = {0099-2399},
doi = {https://doi.org/10.1016/S0099-2399(25)00344-9},
url = {https://www.sciencedirect.com/science/article/pii/S0099239925003449}
}
@article{HE2026113892,
title = {Human-guided urban form generation using multimodal diffusion models},
journal = {Building and Environment},
volume = {287},
pages = {113892},
year = {2026},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113892},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325013629},
author = {Mingyi He and Yuebing Liang and Shenhao Wang and Yunhan Zheng and Qingyi Wang and Dingyi Zhuang and Li Tian and Jinhua Zhao},
keywords = {Urban form generation, Multimodal diffusion models, Human-AI interaction, Building layout, Urban design},
abstract = {Urban morphological design plays a critical role in shaping environmental quality and urban livability. Recent advances in generative AI offer new opportunities for urban form generation, yet existing methods often lack mechanisms for human intervention and struggle to produce high-fidelity and functionally viable designs. This study proposes a human-in-the-loop generative framework for urban design based on multimodal diffusion models. We enhance Stable Diffusion with ControlNet to support high-fidelity urban form generation under environmental constraints and expert guidance. The generation process is structured as a hierarchical, stepwise pipeline, where land use configurations, building layouts, and satellite imagery are sequentially produced based on human input. Using spatial data from Chicago and New York City, we demonstrate that our framework outperforms GAN-based baselines in visual realism, compliance with design intent, and spatial diversity. Compared to end-to-end approaches, the stepwise framework produces more functionally viable and context-sensitive urban forms. A case study involving professional urban designers further illustrates the framework’s effectiveness in supporting collaborative human–AI design. These findings highlight the advantages of diffusion-based models and human-guided generation in supporting scalable and environmentally responsive urban design.}
}
@article{LUO2025105775,
title = {Resistance or resilience? University music teachers' active learning intention in response to the emergence of artificial intelligence},
journal = {Acta Psychologica},
volume = {261},
pages = {105775},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105775},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825010881},
author = {Miao Luo and Shuang Liang},
keywords = {Artificial intelligence, Active learning intention, Conservation of resources theory, Technology impact awareness, University music education},
abstract = {This study examines Chinese university music teachers' responses to AI integration using structural equation modeling (N = 317). Through Conservation of Resources (COR) theory, we investigate relationships between technology impact awareness, job insecurity, proactive personality, and active learning intention. Results reveal a “technology impact-job insecurity decoupling effect”: technology awareness directly motivates learning (β = 0.519, p < 0.001) without triggering job insecurity as mediator. While job insecurity positively influences learning intention (β = 0.338, p < 0.001), it does not mediate the technology-learning relationship. Proactive personality moderates the insecurity-learning link (β = 0.132, p < 0.001). To explain this decoupling, we propose an “art-technology cognitive separation” mechanism whereby music teachers perceive AI as an auxiliary tool enhancing rather than threatening their artistic core. These finding challenges traditional assumptions that technological threats necessarily induce occupational anxiety before motivating adaptation. The study extends COR theory to creative professions and suggests institutions should focus on increasing AI awareness through opportunity-framed exposure rather than threat-based messaging, while tailoring support strategies to teachers' personality traits.}
}
@article{PUSEY2024102888,
title = {Exploring the interaction among writing fluency, writing processes, and external resource access in second language writing assessment},
journal = {Computers and Composition},
volume = {74},
pages = {102888},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102888},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000641},
author = {Kerry Pusey and Yuko Goto Butler},
keywords = {Writing assessment, Writing processes, Writing fluency, English for academic purposes, Test task characteristics},
abstract = {As part of a larger investigation into the ecology of language tests, this study explores how writing fluency and writing processes are impacted by (dis)allowing access to external writing resources. An analysis was conducted of three international graduate students’ writing practices as they completed two argumentative writing assessment tasks. On one task, participants could access external writing resources (e.g., the internet) and had additional time to complete the task; on the other, access to writing resources was not permitted and a more restricted time limit was enforced. Data were collected from digital screen capture recordings of participants’ compositional practices and analyzed both qualitatively and quantitatively. Results indicated that participants took more time and wrote at a slower pace when they had access to external resources; however, additional time did not necessarily lead to a greater volume of writing. Participants also tended to shuttle between writing processes more frequently and execute more micro-level writing actions when they had access to external resources. However, there was substantial individual variation for both fluency and writing processes, highlighting the mediating role of individual differences in L2 writing. Implications for how the construct of academic writing ability is defined in different assessment contexts are discussed.}
}
@article{HUANG2024101402,
title = {Does family care promote clean cooking energy choices for older persons? –Analysis in light of home-based care in rural China},
journal = {Energy for Sustainable Development},
volume = {79},
pages = {101402},
year = {2024},
issn = {0973-0826},
doi = {https://doi.org/10.1016/j.esd.2024.101402},
url = {https://www.sciencedirect.com/science/article/pii/S0973082624000280},
author = {Wei Huang and Shiwu Li and He Yang and Hao Yang},
keywords = {Care for the aged, Clean cooking energy, Rural China, Fogg's Behavior Model},
abstract = {In the dual context of global aging and the cleaner energy transition, the impact of home-based care for the aged on cooking energy preferences in rural areas is important. This paper selects CHARLS 2018 data, uses the Probit model, and constructs a theoretical framework with Fogg's Behavior Model to demonstrate the effects of care for the aged. The results showed that older persons with family care in rural areas were more likely to use traditional cooking energy. The disincentive is reinforced by the utilization of traditional cooking energy by neighbors in the community. And those with personal care were more likely to use clean cooking energy. The ability to guarantee clean cooking energy being adopted reinforces the facilitating effect of personal care. In order to promote and use clean energy, it is vital to understand the unique influence of different kinds of care for the aged. Efforts in policy and practice should focus on boosting the motivation and ability to adopt clean energy. The main contributions are: (1) The paper included different kinds of care for the aged as an influencing factor in using clean cooking energy; (2) Through its analysis of motivation and ability factors influencing behavioral choices, it exhaustively explores the inherent mechanisms; (3) This paper can bring policy implications for the promotion of clean cooking energy in rural areas of developing countries.}
}
@article{LEE2024105048,
title = {Becoming epistemically active in online reading: Facilitating elementary school students’ multimodal multiple document reading via sourcing organizers},
journal = {Computers & Education},
volume = {216},
pages = {105048},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105048},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524000629},
author = {Yuan-Hsuan Lee and Jing-Ya Jhang and Huang-Yao Hong},
keywords = {Online multimodal and multiple document reading, Text integration, Source-content link, Reading interest, Reading ability},
abstract = {In the AI era, it has become crucial to evaluate information found on the Internet critically. This research aimed to investigate the impact of a sourcing organizer on sixth graders' online multimodal and multiple document reading (MMDR) abilities, focusing on aspects such as source-content link and text integration in relation to reading on the Internet. Cognitive and affective factors associated with MMDR were examined. The study involved 52 sixth-graders (55.77% males) from two typical elementary school classes in the northern region of Taiwan. Two intact classes were randomly assigned to either the experimental or control group with the quasi-experimental design. The experimental group (n = 26) received a pre-outlined sourcing organizer, guiding them to record the article title, author, publication date, website name, and major assertions from six assigned multimodal texts. In contrast, the control group (n = 26) received a regular organizer, prompting them to summarize the main ideas from the same six assigned multimodal texts. The study's findings indicated that employing sourcing organizers positively impacted students' performance in text integration. However, it was observed that both groups, regardless of whether they used regular organizers or sourcing organizers, experienced benefits in terms of source-content links. Furthermore, reading ability emerged as the sole significant predictor for source-content links, whereas both reading ability and the use of sourcing organizers predicted text integration. The implications of these findings were discussed to provide insights into instructional strategies to develop online MMDR competencies in elementary students.}
}
@article{2025A18,
title = {Guidelines for Authors},
journal = {Journal of Endodontics},
volume = {51},
number = {8},
pages = {A18-A25},
year = {2025},
issn = {0099-2399},
doi = {https://doi.org/10.1016/S0099-2399(25)00406-6},
url = {https://www.sciencedirect.com/science/article/pii/S0099239925004066}
}
@article{PRISTERA2025207,
title = {Testing circularity measures: Lifespan and end-of-life modelling influence on the environmental impact of the EU residential building stock},
journal = {Sustainable Production and Consumption},
volume = {56},
pages = {207-220},
year = {2025},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2025.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S2352550925000648},
author = {G. Pristerà and E. Sanyé-Mengual and P. Wierzgala and S. Sala},
keywords = {Building stock model, LCA, Sensitivity analysis, Circularity, Service life, Embodied impacts},
abstract = {The reduction of the environmental impacts of the building sector, either through a decrease in its operational energy consumption or the promotion of circular practices, is the target of multiple EU policy initiatives. While different modelling approaches have been proposed to quantify the environmental impacts of the EU building stock, limited knowledge is available on the sensitivity of these models to key parameters associated with circular economy measures. To fill this gap, this study aims at testing lifespan and end-of-life modelling choices to gain an improved understanding of their effect on the quantification of the environmental impacts of the EU residential sector, using a Life Cycle Assessment (LCA)-based building stock model developed by the European Commission – Joint Research Centre (JRC) as the reference model. Several options were explored in relation to parameters affecting the service lives of buildings and their components, along with their end-of-life pathways. A sensitivity analysis was also performed to evaluate the model's robustness when subjected to parameter changes derived from the literature. It emerged that, due to the prominent role played by the operational energy phase, environmental impact results at the stock level were not significantly affected by parameter changes, with the exception of the particulate matter impact category, which achieved >10% variations when simultaneously testing shorter finishing material service lives and lower incineration and recycling rates. Shifting the focus to embodied impacts, however, led to increased sensitivity in the model, with oscillations due to service life length overshadowing those connected to end-of-life treatment changes: in terms of single weighted score, the former can achieve a building-level variation of over 100% (when assuming short lifespans), while the latter does not exceed 38% (when maximising incineration rates). It is therefore necessary to take these fluctuations into account when using this LCA-based model as a basis for verifying the potential benefits of measures to promote circularity within the building sector, particularly as said measures primarily target embodied impacts.}
}
@article{CASALO2025104130,
title = {Intelligence and humanness as key drivers of service value in Generative AI chatbots},
journal = {International Journal of Hospitality Management},
volume = {128},
pages = {104130},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104130},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925000532},
author = {Luis V. Casaló and Paola Millastre-Valencia and Daniel Belanche and Carlos Flavián},
keywords = {Warmth, Competence, Automated social presence, Perceived value, Generative AI, Artificial intelligence levels},
abstract = {Automated service agents with different levels of artificial intelligence (AI) - mechanical, analytical, and emotional - are gradually replacing employees in their interactions with customers. Previous research suggests that these agents (e.g., chatbots) should embed human behavioral traits such as warmth, competence, and even automated social presence (i.e., perceiving that one is interacting with someone else). However, it is unknown whether different levels of AI are perceived by customers as features increasing humanness and, subsequently, leading to higher functional, monetary, social, or emotional value. Through an experimental design based on tourism chatbots, the results from structural equation analysis reveal that whereas mechanical AI decreases automated social presence, analytical AI increases perceptions of competence and warmth, and emotional AI improves all humanness cues. The article merges the research streams of service agent design and customers’ perceptions of humanness to guide tourism managers in implementing generative AI agents to increase service value.}
}
@article{LAU2025101077,
title = {Impact-driven scholar, reflective practitioner, or pracademic? Conceptualizing hybrid roles to bridge the research-practice gap in HRM},
journal = {Human Resource Management Review},
volume = {35},
number = {2},
pages = {101077},
year = {2025},
issn = {1053-4822},
doi = {https://doi.org/10.1016/j.hrmr.2025.101077},
url = {https://www.sciencedirect.com/science/article/pii/S1053482225000026},
author = {Annica Lau and Joshua Haist and Rebecca Hewett},
keywords = {Impact-driven scholar, Reflective practitioner, Pracademic, Hybrid roles, Identity, Research-practice gap, Human resource management},
abstract = {Bridging the gap between theoretical concepts relating to human resource management (HRM) and practical application of research insights is essential for creating important, relevant, and therefore high impact management theories about work and organizations. Pracademics, who actively participate in both research and practice activities, cross boundaries between domains, so play a critical role in bringing theories into practice. However, the role of pracademics is conceptually underdeveloped and ambiguous, limiting our understanding of how actors engage in bridging the research-practice divide. We propose a continuum of research-practice roles, recognizing that hybrid roles are often fluid in nature. We explain how hybrid professionals hold different identities; as impact-driven scholars, reflective practitioners, or pracademics. These roles have implications for individuals' activities, identity work, career, and collaboration. Drawing on three contemporary challenges in HRM, we illustrate how hybrid professionals can align HRM theory and practice and help close the research-practice gap. As well as theoretical and managerial implications, we also highlight implications of the continuum of roles for policy makers and funders.}
}
@article{HUANG2025104225,
title = {PaperEval: A universal, quantitative, and explainable paper evaluation method powered by a multi-agent system},
journal = {Information Processing & Management},
volume = {62},
number = {6},
pages = {104225},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104225},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001669},
author = {Shengzhi Huang and Qicong Wang and Wei Lu and Lingyu Liu and Zhenzhen Xu and Yong Huang},
keywords = {Paper evaluation, Multi-agents, Large language model, AI for science},
abstract = {The immediate and efficient evaluation of scientific papers is crucial for advancing scientific progress. However, traditional peer review faces numerous challenges, including reviewer bias, limited expertise, and an overwhelming volume of publications. Recent advancements in large language models (LLMs) suggest their potential as promising evaluators, capable of approximating human cognition and understanding both ordinary and scientific language. In this study, we propose a novel AI-empowered paper evaluation method, PaperEval (PE), which utilizes a multi-agent system powered by LLMs to design evaluation criteria, assess paper quality along different dimensions, and generate explainable scores. We also introduce two variants of PE, Multi-round PaperEval (MPE) and Self-correcting PaperEval (SPE), which produce comparable scores and iteratively refine the evaluation criteria, respectively. To test our methods, we conducted a comprehensive analysis of three curated datasets, encompassing about 66,000 target papers of varying quality across the fields of mathematics, physics, chemistry, and medicine. The results show that our methods can effectively discern between high- and low-quality papers based on scores derived in four dimensions: Question, Method, Result, and Conclusion. Moreover, the results highlight the evaluation’s stability over time, the impact of comparative papers, the advantages of the multi-round evaluation strategy, and the varying correlation between AI ratings and scientific impact across different disciplines. Our method can seamlessly integrate into the existing scientific evaluation system, offering valuable insights for the development of AI-driven scientific evaluation.}
}
@article{WANG2025113542,
title = {Generative emulation and uncertainty quantification of geological CO2 storage with conditional diffusion models},
journal = {Applied Soft Computing},
volume = {182},
pages = {113542},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113542},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625008531},
author = {Zhongzheng Wang and Yuntian Chen and Guodong Chen and Qiang Zheng and Tianhao Wu and Dongxiao Zhang},
keywords = {Geological CO storage, Generative emulation, Uncertainty quantification, Diffusion models, Probabilistic modeling},
abstract = {Carbon capture and storage (CCS) has emerged as a pivotal technology for reaching climate-neutrality targets. Safe and effective deployment of CCS requires reliable predictions of pressure buildup and CO2 plume migration under geological uncertainties. However, traditional numerical simulations are limited by computational inefficiency, while machine learning methods face bottlenecks in predictive accuracy and uncertainty. Here we introduce a generative emulation framework named DiffMF for efficient prediction of multiphase flows in geological CO2 storage. The framework treats flow prediction as conditional generation processes and employs cutting-edge diffusion models to produce the temporal–spatial evolution of pressure and CO2 saturation fields under varying geological property conditions. Unlike existing approaches that focus primarily on point estimation, the probabilistic nature of DiffMF allows for generating multiple predictions that align with the statistics of the underlying dynamics, thereby facilitating effective quantification of predictive uncertainty. Comprehensive evaluations on diverse CO2 storage cases show that DiffMF achieves up to 52.6% lower CO2 saturation error compared to leading baseline models while maintaining high accuracy even under increased geological heterogeneity. Furthermore, we interpret the black-box model via visual analysis, providing insights into the generation process of DiffMF. Finally, the application to uncertainty quantification and propagation task for a field-scale storage system demonstrates that DiffMF yields statistics of the system responses in close agreement with those derived from high-fidelity simulations while executing 100 times faster, underscoring its promising potential in practical applications. The proposed generative emulation paradigm enables real-time prediction and probabilistic modeling that can foster informed decision-making for CCS deployment.}
}
@article{TEERTAM2025100315,
title = {Advances in Microengineered Platforms for Skin Research},
journal = {JID Innovations},
volume = {5},
number = {1},
pages = {100315},
year = {2025},
issn = {2667-0267},
doi = {https://doi.org/10.1016/j.xjidi.2024.100315},
url = {https://www.sciencedirect.com/science/article/pii/S2667026724000638},
author = {Sireesh Kumar Teertam and Vijayasaradhi Setaluri and Jose M. Ayuso},
keywords = {In vitro culture, Microfluidics, Organ-on-a-chip, Skin models},
abstract = {The skin plays a critical role in human physiology, acting both as a barrier to environmental insults and as a window to environmental stimuli. Disruption of this homeostasis leads to numerous skin disorders. Human and animal skin differ significantly, limiting the translational potential of animal-based investigations to advance therapeutics to human skin diseases. Hence, there is a critical need for physiologically relevant human skin models to explore novel treatment strategies. Recent advances in microfluidic technologies now allow design and generation of organ-on-chip devices that mimic critical features of tissue architecture. Skin-on-a-chip and microfluidic platforms hold promise as useful models for diverse dermatology applications. Compared with traditional in vitro models, microfluidic platforms offer improved control of fluid flow, which in turn allows precise manipulation of cell and molecular distribution. These properties enable the generation of multilayered in vitro models that mimic human skin structure while simultaneously offering superior control over nutrient and drug distribution. Researchers have used microfluidic platforms for a variety of applications in skin research, including epidermal–dermal cellular crosstalk, cell migration, mechanobiology, microbiome–immune response interactions, vascular biology, and wound healing. In this review, we comprehensively review state-of-the-art microfluidic models for skin research. We discuss the challenges and promise of current skin-on-a-chip technologies and provide a roadmap for future research in this active field.}
}
@article{FRYER2025115881,
title = {Consumer responses to smoke-impacted pinot noir wine and the influence of label concepts on perception},
journal = {Food Research International},
volume = {203},
pages = {115881},
year = {2025},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2025.115881},
url = {https://www.sciencedirect.com/science/article/pii/S0963996925002182},
author = {Jenna A. Fryer and Amanda {Dupas de Matos} and Joanne Hort and Elizabeth Tomasino},
keywords = {Wildfire, Wine, Smoke Taint, Liking, Emotion, Sensory},
abstract = {While wildfire’s impacts on wine have been considered a defect due to the introduction of smoke-related off-flavours, limited studies have investigated consumers responses to smoke-impacted wines. The aims of this work were (i) to explore how New Zealand consumers respond to smoke-impacted wine; (ii) confirm whether clusters of consumers existed and characterise them by their liking of smoky flavours in foods/beverages and subjective wine knowledge; and (iii) explore how different label concepts influence consumer responses. Participants responded to liking, emotions, and perceived sensory attributes of five blends of smoke-impacted wine with non-impacted wine, along with a smoke-impacted wine presented with four different label concepts. Two clusters of consumers were identified, with one disliking the smoke-impacted wine (smoke-dislikers) and the other cluster liking (smoke-liker). The smoke-liker cluster indicated a greater liking of smoke flavours in foods and beverages, along with a higher level of subjective wine knowledge. For the labels, the introduction of the label concept significantly increased liking of the wine for the smoke-dislikers, as well as had the power to elicit different emotions and sensory experiences. This research provides vital information to the wine industry as they adapt to future wildfire years, along with how the distinct sensory profile may not be detrimental to consumer acceptance and can be modulated by the type of information on label. Further research is needed to explore how different populations and wine styles correlate with these findings, and the effects of varying levels of smoke exposure in Pinot noir and other grape varietals.}
}
@article{NUNES2025102940,
title = {Moral appraisals of generative AI: How mindset framing shapes moral judgments, emotional appraisals and privacy behavior},
journal = {International Journal of Information Management},
volume = {84},
pages = {102940},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102940},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000726},
author = {Joana Rita Nunes and Paulo Rita and Diego {Costa Pinto} and Héctor Gonzalez-Jimenez and Khaoula Akdim and Rafael Luís Wagner},
keywords = {Artificial intelligence, Emotional appraisals, Implicit mindsets, Generative AI, Moral judgments, Privacy behavior},
abstract = {The rapid development of Generative AI (GenAI) and similar technologies has heightened ethical concerns, including privacy issues, discrimination, and data security. However, there is limited understanding of how mindset framing shapes users’ moral judgments and emotional responses toward these technologies. To address this gap, this research examines how framing GenAI, particularly in terms of growth or fixed mindset, influences moral appraisals, emotional reactions, and privacy behaviors. Using a mixed-methods approach, this research combines text mining of a large field dataset (n = 18,035 reviews) with two experimental studies (n = 255 participants). Findings reveal that mindset framing directly influences perceived morality, suggesting that GenAI framed in a growth mindset evokes more positive moral judgments compared to a fixed mindset framing. A growth mindset suggests learning and adaptability, whereas a fixed mindset framing implies that it is immutable and incapable of improvement. Perceived moral judgments mediate the effect of mindset framing (growth vs. fixed) on emotional appraisals. Moreover, mindset framing influences privacy behavior, with participants having low (vs. high) expertise disclosing more under a growth (vs. fixed) mindset. Theoretically, this paper contributes to the literature by integrating key theories on moral judgment, implicit theories, cognitive appraisal theory, and privacy calculus theory, thereby deepening the understanding of moral appraisals regarding GenAI. In practical terms, this research enables organizations to strategically frame GenAI capabilities, positively influencing users' privacy behavior and emotional responses.}
}
@article{RHO2025105413,
title = {Inoculating students against misleading data visualizations with perceptual training and informative feedback},
journal = {Computers & Education},
volume = {238},
pages = {105413},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105413},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001812},
author = {Jihyun Rho and Martina Angela Rau and Xiaojin Zhu},
keywords = {Visual misinformation, Misleading data visualizations, Educational intervention, Perceptual training, Informative feedback},
abstract = {Misleading visualizations are a form of misinformation that distort data interpretation, leading to misunderstandings and poor decision-making. Despite their prevalence in both traditional and digital media, there is limited research on effective educational interventions that help students recognize and resist such deceptive visualization techniques. In this study, we developed a perceptual training intervention specifically designed to inoculate students against misleading visualizations. Unlike traditional perceptual trainings that typically involve only correct visuals, trainings for misleading visualizations require the inclusion of erroneous visual examples. While the informative feedback can help students to efficiently recognize such misleading visualizations and extract correct information, it may also disrupt the inductive learning during training, potentially reducing its overall effectiveness. To shed light into these possibilities, we investigated the role of informative feedback in a perceptual training designed for misleading visualizations. We conducted two experiments with large samples of undergraduate students (Experiment 1: N = 252, Experiment 2: N = 244). Experiment 1 tested the short-term effects of different informative feedback types during perceptual training, while Experiment 2 examined both the long-term retention (after one month) and near transfer to novel misleading visualizations. Results showed that informative feedback significantly improved students’ accuracy and efficiency in detecting misleading features within visualizations. Students also transferred these skills to novel misleading visualization types, and critically the benefits of informative feedback were sustained over a month. These results highlight the potential of perceptual trainings with informative feedback to inoculate students against misleading visualizations, offering valuable guidance for the development of educational interventions aimed at mitigating the effects of visual misinformation.}
}
@article{WEI2025103954,
title = {The two-echelon truck-unmanned ground vehicle routing problem with time-dependent travel times},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {194},
pages = {103954},
year = {2025},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103954},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524005453},
author = {Yuanhan Wei and Yong Wang and Xiangpei Hu},
keywords = {Truck–unmanned ground vehicle routing problem, Urban transportation, Time-dependent travel times, Adaptive large neighborhood search, Uncertain traffic conditions},
abstract = {With the rapid expansion of e-commerce and the resulting surge in parcel delivery demands, the integration of trucks and unmanned ground vehicles (UGVs) in last-mile package delivery provides a more efficient and sustainable venue for a logistics system. However, coordinating trucks and UGVs in the context of fluctuating traffic conditions, especially with varying travel times, continues to be a significant challenge. This study addresses this issue by proposing and solving a two-echelon truck-UGV routing problem with time-dependent travel times. The first echelon encompasses transporting goods from the warehouse to satellites using trucks, considering time-dependent travel times. The second echelon involves distributing goods from satellites to customers using UGVs. Initially, a continuous-time time-dependent travel model is proposed based on the fluid queueing model to estimate vehicle travel times under varying traffic conditions. We then develop a multiobjective mixed integer linear programming model that aims to minimize total operating costs and the number of UGVs used. Subsequently, a novel hybrid algorithm combining an improved three dimension k-nearest neighbor clustering algorithm with an improved multiobjective adaptive large neighborhood search method is developed to solve the model. This algorithm incorporates the adaptive score adjustment and Pareto solution selection strategies to enhance algorithm convergence and evaluate solution quality. The acceptance criterion for new solutions is redesigned based on multiobjective function values to explore the search space more thoroughly. Additionally, the algorithm’s computational performance is verified by comparing it with the CPLEX solver for small-scale problems and with multiobjective ant colony optimization, multiobjective evolutionary algorithms, multiobjective particle swarm optimization, multiobjective monarch butterfly optimization, and multiobjective harmony search algorithms for medium-to-large problems. The results demonstrate the superior convergence, uniformity, and spread of the proposed algorithm. Furthermore, a real-world case study employing traffic information of Dalian city, China, supports that the proposed method enhances the efficiency of delivery. Four different time-dependent travel times model are proposed to analyze the outperformance of the time-dependent travel model in this study. Finally, the sensitivity analysis considers different road congestion states and UGV capacities, aiming to reduce transportation costs, and overcome high coordination and congestion costs in the network. This study offers robust methodologies for theoretically and practically addressing the two-echelon truck-UGV routing problem with time-dependent travel times, providing essential insights for promoting development, enhancing smart city integration, and boosting operational efficiency.}
}
@incollection{ZHOU202585,
title = {Chapter 5 - Macrocyclization strategy in kinase drug discovery},
editor = {Bin Yu and Peng Zhan},
booktitle = {Drug Discovery Stories},
publisher = {Elsevier},
pages = {85-99},
year = {2025},
isbn = {978-0-443-23932-8},
doi = {https://doi.org/10.1016/B978-0-443-23932-8.00005-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443239328000054},
author = {Yang Zhou and Xiaoyun Lu},
keywords = {Macrocycles, kinase, drug design, clinical resistance, selectivity, molecular structure, drug development, computational molecular modeling},
abstract = {Protein kinases inhibitors still have drug resistance and limited selectivity challenges in drug design. Recently, macrocyclization has emerged as an attractive direction for kinase inhibitors development, offering an effective strategy to overcome drug resistance and novel structural frameworks to improve selectivity. This chapter explores the surge in macrocyclic kinase inhibitors, illustrating their pivotal role in advancing kinase drug design, and also comprehensively discusses advantages of macrocyclic kinase inhibitors (MKIs), structure-based design, and computational tools involved in the design of these MKIs, shedding light on their increasing importance and outlining future prospects in this field.}
}
@article{YU2024108870,
title = {Optimal design of a clamp band system based on genetic algorithm and experimental verification},
journal = {Aerospace Science and Technology},
volume = {145},
pages = {108870},
year = {2024},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2024.108870},
url = {https://www.sciencedirect.com/science/article/pii/S1270963824000038},
author = {Baoshi Yu and Dapeng Zhang and Xinfeng Wu and Sondipon Adhikari and Yongjun Lei},
keywords = {Clamp band system, Parameterized modeling method, Genetic algorithm, Optimal design, Explicit nonlinear analysis, Separation shock},
abstract = {As one of the most common separation systems, the clamp band system (CBS) is widely used in the process of connection and release of spacecraft with the launch vehicle. An optimal design method and a separation shock response estimation method were proposed for a large-diameter CBS in this paper. First, a new application based on the parameter modeling method of MSC.Patran and genetic algorithm (GA) was proposed to design the CBS. Finite element techniques for 2D axisymmetric analysis of the CBS were developed, including the modeling of V-clamp, strap pre-tension, and loads, then the optimizing constraints and objectives were also defined. Secondly, a CBS with a diameter of 3 m was designed via the proposed method, which is verified by the 3D finite element analysis under MSC.Marc and a stiffness experiment. Thirdly, the separation process of the CBS and its high-frequency and high-amplitude shock response were calculated by an explicit dynamic solver, and the differences between the model and experimental results were discussed. Finally, a single degree of freedom (SDOF) spring-mass system was constructed to predict the weakening effect of the delay time on the shock response. The slow-release device was designed and the experiment was completed to verify the effectiveness of the method.}
}
@article{PARNON20252561,
title = {A unified framework for asset ranking based on their criticality through case studies},
journal = {International Journal of Quality & Reliability Management},
volume = {42},
number = {9},
pages = {2561-2586},
year = {2025},
issn = {0265-671X},
doi = {https://doi.org/10.1108/IJQRM-01-2025-0038},
url = {https://www.sciencedirect.com/science/article/pii/S0265671X2500012X},
author = {M.A. Amiruddin Parnon and Kassandra A. Papadopoulou and Jyoti K. Sinha},
keywords = {Criticality-based asset management, Risk priority index, Failure mode effects and criticality analysis, Integrated asset ranking framework, Wind turbine},
abstract = {Purpose
Effective asset management is grounded in a strategic framework prioritising assets according to their criticality to minimise downtime, reduce maintenance costs and maintain operational efficiency. This paper introduces a unified framework for asset ranking that integrates expert insights, criteria weighting and risk assessment techniques. Unlike standalone approaches, this framework addresses biases and inaccuracies by harnessing the strengths of each method while mitigating their limitations.
Design/methodology/approach
The framework starts with an asset audit that examines field and historical performance data, followed by data cleaning and expert validation through questionnaires to ensure the criteria’s relevance. A pairwise comparison matrix is used to weight the criteria, while risk elements are assessed using failure mode, effects and criticality analysis. This process leads to calculating the risk priority index, which ranks the critical assets.
Findings
The framework is demonstrated through a case study of two 500 kW wind turbine models: geared and direct-drive. The findings reveal that direct-drive turbines are generally more critical, informing their maintenance priorities.
Research limitations/implications
This paper illustrates the framework’s potential for effective resource allocation and risk mitigation, offering flexibility for application across diverse industries. Nevertheless, its reliance on historical data and expert input may need enhancement.
Originality/value
This comprehensive approach ensures a structured method for asset prioritisation that addresses the real-world challenges inherent in asset management by leveraging the strengths of multiple methodologies and mitigating their limitations.}
}
@article{ZHONG2026102357,
title = {Prediction of particulate matter (PM) in rural built environments based on Generative Adversarial Network (GAN)},
journal = {Computers, Environment and Urban Systems},
volume = {123},
pages = {102357},
year = {2026},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2025.102357},
url = {https://www.sciencedirect.com/science/article/pii/S0198971525001103},
author = {Liqiang Zhong and Hao Zheng},
keywords = {Prediction of particulate matter, Rural built environment, Block scale, Generative Adversarial Network},
abstract = {Particulate matter (PM) is a key parameter for characterizing outdoor air quality. PM concentration is closely related to features of built environment. Rural built environment elements at block scale, such as building massing, impermeable surfaces, and farmlands, significantly impact the PM concentration. However, current research has focused on large-scale and broad-spectrum forecasting models, which are difficult for guide designers to apply because they lack rapid, detailed forecasting and specific visualization. This study proposes an automated design procedure using the Generative Adversarial Network (GAN) model to perform spatial planning oriented by environmental performance in rural blocks. This study collected and obtained data, including satellite land cover maps and PM concentrations, to construct a prediction model. Then, the model was used to quickly and accurately predict the concentrations of three kinds of particulate matter, PM1, PM2.5, and PM10 under different design scenarios. This study found that first, the ratio between industrial and residential buildings (IB:RB) was positively correlated with PM concentration. The buildings with a short-strip configuration exhibited the lowest PM concentration in their environment compared to clusters of buildings in long strips or block-form structures. Second, the ratio between roads and small squares (R:SS) showed a positive correlation with PM concentration. The impervious surfaces characterized by large block configurations demonstrated the lowest PM concentration among the five planar forms evaluated. Third, farmland coverage exhibited a weak negative correlation with PM concentration. Farmlands with small blocks had the lowest PM10 levels among five different planar forms, and small dotted farmlands had the lowest PM1 and PM2.5 levels. Finally, the model was used to simulate PM concentration under different design scenarios and suggested interactive strategies for future rural spatial planning design.}
}
@article{ZHONG2025108611,
title = {PMFSNet: Polarized multi-scale feature self-attention network for lightweight medical image segmentation},
journal = {Computer Methods and Programs in Biomedicine},
volume = {261},
pages = {108611},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2025.108611},
url = {https://www.sciencedirect.com/science/article/pii/S0169260725000288},
author = {Jiahui Zhong and Wenhong Tian and Yuanlun Xie and Zhijia Liu and Jie Ou and Taoran Tian and Lei Zhang},
keywords = {Medical image segmentation, Lightweight neural network, Attention mechanism, Multi-scale feature fusion},
abstract = {Background and objectives:
Current state-of-the-art medical image segmentation methods prioritize precision but often at the expense of increased computational demands and larger model sizes. Applying these large-scale models to the relatively limited scale of medical image datasets tends to induce redundant computation, complicating the process without the necessary benefits. These approaches increase complexity and pose challenges for integrating and deploying lightweight models on edge devices. For instance, recent transformer-based models have excelled in 2D and 3D medical image segmentation due to their extensive receptive fields and high parameter count. However, their effectiveness comes with the risk of overfitting when applied to small datasets. It often neglects the vital inductive biases of Convolutional Neural Networks (CNNs), essential for local feature representation.
Methods:
In this work, we propose PMFSNet, a novel medical imaging segmentation model that effectively balances global and local feature processing while avoiding the computational redundancy typical of larger models. PMFSNet streamlines the UNet-based hierarchical structure and simplifies the self-attention mechanism’s computational complexity, making it suitable for lightweight applications. It incorporates a plug-and-play PMFS block, a multi-scale feature enhancement module based on attention mechanisms, to capture long-term dependencies.
Results:
The extensive comprehensive results demonstrate that our method achieves superior performance in various segmentation tasks on different data scales even with fewer than a million parameters. Results reveal that our PMFSNet achieves IoU of 84.68%, 82.02%, 78.82%, and 76.48% on public datasets of 3D CBCT Tooth, ovarian tumors ultrasound (MMOTU), skin lesions dermoscopy (ISIC 2018), and gastrointestinal polyp (Kvasir SEG), and yields DSC of 78.29%, 77.45%, and 78.04% on three retinal vessel segmentation datasets, DRIVE, STARE, and CHASE-DB1, respectively.
Conclusion:
Our proposed model exhibits competitive performance across various datasets, accomplishing this with significantly fewer model parameters and inference time, demonstrating its value in model integration and deployment. It strikes an optimal compromise between efficiency and performance and can be a highly efficient solution for medical image analysis in resource-constrained clinical environments. The source code is available at https://github.com/yykzjh/PMFSNet.}
}
@article{ZHOU2024105287,
title = {Virtual multiplexed immunofluorescence staining from non-antibody-stained fluorescence imaging for gastric cancer prognosis},
journal = {eBioMedicine},
volume = {107},
pages = {105287},
year = {2024},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2024.105287},
url = {https://www.sciencedirect.com/science/article/pii/S2352396424003232},
author = {Zixia Zhou and Yuming Jiang and Zepang Sun and Taojun Zhang and Wanying Feng and Guoxin Li and Ruijiang Li and Lei Xing},
keywords = {Multiplexed immunofluorescence staining, Artificial intelligence, Gastric cancer prognostic, Immune cell biomarker},
abstract = {Summary
Background
Multiplexed immunofluorescence (mIF) staining, such as CODEX and MIBI, holds significant clinical value for various fields, such as disease diagnosis, biological research, and drug development. However, these techniques are often hindered by high time and cost requirements.
Methods
Here we present a Multimodal-Attention-based virtual mIF Staining (MAS) system that utilises a deep learning model to extract potential antibody-related features from dual-modal non-antibody-stained fluorescence imaging, specifically autofluorescence (AF) and DAPI imaging. The MAS system simultaneously generates predictions of mIF with multiple survival-associated biomarkers in gastric cancer using self- and multi-attention learning mechanisms.
Findings
Experimental results with 180 pathological slides from 94 patients with gastric cancer demonstrate the efficiency and consistent performance of the MAS system in both cancer and noncancer gastric tissues. Furthermore, we showcase the prognostic accuracy of the virtual mIF images of seven gastric cancer related biomarkers, including CD3, CD20, FOXP3, PD1, CD8, CD163, and PD-L1, which is comparable to those obtained from the standard mIF staining.
Interpretation
The MAS system rapidly generates reliable multiplexed staining, greatly reducing the cost of mIF and improving clinical workflow.
Funding
Stanford 2022 HAI Seed Grant; National Institutes of Health 1R01CA256890.}
}
@article{ZHANG2024274,
title = {Energy, exergy, economic, and environmental compromising performance of dual-stage evaporation-ammonia hybrid compression–absorption refrigeration system for the cooling supply of keto-benzene dewaxing process},
journal = {Chinese Journal of Chemical Engineering},
volume = {75},
pages = {274-289},
year = {2024},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S1004954124002507},
author = {Shuaishuai Zhang and Yuanbo Liu and Tong Zheng and Da Ruan and Zhong Lan and Tingting Hao and Xuehu Ma},
keywords = {Evaporation, Optimal design, Thermodynamic process, Multi-objective optimization, Ammonia hybrid refrigeration},
abstract = {ABSTRACT
Absorption refrigeration systems driven by low-temperature waste heat is one way to achieve “carbon neutrality.” Meanwhile, the keto-benzene dewaxing equipment needs a cooling capacity of 5 MW, with refrigeration temperature of −10 °C and −25 °C. This paper researches the feasibility of dual-stage evaporation-ammonia hybrid compression–absorption refrigeration system (DSE-AHCARS) replacing the vapor compression refrigeration system for keto-benzene dewaxing process based on energy, exergy, economic, and environmental (4E) analysis. At the primary- and secondary-stage evaporation temperature of 0 and –23 °C, respectively, the coefficient of performance (COP) reaches the maximum value of 0.85; however, COP-electricity reaches the minimum value of 8.1. When the secondary-stage refrigeration temperature is −23 °C, CO2 emission increases from 1150 t·a−1 to 3600 t·a−1, and life cycle climate performance increases from 3.29 × 104 to 7.7 × 104 t, with the primary-stage refrigeration temperature being −15–0 °C, as well as matching three parameters to ensure the 4E compromising performance by the multi-objective optimization. To guarantee that the life cycle climate performance is less than 5.5 × 104 t, the payback period is <2 a, and COP is >0.6 at the optimal operation ranges, such that the refrigeration temperature difference between primary stage and secondary stage is within 20 °C. The power of DSE-AHCARS was reduced by 77% compared with the vapor-compression refrigeration system. Therefore, the DSE-AHCARS can reduce CO2 emissions by about 6250 t·a−1 and save 1.2 × 105 t of CO2 in the life cycle climate performance term. This result shows that the DSE-AHCARS can completely replace the vapor-compression refrigeration system.}
}
@article{REN2025104305,
title = {LLM-Enhanced Multi-Task Joint Learning Model for Misinformation Detection},
journal = {Information Processing & Management},
volume = {62},
number = {6},
pages = {104305},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104305},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325002468},
author = {Gang Ren and Li Jiang and Tingting Huang and Ying Yang and Ruida Xie},
keywords = {Misinformation Detection, Large Language Models, Multi-task Joint Learning, Contrastive Learning},
abstract = {The coexistence of Human-Generated Content (HGC) and Artificial Intelligence-Generated Content (AIGC) versions of the same event on social media presents significant challenges for governmental governance and information regulation. In this study, we propose a Large Language Model-enhanced Multi-Task Joint Learning Model for Misinformation Detection (LMTMD) to address the challenge of mixed HGC and AIGC on social media. We design a two-stage instruction, leveraging large language models (LLMs) for data augmentation to generate AIGC versions of events. Furthermore, a novel unsupervised joint learning strategy is proposed, which incorporates content consistency contrastive learning and difference consistency learning. The strategy aims to preserve both the consistency of event content and the heterogeneity between AIGC and HGC. Extensive experiments conducted on real-world datasets, including Weibo and GossipCop, demonstrate that the proposed model outperforms state-of-the-art baselines, achieving a Consistent Match Accuracy (CM-Acc) of 77.21% on the Weibo dataset and 78.13% on the GossipCop dataset. Additionally, the model achieves AIGC detection accuracy rates of 90.58% on the Weibo dataset and 90.95% on the GossipCop dataset, thereby validating the effectiveness of both the model and the joint learning strategy. Our model can effectively adapt to the emerging scenario of mixed HGC and AIGC versions of events on social platforms and enriches the research perspective of misinformation detection.}
}
@article{PRAHANI2024101495,
title = {Mapping research on scientific creativity: A bibliometric review of the literature in the last 20 years},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101495},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101495},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000336},
author = {Binar Kurnia Prahani and Iqbal Ainur Rizki and Nadi Suprapto and Irwanto Irwanto and Muhammed Akif Kurtuluş},
keywords = {Scientific creativity, Bibliometric analysis, Bibliometrix, Research trend, Divergent thinking, Teaching creativity},
abstract = {The main goal of this study is to use bibliometric methods to explore the scientific creativity literature over the past two decades. The aim is to gain a deep understanding of how this field has developed conceptually, intellectually, and socially, with the objective of advancing both empirical evidence and conceptual understanding. The study draws upon the Scopus database as the source of literature metadata, subsequently subjecting the data to analysis via the Bibliometrix software. Commencing with an initial identification of 254 articles, a stringent application of search and exclusion criteria led to the inclusion of 110 articles for in-depth analysis. The outcomes of this research unveil pivotal themes within scientific creativity, offering a quantitative analysis that presents an encompassing view through tables, graphs, and maps. Moreover, the study delves into identifying core performance indicators associated with article production and citation rates. As discerned from the results, the emerging research directions within scientific creativity encompass the enhancement and assessment of scientific creativity, pedagogical strategies for teaching creativity within science education, and the exploration of thinking skills pertinent to scientific creativity. These findings provide valuable insights for future researchers and also have practical implications for educators and policymakers. By doing so, this study helps inform the development of strategies to effectively foster scientific creativity in the context of the 21st-century skills era.}
}
@article{PAVLOVA2024117327,
title = {Healthcare compassion interventions co-design and feasibility inquiry with clinicians and healthcare leaders in Aotearoa/New Zealand},
journal = {Social Science & Medicine},
volume = {360},
pages = {117327},
year = {2024},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2024.117327},
url = {https://www.sciencedirect.com/science/article/pii/S0277953624007810},
author = {Alina Pavlova and Sarah-Jane Paine and Amelie Tuato'o and Nathan S. Consedine},
abstract = {Compassion in healthcare is valued by patients, healthcare professionals (HCPs), and leads to improved outcomes. Notwithstanding reports of systemic failings in the provision of compassionate care, research regarding ways to intervene remains limited. The aim of this study is to clarify compassion intervention needs in a diverse HCP workforce in public secondary healthcare in Aotearoa New Zealand (NZ) by utilising a co-design process. The co-design process involved a series of workshops with clinicians followed by in-depth interviews with healthcare leaders to derive input regarding feasibility and implementation. Reflexive thematic analysis was used to analyze the data. There was a great deal of interest in compassion interventions from healthcare professionals and leaders. However, for compassion interventions to be acceptable, feasible, and effective, compassion interventions design should be reimagined and reflected at each step of interventional design and implementation and span across organizational levels. Namely, the results of the study showed the preference for non-individual focused multi-level interventions to build bridges and connections. The desired compassion intervention components included practising connecting with others' humanity, improving compassion knowledge and relational and reflective skills, and cultural safety and anti-racism training. Experiential training embedded in models of cultural dialogue was the preferred interventional modality. Prioritising leadership as an intervention site was suggested to improve leadership's buy-in of compassion interventions and possibly serve as a starting point for transforming the broader culture, reviving interconnectedness in a healthcare system described as fragmented, disconnected, and alienating with compassion also acting as an equalizer of power.}
}
@article{BEZERRA2025126306,
title = {A novel approach based on graph signal processing and sampling theory to set pressure sensors in water distribution networks},
journal = {Expert Systems with Applications},
volume = {270},
pages = {126306},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126306},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424031737},
author = {Daniel Bezerra and Carlo Giudicianni and Enrico Creaco and Gustavo Meirelles and Bruno Brentan},
keywords = {Pressure sensor placement, Graph signal processing, Spectral clustering},
abstract = {Optimizing the arrangement of pressure sensors in water distribution networks (WDNs) is crucial for system efficiency, enabling accurate monitoring and effective control, especially in detecting and mitigating leaks. This study addresses this issue through a joint application of graph signal processing theory and the spectral clustering algorithm. Two WDNs are modeled as graphs, and the spectral clustering algorithm is used to identify leak-sensitive regions based on the properties of the vertices. Then, three metrics from signal sampling on graphs are employed to select the vertices as possible locations for installing the sensors. A new metric, which considers the coverage rate of installed sensors, is introduced to evaluate the performance of the pressure monitoring system, in addition to helping to determine the optimal number of sensors to be deployed. The proposed approach demonstrates an increase of up to 20% in the coverage rate compared to existing methods. Detailed leak simulations show coverage rates of 84% for the Modena network and 92% for the L-Town network with optimal sensor placement. This methodology provides a more efficient and cost-effective solution for WDN managers.}
}
@article{RIKHARI2025420,
title = {Whole transcriptome analysis identifies ALB-EEF1A1 fusion as a novel biomarker in metastatic colorectal cancer},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {5},
pages = {420-433},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000084},
author = {Deeksha Rikhari and Ankit Srivastava and Sandhya Rai and  Mubashra and Srinivas Patnaik and Sameer Srivastava},
keywords = {, Fusion transcript, RNA-seq, Colorectal cancer, Diagnostic, Biomarker, Functional enrichment, Pan-cancer},
abstract = {Background
Colorectal cancer (CRC) is a complex, heterogeneous disease characterized by frequent relapses and metastasis. Previous studies have reported that the invasion and progression of CRC in several cases can be controlled by targeting fusion genes. This study aimed to screen for potent fusion transcripts as potential molecular biomarkers and therapeutic targets for metastatic CRC (mCRC) using an in silico approach.
Methods
RNA sequencing (RNA-seq) data from 18 patients with primary CRC and matched normal and mCRC samples were derived from the same patient set. Novel fusion transcripts were screened using the Kallisto and Pizzly software, followed by Gene Ontology (GO), pathway analysis, transcription factor enrichment, and survival for functional enrichment analysis. Furthermore, the fusion transcripts’ utility as biomarkers was evaluated using a pan-cancer analysis.
Results
In total, 32 fusion genes unique to mCRC were identified. Hub gene analysis identified 17 novel fusion transcripts, and GO analysis revealed that these genes were enriched in different biological and molecular functions. Pathways significantly correlated with CRC included the complement and coagulation cascades, ferroptosis, interleukin-17 (IL-17) signaling pathway, and estrogen signaling pathway. We identified albumin-eukaryotic translation elongation factor 1 alpha 1 (ALB-EEF1A1) as unique to mCRC based on significant gene expression and survival outcomes. Moreover, its utility as a prognostic biomarker was confirmed using a pan-cancer analysis.
Conclusions
ALB-EEF1A1 may play a pivotal role in the metastatic transformation of primary CRC and significantly increase the risk of death. The identified ALB-EEF1A1 fusion transcripts are promising novel molecular targets that may serve as prognostic and diagnostic biomarkers and treatment targets for mCRC in the future.}
}
@article{DARTORA2023100789,
title = {Kombuchas from black tea, green tea, and yerba-mate decocts: Perceived sensory map, emotions, and physicochemical parameters},
journal = {International Journal of Gastronomy and Food Science},
volume = {33},
pages = {100789},
year = {2023},
issn = {1878-450X},
doi = {https://doi.org/10.1016/j.ijgfs.2023.100789},
url = {https://www.sciencedirect.com/science/article/pii/S1878450X23001312},
author = {Bruna Dartora and Ludmylla Tamara Crepalde and Lilian Raquel Hickert and Mariana Fensterseifer Fabricio and Marco Antônio Zachia Ayub and Flávio Fonseca Veras and Adriano Brandelli and Karla Joseane Perez and Voltaire Sant’Anna},
keywords = {Check-All-That-Apply, , Anti-hypertensive, Emotions},
abstract = {The aim of the present work was to compare kombuchas made of green and black teas and yerba-mate. Physicochemical properties, total polyphenols, condensed tannin content, antioxidant and anti-hypertensive activities were evaluated. Check-all-that-apply was used for sensory characterization of the samples and the emotions evoked. Green tea kombucha presented higher values of acetic acid and anti-hypertensive activity and lower values of ethanol. Black tea kombucha presented higher polyphenol content. Yerba-mate kombucha presented lower values of anti-hypertensive activity. Green tea kombucha presented sourness and acid aroma and flavors; black tea beverage, yellow color, and intense flavor; yerba-mate kombucha presented bright color. Ideal kombucha should present smooth smell and flavors and to be sweet. Awareness that kombucha was made of yerba-mate evoked the emotions of peaceful, loving, and quiet; consumers evoked aggressive, worried and good emotions for black tea beverage and green tea consumers evoked to be pleased. Different tea leaves performed differently for physiochemical features, perceived sensory attributes and emotions evoked.}
}
@article{COHEN2025,
title = {The Alongside Digital Wellness Program for Youth: Longitudinal Pre-Post Outcomes Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/73180},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25006973},
author = {Katherine Cohen and Andy Rapoport and Elsa Friis and Shannon Hill and Sergey Feldman and Jessica Schleider},
keywords = {digital mental health, schools, youth, Alongside, LGBTQ},
abstract = {Background
Youth are increasingly experiencing psychological distress. Schools are ideal settings for disseminating mental health support, but they are often insufficiently resourced to do so. Digital mental health tools represent a unique avenue to address this gap. The Alongside digital program is one such tool, intended as a universal prevention and early intervention. The platform includes social-emotional learning and self-help wellness features as well as an artificial intelligence–powered chatbot designed to build coping skills.
Objective
This evaluation aimed to examine the near-term impact of Alongside app use on students’ self-reported mental health outcomes.
Methods
We conducted a nonrandomized pilot pragmatic evaluation leveraging anonymized user data. All data came from current Alongside users attending public middle and high schools in Texas and New Mexico, between 10 and 18 years old. Schools were actively engaged in partnership with Alongside and approved all procedures. Users were asked to complete mental health questionnaires upon app registration and at 1 and 3 months post registration. We conducted preregistered analyses as well as exploratory analyses to determine how symptoms changed over time and what factors (eg, demographic and app use) predicted changes in distress.
Results
Analyses revealed statistically significant within-person decreases in overall distress (Young Person’s CORE; primary outcome) from baseline to 1 month with a small effect size (t42=2.21, P=.03, r=0.34); however, there was no evidence that scores significantly decreased from baseline to 3 months (W=1821, n=85, P=.16). We found that at 3 months, identifying as part of the lesbian, gay, bisexual, transgender, queer, and questioning community predicted greater decreases in distress; otherwise, no demographic factors were significant predictors. In a nonregistered exploratory analysis of a subsample of users who reported elevated distress at baseline, decreases in distress were seen at both 1 month (W=128, n=20, P=.02, r=0.52) and 3 months (W=682, n=42, P=.004, r=0.45).
Conclusions
There may be short-term benefits associated with using the Alongside digital program. Further studies are required to determine potential preventative effects.}
}
@article{YAMAGUCHI2023121,
title = {An analysis of literacy differences related to the identification and dissemination of misinformation in Japan},
journal = {Global Knowledge, Memory and Communication},
volume = {74},
number = {11},
pages = {121-139},
year = {2023},
issn = {2514-9342},
doi = {https://doi.org/10.1108/GKMC-07-2024-0419},
url = {https://www.sciencedirect.com/science/article/pii/S2514934225000030},
author = {Shinichi Yamaguchi and Hidetaka Oshima and Tomoaki Watanabe and Yukiko Osaka and Tsukasa Tanihara and Eri Inoue and Shinnosuke Tanabe},
keywords = {Misinformation, False information, Literacy, True/false judgment, Dissemination behavior, Disinformation},
abstract = {Purpose
This study aims to examine the relationship between various types of literacy on one hand and identification of misinformation and dissemination of such information on the other, in search for better countermeasures against misinformation.
Design/methodology/approach
Based on data from a large-scale survey, models are constructed and analyzed to assess the relationships of literacy with both the identification of inaccuracies and dissemination behavior.
Findings
Regarding the identification of misinformation, individuals with high critical thinking attitudes (subjective literacy) are less likely to recognize misinformation, while other objective literacies do not have a significant relationship. Regarding dissemination behavior, individuals with high information literacy, media literacy and critical thinking scores tend not to disseminate misinformation, whereas those with high critical thinking attitudes are more likely to disseminate such information.
Originality/value
First, it quantitatively elucidates the relationships various literacies have with the accuracy judgment and dissemination behavior of misinformation. This highlights the effectiveness of objective indicators of literacies and the need for caution regarding subjective literacy – i.e. self-confidence in their own literacy. Second, it provides a cross-disciplinary analysis of the relationships, covering not only oft-studied politics and health care but also various other fields, thereby identifying comprehensive literacy strategies against misinformation. Third, it addresses differences in dissemination methods and offers insights into more practical countermeasures.}
}
@article{DU2023132,
title = {The returns to computer use in the Chinese labor market},
journal = {China Economic Quarterly International},
volume = {3},
number = {2},
pages = {132-143},
year = {2023},
issn = {2666-9331},
doi = {https://doi.org/10.1016/j.ceqi.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666933123000205},
author = {Yang Du and Peng Jia and Albert Park},
keywords = {Computer use, Productivity, Solow paradox},
abstract = {With rising wages and increasing maturity of computer technology, computer use in the workplace is becoming increasingly common. Based on data from an urban labor survey, 58 percent of urban workers used computers at work in 2016. Using computer price and density as instrumental variables, we identify the estimation bias from the simultaneous determination of computer use and its productivity effect. We further identify the productivity effect based on computer use frequency. With the above econometric issues taken into account, computer use at work significantly boosts labor productivity and increases workers' wage returns by 48.4 percent.}
}
@article{KRAUS2023122381,
title = {From moon landing to metaverse: Tracing the evolution of Technological Forecasting and Social Change},
journal = {Technological Forecasting and Social Change},
volume = {189},
pages = {122381},
year = {2023},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122381},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523000665},
author = {Sascha Kraus and Satish Kumar and Weng Marc Lim and Jaspreet Kaur and Anuj Sharma and Francesco Schiavone},
keywords = {Bibliometric analysis, Structural topic modelling, STM, , , Review},
abstract = {Technological Forecasting and Social Change (TFSC) is one of the most prominent journals to focus on the methodologies and practices of technological forecasting and futures studies. This study aims to analyse the topical structure of TFSC and track the most cited articles published in the journal using a combination of a structural topic model (STM) and bibliometric analysis. The STM reveals 18 prominent topics in TFSC, and the topical quality of the STM results is verified based on semantic coherence and topic exclusivity scores as well as an assessment of the correlations among topics. The STM also tracks the temporal variations in topical prevalence that occurred from 1969 to 2022, shedding light on the changing popularity of each topic. The bibliometric analysis presents a decade-by-decade perspective on the most cited articles and the geographical dispersion of authors affiliated with TFSC, thereby providing a truly global perspective on the journal's publishing activity.}
}
@article{BELLONI202541,
title = {Fingerprint change as a consequence of anticancer treatments: A systematic integrative review},
journal = {Seminars in Oncology},
volume = {52},
number = {1},
pages = {41-54},
year = {2025},
issn = {0093-7754},
doi = {https://doi.org/10.1016/j.seminoncol.2025.152335},
url = {https://www.sciencedirect.com/science/article/pii/S0093775425000041},
author = {Silvia Belloni and Arianna Magon and Rita {de Sanctis} and Paola Tiberio and Gianluca Conte and Cristina Arrigoni and Rosario Caruso},
keywords = {Adermatoglyphia, Cancer, Change, Chemotherapy, Fingerprint, Loss},
abstract = {ABSTRACT
Objective
While it is widely acknowledged that fingerprint recognition has played an essential part in policing and forensic science, little is known about fingerprint alterations in medical science, specifically as a consequence of anticancer treatments. Thus, we aimed to analyze the extent of evidence between cancer treatments and fingerprint alterations in adults with cancer.
Methods
A systematic integrative review was conducted according to the PRISMA statement and the Cochrane guidelines for conducting a systematic review. PubMed, CINAHL, Web of Science, and Scopus were searched from the inception between August and November 2024. The quality appraisal was conducted to evaluate the methodological quality of the included articles, selecting the most appropriate tool based on the publication type and study design.
Results
Of 176 records, we selected five experimental studies articles and nine case reports publications. A correlation between specific anticancer treatments (capecitabine, taxanes, and tyrosine kinase inhibitors) and fingerprint alterations has been documented in individuals with various cancer diagnoses (mainly advanced breast and colorectal cancers). The majority of articles were of moderate to low quality.
Conclusions
Although fingerprint alteration as a consequence of specific anticancer treatments has been documented, further large and well-designed experimental studies are necessary to quantify the phenomenon burden in relation to specific anticancer regimens and populations.
Prospero registration n
(CRD42024581192).}
}
@article{AMAECHI2025114261,
title = {A systematic literature review on knowledge management for project risk management in construction},
journal = {Journal of Building Engineering},
volume = {114},
pages = {114261},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.114261},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225024982},
author = {Chiemela Victor Amaechi and Ahmed Reda and Salmia Binti Beddu and Daud Bin Mohamed and Agusril Syamsir and Idris {Ahmed Ja'e} and Safi Ullah and Deng Xiaopeng and Bo Huang and Chunguang Wang and Xuanze Ju},
keywords = {Knowledge management, Knowledge-based learning, Project management, Risk management, Construction, Systematic review, Knowledge mapping, Scientometric review},
abstract = {The need for urbanisation, smart cities and high-rise buildings globally has increased the volume of projects carried out in the Architecture, Engineering and Construction (AEC) industry. These buildings are designed under tight schedules, tight contracts, huge budgets, and highly performance-driven construction managers. Thus, this article presents a systematic literature review (SLR) on knowledge management for project risk management in construction. Using the SLR, two academic databases were utilised, namely Dimensions and Scopus for publications from 2000 to 2025. The knowledge acquired from the research was examined by classifying the areas on Project Risk Management (PRM), construction processes and knowledge management associated with construction. The keyword search utilised for this study was conducted in Google Scholar database. The search on this SLR considered three main areas namely project management (PM), knowledge management (KM) and risk management (RM). However, related search was conducted on other aspects like quantitative risk management (QRA). The findings include the development of knowledge maps on publication trends. Findings on the publication trends reflect steady growth in publications, with peaks and dips due to global events (like, COVID-19 pandemic in 2020/2021). Regarding the subject areas, Engineering is the dominant subject area (39 %), followed by Business and Computer Science, then others. Also, the leading countries include USA, China, UK, Australia, Malaysia, then others. The implications of the study reflect knowledge-based learning on construction management. The study found various innovative technologies that are adapted in construction through knowledge management. This SLR shows emerging trends, applications and research collaborations in the construction industry.}
}
@article{XU2025126585,
title = {Towards normalized clinical information extraction in Chinese radiology report with large language models},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126585},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126585},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002076},
author = {Qinwei Xu and Xingkun Xu and Chenyi Zhou and Zuozhu Liu and Feiyue Huang and Shaoxin Li and Lifeng Zhu and Zhian Bai and Yuchen Xu and Weiguo Hu},
keywords = {Clinical information extraction, Large language models, Instruction tuning, Data-efficient learning, Chinese radiology reports},
abstract = {Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this paper, we propose a novel information extraction paradigm named normalized clinical information extraction (NCIE) for Chinese radiology reports. Specifically, NCIE operates in an end-to-end fashion to extract normalized and structured clinical information without decomposing the information extraction process into multiple intermediate tasks. Motivated by recent progress in Large Language Models (LLMs), we address the NCIE problem based on the instruction tuning of LLMs. The proposed approach, termed Radiological Information End-to-end Extraction with LLM (RIEEL), excels at extracting structural information comprising radiological observations alongside their corresponding anatomical locations and status. To ensure the model in learning the normalized medical concepts correctly, we establish a radiology knowledge base with expert knowledge and further curate a high-quality instruction tuning dataset. Moreover, we incorporate two data-efficient learning strategies based on data augmentation and self-training to enhance the model’s NCIE capabilities during instruction tuning. Through extensive experiments, we demonstrate that the proposed RIEEL achieves superior performances with different state-of-the-arts backbone LLMs, including Qwen1.5, Baichuan2 and LLaMA3. Remarkably, the best version of RIEEL surpasses GPT-4 in NCIE by a substantial margin of 30.61% in terms of the F1 score.}
}
@article{VENEGAS2024111001,
title = {Early-life exposure to sex hormones promotes voluntary ethanol intake in adulthood. A vulnerability factor to drug addiction.},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {133},
pages = {111001},
year = {2024},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2024.111001},
url = {https://www.sciencedirect.com/science/article/pii/S0278584624000691},
author = {Francisca C. Venegas and Daniela Rosas and Nicol Delgado and Camila Estay-Olmos and Patricio Iturriaga-Vásquez and Mario Rivera-Meza and Gonzalo E. Torres and Georgina M. Renard and Ramón Sotomayor-Zárate},
keywords = {Dopamine, Ethanol intake, Sex hormones, Nucleus accumbens},
abstract = {While there is extensive research on alcohol dependence, the factors that make an individual vulnerable to developing alcoholism haven't been explored much. In this study, we aim to investigate how neonatal exposure to sex hormones affects alcohol intake and the regulation of the mesolimbic pathway in adulthood. The study aimed to investigate the impact of neonatal exposure to a single dose of testosterone propionate (TP) or estradiol valerate (EV) on ethanol consumption in adult rats. The rats were subjected to a two-bottle free-choice paradigm, and the content of dopamine (DA) and 3,4-dihydroxyphenylacetic acid (DOPAC) in the nucleus accumbens (NAcc) was measured using HPLC-ED. The expression of critical DA-related proteins in the mesolimbic pathway was evaluated through RT-qPCR and western blot analysis. Supraphysiological neonatal exposure to EV or TP resulted in increased ethanol intake over four weeks in adulthood. In addition, the DA and DOPAC content was reduced and increased in the NAcc of EV and TP-treated rats, and β-endorphin content in the hypothalamus decreased in EV-treated rats. The VTA μ receptor and DA type 2 form short receptor (D2S) expression were significantly reduced in EV and TP male rats. Finally, in an extended 6-week protocol, the increase in ethanol consumption induced by EV was mitigated during the initial two hours post-naloxone injection. Neonatal exposure to sex hormones is a detrimental stimulus for the brain, which can facilitate the development of addictive behaviors, including alcohol use disorder.}
}
@article{FAN2026103440,
title = {Social E-commerce Operations: Is it wise to adopt short video and live-streaming together?},
journal = {Omega},
volume = {138},
pages = {103440},
year = {2026},
issn = {0305-0483},
doi = {https://doi.org/10.1016/j.omega.2025.103440},
url = {https://www.sciencedirect.com/science/article/pii/S0305048325001665},
author = {Xiaojun Fan and Lu Zhang},
keywords = {E-commerce, Short video, Live-streaming sales, Multi-channel operation, Fan effect},
abstract = {In social e-commerce operations, both short videos and live-streaming are important strategies for expanding the market and motivating consumer engagement due to the fan effect of key opinion leaders (KOLs). This study is the first to analyze whether and when a manufacturer should offer both strategies and when one strategy is superior to the other. We consider a manufacturer that sells products through an e-commerce platform in traditional e-commerce channels and chooses to hire a KOL on social e-commerce platforms to stimulate consumer demand. This KOL can create short videos or/and use live-streaming. Then, we formulate four modes: Mode NN (no KOL), Mode SN (short videos and no live-streaming sales), Mode NL (no short videos but have live-streaming sales), and Mode SL (short videos and live-streaming sales). Comparing these four modes, we first find that when only considering adopting Mode SN, manufacturers always hire KOLs with high fan effects to sell products at a higher e-commerce price. However, when manufacturers choose Mode NL and Mode SL separately, KOLs with low fan effects can also allow manufacturers to get more profit if the consumer’s time cost is high. Interestingly, if the KOL’s fan effect is low (high), manufacturers may set a lower (higher) e-commerce price in both modes compared to when no social e-commerce strategy is implemented. Moreover, when manufacturers determine the conditions for introducing each social e-commerce mode separately, Mode SN/SL/NL is optimal for manufacturers only if KOLs have a high fan effect and the consumer’s time cost is high/low/medium.}
}
@article{KORZYNSKI2025548,
title = {Humanoid robotics and agentic AI: reframing management theories and future research directions},
journal = {European Management Journal},
volume = {43},
number = {4},
pages = {548-560},
year = {2025},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2025.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0263237325000908},
author = {Pawel Korzynski and Autumn Edwards and Mahesh C. Gupta and Grzegorz Mazurek and Jochen Wirtz},
keywords = {Humanoid robots, AI agents, Artificial Intelligence, Human resource management, Operations management, Marketing, Consumer behavior},
abstract = {The development of humanoid robots and artificial intelligence (AI) agents represents two distinct but complementary advancements in replicating human capabilities in physical and digital environments. This duality reflects a broader shift toward physical AI a term used to describe embodied AI systems capable of interacting with the physical world through movement and perception - of which humanoid robots are a prominent example. Our paper explores how these technologies reshape and extend established management theories across three disciplines—human resource management (HRM), marketing and consumer behavior (CB), and operations management (OM). Specifically, we propose that in HRM, humanoid robots challenge team role theory by introducing machine-oriented roles, such as trainers and testers, while AI agents prompt a rethinking of social learning theory through their capacity to enable behavior simulation and dynamic feedback loops. In marketing and CB, AI agents reconfigure value co-creation within service-dominant logic by acting as autonomous co-creators of value, while humanoid robots influence social agency theory by altering perceptions of trust and power dynamics. In OM, these technologies drive new opportunities for throughput, agility, and process optimization by integrating real-time predictive analytics and adaptive workflow automation. These insights emphasize that while many traditional theories remain relevant, they require adaptation to account for human–machine collaboration, machine agency, and the hybrid roles emerging in organizational contexts.}
}
@article{SAZHIN2024108857,
title = {Trait reward sensitivity modulates connectivity with the temporoparietal junction and Anterior Insula during strategic decision making},
journal = {Biological Psychology},
volume = {192},
pages = {108857},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108857},
url = {https://www.sciencedirect.com/science/article/pii/S0301051124001169},
author = {Daniel Sazhin and James B. Wyngaarden and Jeff B. Dennison and Ori Zaff and Dominic Fareri and Michael S. McCloskey and Lauren B. Alloy and Johanna M. Jarcho and David V. Smith},
keywords = {Reward sensitivity, Strategic behavior, Ultimatum game, Dictator game, Connectivity},
abstract = {Many decisions happen in social contexts such as negotiations, yet little is understood about how people balance fairness versus selfishness. Past investigations found that activation in brain areas involved in executive function and reward processing was associated with people offering less with no threat of rejection from their partner, compared to offering more when there was a threat of rejection. However, it remains unclear how trait reward sensitivity may modulate activation and connectivity patterns in these situations. To address this gap, we used task-based fMRI to examine the relation between reward sensitivity and the neural correlates of bargaining choices. Participants (N = 54) completed the Sensitivity to Punishment (SP)/Sensitivity to Reward (SR) Questionnaire and the Behavioral Inhibition System/Behavioral Activation System scales. Participants performed the Ultimatum and Dictator Games as proposers and exhibited strategic decisions by being fair when there was a threat of rejection, but being selfish when there was not a threat of rejection. We found that strategic decisions evoked activation in the Inferior Frontal Gyrus (IFG) and the Anterior Insula (AI). Next, we found elevated IFG connectivity with the Temporoparietal junction (TPJ) during strategic decisions. Finally, we explored whether trait reward sensitivity modulated brain responses while making strategic decisions. We found that people who scored lower in reward sensitivity made less strategic choices when they exhibited higher AI-Angular Gyrus connectivity. Taken together, our results demonstrate how trait reward sensitivity modulates neural responses to strategic decisions, potentially underscoring the importance of this factor within social and decision neuroscience.}
}
@article{NAKHAEI2024175790,
title = {Contamination of toxic elements in the sediments, water, and igneous rocks of the Sefid-rud River in Northern Iran using contamination indicators, with a specific focus on Ti-rich coastal sediments},
journal = {Science of The Total Environment},
volume = {952},
pages = {175790},
year = {2024},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2024.175790},
url = {https://www.sciencedirect.com/science/article/pii/S0048969724059461},
author = {Shahram Nakhaei and Mojgan Salavati and Ali Moghimi Kandelus},
keywords = {Heavy metals, Toxic effects, Sediment chemistry, Sefid-rud River sediments, Pollution, Environment},
abstract = {The Sefid-rud River is a significant river on the southern coast of the Caspian Sea in Iran. In this study, we collected 28 samples of surface sediments and water to assess the level of metal contamination. Chemical analysis revealed that the average concentrations of heavy metals in both sediments and water increase from upstream to downstream. There is no clear significant relationship observed between changes in the values of investigated elements in sediments and water. The levels of these elements in the sediments, exceed toxic response thresholds. In the water samples, As, Ni and V concentrations exceed the WHO standard values. According to the Igeo, EF and PLI indices, the sediments at most stations are not contaminated by any of the elements. The CF and Dc indices suggest low contamination levels at all stations. The NIPI and ecological risk indices (Er and RI) indicate non-polluted conditions at all stations except SF22, SF20, SF11, and SF6. The MI and HEI indices indicate pollution in all water samples of the Sefid-rud, but critical values are only observed at SF5 and SF15. The other stations show no contamination. The Cf index indicates high pollution levels for all elements except Cu, Zn, and Pb. The upstream area poses a relatively high and considerable ecological risk according to the PERI index. In conclusion, the sediments of the Sefid-rud River have a higher potential for the exchange of toxic substances compared to the aquatic environment.}
}
@article{TRUB2025100957,
title = {Judgment accuracy in primary school EFL writing assessment: Do text characteristics matter?},
journal = {Assessing Writing},
volume = {66},
pages = {100957},
year = {2025},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2025.100957},
url = {https://www.sciencedirect.com/science/article/pii/S1075293525000443},
author = {Ruth Trüb and Jens Möller and Julian Lohmann and Thorben Jansen and Stefan D. Keller},
keywords = {Assessment competence, Judgment accuracy, Text characteristics, English as a foreign language (EFL), Primary school, Writing assessment},
abstract = {Assessing the writing competence of pupils learning English as a foreign language (EFL) at primary school is challenging. This study aimed at examining a largely unexplored topic, namely the role of text characteristics in writing assessment, and analysed judgment accuracy differentiated by nine aspects of text quality (communicative effect, level of detail, coherence, cohesion, complexity of syntax and grammar, correctness of syntax and grammar, vocabulary, orthography and punctuation). Two hundred pre-service teachers assessed four randomly assigned texts from learners in grade six. Their assessment was compared to the existing ratings of two experts from a previous study. We found a relative judgment accuracy between r = .34 and .60 for the nine assessment criteria, with vocabulary being assessed significantly more accurately than almost all other criteria. Orthography, complexity and correctness of syntax and grammar and punctuation were rated with significantly more accuracy than cohesion, level of detail, communicative effect and coherence. The pre-service teachers assessed most criteria more strictly and with higher variability than the experts. The results suggest that teacher education should offer pre-service teachers concrete opportunities to practise writing assessment, implement activities to strengthen the assessment of content- and structure-related criteria, and help them adjust their assessment rigour.}
}
@article{RAFFLOER2025100168,
title = {Of love & lasers: Perceptions of narratives by AI versus human authors},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100168},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000520},
author = {Gavin Raffloer and Melanie C Green},
keywords = {Narrative, Artificial intelligence, Narrative transportation, Human-AI interaction},
abstract = {Artificial Intelligence (AI) programs can produce narratives. However, readers' preconceptions about AI may influence their response to these narratives, and furthermore, AI-generated writing may differ from human writing. Genre may also be relevant for readers’ attitudes regarding AI. This study tests the effects of actual AI versus human authorship, stated (labeled) authorship, and genre on perceptions of narratives and narrative engagement. Participants were randomly assigned within a 2 (actual author: human or AI) X 2 (stated author: human or AI) X 2 (genre: romance or science fiction) design, across two studies. In Study 1, actual AI narratives were perceived as more enjoyable, but human narratives were more appreciated. Furthermore, participants enjoyed actual AI-written sci-fi more than human-written sci-fi. Study 2 found that actual AI stories were rated more highly, particularly in appreciation, transportation, character identification, and future engagement. However, stated human authorship led to higher ratings for romance, but not for sci-fi. An interaction was observed such that for the sci-fi condition, stated human writing was perceived as more likely to be actually AI-written. Future research could expand upon these findings across more genres, as well as examining the determinants of preferences for stated human content.}
}
@article{SANCHEZ2024631,
title = {A Probabilistic Trust Model and Control Algorithm to Protect 6G Networks against Malicious Data Injection Attacks in Edge Computing Environments},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {141},
number = {1},
pages = {631-654},
year = {2024},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2024.050349},
url = {https://www.sciencedirect.com/science/article/pii/S1526149224002273},
author = {Borja Bordel Sánchez and Ramón Alcarria and Tomás Robles},
keywords = {6G networks, noise injection attacks, Gaussian mixture model, Bessel function, traffic filter, Volterra filter},
abstract = {Future 6G communications are envisioned to enable a large catalogue of pioneering applications. These will range from networked Cyber-Physical Systems to edge computing devices, establishing real-time feedback control loops critical for managing Industry 5.0 deployments, digital agriculture systems, and essential infrastructures. The provision of extensive machine-type communications through 6G will render many of these innovative systems autonomous and unsupervised. While full automation will enhance industrial efficiency significantly, it concurrently introduces new cyber risks and vulnerabilities. In particular, unattended systems are highly susceptible to trust issues: malicious nodes and false information can be easily introduced into control loops. Additionally, Denial-of-Service attacks can be executed by inundating the network with valueless noise. Current anomaly detection schemes require the entire transformation of the control software to integrate new steps and can only mitigate anomalies that conform to predefined mathematical models. Solutions based on an exhaustive data collection to detect anomalies are precise but extremely slow. Standard models, with their limited understanding of mobile networks, can achieve precision rates no higher than 75%. Therefore, more general and transversal protection mechanisms are needed to detect malicious behaviors transparently. This paper introduces a probabilistic trust model and control algorithm designed to address this gap. The model determines the probability of any node to be trustworthy. Communication channels are pruned for those nodes whose probability is below a given threshold. The trust control algorithm comprises three primary phases, which feed the model with three different probabilities, which are weighted and combined. Initially, anomalous nodes are identified using Gaussian mixture models and clustering technologies. Next, traffic patterns are studied using digital Bessel functions and the functional scalar product. Finally, the information coherence and content are analyzed. The noise content and abnormal information sequences are detected using a Volterra filter and a bank of Finite Impulse Response filters. An experimental validation based on simulation tools and environments was carried out. Results show the proposed solution can successfully detect up to 92% of malicious data injection attacks.}
}
@article{SETH2025107155,
title = {Classifying fungi biodiversity using hybrid transformer models},
journal = {Journal of Microbiological Methods},
volume = {236},
pages = {107155},
year = {2025},
issn = {0167-7012},
doi = {https://doi.org/10.1016/j.mimet.2025.107155},
url = {https://www.sciencedirect.com/science/article/pii/S0167701225000715},
author = {Madhurie Kumar Seth and K. Srinivas and A. Charan Kumari},
keywords = {Fungi, Classification, Microbiology, Transformer, Biodiversity, Agriculture},
abstract = {Fungi are essential members of ecosystems, playing key roles in nutrient cycling, agriculture, and medicine. Their classification into proper species helps us to understand their biodiversity, allowing us to leverage their ecological and practical benefits. A new hybrid deep learning-based technique has been proposed, merging the Vision Transformer and Swin Transformer models with transfer learning frameworks like MobileNetV2, DenseNet121, and EfficientNetB0 for Fungi multiclass classification. This study utilized a publicly available dataset containing 9115 images of five fungal species from UC Irvine Machine Learning Repository. To address significant class imbalance, several data augmentation techniques were employed. The results showed that the Swin Transformer combined with DenseNet121 achieved the highest classification accuracy of 96.96 % for training, 95.97 % for validation, and 95.57 % for testing, while other models like ViT-DenseNet121 and Swin-MobileNetV2 also delivered competitive results. Using confusion matrices and benchmark classification metrics, and paired statistical testing, the analysis highlights the models' ability to generalize effectively and minimize misclassifications. To further ensure the robustness of the findings, a five-fold cross-validation was performed across all hybrid models. Additionally, explainable AI techniques, specifically Grad-CAM visualizations, were employed to interpret the model's focus areas, confirming attention to biologically significant structures. This research demonstrates a balance between modeling local features and capturing global context. Indeed, these hybrid models prove to be scalable and efficient for complex biological datasets. This interdisciplinary study bridges ecology and advanced technology by applying deep learning to enhance fungal classification. This study aims to improve the management and understanding of fungal biodiversity for the promotion of conservational and sustainable practices for the betterment of our ecosystem. The findings have significant applications, including sustainable agriculture through early detection of fungal plant pathogens, improved medical diagnostics for fungal infections, and biodiversity conservation through precise species monitoring.}
}
@article{BENOIST2024107414,
title = {Better practices for including traditional firewood in LCA: Lessons from a shea butter case study in Burkina Faso},
journal = {Environmental Impact Assessment Review},
volume = {105},
pages = {107414},
year = {2024},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2024.107414},
url = {https://www.sciencedirect.com/science/article/pii/S0195925524000015},
author = {Anthony Benoist and Charline Lanvin and Olivier Lefebvre and Christophe Godard and Hubert Ouedraogo and Marjorie {Riesgo Saives} and Patricia Martz and Stéphanie Ringeissen and Joël Blin},
keywords = {Firewood, Life cycle assessment (LCA), Uncertainties, Shea butter, Cookstove, Emission factors},
abstract = {Firewood is a key energy source in developing countries, but its consideration for Life Cycle Assessment (LCA) purposes suffers from both data and methodological issues. A specific literature review revealed considerable variability in the way these issues have been addressed in existing studies. To improve current practices, a framework for proper inclusion of all environmental impacts related to traditional firewood uses is proposed, and a configurable dataset for other studies was produced. The framework was then applied to a case study on shea butter production, where firewood accounting appeared to be one of the main sources of discrepancies in the results of existing studies. For each parameter related to firewood uses and their impacts, data and methodological choices that LCA practitioners may face were then investigated through uncertainty and sensitivity analyses. Firewood consumption volumes and emission factors from firewood combustion proved to be the most critical parameters for all environmental issues, and the options explored in this study to tackle these data collection issues can be adapted to other case studies. Beyond data matters, the main methodological challenge for firewood accounting lies in estimating the fraction of firewood from non-renewable sources. Use of the default values from the spatially explicit supply-demand WISDOM model is recommended here. For the shea butter value chain in Burkina Faso, one of the main solutions for mitigating environmental impacts would be to reduce firewood consumption by promoting improved cookstoves, improving boiling practices, or replacing firewood with other biomass sources, such as shea nutshells.}
}
@article{PRIMOR2026102015,
title = {Fostering critical evaluation of online information sources across the curriculum},
journal = {Thinking Skills and Creativity},
volume = {59},
pages = {102015},
year = {2026},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.102015},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002639},
author = {Liron Primor and Linor L. Hadar and Sarit Barzilai and Shai {Goldfarb Cohen} and Thuraia Copti-Mshael},
keywords = {Critical evaluation, Information source evaluation, Digital information literacy, Teacher professional development, Epistemic thinking, Metacognition},
abstract = {Despite the importance of critical evaluation of online information, many teachers struggle to integrate evaluation instruction in their disciplinary teaching. This study examined the contribution of a professional development (PD) program designed to foster teachers’ capabilities to cultivate critical evaluation competencies in their disciplines. Grounded in the AIR model of epistemic thinking, the program focused on supporting teachers in promoting students’ evaluation Aims, evaluation Ideals (criteria), and Reliable evaluation processes (strategies) across the regular curriculum. Teachers collaboratively learned, designed, and taught evaluation activities that were intended to foster these elements. We report on the program’s initial implementation with seven junior high school teachers and their students (N = 118), who were assigned to intervention and control groups. Using a mixed-method design, we administered assessments of information source evaluation to teachers and students before and after the intervention. Qualitative data sources included teacher interviews, teacher reflections, classroom observations, and PD meeting transcripts. Following the PD, teachers’ critical evaluation competencies became more elaborate and explicit. All of the teachers integrated information source evaluation in their instruction and adapted or designed evaluation activities that were tailored to their disciplines. Teachers faced challenges related to the complexities of integrating evaluation instruction in disciplinary topics, metacognitive instruction, and curriculum structure. Following the PD, students increasingly used source evaluation criteria, but there were no changes in their evaluation strategies. These results demonstrate the potential of the PD model and identify challenges that may inform future PD initiatives.}
}
@article{LI2026112777,
title = {Dual-scale adaptive attention-based Vision transformer with iterative refinement for clarity and consistency in multi-focus image fusion},
journal = {Engineering Applications of Artificial Intelligence},
volume = {163},
pages = {112777},
year = {2026},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112777},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625028088},
author = {Gengrui Li and Daoyun Tang and Jinhuan Huang and Shaoning Zhu and Jiangtao Cao},
keywords = {Multi-focus Image fusion, Artificial Intelligence, Vision transformer, Medical Image processing, Dual-scale adaptive attention, Iterative refinement fusion, Deep learning, Remote sensing},
abstract = {Multi-focus Image Fusion (MFIF) has become a prominent role in combining focused regions of several source images into a single all-in-focus fused image. However, existing approaches have the limitation of maintaining global spatial coherence and sharp details. To overcome these limitations, the Dual-Scale Adaptive Attention-Based Vision Transformer (DAA-ViT) model is proposed, which integrates fine-scale and coarse-scale attention, with the aim of maintaining local high-resolution information along with structural coherence. Additionally, an Iterative Refinement Fusion (IRF) is introduced to refine focus boundaries through multiple iterations for enhancing overall image definition, while mitigating fusion artifacts and focus selection errors. Especially, this Artificial Intelligence (AI)-based approach is efficient in complex scenes with inconsistent depth levels, which is suitable for applications like remote sensing and medical image processing. Experimental results of several benchmark datasets demonstrate that the proposed method attains better results than existing methods with a Mutual Information (MI) of 8.9671, Structural Similarity Index Measure (SSIM) of 0.9211, Peak Signal-To-Noise Ratio (PSNR) of 36.728 dB, and Lower Root Mean Square Error (RMSE) of 1.5482. Compared to the existing Swin Transformer and Convolutional Neural Network (STCU-Net) model, the proposed model attains 2.65 % improvement in PSNR, 1.99 % improvement in MI, 1.11 % improvement in Structural Similarity Index Measure, and 5.13 % reduction in RMSE. These findings demonstrate the efficiency of AI-based fusion strategies in delivering high-quality all-in-focus images and emphasize their applications in medical imaging and remote sensing processing.}
}
@article{SHIN2025832,
title = {Maintaining brand authenticity after an acquisition: the role of acquirer’s reputation and operational independence},
journal = {Journal of Product & Brand Management},
volume = {34},
number = {6},
pages = {832-846},
year = {2025},
issn = {1061-0421},
doi = {https://doi.org/10.1108/JPBM-03-2024-5035},
url = {https://www.sciencedirect.com/science/article/pii/S106104212500006X},
author = {Daeun Chloe Shin and Byoungho Ellie Jin},
keywords = {Growth strategy, Acquisition, Startup, Brand authenticity, Acquirer reputation, Operational independence},
abstract = {Purpose
For a digital fashion startup, being acquired by a large company can be a viable growth strategy, but consumers may view it as a departure from the startup’s original identity and question its commitment to core values, its perceived brand authenticity. Despite the potential risks to perceived brand authenticity, little is known about its key predictors in the context of startup acquisitions. Drawing from the heuristic–systematic model and cue diagnosticity theory, this study aims to examine the effects of two systematic factors (acquirer reputation and the startup’s operational independence) and a heuristic factor (company size linked to a consumer lay theory about greed) on brand authenticity.
Design/methodology/approach
Via two online experimental studies, data were collected from 401 US consumers (Study 1: 101, Study 2: 300). Data were analyzed through SPSS PROCESS macro mediation and moderation analyses and ANCOVA.
Findings
In Study 1, the authors established a consumer lay theory that larger companies are perceived as greedier, which in turn increases perceived mercenary intent. In Study 2, acquirer reputation significantly predicted perceived brand authenticity, whereas operational independence did not. Notably, the lay theory did not influence perceived brand authenticity in the mergers and acquisitions context.
Originality/value
For startups and prospective acquirers, the findings offer practical suggestions that can help ensure the long-term viability of the acquisition.}
}
@article{LIN2025329,
title = {Automation and aesthetic labour: the micro-mobilities of work in airport self-service},
journal = {Mobilities},
volume = {20},
number = {2},
pages = {329-344},
year = {2025},
issn = {1745-0101},
doi = {https://doi.org/10.1080/17450101.2024.2325372},
url = {https://www.sciencedirect.com/science/article/pii/S1745010124000109},
author = {Weiqiang Lin},
keywords = {Aesthetics, airport, automation, body, customer service, mobile labour, self-service technologies},
abstract = {Recently, the concept of mobile labour has garnered increasing attention among mobilities scholars. Yet, the preponderance of research has emphasised workers’ movements that are fairly large-scale and routes-based. This paper proposes another kind of mobility that is of equal significance—that of micro-mobilities by labour, or more accurately by their bodies. Using original research conducted through semi-structured interviews with 40 customer service agents working in an international airport in Asia, the paper examines three kinds of aesthetic labour that these workers perform alongside passengers. Enacted through various bodily motions intended to speed up aeromobile processes and augment productivity, I argue that these performances produce a (tenuous) aesthetics of assuring presence, orderly movement, and passing time. As more and more work tasks are redistributed across the airport between staff and passengers, ‘new’ automation presents an opportunity to reflect on the mobile practices being invented as self-service technologies infiltrate customer service and other work where human relations and decision-making skills are required. More broadly, it also uncovers the gendered politics of bodily comport, gaits, gestures and other micro-movements in labour (re)production in a wider age of technological change.}
}
@article{VANTVEEN2025133816,
title = {Uncertainty in nitrate load calculations evaluated using Monte Carlo simulations based on in-situ nitrate sensors in two Danish headwater streams},
journal = {Journal of Hydrology},
volume = {662},
pages = {133816},
year = {2025},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2025.133816},
url = {https://www.sciencedirect.com/science/article/pii/S0022169425011540},
author = {Sofie Gyritia Madsen {van’t Veen} and Søren Erik Larsen and Peter Mejlhede Andersen and Niels Bering Ovesen and Jane Rosenstand Laugesen and Brian Kronvang},
keywords = {Nitrate, Ultraviolet sensors, High-frequency measurements, Uncertainty of loads, Monte Carlo approach, Richards-Baker Flashiness Index},
abstract = {This study used high-frequency (HF) nitrate-nitrogen (NO3-N) sensor data to explore the uncertainty of calculating NO3-N loads in two headwater streams (Horndrup and Lyby-Grønning) with infrequent sample collection. Accurate annual and monthly N load estimates are crucial for cost-efficient management of N in catchments and for correct calibration and validation of catchment models like SWAT. Ultraviolet (UV) NO3-N sensors were installed in the two agricultural headwater streams for two hydrological years (June 2021 to May 2023) to measure NO3-N concentrations every minute. The cleaned dataset was used to investigate NO3-N load estimates using a Monte Carlo approach, with 1000 simulations for five infrequent sampling strategies: daily, weekly, fortnightly, 18 annual samples, and monthly samples. Bias (Flux Bias Statistic), precision (standard deviation), and total uncertainty (RMSE) were calculated for the annual and monthly NO3-N loads. Richards-Baker Flashiness Index (RBI) was used to explore the influence of hydrology on differences between HF and infrequent sampling. The sampling strategy needed to meet a bias and achieve RMSE <2 %, 5 %, and 10 % for monthly loads was explored. The uncertainty of the load estimates increased with fewer grab samples. The bias and RMSE of the annual load estimates from the five strategies were <±7.7 % and <10.3 %, respectively. Monthly NO3-N loads had higher uncertainties, with average bias and RMSE of ±4 % and 15 % (max. −13 % and 28 %) in Horndrup Stream and ±7 % and 27 % (max. 89 % and 194 %) in Lyby-Grønning Stream. In Horndrup Stream, a significant negative linear relationship between the bias of monthly NO3-N loads and RBI indicated higher underestimation with more storm events. In Lyby-Grønning Stream, precision decreased with higher RBI.}
}
@article{ABDELMOTAAL2024100380,
title = {Keratoconus Detection-based on Dynamic Corneal Deformation Videos Using Deep Learning},
journal = {Ophthalmology Science},
volume = {4},
number = {2},
pages = {100380},
year = {2024},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2023.100380},
url = {https://www.sciencedirect.com/science/article/pii/S2666914523001124},
author = {Hazem Abdelmotaal and Rossen Mihaylov Hazarbassanov and Ramin Salouti and M. Hossein Nowroozzadeh and Suphi Taneri and Ali H. Al-Timemy and Alexandru Lavric and Siamak Yousefi},
keywords = {Artificial intelligence, Deep learning, Convolutional neural network, Keratoconus, Scheimpflug-based dynamic corneal deformation videos},
abstract = {Objective
To assess the performance of convolutional neural networks (CNNs) for automated detection of keratoconus (KC) in standalone Scheimpflug-based dynamic corneal deformation videos.
Design
Retrospective cohort study.
Participants
We retrospectively analyzed datasets with records of 734 nonconsecutive, refractive surgery candidates, and patients with unilateral or bilateral KC.
Methods
We first developed a video preprocessing pipeline to translate dynamic corneal deformation videos into 3-dimensional pseudoimage representations and then trained a CNN to directly identify KC from pseudoimages. We calculated the model's KC probability score cut-off and evaluated the performance by subjective and objective accuracy metrics using 2 independent datasets.
Main Outcome Measures
Area under the receiver operating characteristics curve (AUC), accuracy, specificity, sensitivity, and KC probability score.
Results
The model accuracy on the test subset was 0.89 with AUC of 0.94. Based on the external validation dataset, the AUC and accuracy of the CNN model for detecting KC were 0.93 and 0.88, respectively.
Conclusions
Our deep learning-based approach was highly sensitive and specific in separating normal from keratoconic eyes using dynamic corneal deformation videos at levels that may prove useful in clinical practice.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@article{LU2024130354,
title = {Analyzing the structure-activity relationship of raspberry polysaccharides using interpretable artificial neural network model},
journal = {International Journal of Biological Macromolecules},
volume = {264},
pages = {130354},
year = {2024},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2024.130354},
url = {https://www.sciencedirect.com/science/article/pii/S0141813024011577},
author = {Jie Lu and Yongjing Yang and Eun-Kyung Hong and Xingxing Yin and Xuehong Wang and Yuting Wang and Dejun Zhang},
keywords = {Raspberry polysaccharides, Structure-activity relationship, Interpretable artificial neural network},
abstract = {The structure-activity relationship has been a hot topic in the field of polysaccharide research. Six polysaccharides and three polysaccharide fragments were obtained from raspberry pulp. Based on their structural information and immune-enhancing activity data, an artificial neural network (ANN) model was used for prediction, and Gradient-weighted class activation mapping (Grad-CAM) algorithm was exploited for explanation structure-activity relationship of these raspberry polysaccharides in the present study. The structural information and immune activity data of raspberry polysaccharides were respectively used as input and output in the ANN model. The training and testing losses of ANN model was no longer decreased after trained for 200 epochs. The mean-square error (MSE) of training set and test set stabilized around 0.003 and 0.013, and the mean absolute percentage error (MAPE) of training set and test set were 0.21 % and 0.98 %, indicating the trained ANN model converged well and exhibited strong robustness. The interpretability analysis showed that molecular weight, content of arabinose, galactose or galacturonic acid, and glycosyl linkage patterns of →3)-Arap-(1→, Araf-(1→, →4)-Galp-(1 → were the main structural factors greatly affecting the immune-enhancing activity of raspberry polysaccharides. This work may provide a new perspective for the study of structure-activity relationship of polysaccharides.}
}
@article{NING2025128397,
title = {Research on the multi-chip cooperative module of annular nozzle jet dry ice cooling based on parameter optimization},
journal = {Applied Thermal Engineering},
volume = {280},
pages = {128397},
year = {2025},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2025.128397},
url = {https://www.sciencedirect.com/science/article/pii/S1359431125029898},
author = {Jinghong Ning and Qing Xu and Qiqi Wang and Mingzhu Liu and Xi Chen and Xiuxu Zheng},
keywords = {Multi-chip collaboration, Annular nozzle, Pin fins heat sink, Dry ice, Cooling, Heat transfer},
abstract = {To achieve efficient cooling of the multi-chip collaborative module with high heat flux, an annular nozzle dry ice particle jet fluid cooling method is proposed. The physical models of the multi-chip collaborative module, annular nozzle and heat sink are established. The multi-chip collaborative module consists of one logic chip with a heat flux of 295.86 W/cm2, and four High Bandwidth Memory (HBM) chips each with a heat flux of 52.08 W/cm2. Due to the difference in chip heat flux, pin fins are added to the internal copper base plate of the heat sink above the logic chip. In this paper, the method of numerical simulation is adopted, by changing the inclined angle of the annular nozzle outlet, the height of the heat sink, the size and distribution of the pin fins and other structural parameters, as well as the inlet fluid velocity of the nozzle and the proportion of dry ice and other thermal parameters, the cooling and heat transfer characteristics of the multi-chip collaborative module with a safety temperature of 378 K for the logic chip and 358 K for the HBM chip are simulated. The results show that the model with an annular nozzle outlet inclined at 60°, a heat sink height of ​​20 mm​​, and ​​a 6 × 6 arrangement of pin fins​​ with a diameter of ​​3 mm​​ and a height of ​​15 mm​​ ​​provides the optimal performance​​ for dry ice particle jet cooling. The greater the inlet velocity of the dry ice particle fluid and the higher the dry ice proportion at the inlet, the better the cooling effect of the chip. When the dry ice proportion at nozzle inlet is 0.3, as the nozzle inlet velocity increases from 1 to 4 m/s, maximum temperature at the logic chip undersurface decreases by 95.7 K. When the nozzle inlet fluid velocity is 3 m/s, as the dry ice proportion at the nozzle inlet increases from 0.1 to 0.2, maximum temperature at the logic chip undersurface decreases by 114.15 K. When the nozzle inlet velocity is 12 m/s and the dry ice proportion is 0.5, the heat flux of the annular nozzle dry ice particle jet fluid cooling multi-chip collaborative module is as high as 650 W/cm2 for the logic chip and 450 W/cm2 for the HBM chip. When the nozzle inlet velocity is 12 m/s and the dry ice proportion is 0.5, the total thermal resistance of the logic chip and the HBM chip decreases by 2.2 cm2·K/W and 10.57 cm2·K/W, respectively, compared to when the nozzle inlet velocity is 1 m/s and the dry ice proportion is 0.1. Based on the results of this paper, the quantitative relationship is fitted between the maximum temperature at the undersurface of the logic chip and the heat flux under different inlet fluid velocity and the proportion of dry ice. The research results provide targeted theoretical support and data references for the cooling scheme design, thermal performance regulation, and reliability improvement of multi-chip integration modules.}
}
@article{OYADEYI2025102057,
title = {Financial innovation and money demand in Nigeria: Exploring the impact of banking innovations, fintech developments and digital payment channels on the money demand},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {102057},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.102057},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125007867},
author = {Olajide O. Oyadeyi},
keywords = {Financial innovation, Bank innovation, Money demand, Digital payment channels, Fintech developments, Feasible quasi generalized least squares},
abstract = {The paper contributes to the frontier of knowledge by examining the role of banks and Fintech innovations across the different financial innovation platforms on four money-demand models. Quarterly data from Q1 2009 to Q4 2022 were adopted by employing the Feasible Quasi Generalized Least Squares technique, the CUSUM and CUSUMSQ techniques, and the Granger causality methods due to their suitability for running this type of regression. The results indicate that the value and volume of payments within the banking industry have a significant positive impact on the demand for reserve money. In contrast, the value of payments had adverse effects on the demand for narrow money, broad money, and total money. The significant positive impact of payment value and volume on the demand for reserve money indicates that as transactional activities increase, banks require more reserves. The negative impact of payment value on the demand for narrow, broad, and total money suggests a substitution effect where higher transaction volumes reduce the need for holding other forms of money. Furthermore, the findings demonstrated that money demand is unstable, implying that the monetary authorities should provide the transition framework for a proper inflation-targeting strategy to achieve its key objective of attaining low and stable inflation. The instability in money demand suggests that traditional monetary aggregates may not be reliable indicators for monetary policy. Therefore, the central bank should adopt a more flexible and responsive framework, such as inflation targeting, which focuses directly on achieving price stability rather than relying on intermediary targets.}
}
@article{DEMURO2025101743,
title = {Language ontologies and the worlding of language(s)/languaging: does language create the world or does worlding create language?},
journal = {Language Sciences},
volume = {111},
pages = {101743},
year = {2025},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2025.101743},
url = {https://www.sciencedirect.com/science/article/pii/S0388000125000385},
author = {Eugenia Demuro and Laura Gurney},
keywords = {Language ontologies, language(s)/languaging, Ethnographic encounter, Posthumanism, Languaging, Assemblage},
abstract = {This article argues for the importance of understanding language ontologies in applied linguistics. We draw on a range of related fields to further develop this framework, questioning the notion of a singular and homogeneous understanding of language. We not only move beyond a monolingual focus to embrace a more inclusive understanding of language(s) and their sociocultural underpinnings, but, drawing on the ‘ontological turn’ and its exploration of diverse worlds, we theorise language as a dynamic assemblage of elements that emerges uniquely in each performance or practice, grounded in specific contexts. Our contribution aims to expand the understanding of language as multifaceted and ever evolving phenomena, reflecting on a range of themes and questions, including how we might pluralise language within Western modernity. Is language the same across all contexts of contemporary western societies or within Western modernity? Does language apply only to human groups? How do nonhuman others perform language(s)/languaging? In challenging existing assumptions regarding what language is or what it might be, our research invites others to explore new possibilities in their examination of language(s), languaging, and semiotic practices.}
}