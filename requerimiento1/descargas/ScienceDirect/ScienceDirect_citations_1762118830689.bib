@article{ZHU2024,
title = {The Evaluation of Generative AI Should Include Repetition to Assess Stability},
journal = {JMIR mHealth and uHealth},
volume = {12},
year = {2024},
issn = {2291-5222},
doi = {https://doi.org/10.2196/57978},
url = {https://www.sciencedirect.com/science/article/pii/S2291522224000792},
author = {Lingxuan Zhu and Weiming Mou and Chenglin Hong and Tao Yang and Yancheng Lai and Chang Qi and Anqi Lin and Jian Zhang and Peng Luo},
keywords = {large language model, generative AI, ChatGPT, artificial intelligence, health care},
abstract = {The increasing interest in the potential applications of generative artificial intelligence (AI) models like ChatGPT in health care has prompted numerous studies to explore its performance in various medical contexts. However, evaluating ChatGPT poses unique challenges due to the inherent randomness in its responses. Unlike traditional AI models, ChatGPT generates different responses for the same input, making it imperative to assess its stability through repetition. This commentary highlights the importance of including repetition in the evaluation of ChatGPT to ensure the reliability of conclusions drawn from its performance. Similar to biological experiments, which often require multiple repetitions for validity, we argue that assessing generative AI models like ChatGPT demands a similar approach. Failure to acknowledge the impact of repetition can lead to biased conclusions and undermine the credibility of research findings. We urge researchers to incorporate appropriate repetition in their studies from the outset and transparently report their methods to enhance the robustness and reproducibility of findings in this rapidly evolving field.}
}
@article{BRAGAZZI2025,
title = {Proficiency, Clarity, and Objectivity of Large Language Models Versus Specialists’ Knowledge on COVID-19's Impacts in Pregnancy: Cross-Sectional Pilot Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/56126},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25001064},
author = {Nicola Luigi Bragazzi and Michèle Buchinger and Hisham Atwan and Ruba Tuma and Francesco Chirico and Lukasz Szarpak and Raymond Farah and Rola Khamisy-Farah},
keywords = {COVID-19, vaccine, reproductive health, generative artificial intelligence, large language model, chatGPT, google bard, microsoft copilot, vaccination, natural language processing, obstetric, gynecology, women, text mining, sentiment, accuracy, zero shot, pregnancy, readability, infectious},
abstract = {Background
The COVID-19 pandemic has significantly strained health care systems globally, leading to an overwhelming influx of patients and exacerbating resource limitations. Concurrently, an “infodemic” of misinformation, particularly prevalent in women’s health, has emerged. This challenge has been pivotal for health care providers, especially gynecologists and obstetricians, in managing pregnant women’s health. The pandemic heightened risks for pregnant women from COVID-19, necessitating balanced advice from specialists on vaccine safety versus known risks. In addition, the advent of generative artificial intelligence (AI), such as large language models (LLMs), offers promising support in health care. However, they necessitate rigorous testing.
Objective
This study aimed to assess LLMs’ proficiency, clarity, and objectivity regarding COVID-19’s impacts on pregnancy.
Methods
This study evaluates 4 major AI prototypes (ChatGPT-3.5, ChatGPT-4, Microsoft Copilot, and Google Bard) using zero-shot prompts in a questionnaire validated among 159 Israeli gynecologists and obstetricians. The questionnaire assesses proficiency in providing accurate information on COVID-19 in relation to pregnancy. Text-mining, sentiment analysis, and readability (Flesch-Kincaid grade level and Flesch Reading Ease Score) were also conducted.
Results
In terms of LLMs’ knowledge, ChatGPT-4 and Microsoft Copilot each scored 97% (32/33), Google Bard 94% (31/33), and ChatGPT-3.5 82% (27/33). ChatGPT-4 incorrectly stated an increased risk of miscarriage due to COVID-19. Google Bard and Microsoft Copilot had minor inaccuracies concerning COVID-19 transmission and complications. In the sentiment analysis, Microsoft Copilot achieved the least negative score (–4), followed by ChatGPT-4 (–6) and Google Bard (–7), while ChatGPT-3.5 obtained the most negative score (–12). Finally, concerning the readability analysis, Flesch-Kincaid Grade Level and Flesch Reading Ease Score showed that Microsoft Copilot was the most accessible at 9.9 and 49, followed by ChatGPT-4 at 12.4 and 37.1, while ChatGPT-3.5 (12.9 and 35.6) and Google Bard (12.9 and 35.8) generated particularly complex responses.
Conclusions
The study highlights varying knowledge levels of LLMs in relation to COVID-19 and pregnancy. ChatGPT-3.5 showed the least knowledge and alignment with scientific evidence. Readability and complexity analyses suggest that each AI’s approach was tailored to specific audiences, with ChatGPT versions being more suitable for specialized readers and Microsoft Copilot for the general public. Sentiment analysis revealed notable variations in the way LLMs communicated critical information, underscoring the essential role of neutral and objective health care communication in ensuring that pregnant women, particularly vulnerable during the COVID-19 pandemic, receive accurate and reassuring guidance. Overall, ChatGPT-4, Microsoft Copilot, and Google Bard generally provided accurate, updated information on COVID-19 and vaccines in maternal and fetal health, aligning with health guidelines. The study demonstrated the potential role of AI in supplementing health care knowledge, with a need for continuous updating and verification of AI knowledge bases. The choice of AI tool should consider the target audience and required information detail level.}
}
@article{CHEN2025,
title = {Semantic-Driven Paradigm Shift in Campus Guide Design Leveraging the KE-AIGC Framework},
journal = {International Journal on Semantic Web and Information Systems},
volume = {21},
number = {1},
year = {2025},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.368039},
url = {https://www.sciencedirect.com/science/article/pii/S1552628325000183},
author = {Xiaoqing Chen and Juanfen Wang and Yi Zhuang},
keywords = {Kansei Engineering, Generative Artificial Intelligence (AIGC), Guide Systems, University Campus, Semantic Web, User Experience},
abstract = {ABSTRACT
Campus guide systems are crucial to university infrastructure, shaping the experiences of students, staff, and visitors. Current systems face critical challenges in three areas: capturing diverse user needs, translating emotional requirements into design elements, and integrating campus cultural identity. This study integrates Kansei Engineering (KE) and Generative Artificial Intelligence (AIGC) to propose a semantic-driven design method. Using Semantic Web and Natural Language Processing (NLP), it models demand semantics, extracts emotional semantics such as safety and belonging, and maps them to design semantics for AIGC to generate personalized guide solutions. The approach leverages data-driven emotional semantic analysis and generative models to improve path guidance precision and cultural representation. Results indicate significant improvements in user experience, pathfinding accuracy, and cultural communication, with higher user satisfaction. This method provides a new semantic-driven pathway for developing campus guide systems and development prospects.}
}
@article{SIRNOORKAR2024100318,
title = {Student and AI responses to physics problems examined through the lenses of sensemaking and mechanistic reasoning},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100318},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100318},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001218},
author = {Amogh Sirnoorkar and Dean Zollman and James T. Laverty and Alejandra J. Magana and N. Sanjay Rebello and Lynn A. Bryan},
keywords = {Generative-AI, Sensemaking, Mechanistic reasoning, Physics problem solving},
abstract = {Several reports in education have called for transforming physics learning environments by promoting sensemaking of real-world scenarios in light of curricular ideas. Recent advancements in Generative-Artificial Intelligence have garnered increasing traction in educators' community by virtue of its potential to transform STEM learning. In this exploratory study, we adopt a mixed-methods approach in comparatively examining student- and AI-generated responses to two different formats of a physics problem through the theoretical lenses of sensemaking and mechanistic reasoning. The student data is derived from think-aloud interviews of introductory students and the AI data comes from ChatGPT's (versions 3.5 and 4o) solutions collected using Zero shot approach. The results highlight AI responses to evidence most features of the two processes through well-structured solutions and student responses to effectively leverage representations in their solutions through iterative refinement of arguments. In other words, while AI responses reflect how physics is talked about, the student responses reflect how physics is practiced. Implications of these results in light of development and deployment of AI systems in physics pedagogy are discussed.}
}
@article{BEGHETTO2025101121,
title = {Partnering with AI for instrument development: Possibilities and pitfalls},
journal = {New Ideas in Psychology},
volume = {76},
pages = {101121},
year = {2025},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2024.101121},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X24000497},
author = {Ronald A. Beghetto and Wendy Ross and Maciej Karwowski and Vlad P. Glăveanu},
keywords = {, , , , , , , },
abstract = {Recent advances in generative artificial intelligence (AI), specifically large language models (LLMs), provide new possibilities for researchers to partner with AI when developing and refining psychological instruments. In this paper we demonstrate how LLMs, such as OpenAI's ChatGPT 4 model, might be used to support the development of new psychometric scales. Partnering with AI for the purpose of developing and refining instruments, however, comes with its share of potential pitfalls. We thereby discuss throughout the paper that instrument development and refinement start and end with human judgment and expertise. We open with two use-cases that describe how we used LLMs in the development and refinement of two new psychological instruments. Next, we discuss possibilities for where and how researchers can use LLMs in the process of instrument development more broadly, including considerations for maximizing the benefits of LLMs and addressing the potential hazards when working with LLMs. Finally, we close by offering initial suggestions for psychology researchers interested in partnering with LLMs in this capacity.}
}
@article{VERMA2025139,
title = {Industry 6.0: Vision, technical landscape, and opportunities},
journal = {Alexandria Engineering Journal},
volume = {130},
pages = {139-174},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1110016825009354},
author = {Ashwin Verma and Vivek Kumar Prasad and Aparna Kumari and Pronaya Bhattacharya and Gautam Srivastava and Kai Fang and Wei Wang and Thippa Reddy Gadekallu},
keywords = {Industry 6.0, Explainable AI, 6G, Dew computing, Quantum computing, Internet-of-Anything},
abstract = {Industry 5.0 is designed with the objective of leveraging collaboration between human intelligence and cyber-driven processes. It aims to present customized manufacturing solutions to the end users as per demand. Despite its promising benefits in the current production landscape, Industry 5.0 faces critical challenges in scalability, workforce transition to collaborate with advanced technologies, high production costs, and privacy and security challenges in the post-quantum era. Thus, necessitates a shift towards more advanced Industrial paradigm that modernize and reinvent operations to synergize with high end sustainable and scalable machineries, products and processes. Industry 6.0 is defined as ubiquitous, hyper-customer driven, virtualized, and sustainable manufacturing, where focus is towards hyper-connected factories and dynamic supply chains. Industry 6.0 is expected to connect cross-vertical applications, and in this paper, we present a tutorial-based survey on the vision, technical landscape, and advancements which would drive the Industry 6.0. New concepts are introduced over Industry 5.0 processes to support industrial applications like supply-chain based productions, human–robotic industrial pipelines, green computing, and generative artificial intelligence (GAI) induction in control processes. We highlight the key enablers to support the 6.0 vision-automated digital twins, metaverse-assisted virtual production, 6G, dew computing, GAI Cobots Networks (GOBOTs), Internet-of-Anything (IoX), quantum-assisted nano production, and other technologies. We highlight the reference architecture, Industry 6.0 vision, features, components, and the threats surrounding Industry 6.0, and solutions. We also present the sustainability aspects of Industry 6.0, and finally discuss future challenges and directions. The article is presented to assist researchers, industry practitioners, and allied stakeholders to design cost-effective, customized, and process driven Industrial operations.}
}
@article{WU20252709,
title = {Anime Generation through Diffusion and Language Models: A Comprehensive Survey of Techniques and Trends},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {144},
number = {3},
pages = {2709-2778},
year = {2025},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2025.066647},
url = {https://www.sciencedirect.com/science/article/pii/S1526149225002991},
author = {Yujie Wu and Xing Deng and Haijian Shao and Ke Cheng and Ming Zhang and Yingtao Jiang and Fei Wang},
keywords = {Diffusion models, language models, anime generation, image synthesis, video generation, stable diffusion, AIGC},
abstract = {The application of generative artificial intelligence (AI) is bringing about notable changes in anime creation. This paper surveys recent advancements and applications of diffusion and language models in anime generation, focusing on their demonstrated potential to enhance production efficiency through automation and personalization. Despite these benefits, it is crucial to acknowledge the substantial initial computational investments required for training and deploying these models. We conduct an in-depth survey of cutting-edge generative AI technologies, encompassing models such as Stable Diffusion and GPT, and appraise pivotal large-scale datasets alongside quantifiable evaluation metrics. Review of the surveyed literature indicates the achievement of considerable maturity in the capacity of AI models to synthesize high-quality, aesthetically compelling anime visual images from textual prompts, alongside discernible progress in the generation of coherent narratives. However, achieving perfect long-form consistency, mitigating artifacts like flickering in video sequences, and enabling fine-grained artistic control remain critical ongoing challenges. Building upon these advancements, research efforts have increasingly pivoted towards the synthesis of higher-dimensional content, such as video and three-dimensional assets, with recent studies demonstrating significant progress in this burgeoning field. Nevertheless, formidable challenges endure amidst these advancements. Foremost among these are the substantial computational exigencies requisite for training and deploying these sophisticated models, particularly pronounced in the realm of high-dimensional generation such as video synthesis. Additional persistent hurdles include maintaining spatial-temporal consistency across complex scenes and mitigating ethical considerations surrounding bias and the preservation of human creative autonomy. This research underscores the transformative potential and inherent complexities of AI-driven synergy within the creative industries. We posit that future research should be dedicated to the synergistic fusion of diffusion and autoregressive models, the integration of multimodal inputs, and the balanced consideration of ethical implications, particularly regarding bias and the preservation of human creative autonomy, thereby establishing a robust foundation for the advancement of anime creation and the broader landscape of AI-driven content generation.}
}
@article{MISHRA202589,
title = {Leveraging Generative AI for Drug Safety and Pharmacovigilance},
journal = {Current Reviews in Clinical and Experimental Pharmacology},
volume = {20},
number = {2},
pages = {89-97},
year = {2025},
issn = {2772-4328},
doi = {https://doi.org/10.2174/0127724328311400240823062829},
url = {https://www.sciencedirect.com/science/article/pii/S2772432825000121},
author = {Hara Prasad Mishra and Rachna Gupta},
keywords = {Generative AI, Chat -GPT, pharmacovigilance, drug safety, patient safety, artificial intelligence, machine learning},
abstract = {Predictions are made by artificial intelligence, especially through machine learning, which uses algorithms and past knowledge. Notably, there has been an increase in interest in using artificial intelligence, particularly generative AI, in the pharmacovigilance of pharmaceuticals under development, as well as those already in the market. This review was conducted to understand how generative AI can play an important role in pharmacovigilance and improving drug safety monitoring. Data from previously published articles and news items were reviewed in order to obtain information. We used PubMed and Google Scholar as our search engines, and keywords (pharmacovigilance, artificial intelligence, machine learning, drug safety, and patient safety) were used. In toto, we reviewed 109 articles published till 31st January 2024, and the obtained information was interpreted, compiled, evaluated, and conclusions were reached. Generative AI has transformative potential in pharmacovigilance, showcasing benefits, such as enhanced adverse event detection, data-driven risk prediction, and optimized drug development. By making it easier to process and analyze big datasets, generative artificial intelligence has applications across a variety of disease states. Machine learning and automation in this field can streamline pharmacovigilance procedures and provide a more efficient way to assess safety-related data. Nevertheless, more investigation is required to determine how this optimization affects the caliber of safety analyses. In the near future, the increased utilization of artificial intelligence is anticipated, especially in predicting side effects and Adverse Drug Reactions (ADRs).}
}
@article{HUANG2024100302,
title = {Examining the relationship between the L2 motivational self system and technology acceptance model post ChatGPT introduction and utilization},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100302},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100302},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400105X},
author = {Jerry Huang and Atsushi Mizumoto},
keywords = {The L2 motivational self system, Ideal L2 self, Ought-to L2 self, L2 learning experience, Technology acceptance model, ChatGPT},
abstract = {Since the introduction of the L2 Motivational Self System (L2MSS), numerous studies worldwide have highlighted its effectiveness in elucidating Second Language Acquisition. However, the influence of generative artificial intelligence (GenAI) technology on this model remains largely unexplored. The Technology Acceptance Model (TAM) is a widely employed framework for examining the impact of a new technology, and this study explores the intercorrelation when these two models are considered together. Conducted with 35 s-year university English as a foreign language (EFL) students in humanities, the study involved two sessions of instructor-led ChatGPT usage writing workshops, followed by the collection of survey responses. Data analysis unveiled a notable correlation between the L2 Motivational Self System and the Technology Acceptance Model. Particularly noteworthy is the finding that Ought-to L2 Self positively predict Actual Usage. The study discusses pedagogical and theoretical implications, along with suggesting future research directions.}
}
@article{SHARMASHARMA2023150,
title = {How does transformational leadership impact organizational unlearning: insights from persistence theories},
journal = {Journal of Organizational Change Management},
volume = {37},
number = {1},
pages = {150-172},
year = {2023},
issn = {0953-4814},
doi = {https://doi.org/10.1108/JOCM-07-2023-0302},
url = {https://www.sciencedirect.com/science/article/pii/S0953481423001641},
author = {ShubhamShubham SharmaSharma and UshaUsha LenkaLenka},
keywords = {Organizational unlearning, Transformational leadership, Persistence theories, Higher education},
abstract = {Purpose
Empirical attempts to recommend enabling mechanisms for organizational unlearning are sparse and have almost neglected the vital role of leadership in transforming organizations through unlearning. Based on the tenets of persistence theories like path-dependence and imprinting theory, this study examines the relationship between transformational leadership and unlearning with the mediating role of knowledge sharing, transparent internal communication and intrapreneurship.
Design/methodology/approach
To analyze the hypothesized relationship between these constructs, data were collected from 452 faculty members working in Centrally Funded Technical Institutions (CFTIs) in India. The data were analyzed using Process macro (Hayes, 2022).
Findings
The results show a significant effect of transformational leadership on organizational unlearning. This effect is mediated by transparent internal communication and intrapreneurship. However, knowledge sharing did not mediate the relationship between transformational leadership and organizational unlearning.
Practical implications
The Fourth Industrial Revolution, Covid-19, the rise of generative artificial intelligence tools like ChatGPT and policy reforms have pushed higher educational institutions to transform by unlearning old practices and experimenting with new ones. This paper informs how educational institutions can initiate and sustain the unlearning process.
Originality/value
Persistence theories like path-dependence and imprinting theory suggest that organizations often stick with proven success formulas and find it challenging to adopt new practices. Moreover, path dependence theorists advocate the role of an external intervening mechanism to break away from rigid and inefficient routines (or paths). This paper argues that in addition to external events (e.g. crisis, etc.), transformational leaders combined with organizational processes also help in unlearning obsolete knowledge and routines.}
}
@article{ILLE20231014,
title = {AI interprets the Central Dogma and Genetic Code},
journal = {Trends in Biochemical Sciences},
volume = {48},
number = {12},
pages = {1014-1018},
year = {2023},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2023.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S096800042300230X},
author = {Alexander M. Ille and Michael B. Mathews},
keywords = {artificial intelligence, ChatGPT, natural language processing, large language models, Central Dogma, Sequence Hypothesis},
abstract = {Generative artificial intelligence (AI) is a burgeoning field with widespread applications, including in science. Here, we explore two paradigms that provide insight into the capabilities and limitations of Chat Generative Pre-trained Transformer (ChatGPT): its ability to (i) define a core biological concept (the Central Dogma of molecular biology); and (ii) interpret the genetic code.}
}
@article{CHRISTENSEN2025102557,
title = {To hasten slowly: The prudence of slow AI implementation in public relations},
journal = {Public Relations Review},
volume = {51},
number = {2},
pages = {102557},
year = {2025},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2025.102557},
url = {https://www.sciencedirect.com/science/article/pii/S0363811125000190},
author = {Emma Christensen and Rickard Andersson},
keywords = {Generative artificial intelligence, Implementation, STS, Qualitative case study, Slow implementation, Employee participation},
abstract = {Public relations professionals’ use of generative artificial intelligence (GenAI) tripled during 2023. Despite this surge, there is a notable lack of in-field studies examining GenAI and other CommTech implementation in public relations. To address this research gap, we adopt the view of the digital transformation of public relations as a socio-technical change process and explore how a communication department in a large Danish municipality approached the implementation of AI, drawing upon the socio-technical system view of technology implementation (STS) as our analytic lens. Instead of hasty implementation, the department spent one year on a learning process, providing them with the knowledge and skills needed to secure a sound and sustainable implementation. We contribute to the emerging literature on CommTech, AI, and AI implementation in public relations by highlighting the importance of thoroughly exploring and evaluating GenAI prior to implementation and actively involving co-workers in organizing and executing such projects. To encapsulate our findings, we introduce the concept and practice of Slow Implementation, emphasizing the importance of dedicating time to the implementation phase.}
}
@article{HUO2025103222,
title = {Reporting guideline for chatbot health advice studies: The CHART statement},
journal = {Artificial Intelligence in Medicine},
volume = {168},
pages = {103222},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103222},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001575},
author = {Bright Huo and Gary Collins and David Chartash and Arun Thirunavukarasu and Annette Flanagin and Alfonso Iorio and Giovanni Cacciamani and Xi Chen and Nan Liu and Piyush Mathur and An-Wen Chan and Christine Laine and Daniela Pacella and Michael Berkwits and Stavros A. Antoniou and Jennifer C. Camaradou and Carolyn Canfield and Michael Mittelman and Timothy Feeney and Elizabeth Loder and Riaz Agha and Ashirbani Saha and Julio Mayol and Anthony Sunjaya and Hugh Harvey and Jeremy Y. Ng and Tyler McKechnie and Yung Lee and Nipun Verma and Gregor Stiglic and Melissa McCradden and Karim Ramji and Vanessa Boudreau and Monica Ortenzi and Joerg Meerpohl and Per Olav Vandvik and Thomas Agoritsas and Diana Samuel and Helen Frankish and Michael Anderson and Xiaomei Yao and Stacy Loeb and Cynthia Lokker and Xiaoxuan Liu and Eliseo Guallar and Gordon Guyatt},
keywords = {LLMs, Generative AI, Reporting standards},
abstract = {The Chatbot Assessment Reporting Tool (CHART) is a reporting guideline developed to provide reporting recommendations for studies evaluating the performance of generative artificial intelligence (AI)-driven chatbots when summarizing clinical evidence and providing health advice, referred to as Chatbot Health Advice (CHA) studies. CHART was developed in several phases after performing a comprehensive systematic review to identify variation in the conduct, reporting and methodology in CHA studies. Findings from the review were used to develop a draft checklist that was revised through an international, multidisciplinary modified asynchronous Delphi consensus process of 531 stakeholders, three synchronous panel consensus meetings of 48 stakeholders, and subsequent pilot testing of the checklist. CHART includes 12 items and 39 subitems to promote transparent and comprehensive reporting of CHA studies. These include Title (subitem 1a), Abstract/Summary (subitem 1b), Background (subitems 2ab), Model Identifiers (subitem 3ab), Model Details (subitems 4abc), Prompt Engineering (subitems 5ab), Query Strategy (subitems 6abcd), Performance Evaluation (subitems 7ab), Sample Size (subitem 8), Data Analysis (subitem 9a), Results (subitems 10abc), Discussion (subitems 11abc), Disclosures (subitem 12a), Funding (subitem 12b), Ethics (subitem 12c), Protocol (subitem 12d), and Data Availability (subitem 12e). The CHART checklist and corresponding methodological diagram were designed to support key stakeholders including clinicians, researchers, editors, peer reviewers, and readers in reporting, understanding, and interpreting the findings of CHA studies.}
}
@incollection{MYLREA2025315,
title = {14 - The generative AI weapon of mass destruction: Evolving disinformation threats, vulnerabilities, and mitigation frameworks},
editor = {William Lawless and Ranjeev Mittu and Donald Sofge and Hesham Fouad},
booktitle = {Interdependent Human-Machine Teams},
publisher = {Academic Press},
pages = {315-347},
year = {2025},
isbn = {978-0-443-29246-0},
doi = {https://doi.org/10.1016/B978-0-443-29246-0.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292460000079},
author = {Michael Mylrea},
keywords = {AI cybersecurity, AI explainability, AI governance, AI trust, Autonomous-human–machine-teams, Disinformation, Generative artificial intelligence, Guardrails},
abstract = {In the absence of ethical guardrails, generative artificial intelligence (GenAI) can be weaponized to autonomously generate and disseminate highly convincing and tailored disinformation at an unprecedented scale. Disinformation causes confusion, division between groups and undermines trust institutions to create societal chaos and destabilization. In an era of hyperconnectivity, GenAI can weaponize social media platforms that rapidly disseminate information without verifying the authenticity of content, creating new threats and vulnerabilities. But even as GenAI has emerged as a powerful tool in shaping society, disinformation threats, vulnerabilities, and mitigations remain underexplored. This chapter investigates the burgeoning threat posed by GenAI as a potential weapon of mass destruction within the domain of disinformation. Through a comprehensive analysis of its threats and vulnerabilities, including content manipulation, targeted dissemination, and the creation of deepfakes, this study elucidates how GenAI could impair decision-making in human–machine teams, polarize societies, and destabilize geopolitical landscapes. Furthermore, this chapter explores potential countermeasures and mitigations, emphasizing the critical need for improved governance and regulatory frameworks. Applying these mitigations may help to reduce the pernicious influence of GenAI-driven disinformation and to preserve societal resilience against its malevolent applications.}
}
@article{WISS2025100752,
title = {Development of the AI Acceptance Scale for Interprofessional Education (AAIPE) and Collaborative Practice Settings},
journal = {Journal of Interprofessional Education & Practice},
volume = {40},
pages = {100752},
year = {2025},
issn = {2405-4526},
doi = {https://doi.org/10.1016/j.xjep.2025.100752},
url = {https://www.sciencedirect.com/science/article/pii/S2405452625000151},
author = {Andrew Wiss and Dawn Joosten-Hagye and Jennifer Pattershall-Geide and Mary Showstark and Elke Zschaebitz and Kirsten Potter and Erin Embry and Heather Hageman and Patti Brooks},
keywords = {AI acceptance, Measurement of AI acceptance, Interprofessional education settings, Interprofessional collaboration and AI, Validated scale, Assessment, Generative artificial intelligence, GenAI and healthcare settings},
abstract = {Background
As artificial intelligence (AI) based tools become a more prevalent part of the work taking place in health and healthcare settings, students preparing for health profession roles will be asked with increasing frequency to adopt and integrate these tools into their developing knowledge and skills-sets. Because of this, developing an understanding of levels of AI acceptance, and the factors that play into that acceptance will be essential for supporting individuals training for health workforce roles and their collaborative work within and across disciplines.
Purpose
This paper describes the methodology utilized to create and then validate the Artificial Intelligence Acceptance Scale for Interprofessional Education (AAIPE). This validated scale is intended to measure health sector student levels of acceptance of artificial intelligence as a part of their workplace roles and responsibilities.
Method
The AAIPE scale was utilized at the conclusion of multi-discipline interprofessional education activity (N = 161).
Results
Analysis of the AAIPE results indicated moderate-to-high levels of internal consistency for scale items. Student participant AAIPE scores indicated neutral-to-moderately positive levels of acceptance overall without significant difference between students from different health sector academic programs.
Conclusions
This research uncovered lower levels of student acceptance of artificial intelligence's influence on professional ethics and AI's influence on role clarity. Higher levels of acceptance relating to AI as an evolving component of health sector work were also found. A discussion of these results relating to interprofessional education and practice is conducted.}
}
@article{HAN2024112034,
title = {A GAI-based multi-scale convolution and attention mechanism model for music emotion recognition and recommendation from physiological data},
journal = {Applied Soft Computing},
volume = {164},
pages = {112034},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112034},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624008081},
author = {Xiao Han and Fuyang Chen and Junrong Ban},
keywords = {Music emotion recognition, Physiological signals, Three-dimensional emotion model, Music recommendation, Multi-scale parallel convolution, GAI-based-attention mechanism},
abstract = {Due to the subjectivity of emotions and the limited number of emotion categories, existing deep learning models require assistance to achieve objective, accurate, and flexible personalized music emotion recommendations. This paper introduces a deep learning approach that combines Generative Artificial Intelligence (GAI) and explicitly leverages physiological indicators to enhance the model's intelligence, versatility, and automation. Physiological indicators such as Heart Rate Variability (HRV) and Galvanic Skin Response (GSR) can be measured using sensors placed on the body's surface, providing more precise information about human emotional changes. This research employs a three-dimensional emotion model, including the tension-arousal axis, energy-arousal axis, and valence axis, to explain the correlation and accuracy between music data and emotions. Based on this, a music emotion classifier is designed, incorporating GAI algorithms to recommend music by matching users' physiological and emotional types with the emotional features of music. The classifier uses Mel-Frequency Cepstral Coefficients (MFCC) to transform audio into Mel-spectrogram as input features. The music emotion selection module adopts a GAI framework of Variational Autoencoder (VAE) and integrates multi-scale parallel convolution and attention mechanism modules. Experimental results demonstrate that this approach is competitive compared to existing deep learning architectures on PMEmo, RAVDESS, and Soundtrack datasets. Furthermore, due to GAI's efficient classification capability, this model is suitable for resource-constrained mobile devices and other smart devices. The results of this study can be applied to emotion-based music recommendation systems, contributing to emotional interventions and improving the performance of exercise and music therapy.}
}
@article{HUBBARD2025,
title = {AI and the Future of Language Teaching:},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.378304},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000106},
author = {Philip Hubbard and Mathias Schulze},
keywords = {Generative AI, GenAI, Professional Development, Ethics, Chatbots, Machine Translation, AI Competency, AI Literacy, Assessment, Large Language Models},
abstract = {ABSTRACT
The November 2022 release of ChatGPT revolutionized the accessibility, perception, and use of generative artificial intelligence (GenAI). In this position paper, we argue that a major goal of currently-practicing language teachers should be to acquire relevant knowledge and skills in GenAI, with teacher educators, professional organizations, and language programs co-responsible in that effort. As necessary background, we describe the history and current state of AI in language teaching, especially as it relates to GenAI. Then, drawing on recent research and in-service training sources, we offer guidance for practicing teachers at all stages of their careers to achieve a basic understanding of and facility with GenAI in a range of forms relevant for language teaching and learning. We propose that teachers engage in a targeted form of continuous professional development, GenAI sustained integrated professional development (SIPD), to accommodate the rapid, unpredictable, and likely transformative changes in GenAI for language education.}
}
@article{AKRAM2026102637,
title = {A review of generative AI in aquaculture: Applications, case studies and challenges for smart and sustainable farming},
journal = {Aquacultural Engineering},
volume = {112},
pages = {102637},
year = {2026},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2025.102637},
url = {https://www.sciencedirect.com/science/article/pii/S0144860925001268},
author = {Waseem Akram and Muhayy Ud Din and Lyes {Saad Saoud} and Irfan Hussain},
keywords = {Aquaculture, Marine robots, Generative AI, Autonomous systems, Large language models},
abstract = {Generative Artificial Intelligence (GAI) is revolutionizing aquaculture by providing practical and scalable solutions to longstanding industry challenges, including limited data availability, labor-intensive underwater inspections, disease outbreaks, and inefficiencies in resource management. As the sector evolves toward the Aquaculture 4.0 vision of intelligent, interconnected, and sustainable systems, GAI offers transformative capabilities across perception, planning, optimization, and communication. GAI enhances automation, decision support, and situational awareness across the aquaculture value chain through the intelligent synthesis of multimodal data ranging from sensor logs and underwater imagery to textual records and simulations. This review presents the first comprehensive synthesis of GAI in aquaculture, covering foundational models (e.g., diffusion models, transformers, and GANs), domain-specific applications, and emerging deployment scenarios. We demonstrate how GAI drives industry innovation in areas such as ROV-based infrastructure inspection, digital twins for farm design, synthetic data generation for fish health diagnostics, multimodal sensor fusion, and personalized advisory systems. Importantly, we map GAI models to specific aquaculture tasks, highlighting their suitability and advantages. We also offer a critical assessment of their operational readiness, including trust, performance, and environmental impact issues. In addition, we provide a systematic classification of applications, case studies, and future directions to guide the responsible and scalable integration of GAI in aquaculture. This review highlights GAI as a powerful tool and a foundational enabler of innovative, resilient, and ecologically aligned aquaculture systems, accelerating the industry’s transition toward more efficient, transparent, and adaptive practices.}
}
@article{LENG2025561,
title = {Diffusion model-driven smart design and manufacturing: Prospects and challenges},
journal = {Journal of Manufacturing Systems},
volume = {82},
pages = {561-577},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525001864},
author = {Jiewu Leng and Xuyang Su and Zean Liu and Lianhong Zhou and Chong Chen and Xin Guo and Yiwei Wang and Ru Wang and Chao Zhang and Qiang Liu and Xin Chen and Weiming Shen and Lihui Wang},
keywords = {Diffusion models, Smart manufacturing, Artificial Intelligence-Generated Content, Generative Artificial Intelligence, Industry 5.0, Product lifecycle management},
abstract = {Artificial Intelligence-Generated Content (AIGC), particularly diffusion models as a key component of Generative Artificial Intelligence (GenAI), are transforming smart design and manufacturing in the interplay of Industry 4.0 and Industry 5.0. This paper analyzes the applications of diffusion models in smart design and manufacturing, focusing on three key pillars: diffusion-driven generative design, smart control, and fault diagnosis. Diffusion models enhance manufacturing system flexibility, resilience, and sustainability through their applications as generative design engines, intelligent controllers for adaptive manufacturing processes, and predictive tools for fault diagnosis. This study provides a comprehensive review of the current state of diffusion model-driven smart design and manufacturing. It analyzes key challenges such as model efficiency, data dependency, and system integration, while providing a constructive perspective on potential solutions. This paper also integrates Industry 5.0 considerations by connecting the applications and technical solutions to the core values of human-centricity, sustainability, and resilience. It concludes by emphasizing the necessity of continuous refinement of diffusion models and interdisciplinary research to integrate them into smart design and manufacturing systems further, fostering a more human-centric, resilient, and sustainable industry.}
}
@article{CHAKRABORTY2024114737,
title = {Enhancing trust in online grocery shopping through generative AI chatbots},
journal = {Journal of Business Research},
volume = {180},
pages = {114737},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114737},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002418},
author = {Debarun Chakraborty and Arpan {Kumar Kar} and Smruti Patre and Shivam Gupta},
keywords = {Generative Artificial Intelligence (AI), Online Shopping, Elaboration Likelihood Model, Trust, Status Quo Bias Theory, Chatbots},
abstract = {Generative Artificial Intelligence (GAI) is witnessing a lot of adoption across industries, but literature is yet to fully document the nuances of these applications. We develop a comprehensive framework for understanding the factors that affect trust in online grocery shopping (OGS) using GAI chatbots. Our exploratory study was conducted via interviews, which helped to build our model. We integrate the Elaboration Likelihood Model (ELM) and Status Quo Bias (SQB) theory to develop the Unified Framework for Trust on Technology Platforms. In our confirmatory study, by analyzing 372 responses from users, using structural equation modelling (SEM), we initially validate our path model. Subsequently, we used fuzzy set qualitative comparative analysis (fsQCA) to check the causal combinations to explain different trust levels. Apart from perceived regret avoidance, all of the other factors had a significant effect on attitude and trust. Perceived anthropomorphism moderated the associations between interaction quality, credibility, threat, and attitude.}
}
@article{KOHNKE2024100279,
title = {Exploring EAP students' perceptions of GenAI and traditional grammar-checking tools for language learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100279},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100279},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000821},
author = {Lucas Kohnke},
keywords = {Academic writing, ChatGPT, EAP, English language learners, GenAI},
abstract = {The rapid development of generative artificial intelligence (GenAI) tools (e.g. ChatGPT) has elicited mixed reactions among English language instructors and learners. This study explores how first-year students in an English for Academic Purposes (EAP) course at a Hong Kong university perceive GenAI and traditional grammar-checking tools (e.g. Grammarly, MS Word). We employed a qualitative methodology grounded in the interpretivist paradigm, conducting semi-structured interviews with 14 students. The findings revealed the students perceived GenAI tools to be more comprehensive and authoritative, as they provide detailed explanations and contextual insights that enhance language proficiency. However, they also noted concerns about overreliance, data privacy and equitable access to premium features. The study examines the ethical and pedagogical implications of integrating GenAI tools into higher education, highlighting their potential and the necessity of institutional guidance. It contributes to the ongoing discourse on the role of GenAI in academic writing instruction.}
}
@article{KUOWEI2025101164,
title = {An integrated framework for Gen AI-assisted management learning: Insights from Kolb's learning cycle theory and knowledge types perspectives},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101164},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101164},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725000345},
author = {Lee Kuo-Wei},
keywords = {Management learning, Gen AI-Assisted learning, Learning cycle theory, Knowledge types, ChatGPT},
abstract = {Generative Artificial Intelligence (Gen AI), particularly through advanced models such as ChatGPT developed on the foundation of sophisticated Large Language Models (LLMs), has shown the potential to revolutionize management education. Nevertheless, a comprehensive framework for employing Gen AI in this context remains to be developed. This study proposes a theoretical framework utilizing Gen AI, with a specific focus on ChatGPT, based on Kolb's learning cycle theory and the knowledge type perspective to facilitate systematic integration into management learning. Analyzing data from 348 business students through structural equation modeling, the study demonstrates that the Gen AI -assisted learning process enhances the acquisition of diverse knowledge types. The findings also highlight that teacher support partially strengthens the effectiveness of the Gen AI -assisted learning process in knowledge acquisition. The study contributes to the academic discourse by developing an integrated framework and practical guidelines for integrating Gen AI into management learning, thereby addressing an existing gap in current research.}
}
@article{DEALBUQUERQUE2025103,
title = {Generative AI applied for synthetic data in PMU},
journal = {Energy Reports},
volume = {14},
pages = {103-115},
year = {2025},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2025.05.062},
url = {https://www.sciencedirect.com/science/article/pii/S2352484725003439},
author = {Felipe Proença {de Albuquerque} and Eduardo Coelho Marques {da Costa} and Luisa Helena Bartocci Liboni},
keywords = {Synthetic data, Measurement series, Phasor measurements, Electrical engineering},
abstract = {The growing deployment of Phasor Measurement Units (PMUs) has enhanced power system observability but introduced new challenges related to data privacy, incompleteness, and measurement quality. To address these issues, this paper proposes a data-driven methodology for generating and completing PMU phasor measurements using Generative Artificial Intelligence. Specifically, we employ Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) trained on real-world PMU datasets to learn the underlying empirical data distributions without assuming predefined statistical models. The proposed deep generative models are evaluated against traditional statistical techniques based on Gaussian Copulas using a suite of distributional similarity metrics, including Kullback–Leibler (KL) divergence, Hellinger distance, Maximum Deviation Nearest Neighbor (MDNN), and the Kolmogorov–Smirnov (KS) test. The GAN model achieved the best distributional fidelity, with KL divergence as low as 0.0106 and Hellinger distance of 0.0435 for voltage signals. In a synthetic data reconstruction task with 0.5% missing values, the GAN reduced the percentage root mean squared error (PRMSE) to 0.52% for voltage and 2.19% for current—significantly outperforming baseline methods. Moreover, the GAN was able to augment the dataset from 1489 to 5000 samples while preserving key statistical properties, as validated by empirical distribution tests. These results demonstrate that deep generative models not only offer superior accuracy but also provide statistically consistent synthetic PMU data, making them a robust alternative to conventional methods for enhancing power system datasets.}
}
@article{SEYFI2025104105,
title = {Understanding tourist barriers and personality influences in embracing generative AI for travel planning and decision-making},
journal = {International Journal of Hospitality Management},
volume = {126},
pages = {104105},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104105},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925000283},
author = {Siamak Seyfi and Myung Ja Kim and Amin Nazifi and Samantha Murdy and Tan Vo-Thanh},
keywords = {Generative AI, ChatGPT, Innovation resistance, Personality traits, Tourist decision-making},
abstract = {As generative artificial intelligence (GAI) technologies become increasingly integrated into the travel industry, understanding the barriers tourists face in adopting these innovative technologies for their travel planning and decision-making has growingly become a critical area of focus. Drawing on the theoretical frameworks of innovation resistance and Big Five personality traits, this study surveyed potential travelers in Korea and the US to assess their personality characteristics, innovation resistance, and perceptions of AI-generated travel recommendations. The findings, derived from structural equation modeling, multi-group analysis, and fuzzy-set qualitative comparative analysis, reveal that variations in personality traits significantly affect tourists’ reluctance to adopting these technologies. Overall, the results of this study contribute to the theoretical understanding of acceptance of GAI and offer practical insights for tourism industry stakeholders, enabling them to tailor their offerings to different personality types and enhance the travel experience for a wide range of travelers.}
}
@article{GARCIAPEREZ2025103303,
title = {Improving automatic defect recognition on GDXRay castings dataset by introducing GenAI synthetic training data},
journal = {NDT & E International},
volume = {151},
pages = {103303},
year = {2025},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2024.103303},
url = {https://www.sciencedirect.com/science/article/pii/S0963869524002688},
author = {A. García-Pérez and M.J. Gómez-Silva and A. de la Escalera-Hueso},
keywords = {X-rays, Castings defects, Automated inspection, ADR, WGAN, Neural network, Generative AI},
abstract = {X-rays are a Non Destructive Testing (NDT) technique commonly employed by aerospace, automotive or nuclear industries when the structural integrity of some parts needs to be guaranteed. Industrial dataset are now available with the introduction of Digital Radiography (DR) X-ray machine and are the basis for Automated Defect Recognition (ADR) systems based on Neural Network (NN) object detection models. However, building a big enough dataset is not easy and takes a long time in a production environment, delaying the introduction of ADR models. A potential solution is to use Generative Artificial Intelligence (GenAI) to synthesise new images. However, these models fail to generate full realistic images due to the subtle nature of X-ray images. Hence, this paper propose a combination of flawless images and synthetic defects generated by a novel Scalable Conditional Wasserstein GAN (SCWGAN) model. Such synthetic defects are introduced in the target images by a location algorithm that uses a mask image defining the allowable defective areas, the expected Gaussian or Poisson noise level and the defect size and aspect ratio. By creating such synthetic dataset and combine it with the original GDXRay dataset, our proposed detection system achieves an improvement of 17% in mAP@IoU=0.5:0.95 (our target metric to reduced uncertainty on defect location) with regards the baseline model trained with only real images. As a secondary metric, to allow comparison with other studies, the model also achieves 96.0% mAP@IoU=0.50, which exceeds the maximum accuracy available on current literature for the evaluated dataset.}
}
@article{BREWER2024525,
title = {Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {525-535},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000569},
author = {Jordan Brewer and Dhru Patel and Dennie Kim and Alex Murray},
keywords = {Blockcain, Generative artificial intelligence (GenAI), ChatGPT, Large language models (LLMs), Chatbots},
abstract = {The transformative impact of generative AI (GenAI), extending beyond traditional AI, raises numerous concerns including the replacement of human roles and AI misuse in an array of industries. This article introduces blockchain technology as a complementary technological safeguard to address some of these challenges. We emphasize blockchain’s role in promoting transparency, verifiability, and decentralization in AI development and usage, thereby offering potential solutions for four distinct challenges: (1) AI toxicity, biases, hallucinations, (2) AI interest misalignment, (3) AI as a black box, and (4) AI misuse. This article proposes ways to ensure responsible and transparent AI usage through the integration of blockchain. We position the convergence of AI and blockchain as a means to manage AI’s societal impact and unlock its benefits—contingent upon collaborative efforts among various stakeholders such as businesses, developers, and regulatory bodies. We contribute to the discourse on ethical AI usage and the potential of blockchain to enhance AI’s reliability and accountability for organizations.}
}
@article{MONTAG2025108705,
title = {Introduction of the AI-Interaction Positivity Scale and its relations to satisfaction with life and trust in ChatGPT},
journal = {Computers in Human Behavior},
volume = {172},
pages = {108705},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108705},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001529},
author = {Christian Montag and Jon D. Elhai},
keywords = {ChatGPT, Trust, Generative artificial intelligence, Well-being, Life satisfaction, AI-Well-being, AI-Interaction Positivity},
abstract = {In November 2022, the generative artificial intelligence ChatGPT was presented to the world, and millions of users started to interact with this tool in a short time. Therefore, the present research aimed to investigate individual differences in trusting ChatGPT and other generative AI tools by asking study participants not only about trust in these products but also to explore associations with the attitude towards AI (ATAI) scale and a newly developed measure called the AI-Interaction Positivity Scale (AI-IPS) scale. Of note, further associations between all investigated variables are also presented. The AI-IPS investigates the degree to which humans experience positive emotions and are satisfied when interacting with products in which AI is built in. A final sample of n = 1073 was analyzed, and it was demonstrated that the new AI-IPS has sufficient psychometric properties and is positively linked to trusting ChatGPT (r = 0.698; here a subsample of n = 649 participants was investigated to determine trust in ChatGPT). Of note, this observed association was comparable (although a bit higher) to correlations between positive attitudes towards AI and trust in ChatGPT. Of further interest, satisfaction with life was assessed. Here, a mild positive association between AI-Interaction Positivity and life satisfaction was demonstrated (r = 0.214). This observation leads to interesting new research questions, namely, the potential causality between these variables (please note that causality cannot be established here because of the cross-sectional nature of the present work).}
}
@article{KUMAR2024472,
title = {Anthropomorphic generative AI chatbots for enhancing customer engagement, experience and recommendation},
journal = {Journal of Consumer Marketing},
volume = {42},
number = {4},
pages = {472-483},
year = {2024},
issn = {0736-3761},
doi = {https://doi.org/10.1108/JCM-06-2024-6922},
url = {https://www.sciencedirect.com/science/article/pii/S0736376124000077},
author = {Aman Kumar and Amit Shankar and Abhishek Behl and Debarun Chakraborty and Raghava R. Gundala},
keywords = {Artificial intelligence, Generative AI, Anthropomorphism, Social response theory, Chatbots, Consumers},
abstract = {Purpose
This research focuses on developing and testing a conceptual model that explores customer behavioural responses (engagement, experience and recommendation) towards generative artificial intelligence (AI)-enabled chatbots. It highlights the significant influence of anthropomorphic characteristics in enhancing perceptions of competence and warmth, further enhancing perceived authenticity. In addition, this study aims to investigate how the need for social interactions moderates these relationships.
Design/methodology/approach
This study used a self-administered questionnaire distributed on Prolific Academic to gather data from 282 eligible participants worldwide. This study uses a structural equation modelling approach to answer the research questions.
Findings
The findings reveal that anthropomorphic characteristics of generative AI-enabled chatbots are positively associated with perceived competence. Moreover, the findings show that the perceived competence and warmth of generative AI-enabled chatbots are significantly associated with perceived authenticity. Furthermore, the results highlight that the perceived authenticity of generative AI-enabled chatbots is positively associated with customer engagement, experience and recommendation. Finally, the results illustrate that the impact of anthropomorphic characteristics on perceived warmth is significantly moderated by the need for social interaction.
Originality/value
This study enriches the generative AI literature and guides organizations in understanding consumer interactions for leveraging generative AI-enabled chatbots. Furthermore, this study contributes to the social response theory literature as this study investigates how user behavioural intentions towards generative AI-enabled chatbots are influenced by their perceived level of anthropomorphic characteristics.}
}
@article{ZHOU2025104431,
title = {How do consumers react to AI-generated green marketing content? A hybrid analysis using PLS-SEM and text mining},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104431},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104431},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925002103},
author = {Cheng Zhou and Bing Jiang},
keywords = {AI-generated green marketing content, Perceived pro-environmental, Skepticism to greenwashing, Perceived experience and agency, Green marketing, PLS-SEM and text mining},
abstract = {In the field of marketing, generative artificial intelligence(AI) is gradually becoming an assistant to human creators, enabling them to efficiently create marketing content based on different marketing objectives. Recently, green marketing has become an important strategy implemented by retailers to enhance their corporate image and consumer engagement. This study imitates human creators' strategies for creating green marketing content and categorizes three strategies for using AI-generated green marketing content. The results of two studies reveal that moderate green in AI-generated content (compared to non-green content) awakens consumers' pro-environmental perceptions, consequently increasing their purchase intention. However, excessive green in AI-generated content (compared to moderate green content) evokes skepticism related to greenwashing, which, in turn, negatively impacts their intention to purchase. Additionally, perceived experience and agency positively moderate the relationships between the different strategies of using AI-generated green marketing content and consumers' reactions. Our research highlights the importance of using thoughtful approaches to generative AI implementation in the field of green marketing, especially those aimed at reaping economic advantages (e.g., cost efficiency, enhanced consumer engagement, and improved innovation) while maintaining strong consumer relationships.}
}
@article{SHIBUYA2025103485,
title = {How do people evaluate the accuracy of video posts when a warning indicates they were generated by AI?},
journal = {International Journal of Human-Computer Studies},
volume = {199},
pages = {103485},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103485},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925000424},
author = {Yuya Shibuya and Tomoka Nakazato and Soichiro Takagi},
keywords = {Generative AI, GenAI, Artificial Intelligence, Misinformation, Disinformation, Social media, Facebook, TikTok},
abstract = {Given the rise of concerns about Generative Artificial Intelligence (GenAI) powered misinformation, major platforms like Google, Meta, and TikTok have implemented new policies to warn users of AI-generated content. However, we have not fully understood the impacts of such user interface designs that disclose AI made content on user perceptions. This study investigates how people assess the accuracy of video content when they are warned that it is created by GenAI. We conducted an online experiment in the U.S. (14,930 observations), showing half of the participants warning messages about AI before and after they viewed a mockup of true and false video content on social media, while the other half only viewed the same videos without the warning message. The results indicated that the warning message had an impact on the ability to discern between true and false content only among those who had a positive perception of AI. On the contrary, those with a negative perception of AI tended to perceive all AI-made video posts, including those not containing false information, as less accurate when they knew that a GenAI created the videos. These results indicated the limitations of merely relying on simple warnings to mitigate GenAI-based misinformation. Future research on continuous investigations on designing interfaces that go beyond simple warnings is needed.}
}
@article{WIBOWO20258,
title = {Generative AI for library social media content creation and communication},
journal = {Library Hi Tech News},
volume = {42},
number = {8},
pages = {8-11},
year = {2025},
issn = {0741-9058},
doi = {https://doi.org/10.1108/LHTN-06-2025-0109},
url = {https://www.sciencedirect.com/science/article/pii/S0741905825000196},
author = {Muhamad Prabu Wibowo},
keywords = {Generative artificial intelligence, Library communication, Social media content},
abstract = {Purpose
This paper aims to examine the potential use of generative artificial intelligence (Gen AI) to enhance digital communication in libraries, with a particular emphasis on social media content creation. It seeks to identify emerging opportunities, explore key challenges and address ethical and institutional considerations related to the adoption of Gen AI in outward-facing communication practices.
Design/methodology/approach
The study draws on a combination of literature review and practitioner insights from a 2025 workshop hosted by the Librarian Empowerment Division of the Jakarta Public Library. It highlights how librarians are using Gen AI tools to generate posts, captions and visuals for social media, and presents selected examples and reflections from their experiences.
Findings
Gen AI tools enable libraries to produce social media content more efficiently, particularly in contexts with limited human or technical resources. However, their adoption also reveals challenges such as graphic inconsistencies, copyright ambiguity and ethical concerns. A key issue identified is the absence of clear institutional policies to guide responsible use. In addition, uneven levels of digital competence among staff may hinder experimentation and broader implementation.
Originality/value
This study contributes to the evolving discourse on AI adoption in libraries by focusing specifically on the underexplored area of Gen AI use in social media communication. It provides a contextualized account of how Indonesian libraries are beginning to apply Gen AI tools for creating public-facing content on social media platforms. By documenting early practices and institutional responses, the paper highlights both the creative possibilities and operational challenges of using AI in library outreach strategies.}
}
@article{SAHASHI2025458,
title = {AI-echocardiography: Current status and future direction},
journal = {Journal of Cardiology},
volume = {85},
number = {6},
pages = {458-464},
year = {2025},
issn = {0914-5087},
doi = {https://doi.org/10.1016/j.jjcc.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S091450872500053X},
author = {Yuki Sahashi and David Ouyang and Hiroyuki Okura and Nobuyuki Kagiyama},
keywords = {Artificial intelligence, Deep learning, Echocardiography, Generative artificial intelligence},
abstract = {Summary
Echocardiography, which provides detailed evaluations of cardiac structure and pathology, is central to cardiac imaging. Traditionally, the assessment of disease severity, treatment effectiveness, and prognosis prediction relied on detailed parameters obtained by trained sonographers and the expertise of specialists, which can limit access and availability. Recent advancements in deep learning and large-scale computing have enabled the automatic acquisition of parameters in a short time using vast amounts of historical training data. These technologies have been shown to predict the presence of diseases and future cardiovascular events with or without relying on quantitative parameters. Additionally, with the advent of large-scale language models, zero-shot prediction that does not require human labeling and automatic echocardiography report generation are also expected. The field of AI-enhanced echocardiography is poised for further development, with the potential for more widespread use in routine clinical practice. This review discusses the capabilities of deep learning models developed using echocardiography, their limitations, current applications, and research utilizing generative artificial intelligence technologies.}
}
@article{XIAOYU2025165,
title = {Evaluating the efficacy of ChatGPT in environmental education: findings from heuristic and usability assessments},
journal = {On the Horizon},
volume = {33},
number = {2},
pages = {165-185},
year = {2025},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-11-2024-0079},
url = {https://www.sciencedirect.com/science/article/pii/S1074812125000132},
author = {Wang Xiaoyu and Zamzami Zainuddin and Chin Hai Leng and Dong Wenting and Xiang Li},
keywords = {Environmental education, Usability testing, ChatGPT, Generative artificial intelligence, Heuristic evaluation},
abstract = {Purpose
This study aims to investigate ChatGPT’s potential in environmental education concerning sustainable development goals. Heuristic evaluation and usability testing identify critical usability issues, including inadequate multimedia support, language barriers and insufficient fact-checking capabilities.
Design/methodology/approach
The study uses heuristic evaluation and usability testing to assess ChatGPT’s efficacy in environmental education at a Chinese higher education institution. The evaluation identifies essential limitations, including reliance on text-only resources, absence of multimedia assets, technical deficiencies, language barriers, lack of fact-checking tools, context-related issues, delayed information, inconsistency and limited expertise. Data was collected through quantitative and qualitative analysis, with input from experts and students.
Findings
Findings suggest that while ChatGPT offers opportunities for interactive learning, its limitations hinder comprehensive educational outcomes. A proposed hybrid model combining generative AI and human elements aims to enhance engagement and learning effectiveness. This research offers a foundation for integrating AI tools into environmental education, addressing usability gaps and fostering sustainable learning environments.
Originality/value
This research contributes to a deeper understanding of the role of artificial intelligence in environmental education and underscores the importance of incorporating human intervention. The proposed hybrid approach offers a framework for creating more comprehensive and meaningful learning environments by leveraging the unique strengths of human engagement alongside generative AI technology.}
}
@article{ANDERS2025100482,
title = {Developing generative AI literacies through self-regulated learning: A human-centered approach},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100482},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100482},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001225},
author = {Abram D. Anders and Emily {Dux Speltz}},
keywords = {Artificial intelligence, Multimodal composition, Self-efficacy, Self-regulated learning, Teaching/learning strategies},
abstract = {Generative artificial intelligence (AI) creates both opportunities for enhanced learning and risks of skill erosion and dependency. This exploratory, mixed-methods study investigated how to design AI learning experiences using a human-centered approach that promotes student agency. We developed and investigated an integrated framework combining comprehensive generative AI literacies—functional, critical and ethical, and creative—with self-regulated learning (SRL) processes operationalized as a human-centered Plan, Iterate, Evaluate cycle. Thirty-eight undergraduate students enrolled in an “Artificial Intelligence and Writing” course completed scaffolded experiential challenges followed by self-directed creative projects. Quantitative analysis revealed significant growth in AI literacy self-efficacy across all dimensions, with students progressing from moderate initial confidence (M = 4.68, SD = 2.11) to high confidence levels (M = 8.39, SD = 1.04) on a 10-point scale (t = −9.86, p < .001). Qualitative analysis of project artifacts and student process reflections identified a taxonomy of human in the loop practices integrating AI literacies and self-regulation across the Plan, Iterate, Evaluate cycle. Planning practices involved activating domain knowledge to identify AI applications and establishing evaluative criteria. Iteration practices included developing multi-step workflows, refining prompts through dialogue, and monitoring output quality. Evaluation practices combined assessment of project outcomes with reflection on collaboration processes to inform future use. These practices illustrated adaptive human-AI collaboration strategies that augment rather than replace students’ disciplinary expertise and creative vision. These findings suggest scaffolded experiential learning integrating AI literacies and metacognitive processes can promote effective AI collaboration and empower students to actively direct their own learning.}
}
@article{RAMKUMAR2025276,
title = {Editorial Commentary: Off-the-Shelf Large Language Models Are of Insufficient Quality to Provide Medical Treatment Recommendations, While Customization of Large Language Models Results in Quality Recommendations},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {2},
pages = {276-278},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324007709},
author = {Prem N. Ramkumar and Andrew F. Masotto and Joshua J. Woo},
abstract = {The content accuracy of off-the-shelf large language models (LLMs) mirrors the content accuracy of the unregulated Internet from which these generative artificial intelligence models are supplied. With error rates approximating 30% in terms of treatment recommendations for the management of common musculoskeletal conditions, seeking expert opinion remains paramount. However, custom LLMs represent an excellent opportunity to infuse niche, bespoke expertise from the many specialties and subspecialties within medicine. Methods of customizing these generative models broadly fall under the categories of prompt engineering; “retrieval-augmented generation” prioritizing retrieval of relevant information from a specific domain of data; “fine-tuning” of a basic pretrained model into one that is refined for health care–related vernacular and acronyms; and “agentic augmentation” including software that breaks down complex tasks into smaller ones, recruiting multiple LLMs (with or without retrieval-augmented generation), optimizing the output, internally deciding whether the response is appropriate or sufficient, and even passing on an unmet outcome to a human for supervision (“phone a friend”). Custom LLMs offer physicians and their associated organizations the rare opportunity to regain control of our profession by re-establishing authority in our increasingly digital landscape.}
}
@article{JONAHBARRETT20255686,
title = {Documenting Disclosure: Limited Reporting of Generative AI Usage in Radiology Research Manuscripts},
journal = {Academic Radiology},
volume = {32},
number = {10},
pages = {5686-5692},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2025.06.057},
url = {https://www.sciencedirect.com/science/article/pii/S1076633225006373},
author = {D. {Jonah Barrett} and Richard Heng and Jordan D. Perchik},
keywords = {Large language models, Generative artificial intelligence, Research disclosure},
abstract = {Rationale and Objectives
Large language models (LLMs) show promise in radiology through various clinical applications as well as in assisting with research manuscript development. Recent studies show 52.6% of medical researchers use LLMs in manuscript development, with non-medical researchers showing similar rates. Given concerns about hallucinations, bias, etc., many publishers now require disclosure of LLM use. While most medical imaging journals have LLM policies as of 2025, the actual disclosure rates for LLM usage remain unknown. Our study examines trends in LLM disclosure by analyzing 1998 radiology publications for LLM disclosures.
Materials and Methods
A bibliometric analysis of nine radiology journals with LLM use disclosure requirements was performed. The study included primary investigations and secondary research while excluding short-form publications. The LLM disclosure rate was calculated overall. Logistic regression assessed temporal trends in disclosure rates, while a linear mixed effects model evaluated the relationship between disclosure status and peer review duration. Chi-square analysis examined associations between manuscript type and disclosure rates.
Results
Of 1998 manuscripts, 34 (1.7%) declared LLM use. Most disclosures involved ChatGPT (32, 94.1%), primarily for readability/grammar purposes (33, 97.1%). The majority of manuscripts disclosing LLM use originated from institutions in non-English speaking countries (22, 64.7%). No significant increase in disclosure rates over time was observed (OR: 1.06 [95% CI: 0.98, 1.16], p=0.15), and no relationship with peer review duration (coefficient: −4.85, SE=11.25, p=0.67) was found. Secondary research manuscripts disclosed LLM use more frequently (3.9% vs. 1.3%, p<0.001) with a small effect size (Cramer's V: 0.08 [0.04, 1.00]).
Conclusion
Our findings demonstrate remarkably low disclosure rates in radiology manuscripts despite surveys indicating significant LLM adoption among researchers. This discrepancy may result from true non-use, fear of stigma, perceived advantages of undisclosed use, disagreement with disclosure requirements for minor editing, or policy unawareness, among other reasons. These findings suggest a need for more accepting research environments that recognize legitimate LLM benefits while developing nuanced disclosure policies addressing risks.}
}
@article{ZHAO2025253,
title = {xml:lang="en">Lesson study as an approach to facilitate the integration of Gen-AI into EFL curriculum design in higher education},
journal = {International Journal for Lesson and Learning Studies},
volume = {14},
number = {3},
pages = {253-279},
year = {2025},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-01-2025-0029},
url = {https://www.sciencedirect.com/science/article/pii/S2046825325000101},
author = {Zhi Jian Zhao and Jiajia Li and Yujia Hong and Tian Ying Yun},
keywords = {Lesson study, Generative AI, EFL teachers, Curriculum design},
abstract = {Purpose
This study investigates how English as a Foreign Language (EFL) teachers from higher education develop and refine their curriculum design with Generative Artificial Intelligence (Gen-AI) collaboration during the Lesson Study (LS).
Design/methodology/approach
Through a qualitative case study approach, we followed six English teachers in their collaborative work with a Gen-AI teaching assistant (Kimi) over a 6-month semester. Data were collected through the recordings of LS cycles, teacher interviews and reflections and documentation of teacher-AI interactions etc.
Findings
The findings revealed three key aspects of Gen-AI integration in designing EFL curriculum: First, teachers progressively discovered Kimi’s capabilities in lesson planning, material development, and activity design, showing value in generating differentiated learning resources. Second, the teachers developed sophisticated collaboration patterns with the Gen-AI, demonstrating iterative refinement approaches and strategic integration of Gen-AI suggestions throughout the LS cycles. Third, teachers' critical reflections showed evolution in their evaluation and application of Gen-AI contributions, maintaining professional agency while leveraging Gen-AI capabilities effectively.
Research limitations/implications
This study has several limitations that inform future research directions. Our investigation focused specifically on EFL higher education using a single Gen-AI tool (Kimi), which may limit the generalizability of the findings to other educational contexts and AI platforms.
Practical implications
These findings suggest that Gen-AI integration through LS can enhance teachers' professional practice while promoting critical engagement with Gen-AI tools. The study provides insights into how Gen-AI can be meaningfully integrated into teacher professional development through collaborative LS approaches.
Originality/value
The study demonstrates how the LS framework supports balanced AI integration while maintaining teacher agency. In addition, it reveals the process of AI capability discovery and strategic implementation in EFL teaching.}
}
@article{ARSLAN20244534,
title = {Exploring Business Events using Multi-source RAG},
journal = {Procedia Computer Science},
volume = {246},
pages = {4534-4540},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.303},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023226},
author = {Muhammad Arslan and Saba Munawar and Christophe Cruz},
keywords = {Business events, Extraction methods, Large Language Models, Retrieval-Augmented Generation, Dynamic business environments},
abstract = {Business events signify crucial activities within a company, indicating growth opportunities and investment prospects. They encompass various developments such as recruitment drives, market expansions, mergers, and product launches. Understanding these events is vital for businesses seeking to stay updated with market dynamics, as they provide real-time insights into a company’s trajectory. Moreover, comprehending the business events of one company can offer strategic advantages to others, facilitating informed decision-making and fostering collaboration within the business ecosystem. Extracting information about these events involves diverse structured, semi-structured, and unstructured data sources, posing challenges for traditional extraction methods. Despite the promise shown by existing openly available LLMs driven by Generative Artificial Intelligence (GenAI), they face challenges when dealing with domain-specific queries. Retrieval-Augmented Generation (RAG) addresses this challenge by seamlessly integrating multiple external data sources of varying structures. In our study, we demonstrate how RAG with LLM facilitates precise extraction of business events, ensuring adaptability in dynamic business environments where datasets are constantly evolving.}
}
@article{VHATKAR2024104047,
title = {Leveraging digital technology in retailing business: Unboxing synergy between omnichannel retail adoption and sustainable retail performance},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {104047},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.104047},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924003436},
author = {Manjunath S. Vhatkar and Rakesh D. Raut and Ravindra Gokhale and Mukesh Kumar and Milind Akarte and Sudishna Ghoshal},
keywords = {Omnichannel retailing, Digital technologies, Retail company performance, TBL, Triple bottom line},
abstract = {The retail industry is undergoing a significant transformation driven by digital technology. Among the key challenges retailers face are the rise of e-commerce, changing customer behaviour, and growing supply chain complexity. These shifts have intensified the pressure on retailers’ margins, necessitating bold action to reverse the negative trajectory. By leveraging digital technology in retail, this study unboxes the synergy between omnichannel retail adoption and sustainable retail performance and explores the intersection of omnichannel retail adoption and sustainable performance. By embracing omnichannel strategies and harnessing data at scale, retailers can enhance customer experiences, optimize operations, and drive growth. Utilizing Structural Equation Modelling (SEM) on data from 485 employees of Indian retail respondents. Findings reveal that digital technology has a significant moderation effect that boosts omnichannel activities' financial, environmental, and social aspects. Specifically, Generative Artificial Intelligence (Gen-AI) tools such as chatbots, visual search, and personalized retail experiences play a pivotal role. The study underscores combining data-driven, process, and Gen-AI technologies with omnichannel strategies to elevate performance. These insights contribute to understanding how retailers can leverage digital innovation within omnichannel frameworks for sustainable success.}
}
@article{FRANCE2024649,
title = {Navigating software development in the ChatGPT and GitHub Copilot era},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {649-661},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000697},
author = {Stephen L. France},
keywords = {Generative AI, Large language models, Software developers, AI prompting, Prompt engineering, Capability maturity model},
abstract = {Generative artificial intelligence (GenAI) technologies using LLMs (large language models), such as ChatGPT and GitHub Copilot, with the ability to create code, have the potential to change the software-development landscape. Will this process be incremental, with software developers learning GenAI skills to supplement their existing skills, or will the process be more destructive, with the loss of large numbers of development jobs and a radical change in the responsibilities of the remaining developers? Given the rapid growth of AI capabilities, it is impossible to provide a crystal ball, but this article aims to give insight into the adoption of GenAI with LLMs in software development. The article gives an overview of the software-development industry and of the job functions of software developers. A literature review, combined with a content analysis of online comments from developers, gives insight into how GenAI implemented with LLMs is changing software development and how developers are responding to these changes. The article ties the academic and developer insights together into recommendations for software developers, and it describes a CMM (capability maturity model) framework for assessing and improving LLM development usage.}
}
@article{IBARRAMUNOZ2025100818,
title = {Artificial intelligence in the food and bioprocess industries: Addressing food security challenges},
journal = {Food and Humanity},
volume = {5},
pages = {100818},
year = {2025},
issn = {2949-8244},
doi = {https://doi.org/10.1016/j.foohum.2025.100818},
url = {https://www.sciencedirect.com/science/article/pii/S2949824425003222},
author = {Lizbeth Alejandra Ibarra-Muñoz and Giselle Guadalupe Resendiz-Acosta and Roberto Muñoz-García and Litzy Yazmin Alvarado-Mata and Jazel Doménica Sosa-Martínez and Lourdes Morales-Oyervides and Julio Montañez and Nagamani Balagurusamy},
keywords = {Generative artificial intelligence, Predictive artificial intelligence, Bioprocess optimization, Food safety, Food security},
abstract = {Exponential population growth and increasing global food demand present significant challenges to food security, including risk of food shortages, declining quality and adverse environmental consequences associated with food production. Thus, emerging technologies are being applied to enhance and address challenges within production and safety of food. In this review, the potential of Artificial Intelligence (AI) is being explored as an emerging tool towards food industry and bioprocess concerns such as fermentation parameters, quality control contamination detection, food safety management and bioprocess optimization. By leveraging advanced AI techniques, such as Machine Learning (ML), Deep Learning (DL), Artificial Neural Networks (ANN), and Generative Adversarial Networks (GAN). However ethical implications, such as transparency, liability, AI autonomy and corporation’s awareness, remain critical. Despite its transformative potential, challenges like scalability, data availability, and public perception must be addressed for AI full integration into the food industry. Future perspectives highlight AI’s expanding role in preproduction, processing, and distribution, additionally AI is supported by advancements in synthetic biology and predictive modeling.}
}
@article{GOSAK2024103888,
title = {The ChatGPT effect and transforming nursing education with generative AI: Discussion paper},
journal = {Nurse Education in Practice},
volume = {75},
pages = {103888},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.103888},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324000179},
author = {Lucija Gosak and Lisiane Pruinelli and Maxim Topaz and Gregor Štiglic},
keywords = {Artificial Intelligence, ChatGPT, Documentation, Education, Nursing, Nursing Diagnosis},
abstract = {Aim
The aim of this study is to present the possibilities of nurse education in the use of the Chat Generative Pre-training Transformer (ChatGPT) tool to support the documentation process.
Background
The success of the nursing process is based on the accuracy of nursing diagnoses, which also determine nursing interventions and nursing outcomes. Educating nurses in the use of artificial intelligence in the nursing process can significantly reduce the time nurses spend on documentation.
Design
Discussion paper.
Methods
We used a case study from Train4Health in the field of preventive care to demonstrate the potential of using Generative Pre-training Transformer (ChatGPT) to educate nurses in documenting the nursing process using generative artificial intelligence. Based on the case study, we entered a description of the patient's condition into Generative Pre-training Transformer (ChatGPT) and asked questions about nursing diagnoses, nursing interventions and nursing outcomes. We further synthesized these results.
Results
In the process of educating nurses about the nursing process and nursing diagnosis, Generative Pre-training Transformer (ChatGPT) can present potential patient problems to nurses and guide them through the process from taking a medical history, setting nursing diagnoses and planning goals and interventions. Generative Pre-training Transformer (ChatGPT) returned appropriate nursing diagnoses, but these were not in line with the North American Nursing Diagnosis Association – International (NANDA-I) classification as requested. Of all the nursing diagnoses provided, only one was consistent with the most recent version of the North American Nursing Diagnosis Association – International (NANDA-I). Generative Pre-training Transformer (ChatGPT) is still not specific enough for nursing diagnoses, resulting in incorrect answers in several cases.
Conclusions
Using Generative Pre-training Transformer (ChatGPT) to educate nurses and support the documentation process is time-efficient, but it still requires a certain level of human critical-thinking and fact-checking.}
}
@article{KONSTANTINOU2024621,
title = {Leveraging Generative AI Prompt Programming for Human-Robot Collaborative Assembly},
journal = {Procedia CIRP},
volume = {128},
pages = {621-626},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124007510},
author = {Christos Konstantinou and Dimitris Antonarakos and Panagiotis Angelakis and Christos Gkournelos and George Michalos and Sotiris Makris},
keywords = {Generative AI, Human Robot collaboration, Design informatics},
abstract = {In manufacturing, traditional robotic programming methodologies have often been focused on independent operation, offering limited capabilities for seamless human-robot collaboration. This paper introduces a paradigm shift in collaborative production systems by leveraging generative artificial intelligence (AI), specifically large language models (LLMs). Contrary to traditional methods that rely on pre-defined assembly instructions, this paper introduces a novel framework employing primitive knowledge of the production process, including product design and required assembly steps. By integrating LLMs and a behavior tree-based system control, this approach enables programmers to rapidly deploy collaborative assembly procedures by expediting the programming of robotic operations. The system also incorporates Natural Language Processing (NLP) technologies, which facilitate real-time alterations in assembly steps, leading to reduced overall production time. The framework’s behavior tree-based control architecture allows for dynamic adaptability, offering optimized solutions across a range of assembly scenarios. The results of the framework’s deployment suggest that this innovative programming paradigm significantly enhances both the adaptability and efficiency of collaborative manufacturing settings.}
}
@article{TRAN2025101578,
title = {Students’ self-determination in using machine translation and generative AI tools for English for academic purposes},
journal = {Journal of English for Academic Purposes},
volume = {78},
pages = {101578},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101578},
url = {https://www.sciencedirect.com/science/article/pii/S1475158525001092},
author = {Hao Tran and Peter Crosthwaite and Quy Huynh Phu Pham},
keywords = {Generative AI, Self-determination theory, English for academic purposes, Machine translation, Self-regulated learning},
abstract = {The rise of machine translation (MT) and generative artificial intelligence (GAI) presents opportunities and challenges for English for Academic Purposes (EAP) instruction. While MT/GAI can support students' learning beyond the classroom, overreliance on MT/GAI may hinder development of essential research and composition skills. Despite some research on MT/GAI's role in self-regulated learning, little is known about students' motivations for its use, and the potential mediating influences of instructional context and discipline. This study applies Self-Determination Theory to examine how autonomy, competence, and relatedness influence students' use of MT/GAI in academic writing. Using a mixed-methods approach, the study compares EAP students in an English as a Second Language context in Australia and an English as a Foreign Language context in Vietnam. An online survey validated through confirmatory factor analysis and discriminant validity testing gathered 416 responses, complemented by interviews with 17 students. Findings reveal a complex interplay between MT/GAI use and students' motivational needs. While students generally report moderate autonomy, competence, and relatedness in using MT/GAI in the survey, mixed-effects regression showed Australian students experienced lower relatedness compared with Vietnamese students, with disciplinary differences also significantly influencing students' perceptions of this construct. Interview data further highlighted diversity and complexity of students' perceptions, variation in EAP instructional approaches and peer-teacher dynamics surrounding MT/GAI. These findings support the need for contextually tailored pedagogical approaches fostering collaboration between institutions, teachers, and students, illustrated through innovations from an Australian EAP course that bridge research and practice in MT/GAI-assisted academic writing.}
}
@article{SIDAOUI2024101045,
title = {Generative AI in Responsible Conversational Agent Integration: Guidelines for Service Managers},
journal = {Organizational Dynamics},
volume = {53},
number = {2},
pages = {101045},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101045},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000184},
author = {Karim Sidaoui and Dominik Mahr and Gaby Odekerken-Schröder},
keywords = {Conversational agents, Software development life cycle, Inclusive design, Ethics, Generative artificial intelligence, Corporate digital responsibility, Organizational sensemaking, European Union Artificial Intelligence Act},
abstract = {Responsible integration of conversational agents (CAs) like chatbots is crucial for service firms to mitigate risks and foster positive outcomes. This article provides managerial guidelines through a Corporate Digital Responsibility (CDR) lens, focusing on CDR Culture, Management Structure, and Digital Governance across the service firm, software provider, and customers/society. It examines how organizational sensemaking processes of creation, interpretation, and enactment are triggered by CA-related issues and events. The research highlights the role of generative AI (GenAI) in implementing CDR factors and responsible CA software development lifecycle phases during development and integration. Guidelines are provided for leveraging GenAI to enhance CDR Culture, incorporate ethical considerations into CDR Management Structure, and enable robust Digital Governance mechanisms to prioritize customer/societal well-being. A multilevel framework illustrates reinforcing the guidelines through organizational sensemaking processes, and fostering responsible CA integration aligned with ethical principles and societal values.}
}
@article{BECKMAN2025101036,
title = {The GenAI divide among university students: A call for action},
journal = {The Internet and Higher Education},
volume = {67},
pages = {101036},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101036},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000454},
author = {Karley Beckman and Tiffani Apps and Sarah Katherine Howard and Claire Rogerson and Ann Rogerson and Jo Tondeur},
keywords = {Generative AI in higher education, ChatGPT, AI literacy, Digital divide, Higher education},
abstract = {The rapid pace of technological change with generative artificial intelligence is accelerating much faster than our capacity to understand and regulate it. Higher education institutions have been firmly focused on the impacts of this innovation on academic integrity while grappling with unknown longer-term impacts on students' academic study and future work. This mixed method study aims to capture student perspectives on their self-reported understanding of GenAI and intentions to use GenAI for their academic study during the critical diffusion stage and policy vacuum. Through a survey with 194 university students, the study explored student's understanding, knowledge, experience and intended use of GenAI tools to support their academic study. The paper presents three distinct student profiles established through cluster analysis of measures of digital and AI literacy, which are then explored in-depth through presentation of qualitative items. Notably, the cluster profiles demonstrate variation across the profiles of novice, cautious and enthusiastic users and patterns related to their knowledge of ChatGPT and intended uses. The paper draws on digital divide empirical literature and explores the potential to repeat digital divides among groups of students based on their access, capabilities, and capacity to leverage these for educational advantage. We propose that building upon a vast existing body of educational research about digital literacy inequalities offers rich insights into the current problems facing education institutions, specifically, what role do universities play in supporting students to understand and harness GenAI, now and in their futures.}
}
@article{OU2024101156,
title = {Conceptualising and cultivating Critical GAI Literacy in doctoral academic writing},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101156},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101156},
url = {https://www.sciencedirect.com/science/article/pii/S1060374324000638},
author = {Amy Wanyu Ou and Baraa Khuder and Sindija Franzetti and Raffaella Negretti},
keywords = {Artificial intelligence, Academic writing, Critical GAI Literacy, Self-regulated learning, Doctoral education},
abstract = {Generative artificial intelligence (GAI) has revolutionised the landscape of academic writing, presenting both advantages and risks to learning for L2 writers. It is thus imperative that L2 writers, especially at advanced academic levels, develop the critical skills necessary for employing GAI tools ethically and effectively in their writing processes. Our study addressed this need by 1) conceptualising Critical GAI Literacy based on current research and our collected data, and 2) developing a self-regulated learning-based micro-curriculum for L2 doctoral students to cultivate knowledge and skills using GAI for academic writing. We collected interactive and reflective data in an introductory-level academic writing course at a Swedish university enrolled with 60 PhD students from diverse backgrounds and examined their evolving perspectives and strategies for engaging in GAI-mediated writing. Findings show a spectrum of initial attitudes among students and limited knowledge of GAI use. Final reflections illustrate de-enchantment with GAI, recalibrated and enhanced understanding of ethical issues, developed prompting methods, and increased awareness of text ownership through the self-directed learning process. Furthermore, students demonstrated a discerning approach in evaluating GAI-generated suggestions and sociolinguistic impacts, indicating a growing criticality in L2 writing practices.}
}
@article{LIU2025100438,
title = {Designing a generative AI enabled learning environment for mathematics word problem solving in primary schools: Learning performance, attitudes and interaction},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100438},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100438},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000785},
author = {Jingxi Liu and Daner Sun and Jin Sun and Jingyun Wang and Philip Leung Ho Yu},
keywords = {ChatGPT, Generative artificial intelligence, Mathematics word problem solving, Personalized learning, Primary mathematics education},
abstract = {Mathematics word problem solving is a critical component of elementary education, yet many students encounter persistent difficulties in this area due to the combined cognitive demands of linguistic comprehension and mathematical reasoning. While previous studies have explored various pedagogical strategies to enhance problem-solving skills, the integration of generative artificial intelligence (GenAI) in this domain remains underexplored. This study introduces the ChatGPT-supported Mathematics Problem-Solving System (ChatGPT-MPS), a GenAI-enabled learning environment designed to support primary students in developing problem-solving strategies and deepening conceptual understanding. To evaluate its effectiveness, a quasi-experimental design was employed involving 104 fifth-grade students, assigned to an experimental group (using ChatGPT-MPS) and a control group (traditional instruction). Both groups completed a pre- and post-tests of MPS and interests scale to evaluate their word problem-solving proficiency and learning interests. Quantitively data analysis and its results showed that the experimental group exhibited significantly greater improvements in post-test performance compared to the control group. In addition, student feedback revealed increased interest, perceived value, and motivation when engaging with the ChatGPT-MPS learning environment. These findings provide empirical support for the use of GenAI in mathematics education and demonstrate the potential of ChatGPT-MPS to enhance students' mathematical thinking and engagement in problem-solving tasks. The study contributes to the growing body of research on AI-driven personalized learning in primary education, offering insights into the design and implementation of effective GenAI-enabled learning environments.}
}
@article{ABBARA2025105131,
title = {Artificial intelligence and infectious diseases: Scope and perspectives},
journal = {Infectious Diseases Now},
volume = {55},
number = {7},
pages = {105131},
year = {2025},
issn = {2666-9919},
doi = {https://doi.org/10.1016/j.idnow.2025.105131},
url = {https://www.sciencedirect.com/science/article/pii/S2666991925001101},
author = {S. Abbara and Y. Crabol and J. Goupil {de Bouillé} and A. Dinh and D. Morquin},
keywords = {Infectious diseases, Artificial intelligence, Generative artificial intelligence, Machine learning, Clinical decision support},
abstract = {Artificial intelligence (AI) is set to permeate every facet of infectious disease practice—from prevention and public health surveillance to epidemic management and bedside care. Routine care data (laboratory results, medication orders, progress notes) and research-generated datasets now fuel state-of-the-art machine-learning (ML) pipelines that sharpen diagnosis, prognosis, antimicrobial stewardship, and, by combining both sources, accelerate drug discovery. In diagnostics, deep networks that now flag pneumonia or tuberculosis on chest images are increasingly able to identify—and localize—virtually more infectious processes throughout the body, while simultaneously predicting pathogen identity and antimicrobial resistance from routine microbiology. Prognostic models trained on Electronic Health Records surpass traditional scores in anticipating clinical deterioration or postoperative sepsis, enabling earlier targeted interventions. Predictive analytics can also personalize antimicrobial dosing by fusing real-time drug-monitoring data. Large language models (LLMs) build upon these advances by transforming unstructured clinical narratives into structured phenotypes suitable for predictive modeling, automatically summarizing patient encounters, generating synthetic cohorts for rare conditions, and providing real-time conversational decision support at the patient’s bedside. Despite rapid progress, real-world deployment faces hurdles: high computational and licensing costs, vendor-specific implementation constraints, limited cross-site model transferability, and fragmented governance of safety, bias, and cybersecurity risks. Rigorous, lifecycle-based evaluation frameworks—covering external validation, cost-effectiveness analysis, and post-deployment monitoring—are required to ensure safe, equitable, and sustainable AI adoption. This review synthesizes current applications, evidential strengths, and unresolved challenges, and proposes a translational roadmap aligning technical innovation with clinical and regulatory realities.}
}
@article{FANG2025101300,
title = {Generative AI-enhanced human-AI collaborative conceptual design: A systematic literature review},
journal = {Design Studies},
volume = {97},
pages = {101300},
year = {2025},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2025.101300},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X25000122},
author = {Cong Fang and Yujie Zhu and Le Fang and Yonghao Long and Huan Lin and Yangfan Cong and Stephen Jia Wang},
keywords = {Human-AI collaboration, AI-enhanced design, Design methodology, Design process, Conceptual design},
abstract = {Generative Artificial Intelligence (GenAI) has gained increasing attention, enhancing design productivity by elevating creativity within the conceptual design process. Despite these advancements, how GenAI will influence the conceptual design process and methods remains ambiguous, hindering its full potential. This study introduces a systematic literature review to explore GenAI's role in the conceptual design process, emphasizing the GenAI-human interactions and collaborations. We offer a critical evaluation of the current state of GenAI-human collaboration, identifying challenges, opportunities, and future research directions to leverage GenAI's design potential for enhancing creativity in conceptual design practice. Finally, a Generative AI Enhanced Conceptual Design framework was further proposed to clarify the potential collaborative design process, which can serve as a guideline for effective human-AI collaboration in the conceptual design process.}
}
@article{QIN2025103769,
title = {EFL learners’ perceptual perezhivaniya and actual writing revision behaviors mediated by GenAI: A sociocultural theory perspective},
journal = {System},
volume = {133},
pages = {103769},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103769},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25001794},
author = {Lili Qin and Jingjing Dong},
abstract = {In recent years, Generative Artificial Intelligence (GenAI) has gained prominence as a valuable tool in enhancing EFL learners’ experiences in Second Language Acquisition (SLA). However, empirical studies specifically investigating on GenAI’s role in mediating the revision stage of EFL learners’ L2 writing processes remain scarce. Notably, research exploring the connection between learners’ perceived perezhivaniya—derived from Vygotskyan theory, denoting an individual’’s subjective lived experiences—and their actual revision behaviors is particularly limited. To address this lacuna, we employed interviews, Q-methodology, and the Translog screen recording tool to investigate the revision processes of nineteen EFL learners at a university in Southern China as they revised L2 continuation writing tasks using GenAI. A key contribution of this study is the development of a novel seven-dimensional L2 writing revision taxonomy (word choice, content, discourse, syntax, errors, alignment, and typographic elements), which guided both the Q-questionnaire design and the Translog data coding. This framework uniquely facilitated a comparison between perceived perezhivaniya and actual revision behaviors by integrating online revision with offline reflective perceptions, thereby capturing an essential dynamic aspect of the concept of perezhivanie. Results indicated a strong consistency between most of the learners’ perceived experiences and their actual revision behaviors, in content, alignment, and typographic elements. However, for some learners, alignment—vital for continuation writing—was frequently overlooked despite its perceptual recognition, highlighting significant pedagogical implications.}
}
@article{GERING2025132,
title = {Strategic organisational responses to generative AI-driven digital transformation in leading higher education institutions},
journal = {International Journal of Organizational Analysis},
volume = {33},
number = {12},
pages = {132-152},
year = {2025},
issn = {1934-8835},
doi = {https://doi.org/10.1108/IJOA-09-2024-4850},
url = {https://www.sciencedirect.com/science/article/pii/S1934883525000163},
author = {Zsuzsanna Gering and Katalin Feher and Vanda Harmat and Reka Tamassy},
keywords = {Generative AI, Higher education, Organisational strategy, Digital transformation, Top universities, Future of higher education},
abstract = {Purpose
This study aims to explore generative artificial intelligence (AI) as a significant milestone and key driver of digital transformation in higher education, emphasising the urgent need for universities and policymakers to adapt strategies to remain effective, competitive and aligned with the rapidly evolving demands of education and research.
Design/methodology/approach
This study used qualitative content analysis to examine publicly available strategic documents and statements related to digital transformation from the top 30 ranked universities in the Times Higher Education 2024 Ranking, producing a data set of 98 strategies covering all key organisational domains.
Findings
The collected documents span eight areas, from teaching-learning strategies to information technology (IT) strategies and committees, with substantial variation among universities in scope, content and strategic combinations. A significant result is that teaching-learning offices and development centres serve as bridges between institutional strategies and grassroots innovation, absorbing top-down and bottom-up knowledge and fostering adaptive responses to generative AI-driven transformation.
Practical implications
By showcasing the best practices, this paper provides practical guidance for proactive institutional development, supporting university leadership in strategy-building and aiding national and international policymakers in shaping forward-looking frameworks.
Originality/value
Understanding and defining generative AI as a milestone in digital transformation is crucial for universities. Proactive adaptation to emerging trends and best practices enables institutions to navigate these challenges effectively.}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{JIANG2025109821,
title = {Product line design in the presence of generative AI technology},
journal = {International Journal of Production Economics},
pages = {109821},
year = {2025},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2025.109821},
url = {https://www.sciencedirect.com/science/article/pii/S0925527325003068},
author = {Yu Jiang and Wei Lu},
keywords = {Generative AI, Product line design, Distribution contracts, E-commerce channel},
abstract = {With the boom in economic growth, technology has emerged as a nonnegligible factor in driving productivity and innovation. Generative artificial intelligence (GAI), as a representative of disruptive technological innovation, has reshaped traditional manufacturing processes and opened up a field of possibilities. This paper analyzes the practice of GAI technology in the production process and explores its interaction with product line design under two predominant distribution contracts. We focus on technological innovation factors, such as the impact of GAI technology on product popularity and the probability of a successful GAI-assisted design, and find that the effect of GAI technology on product popularity exhibits a non-monotonic relationship with both product quality and firm profit. Our work also demonstrates that a longer product line could incentivize the supplier to adopt GAI-assisted product design under both agency and wholesale contracts. We also show that GAI technology motivates the supplier to extend its product line. Finally, our extended analysis examines distribution contract choices in the presence of GAI technology and reveals that the platform favors an agency contract over a wholesale contract when the commission rate is either relatively low or high, the impact of GAI technology on product popularity is low, the probability of a successful GAI-assisted design is high, and the product line extension fee is moderate.}
}
@article{SAHEB2024100146,
title = {Convergence of artificial intelligence with social media: A bibliometric & qualitative analysis},
journal = {Telematics and Informatics Reports},
volume = {14},
pages = {100146},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100146},
url = {https://www.sciencedirect.com/science/article/pii/S277250302400032X},
author = {Tahereh Saheb and Mouwafac Sidaoui and Bill Schmarzo},
keywords = {Social media, Artificial intelligence, Bibliometric analysis, Qualitative research},
abstract = {The integration of artificial intelligence (AI) and social media has provided numerous benefits to businesses, including improved audience analysis and content optimization. However, AI has facilitated the spread of misinformation, emphasizing the importance of taking a balanced approach that considers both the technology's positive applications and its ethical risks. This paper looks at the intersection of AI and social media. The researchers use a mixed-method approach to analyze 1540 scholarly documents, combining bibliometric and systematic literature review techniques. The goal of this research is to identify the most important topics and trends, as well as potential business values and implications, in the AI Social Media domain. The first stage of the research involved a quantitative keyword co-occurrence analysis, which resulted in the identification of ten dominant themes. These include Conversational Agents & User Experience, Human Emotion and Content Recommendation & Moderation, Collective Intelligence in Emergency Management, Algorithmic Activism on social media, Deep Fakes and Fake News, Generative Artificial Intelligence, Algorithmic Bias in Content Moderation Systems, Deep Sentiment Analysis, Metaverse Technologies, and NLP & Mental Health Detection. Each identified theme is then subjected to a qualitative thematic literature review, which provides a more in-depth, context-specific understanding of the associated findings. Because of this comprehensive approach, the study provides a broad overview of the current state of AI social media, shedding light on the potential applications and far-reaching implications of this interdisciplinary nexus. The study's findings have the potential to shape strategic decision-making, policy development, and future research directions in this rapidly changing field.}
}
@article{LEE2025113326,
title = {A structured prompt framework for AI-generated biophilic architectural spaces},
journal = {Journal of Building Engineering},
volume = {111},
pages = {113326},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.113326},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225015633},
author = {Eun Ji Lee and Sung Jun Park},
keywords = {Biophilic design, Generative AI, AI-Assisted visualization, Structured prompt engineering, Architectural space},
abstract = {This study proposes a structured prompt framework to improve the quality and consistency of generative visualizations in biophilic architectural space (BAS) design. Existing generative artificial intelligence (Gen AI)-based visualization approaches often lack alignment with biophilic design principles, resulting in outputs that fail to reflect the restorative qualities of nature-integrated spaces. To address this limitation, the study links generative visualization processes to established biophilic frameworks, thereby enhancing the applicability of Gen AI in sustainable and human-centered architectural practice. The methodology follows a three-stage process: (1) exploration of biophilic visualization requirements through literature review and prompt testing, (2) development of the framework through domain-specific dataset construction, text mining, and prompt curation, and (3) expert evaluation of images generated using the structured prompts. The proposed framework consists of five components—subject, attribute, mood, time and background, and negative prompt—to guide the generation of BAS visualizations systematically. The generated images were assessed based on five criteria: domain fidelity, visual coherence, depth and perspective, spatial integration, and overall biophilic appeal. Results demonstrated substantial improvements—up to 75 % in domain fidelity and over 60 % in spatial integration and biophilic appeal—compared to early-tested prompts. These findings underscore the potential of structured prompts, grounded in biophilic design theory, to enhance the effectiveness of AI visualizations. This study offers a replicable and scalable method for integrating nature-based design principles into early-stage spatial planning. It provides design professionals with a practical tool to visualize restorative environments and promote sustainable architectural practice.}
}
@article{MOORHOUSE2023100151,
title = {Generative AI tools and assessment: Guidelines of the world's top-ranking universities},
journal = {Computers and Education Open},
volume = {5},
pages = {100151},
year = {2023},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2023.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2666557323000290},
author = {Benjamin Luke Moorhouse and Marie Alina Yeo and Yuwei Wan},
keywords = {Generative artificial intelligence, Assessment guidelines, Higher education, ChatGPT, Academic integrity},
abstract = {The public release of generative artificial intelligence (GAI) tools (e.g., ChatGPT) has had a disruptive effect on the assessment practices of higher education institutions (HEIs) worldwide. Concerns have largely been associated with academic integrity, cheating and plagiarism. HEIs have had to develop guidelines in response to GAI. As many of these guidelines were developed in haste and could affect a large number of instructors and students, there is a need to examine their content, coverage and suitability. This review examines the extent to which the world's 50 top-ranking HEIs have developed or modified their assessment guidelines to address GAI use and, where guidelines exist, the primary content and advice given to guide instructors in their GAI assessment design and practices. The findings show that just under half of the institutions have developed publicly available guidelines. The guidelines cover three main areas: academic integrity, advice on assessment design and communicating with students. Amongst the suggestions for teachers on assessment design, two appear particularly pertinent in helping develop effective assessment tasks and developing learners’ AI literacy: first, running assessment tasks through GAI to check the extent to which the tool can accomplish the task and, second, having students use GAI as part of the assessment process. Overall, the review suggests that HEIs have come to accept the use of GAI and drafted assessment guidelines to advise instructors on its use. In the article, we argue that it may be beneficial to embrace GAI as a part of the assessment process since this is the reality of today's educational and job landscape. This will require instructors to develop a new competence - generative artificial intelligence assessment literacy - which is conceptualised in this article.}
}
@article{NAMOUN2024671,
title = {Predicting the usability of mobile applications using AI tools: the rise of large user interface models, opportunities, and challenges},
journal = {Procedia Computer Science},
volume = {238},
pages = {671-682},
year = {2024},
note = {The 15th International Conference on Ambient Systems, Networks and Technologies Networks (ANT) / The 7th International Conference on Emerging Data and Industry 4.0 (EDI40), April 23-25, 2024, Hasselt University, Belgium},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.076},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924013127},
author = {Abdallah Namoun and Ahmed Alrehaili and Zaib Un Nisa and Hani Almoamari and Ali Tufail},
keywords = {generative artificial intelligence, LLM, generative UI design, large UI models, mobile apps, usability testing, usability attributes},
abstract = {This article proposes the so-called large user interface models (LUIMs) to enable the generation of user interfaces and prediction of usability using artificial intelligence in the context of mobile applications. To this end, we synergized an integrated framework for the effective testing of the usability of mobile applications following a selective review of the most influential models of mobile usability testing. Next, we identified and analysed 13 recent AI tools that generate user interfaces for mobile apps, and systematically tested these tools to identify their AI capabilities. Our striking findings demonstrate that current generative UI tools fail to address mobile usability attributes, such as efficiency, learnability, effectiveness, satisfaction, and memorability. Our large UI models’ architecture proposes to leverage the capabilities of large language models, large vision models, and large code models to overcome the challenges of AI-driven UI/UX design and front-end implementations. This fascinating UI eco-system must be augmented with sufficient UI data and multi-sensory input regarding user behaviour to train the models. We anticipate LUIMs to create ample opportunities, like expedited frontend software development, enhanced personalised user experience, and wider accessibility of smart technologies. However, the research challenges hindering the UI generation and usability prediction of mobile apps include the seamless integration of complex generative AI models, semantic understanding of non-uniform visual designs, scarcity of UX datasets, and modelling of realistic user interactions.}
}
@article{SEYFI2025101364,
title = {Generational differences in adopting AI-generated travel advice: What drives trust and reduces resistance?},
journal = {Tourism Management Perspectives},
volume = {57},
pages = {101364},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101364},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000297},
author = {Siamak Seyfi and Changkyu Lee and Yunkyoung Jo and Myung Ja Kim},
keywords = {Generative artificial intelligence (GAI), Technology adoption, Generational differences, Innovation resistance theory, Tourism digitalization},
abstract = {The adoption of Generative Artificial Intelligence (GAI) in tourism is expanding, yet significant generational differences remain in its acceptance for travel planning and decision-making. This study, drawing on the theoretical lens of innovation resistance and generation theory, examines how generational attitudes toward technology shape perceptions of barriers to GAI adoption in tourism experiences. Using data from South Korea and the United States, the research employs Structural Equation Modeling (PLS-SEM), multi-group analysis (MGA), and fuzzy-set Qualitative Comparative Analysis (fsQCA) to uncover generational disparities in GAI acceptance. Findings reveal distinct challenges faced by different age groups, emphasizing that trust, usability, and perceived risks influence adoption patterns differently across cohorts. The study contributes to the growing theoretical discourse on GAI adoption in tourism and provides practical insights for tailoring GAI solutions to enhance user acceptance and satisfaction across generations.}
}
@article{YI2025111032,
title = {Multi-Scale Tea Bud Grading Detection in Complex Tea Garden Scenes Based on a GenAI Training Framework},
journal = {Computers and Electronics in Agriculture},
volume = {239},
pages = {111032},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.111032},
url = {https://www.sciencedirect.com/science/article/pii/S016816992501138X},
author = {Xiaomei Yi and Zekai Zheng and Peng Wu and Thippa Reddy Gadekallu and Kai Fang},
keywords = {GenAI, Tea bud grading detection, Efficient generalization, Multi-scale, Transformer},
abstract = {The multi-scale distribution of tea buds, dense small-target occlusion, variable lighting, and complex backgrounds often lead to false detections and missed detections of multi-scale tea buds. To address these issues, this study proposes a multi-scale tea bud grading detection model for complex tea garden scenes, based on a generative artificial intelligence (GenAI) training framework, named GE-DETR. The model consists of a Cascaded Grouped Attention (CGA) module, a Small-Object Feature Enhancement Network (SOFE-Net), and a GenAI adaptive training framework. First, the CGA module is integrated into the Transformer encoder. By utilizing a grouping and cascading strategy, it significantly reduces feature redundancy across scales, overcomes interference from variable illumination and clustered occlusion. It effectively enhances the model’s ability to capture the key features of multi-scale tea buds in complex tea garden scenes. SOFE-Net is incorporated into the neck feature fusion stage, significantly improving the model’s computational efficiency and effectively preserving critical fine-grained information, thereby enhancing the detection performance of small target features. During the model training process, GenAI was used to guide model training and achieve dynamic parameter tuning, greatly enhancing model robustness. Experimental results show that on Test set1, GE-DETR surpasses all other compared models with an mAP@50 of 91.73%, and achieves a 33.60% reduction in parameters, a 21.12% reduction in GFLOPs, and a 39.53% increase in inference speed, fully verifying its excellent grading detection performance and lightweight effectiveness. On Test set2, which includes unknown scenes, GE-DETR’s mAP@50 is 5.44% higher than the baseline model RTDETR, showing superior generalization ability. The GE-DETR proposed in this study effectively balances detection performance and efficiency, providing a reliable technical solution for the intelligent grading and picking of tea buds suitable for deployment on resource-constrained edge devices.}
}
@article{HWANG2025102266,
title = {Who owns AI-generated artwork? Revisiting the work of generative AI based on human-AI co-creation},
journal = {Telematics and Informatics},
volume = {98},
pages = {102266},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102266},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000280},
author = {Yohan Hwang and Dongkwang Shin and Jang Ho Lee},
keywords = {Generative AI, Text-to-image creator, Ownership, Copyright, Human-computer interaction},
abstract = {Generative Artificial Intelligence (AI) tools have become increasingly common in educational contexts. However, questions remain regarding the ownership and copyright of intellectual property generated through human-AI collaboration. The present study explored Korean college students’ perceptions of ownership and copyright over images generated through the iterative process of refining prompts within AI image generators. Participants engaged in the image generation project of visualizing the meaning of target words using ChatGPT to generate prompts for the Bing Image Creator. Post-project survey and reflection papers were administered to assess their emotions, sense of ownership, and copyright views related to AI-generated images through the prompts. Sentiment analysis revealed the complexity of participants’ attitudes toward AI and its creation. Views on copyright varied from individual attribution to shared or uncertain ownership. Frequency of prompt use significantly influenced ownership and prompt-based perceptions of copyright. The results of this study provide insight into the intellectual property issues arising from human-AI co-creation, and point to the urgent need for more discussion and balanced views on creative collaboration with AI.}
}
@article{LAU2025,
title = {Exploring the Acceptance and Opportunities of Using a Specific Generative AI Chatbot to Assist Parents in Managing Pediatric Rheumatological Chronic Health Conditions: Mixed Methods Study},
journal = {JMIR Pediatrics and Parenting},
volume = {8},
year = {2025},
issn = {2561-6722},
doi = {https://doi.org/10.2196/70409},
url = {https://www.sciencedirect.com/science/article/pii/S2561672225000604},
author = {Cheryl W Y Lau and Klaudia Kupiec and Polly Livermore},
keywords = {pediatric health care chatbot, technology acceptance, parental attitudes, children and young people's involvement, chronic disease management, AI hesitancy, chronic health condition, artificial intelligence},
abstract = {Background
Health care chatbots can be used to support patients and their families with everyday decision-making. While there is some research on integrating artificial intelligence into pediatric care, no study has focused on the opportunity of implementing a generative artificial intelligence chatbot for pediatric rheumatology. Pediatric rheumatology conditions require intense family input, which can often leave families struggling to navigate disease flares, pain, fatigue, medication side effects and adherence, and support of their child, often when pediatric rheumatology departments are shut. Understanding how we can support families better, without the need for increased personnel, will have implications for the health care systems.
Objective
The study aimed to explore parental and children and young people’s acceptance of chatbot use in a pediatric context, and understand how a chatbot could be specifically used for managing a child’s chronic health condition.
Methods
This study was a mixed methods design, using both a family workshop and a subsequent questionnaire.
Results
In total, 22 participants contributed to the qualitative design using the world café methodology at a workshop, and 47 participants (36 parents and 11 children and young people) completed quantitative data via a questionnaire. Participants expressed their likelihood of using chatbot technology, including ChatGPT, due to its accessibility. However, participants had significantly greater intention (parents: P<.001; children and young people: P=.006) to use a specific chatbot over ChatGPT, due to increased trust, credibility, and specificity in design. Children and young people and parents should be distinguished as 2 user groups in chatbot design, reflecting their specific needs in chatbot features and personalization.
Conclusions
Overall, the study reinforced the need for a specialized and trusted chatbot designed with input from health professionals to assist families in managing complex chronic health conditions to support families in between appointments and complement existing face-to-face care. Future research should evaluate users’ engagement with a functional prototype to investigate its usefulness and explore its implementation into families’ everyday lives. Importantly, the current findings have broader implications for the field of pediatric health care, as similarly tailored chatbot interventions could benefit families who are managing other chronic health conditions.}
}
@article{LI2025,
title = {Exploring the GenAI Literacy of Chinese University Students in EFL Learning},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.377175},
url = {https://www.sciencedirect.com/science/article/pii/S215570982500009X},
author = {Tongtong Li and Yan Ding},
keywords = {Content Analysis, EFL Students, Focus Groups, GenAI Overdependence, GenAI Underuse, GenAI Usage Reports, Generative AI, Literacy, Process-Oriented Framework},
abstract = {ABSTRACT
Although research on generative artificial intelligence (GenAI) has expanded rapidly, limited attention has been given to students’ GenAI literacy in English as a foreign language learning, particularly from a process-oriented perspective. To address this gap, a process-oriented analytical framework was proposed and applied to examine Chinese university students’ GenAI literacy in English as a foreign language learning. The analysis drew on three datasets from the same cohort of 144 students: focus group transcripts, GenAI usage reports from a video presentation project, and presentation scripts developed with GenAI support. The findings reveal dual challenges in students’ GenAI literacy: a tendency to underutilize advanced functionalities while over-relying on GenAI for basic tasks. Additionally, the results underscore the significant influence of contextual factors in shaping student–GenAI interactions. Theoretical and pedagogical implications of these findings are discussed.}
}
@article{RADO2025,
title = {Co-Design of a Health Screening Program Fact Sheet by People Experiencing Homelessness and ChatGPT: Focus Group Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/68316},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25004524},
author = {Nóra Radó and Orsolya Németh and Sándor Békási},
keywords = {digital health, co-design, oral health, focus group, expert by experience, ChatGPT, health information, leaflet, screening, mixed method study, screening programs, oral cancer, vulnerable population, generative AI, co-design, Hungary, homeless, qualitative method, quantitative method, artificial intelligence},
abstract = {Background
People experiencing homelessness have worse oral health outcomes and a notable health informational asymmetry compared to the general population. Screening programs present a viable option for this population; however, barriers to access, such as lower levels of health literacy, lack of information, and mistrust, narrow their chances to participate in such programs.
Objective
The aim of this study is to investigate the applicability of generative artificial intelligence (AI) in designing a homeless health screening program fact sheet with experts by experience using co-design principles.
Methods
Six fact sheet text variants were created by the open-access version of ChatGPT 3.5 for an oral cancer screening program targeting people experiencing homelessness in Budapest, Hungary. Clients of homeless social services (N=23) were invited to a short questionnaire survey and 3 semistructured focus group discussions between May and July 2024. General opinions regarding generative AI technology and direct feedback on the text variants were obtained. Additionally, a standardized readability assessment of the text variants was completed via the Sydney Health Literacy Lab Editor.
Results
Almost two-thirds of participants (17/23) stated that they had previously heard about AI; however, their self-assessment regarding the extent of their knowledge resulted in an average of 2.38 (n=16) on a 5-point Likert scale. During the first focus group discussion, all 6 variants received a high score (between 4.63 and 4.92 on a 5-point Likert scale). In the next sessions, participants remained positive when the pool was narrowed to 4 versions, although they scored the texts lower. During open discussions, text variants were considered understandable, while difficulties with medical expressions, lengthiness of sentences, and references to a stereotypical homeless subgroup (rough sleepers) were also reported. The health literacy editor showed that most AI-generated text variants were difficult to read and too complex for the target group.
Conclusions
The co-design process revealed that focus group participants actively wanted to shape the fact sheet drafts. They shared their insights on how to make the text variants more appealing for the target audience. Moreover, the involvement of generative AI technology revealed that the participants have heard about the concept of AI and text generation as a potential function, and they have not rejected its use in health care settings.}
}
@article{GIORGI2024116058,
title = {Evaluating generative AI responses to real-world drug-related questions},
journal = {Psychiatry Research},
volume = {339},
pages = {116058},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.116058},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124003433},
author = {Salvatore Giorgi and Kelsey Isman and Tingting Liu and Zachary Fried and João Sedoc and Brenda Curtis},
keywords = {Large language models, Generative AI, Substance use, Alcohol, Marijuana, Opioids},
abstract = {Generative Artificial Intelligence (AI) systems such as OpenAI's ChatGPT, capable of an unprecedented ability to generate human-like text and converse in real time, hold potential for large-scale deployment in clinical settings such as substance use treatment. Treatment for substance use disorders (SUDs) is particularly high stakes, requiring evidence-based clinical treatment, mental health expertise, and peer support. Thus, promises of AI systems addressing deficient healthcare resources and structural bias are relevant within this domain, especially in an anonymous setting. This study explores the effectiveness of generative AI in answering real-world substance use and recovery questions. We collect questions from online recovery forums, use ChatGPT and Meta's LLaMA-2 for responses, and have SUD clinicians rate these AI responses. While clinicians rated the AI-generated responses as high quality, we discovered instances of dangerous disinformation, including disregard for suicidal ideation, incorrect emergency helplines, and endorsement of home detox. Moreover, the AI systems produced inconsistent advice depending on question phrasing. These findings indicate a risky mix of seemingly high-quality, accurate responses upon initial inspection that contain inaccurate and potentially deadly medical advice. Consequently, while generative AI shows promise, its real-world application in sensitive healthcare domains necessitates further safeguards and clinical validation.}
}
@article{TAI2024105112,
title = {Improving elementary EFL speaking skills with generative AI chatbots: Exploring individual and paired interactions},
journal = {Computers & Education},
volume = {220},
pages = {105112},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105112},
url = {https://www.sciencedirect.com/science/article/pii/S036013152400126X},
author = {Tzu-Yu Tai and Howard Hao-Jan Chen},
keywords = {Generative artificial intelligence (GAI), Chatbots, EFL speaking, Cooperative/collaborative learning, Elementary education},
abstract = {Generative artificial intelligence (GAI) and automatic speech recognition (ASR) have ushered in promising tools for foreign language learning, notably GAI chatbots. This study investigated the impact of GAI chatbots on elementary school English as a foreign language (EFL) learners' speaking skills, focusing on two interaction configurations—individual and paired. Eighty-five elementary school EFL learners participated in a three-week summer program, engaging in daily 45-min interactions with CoolE Bot. The participants were randomly assigned to three groups: (1) individual interaction with CoolE Bot (I-Bot group), (2) paired interaction with CoolE Bot (P-Bot group), and (3) interaction with teachers and peers in a conventional English classroom (No-Bot group). In each class, participants in the Bot group received worksheets with a topic, prompts, and vocabulary to guide their interactions with CoolE Bot, while those in the No-Bot group also received worksheets for comparable activities. Quantitative (English-speaking tests) and qualitative data (semi-structured interviews) were collected and analyzed. Results revealed that the I-Bot and P-Bot groups' post-test speaking skills were significantly higher than those of the No-Bot group. CoolE Bot significantly improved the speaking skills of EFL learners. Both individual and paired interactions with CoolE Bot demonstrated positive effects, with no significant differences between groups. Interviews highlight CoolE Bot's adeptness in coherent interaction, charismatic conversational style with a human-like voice, diverse topic discussions tailored to learners' interests, and supportive functions. The participants found GAI chatbot-assisted EFL speaking enjoyable, motivating, and engaging appreciating its cartoonish, human-like characters, conversational style, and voice. Additionally, CoolE Bot fostered rapport and a supportive environment enhancing learners' confidence and reducing anxiety regarding EFL speaking. Individual interactions encourage personalized engagement and self-directed learning, whereas paired interactions involve social dynamics, shared learning experiences, and mutual resolution of language challenges.}
}
@article{BOUNAB2025107142,
title = {Advancing Direct Tablet Compression with AI: A multi-task framework for quality control, batch acceptance, and causal analysis},
journal = {European Journal of Pharmaceutical Sciences},
volume = {212},
pages = {107142},
year = {2025},
issn = {0928-0987},
doi = {https://doi.org/10.1016/j.ejps.2025.107142},
url = {https://www.sciencedirect.com/science/article/pii/S0928098725001411},
author = {Yazid Bounab and Osmo Antikainen and Mia Sivén and Anne Juppo},
keywords = {Direct Tablet Compression, Tablet quality control, Tabular Data Augmentation, Neural networks, Generative artificial intelligence},
abstract = {Pharmaceutical manufacturing has surged in drug development with the rise of Pharma 4.0, leveraging artificial intelligence (AI) to improve efficiency, optimize resource use, and reduce production times. Direct Tablet Compression (DTC), a key manufacturing technique, depends on the physicochemical properties of active pharmaceutical ingredients (API), excipients, and process parameters. This paper presents a novel multi-task framework combining regression, classification, and text generation to predict tablet properties (friability, hardness, disintegration time, and water absorption ratio), determine batch acceptance, and provide insights for optimizing interactions to improve tablet quality. The framework not only enables real-time monitoring, quality control and regulatory compliance, but also helps to understand the reasons why tablets in the manufacturing batch do not meet quality requirements. Using statistical methods, Neural Networks (NN), Natural Language Processing (NLP), and generative AI (GenAI), it outperforms state-of-the-art methods, achieving 91.8% R2 and 95.5% accuracy for regression and classification, respectively, as demonstrated using the Harvard Dataverse V1 dataset of Fast Disintegrating Tablets (FDTs) non placebo.}
}
@article{HADDUD20241293,
title = {ChatGPT in supply chains: exploring potential applications, benefits and challenges},
journal = {Journal of Manufacturing Technology Management},
volume = {35},
number = {7},
pages = {1293-1312},
year = {2024},
issn = {1741-038X},
doi = {https://doi.org/10.1108/JMTM-02-2024-0075},
url = {https://www.sciencedirect.com/science/article/pii/S1741038X24000324},
author = {Abubaker Haddud},
keywords = {ChatGPT, Generative Artificial Intelligence, Supply chain digitalization, Supply chain management, Benefits, Challenges},
abstract = {Purpose
While ChatGPT is gaining popularity, its potential role in supply chains (SCs) remains unexplored. This study explores the potential applications, benefits and challenges of using ChatGPT as a tool in SCs.
Design/methodology/approach
The data were gathered through an online survey involving 116 respondents from the academic and industrial sectors who have knowledge of ChatGPT and SC management. These participants were affiliated with the Decision Science Institute (DSI) in the USA and contributed to the published DSI conference proceedings from 2019 to 2022. The survey is structured in three main sections: (1) general information (5 background questions), (2) ChatGPT's potential applications and benefits in SCs (15 pre-determined questions) and (3) potential challenges with using ChatGPT in SCs (5 pre-determined questions). The collected data underwent analysis using IBM SPSS Statistics software.
Findings
ChatGPT can potentially benefit SC operations in 15 areas. Eight potential benefits received more support than the rest, including enhanced process efficiency, cost reduction, providing sustainability reports, better demand forecasting, improved data analysis, streamlined supplier communication, streamlined customer communication, supported promotional activities and enhanced customer satisfaction, but all were supported. Also, the study identified some challenges and hurdles currently impacting the use of ChatGPT in the SC, including that ChatGPT cannot replace experts, it is not an immediate game changer, its uses may lack accuracy, and ChatGPT may take time to reach maturity.
Originality/value
The study is the first to offer empirically grounded evidence of ChatGPT's potential in SCs. The research enhances academic literature by deepening our comprehension of the potential applications of ChatGPT within SCs. Therefore, the study makes an invaluable contribution to the extant literature on ChatGPT in SCs. It can benefit manufacturers, suppliers, logistics providers and other types of businesses through more efficient procurement practices, supplier management, operations and inventory management, logistics practices and customer relationships. Future research may explore how and why ChatGPT is used in SCs.}
}
@article{NEILL2024108,
title = {2024 practice analysis: a comparison of expectations vs actual performance of essential competencies in public relations},
journal = {Corporate Communications: An International Journal},
volume = {30},
number = {1},
pages = {108-123},
year = {2024},
issn = {1356-3289},
doi = {https://doi.org/10.1108/CCIJ-04-2024-0066},
url = {https://www.sciencedirect.com/science/article/pii/S1356328924000149},
author = {Marlene S. Neill and Lauren Combs and Raphael Roker and Emeri Drewry and Lia Hood and Mallory Vaughan and Aliyah Binford and McKenna Joyce},
keywords = {Accreditation, Artificial intelligence, Professional competencies, Role theory, Social comparison bias, Diffusion of innovations theory},
abstract = {Purpose
We conducted the Universal Accreditation Board (UAB) practice analysis to examine perceptions of US public relations practitioners and educators regarding the essential competencies for entry-level and mid-career professionals. This is a trend analysis survey that is conducted every five years to assess changes in required competencies.
Design/methodology/approach
The survey was distributed via email to organizations affiliated with the UAB. Two variations of the survey were available to differentiate between practitioners and educators. The study was conducted from February through March of 2024.
Findings
We found practitioners’ expectations for others exceeded their own actual performance levels. This may be attributed to social comparison bias. We have provided recommendations for updating the Accreditation in Public Relations (APR) and certificate exams based on our findings. For example, we recommend senior professionals adopt a nurturing leadership style when mentoring young professionals. The study also revealed that educators overestimated generative artificial intelligence (AI) use in the workplace, as practitioners exhibited a slower rate of adoption of AI. The literature and theories that guided the paper were AI use, the history of accreditation in public relations and the diffusion of innovation theory.
Originality/value
This research paper provides insights related to the diffusion of AI competencies in the workplace. Additionally, this research adds to public relations literature by revealing the gap in expectations of senior professionals for beginning and mid-career professionals and their own job performance.}
}
@article{GOLDEN2024,
title = {Describing the Framework for AI Tool Assessment in Mental Health and Applying It to a Generative AI Obsessive-Compulsive Disorder Platform: Tutorial},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/62963},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24005596},
author = {Ashleigh Golden and Elias Aboujaoude},
keywords = {artificial intelligence, ChatGPT, generative artificial intelligence, generative AI, large language model, chatbots, machine learning, digital health, telemedicine, psychotherapy, obsessive-compulsive disorder},
abstract = {As artificial intelligence (AI) technologies occupy a bigger role in psychiatric and psychological care and become the object of increased research attention, industry investment, and public scrutiny, tools for evaluating their clinical, ethical, and user-centricity standards have become essential. In this paper, we first review the history of rating systems used to evaluate AI mental health interventions. We then describe the recently introduced Framework for AI Tool Assessment in Mental Health (FAITA-Mental Health), whose scoring system allows users to grade AI mental health platforms on key domains, including credibility, user experience, crisis management, user agency, health equity, and transparency. Finally, we demonstrate the use of FAITA-Mental Health scale by systematically applying it to OCD Coach, a generative AI tool readily available on the ChatGPT store and designed to help manage the symptoms of obsessive-compulsive disorder. The results offer insights into the utility and limitations of FAITA-Mental Health when applied to “real-world” generative AI platforms in the mental health space, suggesting that the framework effectively identifies key strengths and gaps in AI-driven mental health tools, particularly in areas such as credibility, user experience, and acute crisis management. The results also highlight the need for stringent standards to guide AI integration into mental health care in a manner that is not only effective but also safe and protective of the users’ rights and welfare.}
}
@article{ZHENG2025111,
title = {Detection of Gastrointestinal Bleeding With Large Language Models to Aid Quality Improvement and Appropriate Reimbursement},
journal = {Gastroenterology},
volume = {168},
number = {1},
pages = {111-120.e4},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2024.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0016508524054672},
author = {Neil S. Zheng and Vipina K. Keloth and Kisung You and Daniel Kats and Darrick K. Li and Ohm Deshpande and Hamita Sachar and Hua Xu and Loren Laine and Dennis L. Shung},
keywords = {Generative Artificial Intelligence, Acute Gastrointestinal Bleeding, Large Language Models, Nature Language Processing, Quality Improvement},
abstract = {Background & Aims
Early identification and accurate characterization of overt gastrointestinal bleeding (GIB) enables opportunities to optimize patient management and ensures appropriately risk-adjusted coding for claims-based quality measures and reimbursement. Recent advancements in generative artificial intelligence, particularly large language models (LLMs), create opportunities to support accurate identification of clinical conditions. In this study, we present the first LLM-based pipeline for identification of overt GIB in the electronic health record (EHR). We demonstrate 2 clinically relevant applications: the automated detection of recurrent bleeding and appropriate reimbursement coding for patients with GIB.
Methods
Development of the LLM-based pipeline was performed on 17,712 nursing notes from 1108 patients who were hospitalized with acute GIB and underwent endoscopy in the hospital from 2014 to 2023. The pipeline was used to train an EHR-based machine learning model for detection of recurrent bleeding on 546 patients presenting to 2 hospitals and externally validated on 562 patients presenting to 4 different hospitals. The pipeline was used to develop an algorithm for appropriate reimbursement coding on 7956 patients who underwent endoscopy in the hospital from 2019 to 2023.
Results
The LLM-based pipeline accurately detected melena (positive predictive value, 0.972; sensitivity, 0.900), hematochezia (positive predictive value, 0.900; sensitivity, 0.908), and hematemesis (positive predictive value, 0.859; sensitivity, 0.932). The EHR-based machine learning model identified recurrent bleeding with area under the curve of 0.986, sensitivity of 98.4%, and specificity of 97.5%. The reimbursement coding algorithm resulted in an average per-patient reimbursement increase of $1299 to $3247 with a total difference of $697,460 to $1,743,649.
Conclusions
An LLM-based pipeline can robustly detect overt GIB in the EHR with clinically relevant applications in detection of recurrent bleeding and appropriate reimbursement coding.}
}
@article{JOO2025101571,
title = {Human-AI collaborative reading in academic contexts: An exploratory case study},
journal = {Journal of English for Academic Purposes},
volume = {78},
pages = {101571},
year = {2025},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2025.101571},
url = {https://www.sciencedirect.com/science/article/pii/S147515852500102X},
author = {Dayoung Joo and Diane Belcher},
keywords = {Second language reading, Academic literacy, English for academic purposes, Generative AI, The direct and inferential mediation (DIME) model, Sociocultural theory},
abstract = {The increasing prevalence of generative artificial intelligence (GenAI) in education presents new opportunities and challenges for second language (L2) learners' academic literacy development. While tools like ChatGPT can act as virtual experts, offering immediate feedback and engaging learners in reflective dialogues, little is known about how L2 readers interact with them in their academic practices and how their reading processes evolve. Taking a sociocognitive view, grounded in sociocultural theory and interpreted through the heuristic lens of the Direct and Inferential Mediation (DIME) model of reading comprehension, this exploratory case study examined how one international graduate student engages with GenAI to enhance academic reading. Data were collected over six weeks through screen-recordings of reading sessions, chat logs, stimulated recall interviews, and semi-structured interviews. Findings revealed that ChatGPT functioned as a translator, knowledge facilitator, and strategic partner, reducing reading anxiety while supporting comprehension across key components of the DIME model, such as vocabulary knowledge, background knowledge, inference-making, and reading strategies. Notably, the learner demonstrated a shift in reading approach, moving from an initial dependence on translation toward more strategic engagement with academic texts, including the use of summarization and inference. However, perceived AI limitations, such as questionable reliability and excessively detailed responses, occasionally caused fatigue for the learner. By providing an in-depth exploration of human-AI interaction in academic reading, the study contributes to the growing body of literature on GenAI's role in L2 education, laying the groundwork for future studies on its long-term impact on L2 reading.}
}
@article{LEE2025106317,
title = {Generative AI-driven data augmentation for enhanced construction hazard detection},
journal = {Automation in Construction},
volume = {177},
pages = {106317},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106317},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003577},
author = {YeJun Lee and GyeongNam Kang and Jinwoo Kim and Seonghwan Yoon and JungHo Jeon},
keywords = {Construction safety, Computer vision, Object detection, Generative AI, Image augmentation},
abstract = {The construction industry has long struggled with poor safety records. Traditional safety monitoring methods, reliant on manual observations, are often ineffective. To address these limitations, computer vision and generative artificial intelligence (AI) have been explored. While computer vision has shown promise in automating safety monitoring, its effectiveness is often hindered by the challenges of efficiently collecting diverse datasets. Generative AI offers a potential solution by augmenting image datasets, enabling more robust construction hazard detection. This paper investigates the use of generative AI for augmenting image data to improve hazard detection performance. Various combinations of generative AI tools and prompting strategies are tested. The results show that the combination of image-guided structured prompting with Stable Diffusion achieves the highest detection performance (mAP@50 of 92.5 %) using 150 augmented images. This represents a substantial improvement compared to the baseline mAP@50 of 51.6 % achieved with real images alone.}
}
@article{LIU2025,
title = {Generative AI for clinical reasoning: A scoping review},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002410},
author = {Ying-Mei Liu and Chang-Chuan Chou and Tang-Her Jaing and Chizimuzo T.C. Okoli},
keywords = {clinical reasoning, education, generative artificial intelligence, health, simulation},
abstract = {Objectives
To explore how generative artificial intelligence (AI) supports clinical reasoning development through simulation-based teaching in undergraduate health professions education.
Design
Scoping review.
Data Sources
CINAHL, ERIC, PubMed, ScienceDirect, and Web of Science databases.
Review Methods
A systematic search was conducted to identify studies exploring the integration of generative AI in simulation-based learning. Inclusion criteria focused on undergraduate health professions education and clinical reasoning outcomes.
Results
Six studies with a total of 492 participants met the inclusion criteria. Generative AI was used to create simulation scenarios, virtual patients, provide feedback, analyze student performance, and support inquiry-based learning. Four studies reported significantly improved clinical reasoning outcomes with AI-assisted teaching. One study reported the comparability between AI-generated feedback and expert feedback, though expert input remained superior in complex cases.
Conclusions
The integration of generative AI into simulation-based education is in its early stages. Most studies lacked theoretical frameworks and used diverse outcome measures, limiting comparability and generalizability. Future research should adopt theory-driven designs and standardized assessment tools to better evaluate the impact of generative AI on clinical reasoning development.}
}
@article{DAI202384,
title = {Reconceptualizing ChatGPT and generative AI as a student-driven innovation in higher education},
journal = {Procedia CIRP},
volume = {119},
pages = {84-90},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004407},
author = {Yun Dai and Ang Liu and Cher Ping Lim},
keywords = {ChatGPT, generative AI, higher education, learning analytics, personalized learning, engineering education},
abstract = {Higher education is poised at the precipice of the changes and challenges brought about by ChatGPT. This paper addresses some of the most fundamental questions about the role, position, and implications of ChatGPT and generative artificial intelligence (AI) tools amidst the evolving landscape of higher education and modern society. By linking technological affordances with educational needs, we conceptualize ChatGPT as a student-driven innovation with rich potential to empower students and enhance their educational experiences and resources. However, this empowerment comes at a price. It requires collaborative efforts among the stakeholders to address the new and emerging challenges regarding student training, higher education curricula and assessment, and technology development and governance. It also implies new directions for educational research and theories.}
}
@article{CHANG2026101305,
title = {Exploring the role of GenAI self-efficacy in fostering university students’ creativity: An empirical study in Inner Mongolia and Taiwan},
journal = {The International Journal of Management Education},
volume = {24},
number = {1},
pages = {101305},
year = {2026},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101305},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001752},
author = {Tsung-Sheng Chang and Hung-Yung Hsu and Zhongxing Lei},
keywords = {Generative artificial intelligence, GenAI self-efficacy, Education resources, Individual creativity, General education courses},
abstract = {This study investigates how internal and external educational resources shape college students’ generative AI (GenAI) self-efficacy and creativity across general education courses in business and technology, by comparing learners from Inner Mongolia and Taiwan. It assesses its role as a predictor of individual creativity. PLS-SEM was employed to test the proposed hypotheses and models. The findings reveal that students in both Inner Mongolia and Taiwan benefit from relatively comprehensive resource allocations in computing support, training, and equipment accessibility within their institutions. These resources significantly enhanced GenAI self-efficacy. However, computing training using external resources still needs to be developed for Inner Mongolia. Overall, the results confirmed that GenAI self-efficacy positively influenced student creativity. This study offers an empirical foundation for regional education policies. Educators should actively create a learning environment that can stimulate student creativity and use GenAI technology.}
}
@article{SCHWENDICKE2025100056,
title = {Generative AI: Opportunities, risks, and responsibilities for oral sciences},
journal = {JADA Foundational Science},
volume = {4},
pages = {100056},
year = {2025},
issn = {2772-414X},
doi = {https://doi.org/10.1016/j.jfscie.2025.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2772414X25000143},
author = {Falk Schwendicke and Sharanbir K. Sidhu and Jack L. Ferracane and Antonin Tichy and Nicholas S. Jakubovics},
keywords = {Artificial intelligence, large language models, peer review, reproducibility of results, responsible artificial intelligence, scientific misconduct},
abstract = {Generative artificial intelligence (AI) has the capability to generate new content—including text, code, imagery, video, and speech—based on human prompts and is entering dental and oral research. By retrieving, analyzing, summarizing, and contextualizing vast datasets, generative AI offers substantial potential to enhance scientific workflows. It can improve documentation, communication, and reproducibility while saving time and accelerating discovery. However, its integration into research brings significant ethical, societal, and scientific challenges. Concerns include embedded data biases, automation bias, overreliance, and error propagation, all requiring critical human oversight. Furthermore, generative AI raises complex issues around plagiarism, fraud, attribution, and reproducibility, compounded by the potential for AI “hallucinations” or fabricated content. Addressing these concerns demands transparency, robust verification processes, ethical compliance, and clear documentation distinguishing synthetic from real-world data. Several scientific and regulatory bodies have published guidelines to support responsible AI use. Recommendations relevant to scientists in dental, oral, and craniofacial research include transparent disclosure of AI tools and methods, thorough verification of AI outputs, ethical oversight, and active monitoring. Scientists are urged to work collaboratively with stakeholders to enforce these principles and engage the public in the evolving discourse. The risk of misuse, particularly through fraudulent AI-generated publications, is growing. Paper mills exploiting generative AI can produce fabricated or manipulated articles, which may mislead the scientific community and distort evidence bases. Coordinated action, involving journals, institutions, and ethics bodies, is essential to combat these threats. As generative AI continues to evolve, adaptive and harmonized guidelines wil be necessary to safeguard scientific integrity. Researchers, reviewers, and editors must play a proactive role in ensuring that AI serves to advance—not undermine—the quality and trustworthiness of dental and oral science.}
}
@article{ORRU2025102086,
title = {Large language models and psychiatry},
journal = {International Journal of Law and Psychiatry},
volume = {101},
pages = {102086},
year = {2025},
issn = {0160-2527},
doi = {https://doi.org/10.1016/j.ijlp.2025.102086},
url = {https://www.sciencedirect.com/science/article/pii/S0160252725000196},
author = {Graziella Orrù and Giulia Melis and Giuseppe Sartori},
keywords = {Large language models, Psychiatry, Reasoning, Intelligence},
abstract = {Integrating Generative Artificial Intelligence and Large Language Models (LLMs) such as GPT-4 is transforming clinical medicine and cognitive psychology. These models exhibit remarkable capabilities in understanding and generating human-like language, which can enhance various aspects of healthcare, including clinical decision-making and psychological counseling. LLMs, trained on vast datasets, function by predicting the next word in a sequence, endowing them with extensive knowledge and reasoning abilities. Their adaptability allows them to perform a wide range of language-related tasks, significantly contributing to advancements in cognitive psychology and psychiatry. These models demonstrate proficiency in tasks such as analogical reasoning, metaphor comprehension, and problem-solving, often achieving performance comparable to neurotypical humans. Despite their impressive capabilities, LLMs still exhibit limitations in causal reasoning and complex planning. However, their continuous improvement, exemplified by the enhanced performance of GPT-4 over its predecessors, suggests a trajectory towards overcoming these challenges. The ongoing debate about the “intelligence” of LLMs revolves around their ability to mimic human-like reasoning and understanding, a focal point of contemporary research. This paper explores the cognitive abilities of LLMs, comparing them with human cognitive processes and examining their performance on various psychological tests. It highlights the emergent properties of LLMs, their potential to transform cognitive psychology, and the different applications of LLMs in psychiatry, highlighting the limitations, the ethical considerations, and the importance of scaling and fine-tuning these models to enhance their capabilities. We also explore the parallels between LLMs and human error patterns, underscoring the significance of using LLMs as models for human cognition. Overall, this paper provides substantial evidence supporting the role of LLMs in reviving associationism as a viable framework for understanding human cognition while acknowledging the current limitations and the need for further research to fully realize their potential.}
}
@article{BENTZEN2025103798,
title = {Artificial Intelligence in Health Care: A Rallying Cry for Critical Clinical Research and Ethical Thinking},
journal = {Clinical Oncology},
volume = {41},
pages = {103798},
year = {2025},
issn = {0936-6555},
doi = {https://doi.org/10.1016/j.clon.2025.103798},
url = {https://www.sciencedirect.com/science/article/pii/S0936655525000536},
author = {S.M. Bentzen},
abstract = {Artificial intelligence (AI) will impact a large proportion of jobs in the short to medium term, especially in the developed countries. The consequences will be felt across many sectors including health care, a critical sector for implementation of AI tools because glitches in algorithms or biases in training datasets may lead to suboptimal treatment that may negatively affect the health of an individual. The stakes are obviously higher in case of potentially life-threatening diseases such as cancer and therapies with a potential for causing severe or even fatal adverse events. Over the last two decades, much of the research on AI in health care has focussed on diagnostic radiology and digital pathology, but a solid body of research is emerging on AI tools in the radiation oncology workflow. Many of these applications are relatively uncontroversial, although there is still a lack of evidence regarding effectiveness rather than efficiency, and—the ultimate bar—evidence of clinical utility. Proponents of AI will argue that these algorithms should be implemented with robust human supervision. One challenge here is the deskilling effect associated with new technologies. We will become increasingly dependent on the AI tools over time, and we will become less capable of assessing the quality of the AI output. Much of this research appears almost old-fashioned in view of the rapid advances in Generative artificial intelligence (GenAI). GenAI can draw from multiple types of data and produce output that is personalised and appears relevant in the given context. Especially the rapid progress in large language models (LLMs) has opened a wide field of potential applications that were out of bounds just a few years ago. One LLM, Generative Pre-trained Transformer 4 (GPT-4), has been made widely accessible to end-users as ChatGPT-4, which passed a rigorous Turing test in a recent study. In this viewpoint, I argue for the necessity of independent academic research to establish evidence-based applications of AI in medicine. Algorithmic medicine is an intervention similar to a new drug or a new medical device. We should be especially concerned about under-represented minorities and rare/atypical clinical cases that may drown in the petabyte-sized training sets. A huge educational push is needed to ensure that the end-users of AI in health care understand the strengths and weaknesses of algorithmic medicine. Finally, we need to address the ethical boundaries for where and when GenAI can replace humans in the relation between patients and healthcare providers.}
}
@article{ARSLAN20245027,
title = {Political Events using RAG with LLMs},
journal = {Procedia Computer Science},
volume = {246},
pages = {5027-5035},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.576},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026267},
author = {Muhammad Arslan and Saba Munawar and Christophe Cruz},
keywords = {Political Analysis, Natural Language Processing (NLP), Large Language Models (LLMs), Retrieval-Augmented Generation (RAG)},
abstract = {In the contemporary digital landscape, media content stands as the foundation for political news analysis, offering invaluable insights sourced from various channels like news articles, social media updates, speeches, and reports. Natural Language Processing (NLP) has revolutionized Political Information Extraction (IE), automating tasks such as Event Extraction (EE) from these diverse media outlets. While traditional NLP methods often necessitate specialized expertise to build rule-based systems or train machine learning models with domain-specific datasets, the emergence of Large Language Models (LLMs) driven by Generative Artificial Intelligence (GenAI) presents a promising alternative. These models offer accessibility, alleviating challenges associated with model construction from scratch and reducing the dependency on extensive datasets during the training phase, thus facilitating rapid implementation. However, challenges persist in handling domain-specific tasks, leading to the development of the Retrieval-Augmented Generation (RAG) framework. RAG enhances LLMs by integrating external data retrieval, enriching their contextual understanding, and expanding their knowledge base beyond pre-existing training data. To illustrate RAG’s efficacy, we introduce the Political EE system, specifically tailored to extract political event information from news articles. Understanding these political insights is essential for remaining informed about the latest political advancements, whether on a national or global scale.}
}
@article{MIMOUDI2025102140,
title = {Generative AI to bridge the educational divide: Personalized learning and challenges},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {102140},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.102140},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125008708},
author = {Aziz Mimoudi},
keywords = {Generative AI, Personalized learning, Educational equity, Digital divide, Inclusivity, AI in education, Teacher assistance},
abstract = {Generative artificial intelligence (GenAI) is rapidly transforming education by enabling adaptive tutoring, personalized feedback, and scalable resource creation. Yet its benefits are unevenly distributed: without safeguards, the same systems that promise to close learning gaps may reinforce them. This article presents a systematic review of 75 peer-reviewed studies published between 2016 and 2024, focusing specifically on GenAI through an equity lens. Four main opportunities were identified: personalized learning (60 % of studies), teacher assistance and efficiency (51 %), expanded access and inclusion (44 %), and learning analytics (33 %). Alongside these benefits, significant challenges were reported, including data privacy risks (56 %), algorithmic bias (52 %), depersonalization of learning (48 %), the digital divide (48 %), and transparency and accountability gaps (36 %). The synthesis reveals that GenAI's educational impact is shaped by three intersecting dimensions – personalization, fairness, and access – whose intersections determine whether GenAI narrows or widens learning inequalities. To achieve equitable outcomes, schools and ministries must prioritize governance measures such as privacy safeguards, bias audits, professional development, and infrastructure investment, since equity will not emerge automatically from GenAI adoption; it must be intentionally designed, implemented, and monitored across policy, practice, and pedagogy. Future research should move beyond descriptive accounts to include pragmatic trials in low-resource contexts, longitudinal equity studies, and governance frameworks that integrate technical safeguards with participatory oversight. By addressing these priorities, GenAI can shift from a tool of potential exclusion to a driver of equity and inclusion in education worldwide.}
}
@article{SUBILLAGA2025103566,
title = {Artificial Intelligence-Assisted Narratives: Analysis of Surgical Residency Personal Statements},
journal = {Journal of Surgical Education},
pages = {103566},
year = {2025},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2025.103566},
url = {https://www.sciencedirect.com/science/article/pii/S1931720425001473},
author = {Oswaldo Subillaga and Aixa Pérez Coulter and David Tashjian and Neal Seymour and Daniel Hubbs},
keywords = {artificial intelligence, general surgery residency, personal statements, graduate medical education, NRMP match, interpersonal and communication skills},
abstract = {Objective
Personal statements (PSs) express applicants’ personal characteristics and motivations informing pursuit of a surgical career. Generative artificial intelligence (AI) is a revolutionary technology. There are currently no data to suggest how and to what extent AI is used in surgical residency applications. We examined the prevalence of AI use and applicant pool characteristics in PSs submitted to a surgical residency.
Design
PSs from US MD and DO applicants to an academic general surgery program were collected for both the 2022-23 and 2023-24 NRMP Match cycles. PSs were analyzed using 2 AI-detection tools: GPTZero and Copyleaks. Data were analyzed using T-test and Fisher’s Exact Test.
Setting
UMass Chan Medical School—Baystate general surgery residency program in Springfield, Massachusetts.
Participants
There were 1332 applications during 2022-23 NRMP Match cycle and 1221 for 2023-24. After excluding international medical graduates and incomplete applications, 1490 PSs were analyzed.
Results
1490 PS were included (758 [50.9%] for 2022-23; 732 [49.1%] for 2023-24). Demographic characteristics did not differ between the 2 cycles. GPTZero identified AI use in 77 (10.2%) PSs in 2022-23 and 268 (36.6%) in 2023-24 (p < 0.001). Copyleaks identified AI use in 20 (2.6%) PSs in 2022-23 and 165 (22.5%) in 2023-24 (p < 0.001). Concordance in AI detection with both tools was observed in 13 (1.7% of total PSs) for 2022-23 and 155 (21.2%) for 2023-24 (p < 0.001). Subgroup analysis of concordance in 2023-24 showed increased non-English native language characteristics (38.7% vs 19.6%; p < 0.001), a lower average personal statement word count (597.3 vs 645.9; p < 0.001) and shorter average sentence (10.0 vs 10.4 words; p < 0.001) in the AI group.
Conclusions
Although AI-detection tools are imperfect, demonstration of increased AI use in personal statement preparation is compelling. Implications of AI use in residency applications are unknown, and programs must develop policies anticipating ongoing and potentially increased use of AI in the upcoming application cycles.}
}
@article{CROSTHWAITE2023100066,
title = {Generative AI and the end of corpus-assisted data-driven learning? Not so fast!},
journal = {Applied Corpus Linguistics},
volume = {3},
number = {3},
pages = {100066},
year = {2023},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2666799123000266},
author = {Peter Crosthwaite and Vit Baisa},
keywords = {Data-driven learning, generative AI, ChatGPT, DDL, Corpora},
abstract = {This article explores the potential advantages of corpora over generative artificial intelligence (GenAI) in understanding language patterns and usage, while also acknowledging the potential of GenAI to address some of the main shortcomings of corpus-based data-driven learning (DDL). One of the main advantages of corpora is that we know exactly the domain of texts from which the corpus data is derived, something that we cannot track from current large language models underlying applications like ChatGPT. We know the texts that make up large general corpora such as BNC2014 and BAWE, and can even extract full texts from these corpora if needed. Corpora also allow for more nuanced analysis of language patterns, including the statistics behind multi-word units and collocations, which can be difficult for GenAI to handle. However, it is important to note that GenAI has its own strengths in advancing our understanding of language-in-use that corpora, to date, have struggled with. We therefore argue that by combining corpus and GenAI approaches, language learners can gain a more comprehensive understanding of how language works in different contexts than is currently possible using only a single approach.}
}
@incollection{KHALEEL20262,
title = {Future Proofing the Integrity of Assessments Within Business Management Studies for the Age of Artificial Intelligence},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {2-8},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00330-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013003303},
author = {Fawad Khaleel and Patrick Harte and Alija Avdukic},
keywords = {Academic dishonesty, Academic integrity, Artificial intelligence, Assessment design, Complexity of assessment design, Coursework, Plagiarism, Word count},
abstract = {The content generative artificial intelligence is developing rapidly, and it is challenging the old norms of assessment design within the HEIs. This chapter discusses the impact of AI on the academic integrity, as we argue that with a slight shift within the assessment design, we can address the academic integrity concerns that surfacing within the higher education. This chapter provides practical and useable guidelines that could be used to reduce the breaches of academic integrity within business management programmes at HEIs. These guidelines focus on word count for coursework, complexity of assessment question and social dynamics of assessment design.}
}
@article{DWI2025100136,
title = {Ethical and psychological implications of generative AI in digital afterlife technologies: A systematic literature review on responsible inclusive innovation},
journal = {Journal of Responsible Technology},
volume = {24},
pages = {100136},
year = {2025},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2025.100136},
url = {https://www.sciencedirect.com/science/article/pii/S2666659625000320},
author = {Mariyono Dwi},
keywords = {Generative AI, Digital afterlife, DeathTech, Cultural schemas, Inclusive design, Ethical governance, Grief management, Ritual adaptation},
abstract = {Rapid advances in generative artificial intelligence (GenAI) have given birth to digital afterlife technologies (DeathTech), which enable the preservation of the voices, memories, and personalities of deceased individuals. This study is a systematic review of 45 scientific articles (2020–2025) using a thematic-SWOT analysis approach and the Responsible Inclusive Innovation (RII) framework, to explore how cultural schemas, inclusive design, and governance models influence the acceptance of DeathTech across cultures. Key findings suggest that ritual adaptation and spiritual meanings are critical to the acceptance of this technology. Jewish and Japanese communities show high acceptance through cultural integration, while Hindu and Luhya communities experience ontological dissonance. Design failures such as linguistic exclusion and ritual incongruence impact marginalized groups. In addition, regulatory gaps exist, especially in post-death privacy protection and algorithmic bias. This study proposes a triadic framework for the development of ethical and equitable DeathTech: cultural mediation, inclusive design, and pluralistic governance. This contribution enriches the study of digital thanatology and provides recommendations for culturally and socially sustainable innovation.}
}
@article{ERFANI2026103909,
title = {Applications of multimodal large language models in construction industry},
journal = {Advanced Engineering Informatics},
volume = {69},
pages = {103909},
year = {2026},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103909},
url = {https://www.sciencedirect.com/science/article/pii/S147403462500802X},
author = {Abdolmajid Erfani and Ali Mansouri},
keywords = {Multimodal Language Models, Construction Automation, Generative AI},
abstract = {The advancement of transformer-based models, including multimodal large language models (MLLMs), has led to growing interest in their application across diverse industries, including construction. While a few earlier reviews have explored generative artificial intelligence in the construction sector, they are limited in scope— limited coverage of multimodal models, covering a shorter timeline prior to the expansion of MLLMs research, and offering limited emphasis on practical use cases, adaptation strategies, and integration into construction workflows. This study addresses that gap by reviewing 83 peer-reviewed studies published between January 2020 and February 2025, identified using a structured search process guided by the PRISMA framework and focused on academic literature. By synthesizing these studies, this review highlights trends across application domains, model types, adaptation strategies, technical limitations, and performance evaluation practices—offering a comparative analysis across use cases. It concludes with recommendations for future research, underscoring the need for standardized evaluation frameworks, critical limitations related to technical aspects, ethical risks, and regulatory uncertainty, underscoring the need for responsible development and deployment of MLLMs in construction settings.}
}
@article{ANDRIEUX2024101032,
title = {Ethical considerations of generative AI-enabled human resource management},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101032},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101032},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000056},
author = {Pierre Andrieux and Richard D. Johnson and Jalal Sarabadani and Craig {Van Slyke}},
keywords = {Generative artificial intelligence (GAI), Human resource management (HRM), Affordance, Ethics, Decision-making},
abstract = {This paper examines critical ethical considerations linked to making human resources management (HRM) decisions based on the potential capabilities (affordances) offered by generative artificial intelligence (GAI). We first provide a broad overview of the status quo surrounding the use of GAI in the HRM context. Then, we introduce the concept of “affordance” and explain how it provides a useful perspective for human resource (HR) managers to use when evaluating potential benefits and/or harm resulting from the implementation of a potential GAI-based capability to support HRM processes decisions. We discuss concrete examples of how GAI HRM affordances could be implemented in different HRM functions and the ethical questions that arise from their use. Finally, we present an ethics-based framework, the Two-Rule Method, along with ethics-specific recommendations to guide HR managers through the complex issues that arise because of the use of GAI-enabled HR tools.}
}
@article{CUMMINGS2024102827,
title = {Generative AI in first-year writing: An early analysis of affordances, limitations, and a framework for the future},
journal = {Computers and Composition},
volume = {71},
pages = {102827},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102827},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000033},
author = {Robert E. Cummings and Stephen M. Monroe and Marc Watkins},
keywords = {Generative artificial intelligence, First-year composition, ChatGPT, Elicit, Fermat, Wordtune, DEER Praxis},
abstract = {Our First-year Writing program began intentional student engagements with generative AI in the fall of 2022. We developed assignments for brainstorming research questions, writing counterarguments, and editing assistance using the AI tools Elicit, Fermat, and Wordtune. Students felt that the tools were helpful for finding ideas to get started with writing, to find sources once they had started writing, and to get help with counterarguments and alternate word choices. But when given the choice to use the assistants or not, most declined. Generative AI at this stage is unreliable, and many students found the tradeoff in reviewing AI suggestions to be too time consuming. And many students expressed a preference for continuing to develop their own voices through writing. Our experience in engaging AI led to the creation of the DEER praxis, which emphasizes defined engagements with AI tools for specific purposes, and generous use of reflection.}
}
@article{DUBEY2024103689,
title = {Benchmarking operations and supply chain management practices using Generative AI: Towards a theoretical framework},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103689},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103689},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002801},
author = {Rameshwar Dubey and Angappa Gunasekaran and Thanos Papadopoulos},
keywords = {Generative Artificial Intelligence (Gen AI), Artificial Intelligence Supply Chain Management, Benchmarking, Organisational Theories},
abstract = {Generative Artificial Intelligence (Gen AI) is an up-and-coming technological innovation that has the potential to revolutionise businesses and create significant value. Despite garnering excitement from some quarters, there are still people who are sceptical about its benefits and even fearful of its impact, particularly in the supply chain context, where it is not yet fully understood. To help academics and practitioners better understand the practical implications of Gen AI in benchmarking supply chain management practices, we propose a theoretical toolbox. This toolbox draws from ten popular organisational theories and provides a comprehensive framework for evaluating the usefulness of Gen AI. By expanding theoretical boundaries, the toolbox provides a deeper understanding of the practical applications of Gen AI for researchers and practitioners in supply chain management.}
}
@article{ALIER2025103940,
title = {LAMB: An open-source software framework to create artificial intelligence assistants deployed and integrated into learning management systems},
journal = {Computer Standards & Interfaces},
volume = {92},
pages = {103940},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001090},
author = {Marc Alier and Juanan Pereira and Francisco José García-Peñalvo and Maria Jose Casañ and Jose Cabré},
keywords = {Generative artificial intelligence, Education domain, Learning assistant, Retrieval-Augmented Generation (RAG), Large language model (LLM), IMS learning tools interoperability (LTI)},
abstract = {This paper presents LAMB (Learning Assistant Manager and Builder), an innovative open-source software framework designed to create AI-powered Learning Assistants tailored for integration into learning management systems. LAMB addresses critical gaps in existing educational AI solutions by providing a framework specifically designed for the unique requirements of the education sector. It introduces novel features, including a modular architecture for seamless integration of AI assistants into existing LMS platforms and an intuitive interface for educators to create custom AI assistants without coding skills. Unlike existing AI tools in education, LAMB provides a comprehensive framework that addresses privacy concerns, ensures alignment with institutional policies, and promotes using authoritative sources. LAMB leverages the capabilities of large language models and associated generative artificial intelligence technologies to create generative intelligent learning assistants that enhance educational experiences by providing personalized learning support based on clear directions and authoritative fonts of information. Key features of LAMB include its modular architecture, which supports prompt engineering, retrieval-augmented generation, and the creation of extensive knowledge bases from diverse educational content, including video sources. The development and deployment of LAMB were iteratively refined using a minimum viable product approach, exemplified by the learning assistant: “Macroeconomics Study Coach,” which effectively integrated lecture transcriptions and other course materials to support student inquiries. Initial validations in various educational settings demonstrate the potential that learning assistants created with LAMB have to enhance teaching methodologies, increase student engagement, and provide personalized learning experiences. The system's usability, scalability, security, and interoperability with existing LMS platforms make it a robust solution for integrating artificial intelligence into educational environments. LAMB's open-source nature encourages collaboration and innovation among educators, researchers, and developers, fostering a community dedicated to advancing the role of artificial intelligence in education. This paper outlines the system architecture, implementation details, use cases, and the significant benefits and challenges encountered, offering valuable insights for future developments in artificial intelligence assistants for any sector.}
}
@article{SUFFOLETTO2024,
title = {Deceptively Simple yet Profoundly Impactful: Text Messaging Interventions to Support Health},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58726},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005235},
author = {Brian Suffoletto},
keywords = {SMS intervention, behavior, intervention, review, text messaging, SMS, interventions, behaviors, behaviour, behaviours, effectiveness, development, impact, narrative review, physical activity, diet, weight loss, mental health, substance use, meta-analysis, chatbot, chatbots, large language model, LLM, large language models, mobile phone},
abstract = {This paper examines the use of text message (SMS) interventions for health-related behavioral support. It first outlines the historical progress in SMS intervention research publications and the variety of funds from US government agencies. A narrative review follows, highlighting the effectiveness of SMS interventions in key health areas, such as physical activity, diet and weight loss, mental health, and substance use, based on published meta-analyses. It then outlines advantages of text messaging compared to other digital modalities, including the real-time capability to collect information and deliver microdoses of intervention support. Crucial design elements are proposed to optimize effectiveness and longitudinal engagement across communication strategies, psychological foundations, and behavior change tactics. We then discuss advanced functionalities, such as the potential for generative artificial intelligence to improve user interaction. Finally, major challenges to implementation are highlighted, including the absence of a dedicated commercial platform, privacy and security concerns with SMS technology, difficulties integrating SMS interventions with medical informatics systems, and concerns about user engagement. Proposed solutions aim to facilitate the broader application and effectiveness of SMS interventions. Our hope is that these insights can assist researchers and practitioners in using SMS interventions to improve health outcomes and reducing disparities.}
}
@article{FURTADO2024100086,
title = {A task-oriented framework for generative AI in design},
journal = {Journal of Creativity},
volume = {34},
number = {2},
pages = {100086},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000128},
author = {Lara Sucupira Furtado and Jorge Barbosa Soares and Vasco Furtado},
keywords = {Generative artificial intelligence, Product, Creative computing, Transformational Creativity},
abstract = {The intersection of Artificial Intelligence and Design disciplines such as Architecture, Urban Planning, Engineering and Product Design has been a longstanding pursuit, with Generative AI (GAI) ushering in a new era of possibilities. The research presented here explores how GAI can enhance creativity and assist Design practitioners with tasks to create products such as, but not limited to, renderings, concepts, construction techniques, materials, data analytics or maps. We apply a framework of combinational, exploratory and transformational creativity to organize how recent advancements in GAI can support each creative category. We propose a conceptual framework of GAI towards transformational creativity, and identify real-world examples to demonstrate GAI's impact, such as transforming sketches into detailed renders, facilitating real-time 3D model generation, predicting trends through analytics and creating images or reports via text prompts. Our work envisions a future where GAI becomes a real-time collaborator to complete certain automated tasks while liberating Designers to focus on transformational innovation.}
}
@article{ZHANG2025124442,
title = {Diffusion-based inpainting approach for multifunctional short-term load forecasting},
journal = {Applied Energy},
volume = {377},
pages = {124442},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.124442},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924018257},
author = {Luliang Zhang and Zongxi Jiang and Tianyao Ji and Ziming Chen},
keywords = {Short-term load forecasting, Diffusion model, Imputation, Multifunctional forecasting},
abstract = {Abstact
Short-Term Load Forecasting is of great significance for the economic and stable operation of the power system. Against the background of the breakthrough in generative artificial intelligence based on the Diffusion model, the research on relevant load forecasting methods of the latter is still relatively limited. Therefore, this paper refers to many related excellent works, analyzes the commonalities between image generation tasks and load forecasting tasks, and proposes the Diffusion-based Inpainting Forecasting Method (DIFM). DIFM supports multi-variable inputs and can achieve functions such as load sequence generation, quantile forecasting and missing data imputation, making it a flexible and multifunctional method. The feasibility and performance of this method are validated across multiple datasets, with experimental results revealing that DIFM reduces the mean absolute percentage error by 24.61 % and 17.91 % respectively in short-term load forecasting and load imputation tasks compared to the optimal benchmark models.}
}
@article{HARRISON2024,
title = {Behavioral Nudging With Generative AI for Content Development in SMS Health Care Interventions: Case Study},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/52974},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000589},
author = {Rachel M Harrison and Ekaterina Lapteva and Anton Bibin},
keywords = {generative artificial intelligence, generative AI, prompt engineering, large language models, GPT, content design, brief message interventions, mHealth, behavior change techniques, medication adherence, type 2 diabetes},
abstract = {Background
Brief message interventions have demonstrated immense promise in health care, yet the development of these messages has suffered from a dearth of transparency and a scarcity of publicly accessible data sets. Moreover, the researcher-driven content creation process has raised resource allocation issues, necessitating a more efficient and transparent approach to content development.
Objective
This research sets out to address the challenges of content development for SMS interventions by showcasing the use of generative artificial intelligence (AI) as a tool for content creation, transparently explaining the prompt design and content generation process, and providing the largest publicly available data set of brief messages and source code for future replication of our process.
Methods
Leveraging the pretrained large language model GPT-3.5 (OpenAI), we generate a collection of messages in the context of medication adherence for individuals with type 2 diabetes using evidence-derived behavior change techniques identified in a prior systematic review. We create an attributed prompt designed to adhere to content (readability and tone) and SMS (character count and encoder type) standards while encouraging message variability to reflect differences in behavior change techniques.
Results
We deliver the most extensive repository of brief messages for a singular health care intervention and the first library of messages crafted with generative AI. In total, our method yields a data set comprising 1150 messages, with 89.91% (n=1034) meeting character length requirements and 80.7% (n=928) meeting readability requirements. Furthermore, our analysis reveals that all messages exhibit diversity comparable to an existing publicly available data set created under the same theoretical framework for a similar setting.
Conclusions
This research provides a novel approach to content creation for health care interventions using state-of-the-art generative AI tools. Future research is needed to assess the generated content for ethical, safety, and research standards, as well as to determine whether the intervention is successful in improving the target behaviors.}
}
@article{HABER2025100196,
title = {CanvasHero: The role of artificial intelligence in cultivating resilience among children and youth using the 6-part story method in mass war trauma},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100196},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000805},
author = {Yuval Haber and Inbar Levkovich and Iftach Tzafrir and Karny Gigi and Dror Yinon and Dorit Hadar Shoval and Zohar Elyoseph},
keywords = {Resilience, Mass trauma, Displaced population, Children and youth, AI tools, Imagination},
abstract = {Background
The potential of Generative Artificial Intelligence (GenAI) to promote mental health is of great interest. Specifically, there is growing interest in integrating applied GenAI into psychotherapy or into the teacher/parent-child relationship. This paper describes CanvasHero, a GenAI tool that was developed following the devastating attacks on Israel in October 2023. It aims to promote resilience in children and adolescents who were evacuated from their homes due to the war. CanvasHero serves as a proof of concept for integrating GenAI as an additional element that can enrich and deepen interpersonal interaction.
Tool description
CanvasHero utilizes the BASIC Ph model and 6-Part Story Method for assessing and bolstering coping skills, aided by the interactive scaffolding and synthetic abilities of the GenAI. Key stages comprise (1) collaborative narrative construction between child, meaningful adult, and the GAI; (2) analysis of resilience themes; and (3) generative visualization representing the child's story through DALL-E's imaging capabilities.
Implementation protocol
The CanvasHero is optimally designed for children ages 7–16 under adult supervision, with the HEART Checklist developed to structure this process. Sessions typically occur remotely via videoconference, or in person.
Intended outcomes
CanvasHero aims to create a playful space for processing stress and trauma, identifies resilience resources, and strengthens these capabilities. At the same time, risks in GenAI integration are mitigated via human oversight and an ethics-focused design.
Conclusion
CanvasHero exemplifies a GenAI application that can assist during wartime, serving as a psycho-educational mediator and facilitating an imaginative and playful space between children and meaningful adults. Further studies are required to evaluate effectiveness and potential risks.}
}
@article{SAETRA2023102372,
title = {Generative AI: Here to stay, but for good?},
journal = {Technology in Society},
volume = {75},
pages = {102372},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102372},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2300177X},
author = {Henrik Skaug Sætra},
keywords = {Generative AI, Large language models, Generative adversarial networks, Harms, Power, Inequality},
abstract = {Generative AI has taken the world by storm, kicked off for real by ChatGPT and quickly followed by further development and the release of GPT-4 and similar models from OpenAI's competitors. The street has most certainly found its use for generative artificial intelligence (AI), and there is no longer much point in discussing whether generative AI will be influential. It will, and what remains to be discussed it how influential it will be, and what potential harms arise when we use AI to generate text and other forms of content. Technological change entails societal change, and we must always endeavor to ask how new technologies shapes, engenders, or potentially erodes the “good society”. In this sense, Generative AI is another instance of politically and culturally disruptive autonomous technology, and in this short commentary I highlight some of the key questions to be asked regarding consequences on the micro, meso, and macro level.}
}
@article{KUO2026108677,
title = {Improvement of an eye disease detection model by using the denoising diffusion implicit model},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108677},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108677},
url = {https://www.sciencedirect.com/science/article/pii/S147692712500338X},
author = {Ping-Huan Kuo and Eirene Du and Chiou-Jye Huang and Wei-Chuan Lan and Shu-Hung Chou and Ting-Chun Yao and Chao-Chung Peng},
keywords = {Eye disease detection, Generative artificial intelligence, Image classification, Denoising diffusion implicit model, Quasi-Monte Carlo sampling},
abstract = {With rapid developments in artificial intelligence (AI), the discussion about and applications of generative AI have increased substantially. Generative AI has extensive and valuable applications in many industrial and medical fields and is a possible solution for industries that struggle to collect large quantities of data. The present study evaluated the use of generative AI in eye disease prediction. Because retinal images are difficult to acquire, this study used a generative AI model [i.e., the denoising diffusion implicit model (DDIM)] to conduct data augmentation, thereby improving the accuracy of a convolutional neural network (CNN) model developed for eye disease detection. This study adopted the DDIM primarily for its high inference speed and ability to consistently generate high-quality samples in a limited number of steps, making it suitable for tasks that require high-quality medical images. With the increasing prevalence of electronic products, the number of patients with retinopathy or optic neuropathy is increasing annually, and patients are experiencing these diseases at increasingly younger ages. Moreover, eye diseases such as glaucoma and macular degeneration are becoming increasingly common in modern society. The developed CNN model exhibited a 3 % higher accuracy when it was trained using the data generated by the DDIM than when it was trained without these data. This CNN model can screen eye disease symptoms early to enable patients to receive timely treatment, thereby mitigating the risk and consequences of eye diseases. The results of this study indicate that the training data generated using the DDIM can enhance the accuracy of early eye disease detection.}
}
@article{DEMUTH2025,
title = {Privacy-by-Design Approach to Generate Two Virtual Clinical Trials for Multiple Sclerosis and Release Them as Open Datasets: Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/71297},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125013238},
author = {Stanislas Demuth and Olivia Rousseau and Igor Faddeenkov and Julien Paris and Jérôme {De Sèze} and Béatrice Baciotti and Marianne Payet and Morgan Guillaudeux and Alban-Félix Barreteau and David Laplaud and Gilles Edan and Pierre-Antoine Gourraud},
keywords = {synthetic data, privacy, multiple sclerosis, anonymization, randomized clinical trial},
abstract = {Background
Sharing information derived from individual patient data is restricted by regulatory frameworks due to privacy concerns. Generative artificial intelligence can generate shareable virtual patient populations as proxies for sensitive reference datasets. Explicit demonstration of privacy is demanded.
Objective
This study evaluated whether a privacy-by-design technique called “avatars” can generate synthetic datasets replicating all reported information from randomized clinical trials (RCTs).
Methods
We generated 2160 synthetic datasets from two phase 3 RCTs for patients with multiple sclerosis (NCT00213135 and NCT00906399; n=865 and 1516 patients) with different configurations to select one synthetic dataset with optimal privacy and utility for each. Several privacy metrics were computed, including protection against distance-based membership inference attacks. We assessed fidelity by comparing variable distributions and assessed utility by checking that all end points reported in the publications had the same effect directions, were within the reported 95% CIs, and had the same statistical significance.
Results
Protection against membership inference attacks was the hardest privacy metric to optimize, but the technique yielded robust privacy and replication of the primary end points (in 72.5% and 80.8% of the 1080 generated datasets). Utility was uneven across the variables and end points, such that information about some end points could not be captured. With optimized generation configurations, we selected one dataset from each RCT replicating all efficacy end points of the placebo and approved treatment arms while maintaining satisfactory privacy (hidden rate: 85.0% and 93.2%).
Conclusions
Generating synthetic RCT datasets replicating primary and secondary efficacy end points is possible while achieving a satisfactory and explicit level of privacy. To show the potential of this method to unlock health data sharing, we released both placebo arms as open datasets.}
}
@article{ZHANG2025103746,
title = {Becoming a teacher in the era of AI: A multiple-case study of pre-service teachers’ investment in AI-facilitated learning-to-teach practices},
journal = {System},
volume = {133},
pages = {103746},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103746},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25001563},
author = {Yue Zhang and Chun Lai and Michelle Ming Yue Gu},
keywords = {Generative AI, Pre-service teacher, AI literacies, Identity, Teacher candidate, Teacher identity, ChatGPT},
abstract = {Language learning and teaching research explores the affordances and constraints of generative artificial intelligence (GenAI) tools and learners' and teachers' AI literacy. However, little attention has been directed to teachers' use of such tools and their implications for the development of GenAI literacies as diverse, historically, and culturally variable practices involving AI tools, especially pre-service teachers (PSTs) in the second language (L2) context. Based on an exploratory multiple-case study of five undergraduate PSTs in Hong Kong, this paper adopts the model of L2 investment (Darvin & Norton, 2015) to address this need by posing three question: 1. What are the GenAI literacies that PSTs invest in as they learn to teach? 2. What are the perceived affordances and constraints of GenAI tools in their learning-to-teach practices? 3. To what extent do their identity and access to resources shape these literacies? Data was collected from a survey, interviews, and observations of participants' GenAI use, and triangulated using content analysis. Findings reveal how PSTs invest in their English and pedagogy learner, bilingual writer, and teacher identities that intertwine with their identities as users of various GenAI tools in GenAI-empowered spaces as ideological sites that shaped PSTs' dispositions and positioning. Recognizing how PSTs deploy multiple resources to invest in contrasting GenAI literacies, this study underscores the need for the language classroom to integrate GenAI literacies instruction that enables a critical awareness of how GenAI tools operate.}
}
@article{LIN2024103529,
title = {The grass is not always greener: Teacher vs. GPT-assisted written corrective feedback},
journal = {System},
volume = {127},
pages = {103529},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103529},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24003117},
author = {Shiming Lin and Peter Crosthwaite},
keywords = {Written corrective feedback, ChatGPT, Generative AI, Automated written corrective feedback, Second language writing},
abstract = {Written Corrective Feedback (WCF) is a crucial pedagogical practice where teachers annotate student writing to correct errors and improve language skills, albeit one that is time-consuming and laborious for large classes or under time constraints. However, the advent of advanced generative artificial intelligence and large language models, specifically ChatGPT, has introduced new possibilities for automating such educational tasks. GPT models with their transformer architecture and self-attention mechanism can perform complex natural language tasks including assisting teachers in providing WCF. This study compares the WCF produced by teachers and ChatGPT, examining their respective capabilities while identifying differences in their feedback practice. Findings reveal teacher provided WCF typically involves a consistent combination of direct correction and indirect feedback forms addressing both local and global issues, albeit with a degree of inaccuracy. ChatGPT-assisted WCF tends to be in the form of metalinguistic feedback and/or reformulation of the original text. However, GPT also frequently varies in its entire approach to WCF provision even when using the same prompt on the same text, while also providing grammatically accurate yet redundant WCF in certain cases. We discuss the implications of these findings for L2 writing practice.}
}