@article{BURKE2024,
title = {Assessing the Ability of a Large Language Model to Score Free-Text Medical Student Clinical Notes: Quantitative Study},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/56342},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000886},
author = {Harry B Burke and Albert Hoang and Joseph O Lopreiato and Heidi King and Paul Hemmer and Michael Montgomery and Viktoria Gagarin},
keywords = {medical education, generative artificial intelligence, natural language processing, ChatGPT, generative pretrained transformer, standardized patients, clinical notes, free-text notes, history and physical examination, large language model, LLM, medical student, medical students, clinical information, artificial intelligence, AI, patients, patient, medicine},
abstract = {Background
Teaching medical students the skills required to acquire, interpret, apply, and communicate clinical information is an integral part of medical education. A crucial aspect of this process involves providing students with feedback regarding the quality of their free-text clinical notes.
Objective
The goal of this study was to assess the ability of ChatGPT 3.5, a large language model, to score medical students’ free-text history and physical notes.
Methods
This is a single-institution, retrospective study. Standardized patients learned a prespecified clinical case and, acting as the patient, interacted with medical students. Each student wrote a free-text history and physical note of their interaction. The students’ notes were scored independently by the standardized patients and ChatGPT using a prespecified scoring rubric that consisted of 85 case elements. The measure of accuracy was percent correct.
Results
The study population consisted of 168 first-year medical students. There was a total of 14,280 scores. The ChatGPT incorrect scoring rate was 1.0%, and the standardized patient incorrect scoring rate was 7.2%. The ChatGPT error rate was 86%, lower than the standardized patient error rate. The ChatGPT mean incorrect scoring rate of 12 (SD 11) was significantly lower than the standardized patient mean incorrect scoring rate of 85 (SD 74; P=.002).
Conclusions
ChatGPT demonstrated a significantly lower error rate compared to standardized patients. This is the first study to assess the ability of a generative pretrained transformer (GPT) program to score medical students’ standardized patient-based free-text clinical notes. It is expected that, in the near future, large language models will provide real-time feedback to practicing physicians regarding their free-text notes. GPT artificial intelligence programs represent an important advance in medical education and medical practice.}
}
@article{HOLMES2025,
title = {Applications of Large Language Models in the Field of Suicide Prevention: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/63126},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125001098},
author = {Glenn Holmes and Biya Tang and Sunil Gupta and Svetha Venkatesh and Helen Christensen and Alexis Whitton},
keywords = {suicide, suicide prevention, large language model, self-harm, artificial intelligence, AI, PRISMA},
abstract = {Background
Prevention of suicide is a global health priority. Approximately 800,000 individuals die by suicide yearly, and for every suicide death, there are another 20 estimated suicide attempts. Large language models (LLMs) hold the potential to enhance scalable, accessible, and affordable digital services for suicide prevention and self-harm interventions. However, their use also raises clinical and ethical questions that require careful consideration.
Objective
This scoping review aims to identify emergent trends in LLM applications in the field of suicide prevention and self-harm research. In addition, it summarizes key clinical and ethical considerations relevant to this nascent area of research.
Methods
Searches were conducted in 4 databases (PsycINFO, Embase, PubMed, and IEEE Xplore) in February 2024. Eligible studies described the application of LLMs for suicide or self-harm prevention, detection, or management. English-language peer-reviewed articles and conference proceedings were included, without date restrictions. Narrative synthesis was used to synthesize study characteristics, objectives, models, data sources, proposed clinical applications, and ethical considerations. This review adhered to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) standards.
Results
Of the 533 studies identified, 36 (6.8%) met the inclusion criteria. An additional 7 studies were identified through citation chaining, resulting in 43 studies for review. The studies showed a bifurcation of publication fields, with varying publication norms between computer science and mental health. While most of the studies (33/43, 77%) focused on identifying suicide risk, newer applications leveraging generative functions (eg, support, education, and training) are emerging. Social media was the most common source of LLM training data. Bidirectional Encoder Representations from Transformers (BERT) was the predominant model used, although generative pretrained transformers (GPTs) featured prominently in generative applications. Clinical LLM applications were reported in 60% (26/43) of the studies, often for suicide risk detection or as clinical assistance tools. Ethical considerations were reported in 33% (14/43) of the studies, with privacy, confidentiality, and consent strongly represented.
Conclusions
This evolving research area, bridging computer science and mental health, demands a multidisciplinary approach. While open access models and datasets will likely shape the field of suicide prevention, documenting their limitations and potential biases is crucial. High-quality training data are essential for refining these models and mitigating unwanted biases. Policies that address ethical concerns—particularly those related to privacy and security when using social media data—are imperative. Limitations include high variability across disciplines in how LLMs and study methodology are reported. The emergence of generative artificial intelligence signals a shift in approach, particularly in applications related to care, support, and education, such as improved crisis care and gatekeeper training methods, clinician copilot models, and improved educational practices. Ongoing human oversight—through human-in-the-loop testing or expert external validation—is essential for responsible development and use.
Trial Registration
OSF Registries osf.io/nckq7; https://osf.io/nckq7}
}
@article{MEDINAMURILLO2025309,
title = {Masson’s pseudoangiosarcoma located in the perianal region: A rare entity},
journal = {Revista de Gastroenterología de México (English Edition)},
volume = {90},
number = {2},
pages = {309-310},
year = {2025},
issn = {2255-534X},
doi = {https://doi.org/10.1016/j.rgmxen.2024.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2255534X25000726},
author = {G.R. Medina-Murillo and U. Rodríguez-Medina and U. Rodríguez-Wong}
}
@article{LIU2026124387,
title = {How does artificial intelligence adoption shape employee performance? A novel exploration of mimetic artificial intelligence performance through a hybrid approach based on PLS-SEM and ANN},
journal = {Technological Forecasting and Social Change},
volume = {222},
pages = {124387},
year = {2026},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124387},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525004184},
author = {Shengmin Liu and Yu Mei},
keywords = {Artificial intelligence adoption at work, Employee problem-solving efficacy, Employee learning from artificial intelligence, Adaptive performance, Mimetic artificial intelligence performance, ANN},
abstract = {Within the context of Industry 5.0 and digital transformation, the rapid advancement of information technology has rendered artificial intelligence ubiquitous, presenting significant challenges and opportunities for the workforce. This study employs a hybrid Partial Least Squares Structural Equation Modeling (PLS-SEM) and Artificial Neural Network (ANN) approach to investigate employee performance within artificial intelligence-adoption work environments. Utilizing a three-wave experience sampling methodology, we collected 308 valid questionnaires from employees in Chinese internet companies. Our findings demonstrate that artificial intelligence adoption at work positively associated with employees' problem-solving efficacy, which in turn influences adaptive performance. Furthermore, stronger artificial intelligence adoption at work is associated with an increased employees' mimetic artificial intelligence performance through employee learning from artificial intelligence. Task-oriented leadership amplifies the effects of artificial intelligence adoption at work on both problem-solving efficacy and adaptive performance. Conversely, knowledge-oriented leadership strengthens the relationship between artificial intelligence adoption at work and employee learning from artificial intelligence, thereby developping mimetic artificial intelligence performance. This research contributes by introducing and measuring the novel concept of “mimetic artificial intelligence performance,” extending the application of social comparison, learning and influence theories. The study offers valuable theoretical insights and practical implications for understanding and optimizing employee performance in artificial intelligence-driven workplaces.}
}
@article{2025vii,
title = {Contents},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {vii-ix},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/S0733-8635(25)00057-9},
url = {https://www.sciencedirect.com/science/article/pii/S0733863525000579}
}
@article{BOUVAREL2025203024,
title = {CO11.1 - Causal inference by generation of synthetic data from electronic health records as an alternative to inverse probability of treatment weighting: a simulation study},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
pages = {203024},
year = {2025},
note = {EPICLIN 2025, 19ème Conférence francophone d’Épidémiologie Clinique et 32èmes Journées des Statisticiens des Centres de Lutte Contre le Cancer, Bordeaux, France, 14-16 mai 2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.203024},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325002186},
author = {B. Bouvarel and N. Lapidus},
keywords = {Causality, Observational Studies, Generative Artificial Intelligence, Computer Simulation, Electronic Health Records},
abstract = {Background and objective(s)
Causal inference from observational studies is increasingly considered to evaluate treatment effects when randomized clinical trials (RCTs) are impractical, as it addresses confounding biases inherent in non-randomized data. Methods such as inverse probability of treatment weighting (IPTW) are widely employed to mitigate these biases. However, IPTW often faces challenges, including issues with extreme weights, sensitivity to unmeasured confounding, and large sample size requirements. Recent advances in neural networks have demonstrated the potential to generate realistic synthetic data that replicate the statistical properties of real-world data. These advances may enhance traditional causal inference methods by creating counterfactual populations. However, the use of synthetic data in causal inference remains largely unexplored. This study aimed to evaluate the adequacy of synthetic data generation for creating counterfactual populations and to compare its performance with IPTW. This approach was applied to evaluate the effect of early prone position on 28-day mortality in mechanically ventilated COVID-19 patients.
Material and Methods
We conducted a simulation study with 2,000 observations, considering a treatment and a binary outcome influenced by confounding factors. Three methods were used to generate datasets of 50,000 synthetic observations: Conditional Tabular Generative Adversarial Network (CTGAN), Realistic Relational and Tabular Data using Transformers (REaLTabFormer), and simpler regression models. Observations with similar propensity scores were sampled from the synthetic dataset to create counterfactual populations, with sample sizes corresponding to inverse probability of treatment weights. The treatment effect was estimated using univariable logistic regression and compared to the true simulated effect. These methods were applied to electronic health records (EHRs) from the “Assistance publique–Hôpitaux de Paris” data warehouse, focusing on COVID-19 patients under mechanical ventilation within 48 hours of admission.
Results
Both REaLTabFormer and regression methods achieved performance broadly similar to that obtained using only the original data with IPTW. CTGAN exhibited higher biases, larger standard errors, and higher type I and type II error rates. The application of these methods to real-world EHR data from mechanically ventilated COVID-19 patients demonstrated the high quality of data generated by the models, with joint distributions of variables closely mimicking those of the original datasets. None of the evaluated methods identified an effect of early prone position on 28-day mortality.
Conclusion
This study highlights the potential of synthetic data generation for creating counterfactual populations, thereby addressing some of the limitations of IPTW. While the evaluated frameworks provided estimates that were at best similar to IPTW, further research is needed in scenarios where IPTW may encounter more limitations, such as small sample sizes or larger numbers of confounding factors. These findings underline both the promise and the challenges of integrating synthetic data into causal inference methods.}
}
@incollection{2026637,
title = {INDEX},
editor = {Alex Khang},
booktitle = {Revolutionizing Digital Healthcare Through Artificial Intelligence and Automation},
publisher = {Academic Press},
pages = {637-648},
year = {2026},
isbn = {978-0-443-36434-1},
doi = {https://doi.org/10.1016/B978-0-443-36434-1.00506-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443364341005061}
}
@article{DWIVEDI2023102642,
title = {Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy},
journal = {International Journal of Information Management},
volume = {71},
pages = {102642},
year = {2023},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2023.102642},
url = {https://www.sciencedirect.com/science/article/pii/S0268401223000233},
author = {Yogesh K. Dwivedi and Nir Kshetri and Laurie Hughes and Emma Louise Slade and Anand Jeyaraj and Arpan Kumar Kar and Abdullah M. Baabdullah and Alex Koohang and Vishnupriya Raghavan and Manju Ahuja and Hanaa Albanna and Mousa Ahmad Albashrawi and Adil S. Al-Busaidi and Janarthanan Balakrishnan and Yves Barlette and Sriparna Basu and Indranil Bose and Laurence Brooks and Dimitrios Buhalis and Lemuria Carter and Soumyadeb Chowdhury and Tom Crick and Scott W. Cunningham and Gareth H. Davies and Robert M. Davison and Rahul Dé and Denis Dennehy and Yanqing Duan and Rameshwar Dubey and Rohita Dwivedi and John S. Edwards and Carlos Flavián and Robin Gauld and Varun Grover and Mei-Chih Hu and Marijn Janssen and Paul Jones and Iris Junglas and Sangeeta Khorana and Sascha Kraus and Kai R. Larsen and Paul Latreille and Sven Laumer and F. Tegwen Malik and Abbas Mardani and Marcello Mariani and Sunil Mithas and Emmanuel Mogaji and Jeretta Horn Nord and Siobhan O’Connor and Fevzi Okumus and Margherita Pagani and Neeraj Pandey and Savvas Papagiannidis and Ilias O. Pappas and Nishith Pathak and Jan Pries-Heje and Ramakrishnan Raman and Nripendra P. Rana and Sven-Volker Rehm and Samuel Ribeiro-Navarrete and Alexander Richter and Frantz Rowe and Suprateek Sarker and Bernd Carsten Stahl and Manoj Kumar Tiwari and Wil {van der Aalst} and Viswanath Venkatesh and Giampaolo Viglia and Michael Wade and Paul Walton and Jochen Wirtz and Ryan Wright},
keywords = {Conversational agent, Generative artificial intelligence, Generative AI, ChatGPT, Large language models},
abstract = {Transformative artificially intelligent tools, such as ChatGPT, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge ChatGPT’s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether ChatGPT’s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative AI; examining biases of generative AI attributable to training datasets and processes; exploring business and societal contexts best suited for generative AI implementation; determining optimal combinations of human and generative AI for various tasks; identifying ways to assess accuracy of text produced by generative AI; and uncovering the ethical and legal issues in using generative AI across different contexts.}
}
@article{ILAGAN2024420,
title = {Exploratory prompting of large language models to act as co-pilots for augmenting business process work in document classification},
journal = {Procedia Computer Science},
volume = {237},
pages = {420-425},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011396},
author = {Jose Ramon Ilagan and Joseph Benjamin Ilagan and Claire Louisse Basallo and Zachary Matthew Alabastro},
keywords = {LLM, Document classification, GPT, RPA, Generative AI, AI, Natural language processing, NLP},
abstract = {Businesses deal with different types of documents containing unstructured documents. The data in these documents must be converted into digital forms other automated systems could only process. One generic use case is document classification, which usually involves manual transformation due to human understanding needed in the process. These documents go beyond those generated through regular business transactions and operations and also include web-based content such as online news, blogs, e-mails, and various digital libraries. Recent developments in robotic process automation (RPA) and artificial intelligence (AI) aim to automate the otherwise expensive, time-consuming, and repetitive manual steps. Through more powerful natural language processing (NLP) and natural language understanding (NLU) capabilities, large language models (LLMs) may come as a big boost in applying AI to RPA initiatives. This study proposes a general approach to using LLMs as document classifier co-pilots for knowledge workers in charge of classifying documents to be useful. The manner of prompt engineering and refinement involving labeled health insurance documents to achieve better results is discussed and evaluated through early, iterative classification attempts. However, early tests with a complex sample use case show unsatisfactory results. The study ends with recommendations for future work to improve precision and recall performance.}
}
@article{LIN2025102895,
title = {Integrating generative AI into digital multimodal composition: A study of multicultural second-language classrooms},
journal = {Computers and Composition},
volume = {75},
pages = {102895},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102895},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000719},
author = {Chin-Hsi Lin and Keyi Zhou and Lanqing Li and Lanfang Sun},
keywords = {Generative AI, Multimodal composing, Multicultural education},
abstract = {This study examines the integration of generative AI tools into digital multimodal composition (DMC) within a multicultural context, examining their impact on students’ motivation, writing processes, and outcomes. Eleven culturally diverse students from two high schools in Hong Kong participated in the study. The study developed and employed a novel pedagogical framework, IDEA (Interpret, Design, Evaluate, and Articulate), to seamlessly incorporate generative AI into DMC practices. Data-collection methods included analysis of generative AI tool-usage history, classroom video observations, surveys, and interviews. The findings reveal that students leveraged generative AI’s capabilities across five key areas: content generation, feedback and revision, multilingual support, critical thinking, and visual representation. The integration of AI tools followed distinct stages in the composition process, resulting in enhancements to the vocabulary, grammar, and structural elements of students’ work. This research contributes to the growing body of knowledge on the intersection of generative AI, education, and multimodal literacy, with a particular emphasis on human-AI collaboration in multicultural settings. It also offers valuable insights for educators seeking to enhance students’ DMC skills through the thoughtful integration of generative AI tools, potentially increasing engagement, motivation, and creative expression among learners from diverse cultural backgrounds.}
}
@article{GOROSPE2025107170,
title = {False positive AI results due to breast implants on chest radiographs: The importance of the lateral view},
journal = {Medicina Clínica},
volume = {165},
number = {6},
pages = {107170},
year = {2025},
issn = {0025-7753},
doi = {https://doi.org/10.1016/j.medcli.2025.107170},
url = {https://www.sciencedirect.com/science/article/pii/S0025775325003987},
author = {Luis Gorospe and Esther Gambí-Pisonero and Ana María Ayala-Carbonero}
}
@article{MARTIN2025216,
title = {Prevalence of artificial intelligence use and instruction in nursing education: A national study of prelicensure nursing programs in the United States},
journal = {Journal of Nursing Regulation},
volume = {16},
number = {3},
pages = {216-222},
year = {2025},
note = {Technology and the Nursing Needs of Tomorrow},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000924},
author = {Brendan Martin and Michaela Reid},
keywords = {Prelicensure nursing education, Artificial intelligence},
abstract = {Background
There is ample evidence that the integration of artificial intelligence (AI) tools into nursing practice is becoming more commonplace, but there are fewer national resources indicating to what degree prelicensure nursing programs employ these technologies and incorporate related topics into their curriculum.
Purpose
The current survey study sought to determine the prevalence of registered nurse (RN) and licensed practical nurse (LPN) education programs’ use of generative AI technologies, and the extent to which they embed AI and other digital health topics into their instructional content.
Methods
A national survey was conducted of all RN and LPN program administrators nationwide for which we had email contact information (N = 2744).
Results
Prelicensure RN programs (n = 122, 24 %) were more likely to use generative AI technology than LPN programs (n = 27, 12 %, p < 0.001), but more than three-quarters of both types of programs reported they do not use such tools or are not sure. In addition to the low usage of generative AI technology, few programs reported teaching advancements in AI and/or other digital health–related topics to their students (RN n = 87, 17 %; LPN n = 25, 11 %).
Conclusion
Nursing education programs that limit integration of AI into their curriculum risk potentially limiting students’ learning on evidence-based practice and may miss opportunities to promote critical reflection. The results of our study underscore the need to support nursing faculty to ensure prelicensure instructional content prepares nursing students for advancements in clinical practice.}
}
@incollection{2026vii,
title = {Contents},
editor = {Jason C. Vladescu and David J. Cox},
booktitle = {Applied Behavior Analysis for Business and Technology Applications},
publisher = {Academic Press},
pages = {vii-xiii},
year = {2026},
isbn = {978-0-443-22358-7},
doi = {https://doi.org/10.1016/B978-0-443-22358-7.00009-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223587000095}
}
@article{CHAVEZMOSTAJO2026101116,
title = {MED-IA: modelo educativo digital para la formación médica de especialidades clínicas, basado en inteligencia artificial},
journal = {Educación Médica},
volume = {27},
number = {1},
pages = {101116},
year = {2026},
issn = {1575-1813},
doi = {https://doi.org/10.1016/j.edumed.2025.101116},
url = {https://www.sciencedirect.com/science/article/pii/S1575181325000944},
author = {Nelson Iván {Chávez Mostajo}},
keywords = {Inteligencia artificial, Tutoría virtual, Educación médica, Desempeño académico, Aprendizaje personalizado, Artificial Intelligence, Virtual tutoring, Medical education, Academic performance, Personalized learning},
abstract = {Resumen
Introducción
la digitalización de la educación médica exige modelos formativos capaces de personalizar la tutoría clínica. El modelo pedagógico MED-IA propone integrar inteligencia artificial (IA) generativa para acompañar a médicos residentes.
Métodos
se realizó un estudio mixto, longitudinal, con diseño investigación-acción. Participaron 27 residentes del área clínica de un hospital de tercer nivel en Bolivia. Se diseñó e implementó un programa didáctico basado en un tutor virtual personalizado, llamado Guard IA, sustentado en GPT-4o, que fue operado durante 8 semanas. Se midió el rendimiento académico según las notas de la evaluación sumativa y las percepciones de los usuarios mediante escalas Likert para su posterior análisis estadístico por las pruebas de Wilcoxon y correlaciones de Spearman. A partir de ese programa, se plantean las bases teóricas para el modelo pedagógico MED-IA.
Resultados
la calificación promedio aumentó de 65,5±6,8 a 88,0±5,4 (p<0,001) en quienes utilizaron el tutor virtual. El 84% de los usuarios mejoró su rendimiento frente al 33% de los no usuarios; la frecuencia de uso se correlacionó con la diferencia de nota (r=0,54). El 91% declaró alta satisfacción y el 76% recomendaría el tutor.
Conclusión
el modelo demostró eficacia pedagógica y aceptación, ofreciendo un acompañamiento adaptativo que fortalece el razonamiento clínico y la autonomía del aprendizaje.
Introduction
The digitalization of medical education demands instructional models capable of personalizing clinical tutoring. The pedagogical model MED-IA proposes integrates generative artificial intelligence (AI) to support medical residents.
Methods
A mixed-method, longitudinal, action-research study was conducted. Twenty-seven residents from the clinical area of a tertiary hospital in Bolivia participated. A didactic program was designed and implemented, centered on a personalized virtual tutor named Guard IA, powered by GPT-4o, and operated over eight weeks. Academic performance was measured through summative evaluation scores, and user perceptions were assessed using Likert scales. Statistical analysis included Wilcoxon tests and Spearman correlations. Based on this program, the theoretical foundations for the MED-IA pedagogical model were established.
Results
The average score increased from 65.5±6.8 to 88.0±5.4 (p<0.001) among users of the virtual tutor. A total of 84% of users improved their performance, compared to 33% of non-users; usage frequency correlated with score improvement (r=0.54). Additionally, 91% of participants reported high satisfaction, and 76% would recommend the tutor.
Conclusion
The model demonstrated pedagogical effectiveness and user acceptance, offering adaptive support that strengthens clinical reasoning and learning autonomy.}
}
@article{VILLALONGALOPEZURIBARRI2025477,
title = {Acute phlegmonous gastritis. A rare case of acute abdominal pain},
journal = {Revista de Gastroenterología de México (English Edition)},
volume = {90},
number = {3},
pages = {477-478},
year = {2025},
issn = {2255-534X},
doi = {https://doi.org/10.1016/j.rgmxen.2025.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S2255534X25000970},
author = {L. {Villalonga Lopez-Uribarri} and J. {Carrascosa Gil} and H. {Rodrigo Pérez}}
}
@article{KE2024,
title = {Mitigating Cognitive Biases in Clinical Decision-Making Through Multi-Agent Conversations Using Large Language Models: Simulation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/59439},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124008124},
author = {Yuhe Ke and Rui Yang and Sui An Lie and Taylor Xin Yi Lim and Yilin Ning and Irene Li and Hairil Rizal Abdullah and Daniel Shu Wei Ting and Nan Liu},
keywords = {clinical decision-making, cognitive bias, generative artificial intelligence, large language model, multi-agent},
abstract = {Background
Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field.
Objective
This study aimed to explore the role of large language models (LLMs) in mitigating these biases through the use of the multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy compared with humans.
Methods
A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent framework, we leveraged GPT-4 (OpenAI) to facilitate interactions among different simulated agents to replicate clinical team dynamics. Each agent was assigned a distinct role: (1) making the final diagnosis after considering the discussions, (2) acting as a devil’s advocate to correct confirmation and anchoring biases, (3) serving as a field expert in the required medical subspecialty, (4) facilitating discussions to mitigate premature closure bias, and (5) recording and summarizing findings. We tested varying combinations of these agents within the framework to determine which configuration yielded the highest rate of correct final diagnoses. Each scenario was repeated 5 times for consistency. The accuracy of the initial diagnoses and the final differential diagnoses were evaluated, and comparisons with human-generated answers were made using the Fisher exact test.
Results
A total of 240 responses were evaluated (3 different multi-agent frameworks). The initial diagnosis had an accuracy of 0% (0/80). However, following multi-agent discussions, the accuracy for the top 2 differential diagnoses increased to 76% (61/80) for the best-performing multi-agent framework (Framework 4-C). This was significantly higher compared with the accuracy achieved by human evaluators (odds ratio 3.49; P=.002).
Conclusions
The multi-agent framework demonstrated an ability to re-evaluate and correct misconceptions, even in scenarios with misleading initial investigations. In addition, the LLM-driven, multi-agent conversation framework shows promise in enhancing diagnostic accuracy in diagnostically challenging medical scenarios.}
}
@article{THANG2025,
title = {Incidence and prevalence of perioral dermatitis in the United States: A retrospective cohort study using TriNetX},
journal = {Journal of the American Academy of Dermatology},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.09.096},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225029226},
author = {Christopher J. Thang and David Garate and Jenny Lai and Sherry Ershadi and George Golovko and Michael G. Wilkerson and John S. Barbieri},
keywords = {epidemiology, incidence, medical dermatology, perioral dermatitis, periorificial dermatitis, prevalence}
}
@article{HIROSAWA2024,
title = {Evaluating ChatGPT-4’s Diagnostic Accuracy: Impact of Visual Data Integration},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/55627},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000401},
author = {Takanobu Hirosawa and Yukinori Harada and Kazuki Tokumasu and Takahiro Ito and Tomoharu Suzuki and Taro Shimizu},
keywords = {artificial intelligence, large language model, LLM, LLMs, language model, language models, ChatGPT, GPT, ChatGPT-4V, ChatGPT-4 Vision, clinical decision support, natural language processing, decision support, NLP, diagnostic excellence, diagnosis, diagnoses, diagnose, diagnostic, diagnostics, image, images, imaging},
abstract = {Background
In the evolving field of health care, multimodal generative artificial intelligence (AI) systems, such as ChatGPT-4 with vision (ChatGPT-4V), represent a significant advancement, as they integrate visual data with text data. This integration has the potential to revolutionize clinical diagnostics by offering more comprehensive analysis capabilities. However, the impact on diagnostic accuracy of using image data to augment ChatGPT-4 remains unclear.
Objective
This study aims to assess the impact of adding image data on ChatGPT-4’s diagnostic accuracy and provide insights into how image data integration can enhance the accuracy of multimodal AI in medical diagnostics. Specifically, this study endeavored to compare the diagnostic accuracy between ChatGPT-4V, which processed both text and image data, and its counterpart, ChatGPT-4, which only uses text data.
Methods
We identified a total of 557 case reports published in the American Journal of Case Reports from January 2022 to March 2023. After excluding cases that were nondiagnostic, pediatric, and lacking image data, we included 363 case descriptions with their final diagnoses and associated images. We compared the diagnostic accuracy of ChatGPT-4V and ChatGPT-4 without vision based on their ability to include the final diagnoses within differential diagnosis lists. Two independent physicians evaluated their accuracy, with a third resolving any discrepancies, ensuring a rigorous and objective analysis.
Results
The integration of image data into ChatGPT-4V did not significantly enhance diagnostic accuracy, showing that final diagnoses were included in the top 10 differential diagnosis lists at a rate of 85.1% (n=309), comparable to the rate of 87.9% (n=319) for the text-only version (P=.33). Notably, ChatGPT-4V’s performance in correctly identifying the top diagnosis was inferior, at 44.4% (n=161), compared with 55.9% (n=203) for the text-only version (P=.002, χ2 test). Additionally, ChatGPT-4’s self-reports showed that image data accounted for 30% of the weight in developing the differential diagnosis lists in more than half of cases.
Conclusions
Our findings reveal that currently, ChatGPT-4V predominantly relies on textual data, limiting its ability to fully use the diagnostic potential of visual information. This study underscores the need for further development of multimodal generative AI systems to effectively integrate and use clinical image data. Enhancing the diagnostic performance of such AI systems through improved multimodal data integration could significantly benefit patient care by providing more accurate and comprehensive diagnostic insights. Future research should focus on overcoming these limitations, paving the way for the practical application of advanced AI in medicine.}
}
@article{PAN2025100162,
title = {AI literacy and trust: A multi-method study of Human-GAI team collaboration},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100162},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100162},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000465},
author = {Zilong Pan and Ozias A. Moore and Antigoni Papadimitriou and Jiayan Zhu},
keywords = {AI literacy, AI teammate, Generative AI, Human-GAI collaboration, Team-based projects, Trust},
abstract = {As artificial intelligence (AI) becomes increasingly integrated into team settings for collaboration with humans, understanding the dynamics of trust and AI literacy is essential for enhancing team effectiveness. This study investigates the relationship between trust and AI literacy in human-generative AI (GAI) team collaboration, focusing on how AI literacy affects trust formation in these interactions. Drawing upon foundational teamwork literature and AI literacy frameworks, we conducted a multi-method investigation involving 116 undergraduate team members across 23 project teams throughout a semester. In Study 1, qualitative findings revealed distinct attitudes toward GAI as a teammate, categorized as trust, distrust, and ambivalence. Study 2 employed quantitative methods to determine predictors of trust in GAI, demonstrating that AI knowledge and perceived value—key components of AI literacy—significantly influenced perceptions of trust. Notably, perceptions of GAI accuracy emerged as a critical determinant of trust. Our findings highlight the complex interplay between AI literacy and trust in human-GAI collaboration. We observed a paradox: increased AI literacy can enhance collaboration but may also lead to hesitancy in future AI use. We contribute to advancing the understanding of human-AI collaboration by highlighting the critical role of AI literacy in shaping trust and socio-technical team dynamics. Our study provides evidence demonstrating the importance of targeted AI literacy development in building trust and fostering effective collaboration in human-GAI teams. These findings provide a foundation for research aimed at optimizing human-GAI teamwork and developing adaptive AI literacy frameworks, empowering individuals to effectively engage with AI across diverse collaborative settings.}
}
@incollection{AUSTIN2025,
title = {Knowledge work},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-26629-4.00028-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443266294000289},
author = {Robert D. Austin and Milad Saeedi},
keywords = {Agency, Agency theory, Attributability, Generative artificial intelligence, Intrinsic motivation, Knowledge asymmetry, Knowledge work, Measurability, Observability, Principal, Principal-agent theory, Skill},
abstract = {Knowledge work, in which valuable transformations occur in the realm of thoughts, ideas, and symbols, presents particular challenges for social measurement. Difficulties arise from the relative inobservability of knowledge work, in contrast with physical work, due to the intangibility of activities, materials, and some outputs. Difficulties observing knowledge work lead to problems attributing causality and discerning important inner aspects of value creation. The problems have grown more serious as knowledge work has widened to include the sometimes inscrutable work of artificially intelligent generative collaborators and autonomous agents.}
}
@article{MEHRVARZ2025100459,
title = {How does students' perception of ChatGPT shape online learning engagement and performance?},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100459},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100459},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000992},
author = {Mahboobeh Mehrvarz and Ghasem Salimi and Samaneh Abdoli and Bruce M. McLaren},
keywords = {Academic performance, Generative AI, Online learning engagement, Student perception of ChatGPT, Structural Equation Modeling},
abstract = {Artiicial intelligence technologies, such as ChatGPT, Bert, LaMDA, and T5 have become deeply integrated into universities, influencing numerous functions within higher education and various aspects of students' lives. This article examined how students' perceptions of ChatGPT influence their engagement and performance in online learning, focusing on the mediating role of engagement. The perception of ChatGPT involves a student's understanding of, willingness to utilize, and concerns regarding the technology. These interconnected factors can influence students' online learning engagement with the software and, consequently, affect their academic performance. The study used self-reported data from 305 participants at a large university in Iran. The findings from Structural Equation Modeling (SEM) revealed that students' perception of ChatGPT accounts for 19.2 % of the variance in online learning engagement, while the combination of ChatGPT perception and online learning engagement explains 40.4 % of the variance in academic performance. Furthermore, students' perceptions of ChatGPT had direct effects on online learning engagement (β = 0.438) and academic performance (β = 0.268). Additionally, online engagement significantly mediated this relationship, with an indirect effect of β = 0.206. The observed direct and indirect effects highlighted the essential role of online learning engagement in fostering interaction and enhancing students' performance. Overall, our conceptual model provides researchers and university administrators with a comprehensive understanding of students' perceptions of ChatGPT, their engagement, and their academic performance in an online setting. This model also provides valuable insights for future research on designing student activities that leverage artificial intelligence technologies, including ChatGPT-based tools.}
}
@article{2025i,
title = {Table of contents},
journal = {Journal of Professional Nursing},
volume = {57},
pages = {i-ii},
year = {2025},
issn = {8755-7223},
doi = {https://doi.org/10.1016/S8755-7223(25)00027-4},
url = {https://www.sciencedirect.com/science/article/pii/S8755722325000274}
}
@article{RIGAS2025S-318,
title = {1300: AN AUTONOMOUS, AI-ENHANCED, PALM-SIZE, HAND-HELD BREATHALYZER DEVICE FOR POINT-OF-CARE AND HOME SELF-TESTING AND A NATURAL UREA BREATH TEST (UBT) DETECTING H. PYLORI INFECTION WITH 100% SENSITIVITY AND 100% SPECIFICITY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01678-6},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016786},
author = {Anastasia Rigas}
}
@article{ZHANG2025101392,
title = {Deep learning empowered gadolinium-free contrast-enhanced abbreviated MRI for diagnosing hepatocellular carcinoma},
journal = {JHEP Reports},
volume = {7},
number = {5},
pages = {101392},
year = {2025},
issn = {2589-5559},
doi = {https://doi.org/10.1016/j.jhepr.2025.101392},
url = {https://www.sciencedirect.com/science/article/pii/S2589555925000692},
author = {Yunfei Zhang and Ruofan Sheng and Xianling Qian and Heqing Wang and Fei Wu and Haoran Dai and Mingyue Song and Chun Yang and Jianjun Zhou and Weiguo Zhang and Mengsu Zeng},
keywords = {Abbreviated magnetic resonance imaging, Hepatocellular carcinoma diagnosis, Generative artificial intelligence, Image synthesis, Stable diffusion models},
abstract = {Background & Aims
By reducing some magnetic resonance imaging (MRI) sequences, abbreviated MRI (aMRI) has shown extensive promise for detecting hepatocellular carcinoma (HCC). We aim to develop deep learning (DL)-based gadolinium-free contrast-enhanced (CE) aMRI protocols (DL-aMRI) for detecting HCC.
Methods
In total, 1,769 patients (913 with HCC) were retrospectively included from three institutions for training, testing, and external validation. Stable diffusion-based DL models were trained to generate CE-MRI, including T1-weighted arterial, portal venous, transitional, and hepatobiliary phase images (AP-syn, VP-syn, TP-syn, and HBP-syn, respectively). Non-contrast-MRI (NC-MRI), including T2-weighted, diffusion-weighted, and pre-contrast T1-weighted (Pre) sequences, along with either actual or DL-synthesized CE-MRI (AP, VP, TP, and HBP or AP-syn, VP-syn, TP-syn, and HBP-syn), were used to create conventional complete MRI (cMRI) and DL-aMRI protocols. An inter-method comparison of image quality between DL-aMRI and cMRI was conducted using a non-inferiority test. The sensitivity and specificity of DL-aMRI and cMRI for detecting HCC were statistically compared using the non-inferiority test and generalized estimating equations models.
Results
DL-aMRI showed a remarkable reduction in acquisition time compared with cMRI (4.1 vs. 28.1 min). The image quality of DL-synthesized CE-MRI was not inferior to that of actual CE-MRI (p <0.001). There was an excellent inter-method agreement between the HCC sizes measured by the two protocols (R2 = 0.9436–0.9683). The pooled sensitivity and specificity of cMRI and DL-aMRI were 0.899 and 0.925 and 0.866 and 0.922, respectively. No significant differences were found between the sensitivity and specificity of the two protocols.
Conclusions
The proposed DL-aMRI could facilitate precise HCC diagnosis with no need for contrast agents, a substantial reduction in acquisition time, and preservation of both NC-MRI and CE-MRI data. DL-aMRI may serve as a valuable tool for HCC diagnosing.
Impact and implications
In this multi-center study involving 1,769 participants, we developed a generative deep learning-based abbreviated MRI (DL-aMRI) strategy that provides an efficient, contrast-agent-free alternative for detecting HCC with accuracy comparable to that of conventional complete MRI, significantly reducing acquisition time from 28.1 min to just 4.1 min. This strategy is valuable for clinicians who face significant workloads resulting from long MRI scanning times and the potential adverse effects of contrast agents, as well as for researchers focused on developing cost-effective and accessible diagnostic tools for HCC detection. The proposed DL-aMRI protocol has practical implications for clinical settings, enhancing diagnostic efficiency while maintaining high image quality, eliminating the need for contrast agents and ultimately benefiting patients and healthcare providers.}
}
@article{XU2025,
title = {Key Challenges and Research Directions for Space–Air–Ground Integrated Emergency Communication Networks},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925005624},
author = {Bo Xu and Haitao Zhao and Jiawen Kang and Dusit Niyato}
}
@article{CHERIF2024,
title = {Appraisal of ChatGPT’s Aptitude for Medical Education: Comparative Analysis With Third-Year Medical Students in a Pulmonology Examination},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/52818},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000862},
author = {Hela Cherif and Chirine Moussa and Abdel Mouhaymen Missaoui and Issam Salouage and Salma Mokaddem and Besma Dhahri},
keywords = {medical education, ChatGPT, GPT, artificial intelligence, natural language processing, NLP, pulmonary medicine, pulmonary, lung, lungs, respiratory, respiration, pneumology, comparative analysis, large language models, LLMs, LLM, language model, generative AI, generative artificial intelligence, generative, exams, exam, examinations, examination},
abstract = {Background
The rapid evolution of ChatGPT has generated substantial interest and led to extensive discussions in both public and academic domains, particularly in the context of medical education.
Objective
This study aimed to evaluate ChatGPT’s performance in a pulmonology examination through a comparative analysis with that of third-year medical students.
Methods
In this cross-sectional study, we conducted a comparative analysis with 2 distinct groups. The first group comprised 244 third-year medical students who had previously taken our institution’s 2020 pulmonology examination, which was conducted in French. The second group involved ChatGPT-3.5 in 2 separate sets of conversations: without contextualization (V1) and with contextualization (V2). In both V1 and V2, ChatGPT received the same set of questions administered to the students.
Results
V1 demonstrated exceptional proficiency in radiology, microbiology, and thoracic surgery, surpassing the majority of medical students in these domains. However, it faced challenges in pathology, pharmacology, and clinical pneumology. In contrast, V2 consistently delivered more accurate responses across various question categories, regardless of the specialization. ChatGPT exhibited suboptimal performance in multiple choice questions compared to medical students. V2 excelled in responding to structured open-ended questions. Both ChatGPT conversations, particularly V2, outperformed students in addressing questions of low and intermediate difficulty. Interestingly, students showcased enhanced proficiency when confronted with highly challenging questions. V1 fell short of passing the examination. Conversely, V2 successfully achieved examination success, outperforming 139 (62.1%) medical students.
Conclusions
While ChatGPT has access to a comprehensive web-based data set, its performance closely mirrors that of an average medical student. Outcomes are influenced by question format, item complexity, and contextual nuances. The model faces challenges in medical contexts requiring information synthesis, advanced analytical aptitude, and clinical judgment, as well as in non-English language assessments and when confronted with data outside mainstream internet sources.}
}
@article{2025A7,
title = {Table of Contents},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {A7-A8},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/S0016-5085(25)05755-5},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525057555}
}
@article{ANDERSON2025100292,
title = {Evaluating the Quality and Safety of Ambient Digital Scribe Platforms Using Simulated Ambulatory Encounters},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {4},
pages = {100292},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100292},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000999},
author = {Taylor N. Anderson and Vishnu Mohan and David A. Dorr and Raj M. Ratwani and Joshua M. Biro and Jeffrey A. Gold},
abstract = {Objective
To evaluate and compare the quality and safety of ambient digital scribe (ADS) platforms using simulated ambulatory encounters.
Methods
Five ADS platforms were evaluated using audio recordings of fourteen simulated clinical encounters. Audio recordings were played on a laptop computer and captured by ADS platforms on a mobile phone. Generated transcripts were compared to professional transcriptions. Clinical notes were graded using rubrics of key elements for each case. Note errors were classified as omission, commission, or partially correct. Potential clinical harm was assessed using the agency for healthcare research and quality harm scale. Note quality was assessed using the 9-item Physician Documentation Quality Instrument (range 9-45). Statistical comparisons included Friedman and χ2 tests with a correction for multiple comparisons.
Results
Transcripts generated by platforms A through D contained an average of 13.9 (95% CI, 6.0-17.5) errors, with 19.5% of the transcript errors transmitted to the clinical note (95% CI, 6.6%-28.8%). For clinical notes, mean percent error across platforms was 26.3% (95% CI, 17.0%-31.0%) with a significantly higher proportion of errors in notes generated by platform E (P<.0053 for all comparisons). Of correctly reported elements, only 35.8%±11.3% were consistently correct across all platforms. An average of 3.0 (95% CI, 0-4, range 0-21) errors per case had potential for moderate-to-severe harm. The mean physician documentation quality instrument–9 score was 36±4, with significant variation between platforms.
Conclusion
Clinical notes generated by ADS platforms using simulated encounters reports important inter-platform and intra-platform variability in accuracy and quality. These findings indicate a need for standardized, objective evaluation and reporting.}
}
@article{BURKE2025,
title = {Association of glucagon-like peptide-1 agonist use with atopic dermatitis in obese patients: A retrospective cohort study},
journal = {Journal of the American Academy of Dermatology},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.09.080},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225029032},
author = {Samantha M. Burke and Mara Beveridge and Betul Hatipoglu and Jennifer Murphy and Bryan T. Carroll},
keywords = {anti-inflammatory, atopic dermatitis, corticosteroids, GLP-1 agonists, obesity, weight loss}
}
@article{FAUGHT2025e731,
title = {Implementing Generative AI in Radiation Oncology: What Could Possibly Go Wrong?},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {123},
number = {1, Supplement },
pages = {e731},
year = {2025},
note = {ASTRO 2025: 67th Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2025.06.3145},
url = {https://www.sciencedirect.com/science/article/pii/S0360301625037502},
author = {A.M. Faught and P.E. Klages and P. Sadeghi and J.M. Pakela and E. Lee and A.S. Ayan},
abstract = {Purpose/Objective(s)
The rapid gains in generative artificial intelligence (AI) have resulted in a myriad of potential uses in the radiation oncology domain. We have been interested in using a large language model (LLM) as an advisor on group, departmental, and industry policies and guidelines. We sought to identify the risks associated with the tool through a failure modes and effects analysis (FMEA) study.
Materials/Methods
Six medical physicists were instructed to generate a list of failure modes (FMs) associated with using a LLM to offer guidance in clinical decision making for the medical physics group based on adopted standard operating procedures, departmental policies, and American Association of Physicists in Medicine (AAPM) guidance documents. The FMs were then redistributed to the physicists for independent scoring of probability of occurrence (O), severity (S), and lack of detectability (D). Average scores for each of the three metrics were calculated along with a final risk probability number (RPN). As an example of its proposed use, and as a method for further evaluating the risk, an LLM model was asked to perform on FMEA on its own list of ten FMs. The LLM was pointed to a directory of 32 AAPM task group (TG) reports, including TG-100, the report on risk analysis methods in radiation therapy, as a knowledge base for the task.
Results
The human scorers identified 22 unique FMs. Only one FM, a limited ability to handle updates to policy or procedures, was independently identified by all six physicists. A total of 11 of the 22 FMs were identified by at least two physicists. Fourteen of twenty-two FMs had an RPN greater than or equal to 125, the cutoff at which AAPM TG-100 suggests more attention is warranted for a FM. Of the ten FMs generated by the AI, six overlapped with FMs identified by the human scorers, including the FM identified by all six physicists. Nine of the ten AI generated FMs were scored with RPNs greater than 125, and the lone FM less than 125 had a severity of 10. The root mean squared error of the difference between AI RPNs and human scored RPNs in the overlapping FMs was 66, with differences as small as 0 and as large as 144. There were no instances of an overlapping human and AI generated FM having an RPN greater than 125 from one methodology and not the other.
Conclusion
Generative AI has the potential to be an invaluable tool in the field of radiation oncology. Specifically, the use of LLM models can help to enforce departmental consistency in practice, adherence to industry standards, and efficient means of referencing departmental guidelines. Even as an advisor, and not as a decision-making entity directly touching patients, the implementation of generative AI is not without risk. This work outlined those risks and highlighted the utility of the AI by having it perform its own risk assessment through an FMEA. Prospective risk mitigation strategies such as this exercise can be invaluable in both understanding risk and implementing preventions and barriers to reduce risk associated with adopting new technologies.}
}
@article{ELBANNA202316,
title = {Exploring the integration of ChatGPT in education: adapting for the future},
journal = {Management & Sustainability: An Arab Review},
volume = {3},
number = {1},
pages = {16-29},
year = {2023},
issn = {2752-9819},
doi = {https://doi.org/10.1108/MSAR-03-2023-0016},
url = {https://www.sciencedirect.com/science/article/pii/S2752981923000102},
author = {Said Elbanna and Loreta Armstrong},
keywords = {ChatGPT, AI, Learning, Education, Responsible education, Content creation, Ethics},
abstract = {Purpose
This article aims to explore the advantages of integrating a new generative artificial intelligence (AI) technology in education. It investigates the use of ChatGPT in personalized learning, assessment and content creation and examines ways to manage its limitations and some ethical considerations. The purpose is to stimulate discussion on the effective application of ChatGPT as a tool for learning and skill development while remaining mindful of the ethical issues involved.
Design/methodology/approach
The methodology in this article includes four steps: a literature search, screening and selection, analysis and synthesis. The literature was thoroughly screened and selected on the basis of its relevance to the research question, before selected material were carefully read and analyzed. The insights gained from this analysis were then synthesized to identify key considerations in integrating ChatGPT in education.
Findings
The study concludes that ChatGPT can be effectively integrated into education to automate routine tasks and enhance the learning experience for students, ultimately increasing productivity and efficiency and fostering adaptive learning. However, the limitations of ChatGPT, even when updated, must be borne in mind, including factual inconsistencies, potential bias promotion, lack of in-depth understanding and safety concerns. The study nevertheless highlights the benefits of responsibly integrating ChatGPT within the field of education.
Practical implications
This study has practical implications for educators and policymakers who are interested in the integration of AI technology in education. The study provides insights of using ChatGPT in education.
Originality/value
This article contributes to the existing literature by specifically examining the advantages of integrating ChatGPT in higher education and offering recommendations for its responsible use. Moreover, the article emphasizes ethical considerations in the context of ChatGPT integration.}
}
@article{OCONNOR2025108701,
title = {Is the metaverse failing? An exploratory study of self-employed artists and their resistance to NFTs},
journal = {Computers in Human Behavior},
volume = {170},
pages = {108701},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108701},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001487},
author = {Yvonne {O’ Connor} and Katie {O’ Reilly}},
keywords = {NFTs, Resistance, Non-sellers, Self-employed, Conceptual model},
abstract = {Headlines globally have highlighted the role of Non-Fungible Tokens (NFTs) within the metaverse in radically reshaping future retail in the digital world. Yet, NFTs are not fulfilling its disruptive potential in virtual marketplaces. Researchers must understand the strategic concerns of non-sellers of NFTs before theorising about long-term implementation, diffusion, and adoption. An exploratory case study of non-selling content creators is employed in this study. The findings of this study reveal that resistance to NFT sales is influenced by several factors including external influences, initial conditions, social responsibility beliefs and individual values. Whilst a lot of research has examined the positive associations with NFT (e.g. motivations to buy) this paper focuses on resistance from a seller's perspective. It further provides a foundation for understanding resistance from individuals who are self-employed and thus sheds new insights for this domain.}
}
@article{GOROSPE2025106968,
title = {Hodgkin disease presenting as hemoptysis and mimicking lung cancer},
journal = {Medicina Clínica},
volume = {165},
number = {1},
pages = {106968},
year = {2025},
issn = {0025-7753},
doi = {https://doi.org/10.1016/j.medcli.2025.106968},
url = {https://www.sciencedirect.com/science/article/pii/S0025775325001940},
author = {Luis Gorospe and Odile Ajuria-Illarramendi and Rosa Mariela Mirambeaux-Villalona}
}
@article{DEMPSEYJONES2025,
title = {Why were the textbooks wrong about brain plasticity?},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661325002426},
author = {Harriet Dempsey-Jones},
keywords = {reorganisation, remapping, primary somatosensory cortex, SI, deprivation, phantom limb, phantom pain, cortical maps, cortical reorganisation},
abstract = {Schone and colleagues reveal surprising stability in the brain’s body map, challenging textbook notions of dramatic remapping. But why were the textbooks wrong? Because what was interpreted as plasticity was only half of the story. In fact, missing limb representations do persist, awaiting the right probe.}
}
@article{GOROSPE2025106968,
title = {Hodgkin disease presenting as hemoptysis and mimicking lung cancer},
journal = {Medicina Clínica (English Edition)},
volume = {165},
number = {1},
pages = {106968},
year = {2025},
issn = {2387-0206},
doi = {https://doi.org/10.1016/j.medcle.2025.106968},
url = {https://www.sciencedirect.com/science/article/pii/S2387020625003146},
author = {Luis Gorospe and Odile Ajuria-Illarramendi and Rosa Mariela Mirambeaux-Villalona}
}
@incollection{2026i,
title = {Front Matter},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {i-ii},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00301-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244003015}
}
@article{JAIN20251871,
title = {Citation integrity in the age of AI: evaluating the risks of reference hallucination in maxillofacial literature},
journal = {Journal of Cranio-Maxillofacial Surgery},
volume = {53},
number = {10},
pages = {1871-1872},
year = {2025},
issn = {1010-5182},
doi = {https://doi.org/10.1016/j.jcms.2025.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S101051822500263X},
author = {Anuj Jain and Pranali Nimonkar and Pratap Jadhav},
keywords = {ChatGPT, Large language models, Artificial intelligence, Reference hallucination, Oral and maxillofacial surgery, Academic integrity},
abstract = {The increasing adoption of large language models (LLMs) such as ChatGPT in academic writing has introduced both opportunities and risks. While these tools enhance productivity and accessibility, their reliability in generating accurate references remains uncertain. This short communication highlights the growing concern of ‘reference hallucination’, where AI-generated citations appear legitimate but are fabricated or contain significant metadata errors. Across all scientific disciplines, including oral and maxillofacial surgery (OMFS), where evidence-based practice is foundational, such inaccuracies can undermine academic integrity and clinical trust. This article summarizes common reference-related errors reported in literature and calls for heightened editorial vigilance, AI-literacy training, and the integration of real-time bibliographic tools. Responsible use of AI in scholarly publishing is essential to preserving the quality and credibility of surgical literature.}
}
@article{ALI2021100040,
title = {Children as creators, thinkers and citizens in an AI-driven future},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100040},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000345},
author = {Safinah Ali and Daniella DiPaola and Irene Lee and Victor Sindato and Grace Kim and Ryan Blumofe and Cynthia Breazeal},
keywords = {Misinformation, Deepfakes, Generative AI, Digital literacy, Media literacy, Social media},
abstract = {Generative Artificial Intelligence (AI) approaches open up new avenues of digital creation, and are simultaneously accompanied by societal and ethical implications such as the creation of Deepfakes and spread of misinformation, renewing our understanding of technical AI systems as socio-technical systems. Applications of, and media generated by generative AI techniques are abundantly present on social media platforms frequented by children, who are not yet aware of the existence of AI-manipulated media. Previous work has highlighted the importance of digital media literacy and AI literacy for children. In this work, we introduce middle school students to generative AI techniques as a tool for creation, while also focusing on critical discussion about their societal and ethical implications, and encouraging pro-activeness in being responsible consumers, creators and stakeholders of technology. We present learning activities that introduce 38 middle-school students to generative modeling, how it is used to generate Deepfakes, cues that help to recognize Deepfakes, and the spread and effects of misinformation. Students demonstrated an understanding that generative media may be believable, but not necessarily true, and can contribute to the spread of misinformation. They were also able to identify why misinformation may be harmful or lasting, drawing specific examples to social settings that indicate human-centered implications. Finally, students expressed opinions about policies surrounding the presence of Deepfakes on social media. This approach can be adopted to introduce students to other technical systems that constitute both productive applications and potential negative implications of technology.
CCS concepts
⋅Applied computing → Interactive learning environments; ⋅Human-centered computing → Social media; Social networks; ⋅Social and professional topics → Computing literacy; K-12 education;
Additional key words and phrases
Misinformation, Deepfakes, digital literacy, media literacy, social media.}
}
@article{MEJIA2025,
title = {Time for Clarity in Exploring the Evidence and Key Concepts of Human-Centered Design in Digital Health Care: Protocol for a Scoping Review},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/74067},
url = {https://www.sciencedirect.com/science/article/pii/S192907482500722X},
author = {Luisa Mejia and Björn Bergh and Björn Schreiweis},
keywords = {patient-centric health care, user experience, user interface, usability, mobile health, mHealth human-centered design, design thinking, scoping review, participatory design, generative artificial intelligence, GenAI},
abstract = {Background
Human-centered design (HCD) methodologies such as design thinking (DT), user-centered design, cocreation, and participatory design (PD) have been adopted to facilitate user and stakeholder involvement in the development of eHealth applications. However, there is frequent confusion around these methodologies, leading to the fragmentation of the discourse and limited integration opportunities. The absence of an empirically grounded framework for HCD limits research and theoretical consensus, particularly in the highly regulated context of eHealth solution development. For this scoping review, the term HCD will be used as an umbrella term, under which the terms user-centered design, patient-centered design, cocreation, co-design, PD, and DT will be used in this protocol.
Objective
In this paper, we describe a protocol for a scoping review that aims to explore and analyze the scope, definitions, key concepts, and motivations reported in peer-reviewed studies that have applied stakeholder engagement methods such as HCD, PD, or DT in developing eHealth applications.
Methods
A team of 3 reviewers will conduct this scoping review to identify and synthesize key concepts at the intersection of HCD methodologies and their application to the development of eHealth applications. We will follow the Joanna Briggs Institute methodology for scoping reviews and the guidelines for conducting systematic mapping studies in software engineering. The reporting of the results will be guided by the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) extension. This review will include only primary studies reporting on the experience, challenges, and applicability of HCD for the design and development of eHealth applications, identified through the PubMed, IEEE Xplore, Web of Science, Scopus, PsycINFO, CINAHL, and ACM Digital Library databases, and limited to articles from the past 10 years.
Results
A preliminary search applying the search strategy resulted in 826 records. The search was initiated in March 2025. Title and abstract screening will conclude by mid-2025, followed by full-text screening, data extraction, and analysis in the second half of 2025. Results are expected to be submitted for publication in the first half of 2026.
Conclusions
This protocol describes a systematic approach for conducting a scoping literature review, aimed at synthesizing definitions, concepts, and methodologies related to HCD in eHealth application development. This review aims to identify research gaps and trends to guide the future of mobile health innovation, with a focus on improving adoption and long-term sustainability, particularly from the perspective of technologies for vulnerable populations.
International Registered Report Identifier (IRRID)
DERR1-10.2196/74067}
}
@article{KODWEIS2025100553,
title = {Let's chat(GPT): Implementation of a ChatGPT-generated social determinants of health activity},
journal = {Exploratory Research in Clinical and Social Pharmacy},
volume = {18},
pages = {100553},
year = {2025},
issn = {2667-2766},
doi = {https://doi.org/10.1016/j.rcsop.2024.100553},
url = {https://www.sciencedirect.com/science/article/pii/S2667276624001501},
author = {Karl R. Kodweis and Theodore J. Cory and Elizabeth A. Hall and Christa M. George and Katherine L. March},
keywords = {Artificial intelligence, ChatGPT, Social determinants of health, Pharmacy education, Team-based learning},
abstract = {Background
Artificial intelligence (AI)- powered chatbots have provided some notable benefits for learners. Educators are beginning to explore their possible utility and find ways to leverage AI in their classrooms.
Objective
This study aimed to evaluate the implementation of ChatGPT-generated social determinants of health (SDOH) activity in a team-based pharmacy education course.
Methods
Instructors asked the software to generate a set of learning objectives, an in-class activity, assessment strategies, and summative assessments for a student's conceptual understanding of SDOH. During a required first-year, team-based pharmacy course at the University of Tennessee Health Science Center, participants (n = 95) completed a ChatGPT-generated, in-class activity on SDOH within groups. The students' views on the quality of the activity were evaluated using five Likert-scale questions. Four of the questions assessed the applicability and usefulness of the assignment, with rankings on a scale of 1–4 (1 = strongly disagree; 4 = strongly agree). The fifth question evaluated the quality of the activity compared to activities generated by the instructor, using a scale of 1–5 (1 = far worse; 5 = far better).
Results
For applicability and usefulness,”94.7 % (n = 90) of students agreed that “This in-class exercise was valuable to my professional development as a pharmacist;” 96.8 % (n = 92) agreed with “It is necessary for pharmacists to understand SDOH;” 94.7 % (n = 90) agreement with the statement, “The quality of this in-class activity was on-par with other in-class activities in the course;” and 90.5 % (n = 86) agreed with “This in-class exercise was just as impactful to my professional development as other in-class activities.” The majority of students (63.2 %; n = 60) selected either “somewhat better” (40 %; n = 38) or far better (23.2 %; n = 22) for, “Regarding quality, I feel the in-class activity was ____ than other in-class activities.”
Conclusions
Most students reported that the ChatGPT-generated activity on social determinants of health was useful, applicable, and somewhat or far better than instructor activities. However, AI can generate incorrect information and potentially hinder student learning of conceptual frameworks; thus, instructors should review all output carefully.}
}
@article{SCHNEPPER2025,
title = {Exploring Biases of Large Language Models in the Field of Mental Health: Comparative Questionnaire Study of the Effect of Gender and Sexual Orientation in Anorexia Nervosa and Bulimia Nervosa Case Vignettes},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/57986},
url = {https://www.sciencedirect.com/science/article/pii/S236879592500037X},
author = {Rebekka Schnepper and Noa Roemmel and Rainer Schaefert and Lena Lambrecht-Walzinger and Gunther Meinlschmidt},
keywords = {anorexia nervosa, artificial intelligence, bulimia nervosa, ChatGPT, eating disorders, LLM, responsible AI, transformer, bias, large language model, gender, vignette, quality of life, symptomatology, questionnaire, generative AI, mental health, AI},
abstract = {Background
Large language models (LLMs) are increasingly used in mental health, showing promise in assessing disorders. However, concerns exist regarding their accuracy, reliability, and fairness. Societal biases and underrepresentation of certain populations may impact LLMs. Because LLMs are already used for clinical practice, including decision support, it is important to investigate potential biases to ensure a responsible use of LLMs. Anorexia nervosa (AN) and bulimia nervosa (BN) show a lifetime prevalence of 1%‐2%, affecting more women than men. Among men, homosexual men face a higher risk of eating disorders (EDs) than heterosexual men. However, men are underrepresented in ED research, and studies on gender, sexual orientation, and their impact on AN and BN prevalence, symptoms, and treatment outcomes remain limited.
Objectives
We aimed to estimate the presence and size of bias related to gender and sexual orientation produced by a common LLM as well as a smaller LLM specifically trained for mental health analyses, exemplified in the context of ED symptomatology and health-related quality of life (HRQoL) of patients with AN or BN.
Methods
We extracted 30 case vignettes (22 AN and 8 BN) from scientific papers. We adapted each vignette to create 4 versions, describing a female versus male patient living with their female versus male partner (2 × 2 design), yielding 120 vignettes. We then fed each vignette into ChatGPT-4 and to “MentaLLaMA” based on the Large Language Model Meta AI (LLaMA) architecture thrice with the instruction to evaluate them by providing responses to 2 psychometric instruments, the RAND-36 questionnaire assessing HRQoL and the eating disorder examination questionnaire. With the resulting LLM-generated scores, we calculated multilevel models with a random intercept for gender and sexual orientation (accounting for within-vignette variance), nested in vignettes (accounting for between-vignette variance).
Results
In ChatGPT-4, the multilevel model with 360 observations indicated a significant association with gender for the RAND-36 mental composite summary (conditional means: 12.8 for male and 15.1 for female cases; 95% CI of the effect –6.15 to −0.35; P=.04) but neither with sexual orientation (P=.71) nor with an interaction effect (P=.37). We found no indications for main effects of gender (conditional means: 5.65 for male and 5.61 for female cases; 95% CI –0.10 to 0.14; P=.88), sexual orientation (conditional means: 5.63 for heterosexual and 5.62 for homosexual cases; 95% CI –0.14 to 0.09; P=.67), or for an interaction effect (P=.61, 95% CI –0.11 to 0.19) for the eating disorder examination questionnaire overall score (conditional means 5.59‐5.65 95% CIs 5.45 to 5.7). MentaLLaMA did not yield reliable results.
Conclusions
LLM-generated mental HRQoL estimates for AN and BN case vignettes may be biased by gender, with male cases scoring lower despite no real-world evidence supporting this pattern. This highlights the risk of bias in generative artificial intelligence in the field of mental health. Understanding and mitigating biases related to gender and other factors, such as ethnicity, and socioeconomic status are crucial for responsible use in diagnostics and treatment recommendations.}
}
@article{TELBANY2025S-318,
title = {1298: COMPARATIVE EFFECTIVENESS OF POTASSIUM-COMPETITIVE ACID BLOCKERS VERSUS PROTON PUMP INHIBITORS IN UPPER GASTROINTESTINAL BLEEDING: A U.S. MULTICENTER PROPENSITY-MATCHED STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01676-2},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016762},
author = {Ahmed Telbany and Abhishek Patel and Evelyn Inga and Pooja Viswanath and Christopher Chang}
}
@article{GE20244017,
title = {Data-augmented landslide displacement prediction using generative adversarial network},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {16},
number = {10},
pages = {4017-4033},
year = {2024},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2024.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1674775524000726},
author = {Qi Ge and Jin Li and Suzanne Lacasse and Hongyue Sun and Zhongqiang Liu},
keywords = {Machine learning (ML), Time series, Generative adversarial network (GAN), Three Gorges reservoir (TGR), Landslide displacement prediction},
abstract = {Landslides are destructive natural disasters that cause catastrophic damage and loss of life worldwide. Accurately predicting landslide displacement enables effective early warning and risk management. However, the limited availability of on-site measurement data has been a substantial obstacle in developing data-driven models, such as state-of-the-art machine learning (ML) models. To address these challenges, this study proposes a data augmentation framework that uses generative adversarial networks (GANs), a recent advance in generative artificial intelligence (AI), to improve the accuracy of landslide displacement prediction. The framework provides effective data augmentation to enhance limited datasets. A recurrent GAN model, RGAN-LS, is proposed, specifically designed to generate realistic synthetic multivariate time series that mimics the characteristics of real landslide on-site measurement data. A customized moment-matching loss is incorporated in addition to the adversarial loss in GAN during the training of RGAN-LS to capture the temporal dynamics and correlations in real time series data. Then, the synthetic data generated by RGAN-LS is used to enhance the training of long short-term memory (LSTM) networks and particle swarm optimization-support vector machine (PSO-SVM) models for landslide displacement prediction tasks. Results on two landslides in the Three Gorges Reservoir (TGR) region show a significant improvement in LSTM model prediction performance when trained on augmented data. For instance, in the case of the Baishuihe landslide, the average root mean square error (RMSE) increases by 16.11%, and the mean absolute error (MAE) by 17.59%. More importantly, the model's responsiveness during mutational stages is enhanced for early warning purposes. However, the results have shown that the static PSO-SVM model only sees marginal gains compared to recurrent models such as LSTM. Further analysis indicates that an optimal synthetic-to-real data ratio (50% on the illustration cases) maximizes the improvements. This also demonstrates the robustness and effectiveness of supplementing training data for dynamic models to obtain better results. By using the powerful generative AI approach, RGAN-LS can generate high-fidelity synthetic landslide data. This is critical for improving the performance of advanced ML models in predicting landslide displacement, particularly when there are limited training data. Additionally, this approach has the potential to expand the use of generative AI in geohazard risk management and other research areas.}
}
@article{UPTEGRAFT2025,
title = {The Elastic Electronic Health Record: A Five-Tiered Framework for Applying Artificial Intelligence to Electronic Health Record Maintenance, Configuration, and Use},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66741},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000407},
author = {Colby Uptegraft and Kameron Collin Black and Jonathan Gale and Andrew Marshall and Shuhan He},
keywords = {semi-autonomous database, back-end EHR, self-configuring database, machine learning, health care, generative artificial intelligence, elastic EHR, electronic record, electronic health record, artificial intelligence, AI, EHR, database},
abstract = {Properly configuring modern electronic health records (EHRs) has become increasingly challenging for human operators, failing to fully meet the efficiency and cost-saving potential seen with the digitization of other sectors. The integration of artificial intelligence (AI) offers a promising solution, particularly through a comprehensive governance approach that moves beyond front-end enhancements such as user- and patient-facing copilots. These copilots, although useful, are limited by the underlying EHR configuration, leading to inefficiencies and high maintenance costs. To address this, we propose the concept of an “Elastic EHR,” which proactively suggests and validates optimal content and configuration changes, significantly reducing governance costs and enhancing user experience, as well as reducing many of the common frustrations including the documentation burden, alert fatigue, system responsiveness, outdated content, and unintuitive design. Our five-tiered model details a structured approach to AI integration within EHRs. Tier I focuses on autonomous database reconfiguration, akin to Oracle Autonomous Database functionalities, to ensure continuous system improvements without direct edits to the production environment. Tier II empowers EHR clients to shape system performance according to predefined strategies and standards, ensuring coordinated and efficient EHR solution builds. Tier III optimizes EHR choice architecture by analyzing user behaviors and suggesting content and configuration changes that minimize clicks and keystrokes, thereby enhancing workflow efficiency. Tier IV maintains the currency of EHR clinical content and decision support by linking content and configuration to updated guidelines and literature, ensuring the EHR remains evidence-based and compliant with evolving standards. Finally, Tier V incorporates context-dependent AI copilots to enhance care efficiency, quality, and user experience. Despite the potential benefits, major limitations exist. The market dominance of a few major EHR vendors—Epic Systems, Oracle Health, and MEDITECH—poses a challenge, as any enhancements require their cooperation and financial motivation. Furthermore, the diverse and complex nature of health care environments demands a flexible yet robust AI system that can adapt to various institutional needs that has not yet been developed, researched, or tested. The Elastic EHR model proposes a five-tiered framework for optimizing EHR systems and user experience with AI. By overcoming the identified limitations through vendor-led, collaborative efforts, AI-enabled EHRs could improve the efficiency, quality, and user experience of health care delivery, fully delivering on the promises of digitization within health care.}
}
@article{ROSSI2025S249,
title = {T.06.1 GENDER-RELATED DIFFERENCES IN CELIAC DISEASE PRESENTATION AND FOLLOW-UP IN ADULT PATIENTS},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S249-S250},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00601-2},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825006012},
author = {R.E. Rossi and B. Masoni and D. {De Deo} and M. Ferraris and G. Franchellucci and C. Hassan and A. Repici}
}
@incollection{2026i,
title = {Titlepage},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {i},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00302-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244003027}
}
@incollection{ARYADOUST2025,
title = {Assessing Listening Skills in SLA},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.01010-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041010103},
author = {Vahid Aryadoust and Yichen Jia},
keywords = {Adaptive listening assessment, Cognitive process, Generative artificial intelligence (GenAI), Listening comprehension assessment, Multimodal listening assessment, Personalized testing, Second language acquisition, Test authenticity, Gen AI, Sensor technology, Text-to-speech, Test development},
abstract = {This entry explores the multifaceted nature of assessing listening comprehension1 within the broader context of language learning including second language acquisition (SLA). It begins with a review of current approaches to assessing listening comprehension skills and then discusses the task types that are prevalent in listening comprehension assessment. The entry then identifies limitations in these practices, including the authenticity of task materials, such as restricted accent variations and the absence of non-verbal visual inputs in some, alongside the “over-standardization” of tests that may fail to accommodate individual learning preferences. To overcome these challenges, we suggest several potential solutions. These include the integration of sensor technologies to enhance the capture of test-takers’ performances beyond traditional ratings, the development of an adaptive assessment system tailored to individual learning trajectories, and the application of Generative AI (GenAI) to create customized listening tasks.}
}
@article{TEJAMAYA2025,
title = {Dynamics of COVID-19 Risk Perception in Indonesia: A Consecutive Cross-sectional Study From 2020 to 2022},
journal = {Safety and Health at Work},
year = {2025},
issn = {2093-7911},
doi = {https://doi.org/10.1016/j.shaw.2025.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2093791125000563},
author = {Mila Tejamaya and Amelia A. Putri and Baiduri Widanarko and I Md Ady Wirawan and Bina Kurniawan and Yahya Thamrin},
keywords = {COVID-19, Indonesia, religion, risk perception, risk tolerance},
abstract = {Background
According to Schneider et al (2021), the perception on COVID-19 risk needs to be assessed longitudinally to understand its persistence and predictors. This stability of this perception helps in designing communication strategies, especially during a pandemic.
Aims
This study aimed to evaluate changes in of Indonesians' risk perceptions toward COVID-19 over a three-year period (2020–2022) and factors associated with the changes.
Methods
A standardized, self-directed online questionnaire developed by Effective Communications in Outbreak Management for Europe was used to assess risk perception and its associated variables.
Results
A total of 2,708 people participated in the survey, which comprised 1,043 participants in 2020, 890 in 2021, and 775 in 2022. Analysis of variance and Tukey's HSD (Honestly Significant Difference) post hoc analysis revealed that risk perception of COVID-19 significantly declined in 2022 compared to previous years. At the same time, risk tolerance—such as readiness, ability to control risk, belief in efficacy, and willingness to implement control measures—peaked. Personal responsibility for protecting one's own health and preventing harm to others was reported as key driver for implementing control measures. Linear regression analysis shows that the sociodemographic variables, namely sex and occupation, consistently influenced risk perception throughout the three-year study (p < 0.05).
Conclusion
Therefore, it is essential to develop a tailored communication strategy for different sexes and occupations.}
}
@article{GOROSPE20251069930,
title = {Eribulin-induced pulmonary toxicity mimicking metastatic lung disease},
journal = {Medicina Clínica (English Edition)},
volume = {165},
number = {1},
pages = {1069930},
year = {2025},
issn = {2387-0206},
doi = {https://doi.org/10.1016/j.medcle.2025.1069930},
url = {https://www.sciencedirect.com/science/article/pii/S2387020625003237},
author = {Luis Gorospe and Cristina Saavedra-Serrano and Noelia Martínez-Jáñez}
}
@article{JANG2024e629,
title = {Hype or Reality: Utility of Large Language Models in Radiation Oncology},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {120},
number = {2, Supplement },
pages = {e629-e630},
year = {2024},
note = {ASTRO 2024: 66th Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2024.07.1386},
url = {https://www.sciencedirect.com/science/article/pii/S0360301624021485},
author = {B.S. Jang and S.R. Alcorn and T.R. McNutt and U. Ehsan},
abstract = {Purpose/Objective(s)
Generative artificial intelligence (AI)–especially large language models (LLMs)–promises to make a profound impact on providers’ productivity and wellness. Algorithmic benchmarks make impressive claims like LLMs having superior bedside manner and diagnostic abilities than providers. But how useful are LLMs for typical tasks in radiation oncology? Do LLMs save time or cognitive burden? How does it impact provider frustration?
Materials/Methods
Using a scenario-based design with a multidisciplinary team (radiation oncologists (RO), AI researcher, and medical physicist) we created four ecologically-situated tasks that would be helpful to an RO– medical decision making (MDM), letter of medical necessity (LOMN), summary of a consult note, summary of a radiology note). Using a diary study method with standardized prompts, we prompted three publicly available LLMs (Bard, BingChat, ChatGPT) for all use cases. The prompts contained deidentified text from patient notes, case details, and radiology reports. All LLMs were prompted on the same date and multiple points across multiple dates to avoid model update confounds. Using an iterative inductive qualitative coding process, we assessed each use case for perceived usefulness according to themes including accuracy, breadth of response, consistency, efficiency, cognitive burden, and frustration.
Results
Across use cases, while LLMs usually produced outputs, the quality of the output, especially for MDM, added more complexity and frustration. Time spent checking for hallucinations increased the overall burden. While LLMs performed well for summarization tasks and produced moderately useful LOMN, efficiency was offset by time required to review output. MDM output lacked breadth of treatment options but also failed to provide patient-specific recommendations. Table 1 summarizes findings. * Prompt character count exceeded † LLM initially refused but later complied after prompt injection.
Conclusion
In four ecology-situated scenarios investigated, utility of LLMs fell below expectations. While summarization tasks were well-performed, cases where the assistance is most useful–such as medical decision-making– the LLMs performed the worst by including overly generalized guidance and hallucinations. This added to the RO’s cognitive burden and frustration. Gains in efficiency where LLMs successfully summarized technical text may be obviated by liability concerns.}
}
@article{WU2025103111,
title = {A survey on the current status of AI literacy lectures in China’s university libraries under the AIGC background},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103111},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103111},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325001077},
author = {Yubing Wu and Yifeng Lin and Yingying Liu and Yuer Yang},
keywords = {Top 40 QS ranking universities, “Double first-class” university, University library, GenAI, AI literacy},
abstract = {This paper selects the top 40 universities in the 2025 QS World University Rankings (including 41 tied universities) and 42 “Double First-Class” university libraries in China as research objects, and conducts an empirical study on their AI literacy lecture training activities (including lectures, seminars, etc.). By combining quantitative statistics (structured data such as activity name, sponsor, audience characteristics, and organizational form) with qualitative analysis (text mining of lecture training content), the current status of AI literacy lecture training in their university libraries is systematically examined. The study found that China’s “Double First-Class” university libraries have the following prominent problems in AI literacy lecture training: the degree of attention and implementation strength are different, the participation of librarians is low, lecture training mainly relies on teachers outside the library, the lecture training content is unbalanced, there is a lack of AI cognition and AI ethics, AI lecture training lacks systematicness, and AI skills education is out of touch with practical applications. Based on an international comparative perspective, the paper proposes eight optimization strategies: Strengthen the emphasis and implementation of AI literacy lecture training, provide continuous AI literacy lecture training for librarians and strengthen the construction of AI-Literate librarians, improve AI lecture training content and strengthen AI cognition and AI ethics education, establishing the AI workshop series: achieving systematic and comprehensive craining, increase AI practice components, holding GenAI research cafe, and cooperate with multiple institutions to organize AI lecture training, in order to provide practical reference for the innovative development of AI literacy education system in university libraries around the world.}
}
@article{HE2024,
title = {Quality of Answers of Generative Large Language Models Versus Peer Users for Interpreting Laboratory Test Results for Lay Patients: Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/56655},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124001912},
author = {Zhe He and Balu Bhasuran and Qiao Jin and Shubo Tian and Karim Hanna and Cindy Shavor and Lisbeth Garcia Arguello and Patrick Murray and Zhiyong Lu},
keywords = {large language models, generative artificial intelligence, generative AI, ChatGPT, laboratory test results, patient education, natural language processing},
abstract = {Background
Although patients have easy access to their electronic health records and laboratory test result data through patient portals, laboratory test results are often confusing and hard to understand. Many patients turn to web-based forums or question-and-answer (Q&A) sites to seek advice from their peers. The quality of answers from social Q&A sites on health-related questions varies significantly, and not all responses are accurate or reliable. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to have their questions answered.
Objective
We aimed to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to laboratory test–related questions asked by patients and identify potential issues that can be mitigated using augmentation approaches.
Methods
We collected laboratory test result–related Q&A data from Yahoo! Answers and selected 53 Q&A pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from 5 LLMs: GPT-4, GPT-3.5, LLaMA 2, MedAlpaca, and ORCA_mini. We assessed the similarity of their answers using standard Q&A similarity-based evaluation metrics, including Recall-Oriented Understudy for Gisting Evaluation, Bilingual Evaluation Understudy, Metric for Evaluation of Translation With Explicit Ordering, and Bidirectional Encoder Representations from Transformers Score. We used an LLM-based evaluator to judge whether a target model had higher quality in terms of relevance, correctness, helpfulness, and safety than the baseline model. We performed a manual evaluation with medical experts for all the responses to 7 selected questions on the same 4 aspects.
Results
Regarding the similarity of the responses from 4 LLMs; the GPT-4 output was used as the reference answer, the responses from GPT-3.5 were the most similar, followed by those from LLaMA 2, ORCA_mini, and MedAlpaca. Human answers from Yahoo data were scored the lowest and, thus, as the least similar to GPT-4–generated answers. The results of the win rate and medical expert evaluation both showed that GPT-4’s responses achieved better scores than all the other LLM responses and human responses on all 4 aspects (relevance, correctness, helpfulness, and safety). LLM responses occasionally also suffered from lack of interpretation in one’s medical context, incorrect statements, and lack of references.
Conclusions
By evaluating LLMs in generating responses to patients’ laboratory test result–related questions, we found that, compared to other 4 LLMs and human answers from a Q&A website, GPT-4’s responses were more accurate, helpful, relevant, and safer. There were cases in which GPT-4 responses were inaccurate and not individualized. We identified a number of ways to improve the quality of LLM responses, including prompt engineering, prompt augmentation, retrieval-augmented generation, and response evaluation.}
}
@article{WAKEFIELD2025104694,
title = {Artificial intelligence in prediction of postpartum hemorrhage: a primer and review},
journal = {International Journal of Obstetric Anesthesia},
volume = {63},
pages = {104694},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2025.104694},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X25002869},
author = {B.M. Wakefield and M.A. Zapf and H.B. Ende},
keywords = {Artificial Intelligence, Postpartum hemorrhage, Electronic Health Record, Risk Assessment, Machine Learning},
abstract = {Postpartum hemorrhage (PPH) is a leading cause of maternal mortality worldwide, and the ability to predict PPH may help address preventable causes of morbidity and mortality such as delays in care. Understanding the importance of standardized approaches to PPH, the National Partnership for Maternal Safety Consensus Bundle on Obstetric Hemorrhage outlines four critical domains for safe and effective PPH care: 1) Readiness; 2) Recognition and Prevention; 3) Response; and 4) Reporting and System Learning. The Recognition and Prevention domain includes recommendations for standardized methods of PPH risk prediction, and The Joint Commission now requires use of an evidence-based PPH prediction tool. Postpartum hemorrhage risk predictions can be accomplished via checklist tools completed manually by healthcare providers or via machine-assisted calculations in the form of logistic regression or machine learning populated by automated electronic health record data. The latter examples of machine-assisted calculations of PPH risk are a form of artificial intelligence. The purpose of this review is to describe the current state of AI-based PPH risk assessment, including the application of logistic regression and machine learning. A primer on interpretation of such models is provided, along with identification of research gaps and future directions.}
}
@article{FREEMAN2025102868,
title = {Adolescents' Trust in Health Information in an Evolving Social Media Landscape},
journal = {Academic Pediatrics},
volume = {25},
number = {7},
pages = {102868},
year = {2025},
issn = {1876-2859},
doi = {https://doi.org/10.1016/j.acap.2025.102868},
url = {https://www.sciencedirect.com/science/article/pii/S1876285925000932},
author = {Jaimie L. Freeman and Patrina H.Y. Caldwell and Karen M. Scott},
keywords = {adolescent, health education, health literacy, information seeking behavior, internet}
}
@article{PATEL2025102296,
title = {Patient-centered reporting: Should this become the new standard?},
journal = {Journal of Nuclear Cardiology},
volume = {51},
pages = {102296},
year = {2025},
issn = {1071-3581},
doi = {https://doi.org/10.1016/j.nuclcard.2025.102296},
url = {https://www.sciencedirect.com/science/article/pii/S1071358125001709},
author = {Krishna K. Patel and John A. Spertus},
keywords = {Patient-centered reporting, Myocardial perfusion imaging, Reporting}
}
@article{FLEURENCE2024692,
title = {Assessing Real-World Data From Electronic Health Records for Health Technology Assessment: The SUITABILITY Checklist: A Good Practices Report of an ISPOR Task Force},
journal = {Value in Health},
volume = {27},
number = {6},
pages = {692-701},
year = {2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S109830152400069X},
author = {Rachael L. Fleurence and Seamus Kent and Blythe Adamson and James Tcheng and Ran Balicer and Joseph S. Ross and Kevin Haynes and Patrick Muller and Jon Campbell and Elsa Bouée-Benhamiche and Sebastián {García Martí} and Scott Ramsey},
keywords = {data quality, electronic health records, health technology assessment, real-world data, real-world evidence},
abstract = {This ISPOR Good Practices report provides a framework for assessing the suitability of electronic health records data for use in health technology assessments (HTAs). Although electronic health record (EHR) data can fill evidence gaps and improve decisions, several important limitations can affect its validity and relevance. The ISPOR framework includes 2 components: data delineation and data fitness for purpose. Data delineation provides a complete understanding of the data and an assessment of its trustworthiness by describing (1) data characteristics; (2) data provenance; and (3) data governance. Fitness for purpose comprises (1) data reliability items, ie, how accurate and complete the estimates are for answering the question at hand and (2) data relevance items, which assess how well the data are suited to answer the particular question from a decision-making perspective. The report includes a checklist specific to EHR data reporting: the ISPOR SUITABILITY Checklist. It also provides recommendations for HTA agencies and policy makers to improve the use of EHR-derived data over time. The report concludes with a discussion of limitations and future directions in the field, including the potential impact from the substantial and rapid advances in the diffusion and capabilities of large language models and generative artificial intelligence. The report’s immediate audiences are HTA evidence developers and users. We anticipate that it will also be useful to other stakeholders, particularly regulators and manufacturers, in the future.}
}
@article{GOROSPE2025510,
title = {Why do Artificial-Intelligence Based Chest Radiograph Applications Ignore the Lateral View?},
journal = {Archivos de Bronconeumología},
volume = {61},
number = {8},
pages = {510-511},
year = {2025},
issn = {0300-2896},
doi = {https://doi.org/10.1016/j.arbres.2025.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0300289625001139},
author = {Luis Gorospe}
}
@article{GOROSPE2025106993,
title = {Eribulin-induced pulmonary toxicity mimicking metastatic lung disease},
journal = {Medicina Clínica},
volume = {165},
number = {1},
pages = {106993},
year = {2025},
issn = {0025-7753},
doi = {https://doi.org/10.1016/j.medcli.2025.106993},
url = {https://www.sciencedirect.com/science/article/pii/S0025775325002210},
author = {Luis Gorospe and Cristina Saavedra-Serrano and Noelia Martínez-Jáñez}
}
@article{CHEN2024,
title = {EyeGPT for Patient Inquiries and Medical Education: Development and Validation of an Ophthalmology Large Language Model},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60063},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124009361},
author = {Xiaolan Chen and Ziwei Zhao and Weiyi Zhang and Pusheng Xu and Yue Wu and Mingpu Xu and Le Gao and Yinwen Li and Xianwen Shang and Danli Shi and Mingguang He},
keywords = {large language model, generative pretrained transformer, generative artificial intelligence, ophthalmology, retrieval-augmented generation, medical assistant, EyeGPT, generative AI},
abstract = {Background
Large language models (LLMs) have the potential to enhance clinical flow and improve medical education, but they encounter challenges related to specialized knowledge in ophthalmology.
Objective
This study aims to enhance ophthalmic knowledge by refining a general LLM into an ophthalmology-specialized assistant for patient inquiries and medical education.
Methods
We transformed Llama2 into an ophthalmology-specialized LLM, termed EyeGPT, through the following 3 strategies: prompt engineering for role-playing, fine-tuning with publicly available data sets filtered for eye-specific terminology (83,919 samples), and retrieval-augmented generation leveraging a medical database and 14 ophthalmology textbooks. The efficacy of various EyeGPT variants was evaluated by 4 board-certified ophthalmologists through comprehensive use of 120 diverse category questions in both simple and complex question-answering scenarios. The performance of the best EyeGPT model was then compared with that of the unassisted human physician group and the EyeGPT+human group. We proposed 4 metrics for assessment: accuracy, understandability, trustworthiness, and empathy. The proportion of hallucinations was also reported.
Results
The best fine-tuned model significantly outperformed the original Llama2 model at providing informed advice (mean 9.30, SD 4.42 vs mean 13.79, SD 5.70; P<.001) and mitigating hallucinations (97/120, 80.8% vs 53/120, 44.2%, P<.001). Incorporating information retrieval from reliable sources, particularly ophthalmology textbooks, further improved the model's response compared with solely the best fine-tuned model (mean 13.08, SD 5.43 vs mean 15.14, SD 4.64; P=.001) and reduced hallucinations (71/120, 59.2% vs 57/120, 47.4%, P=.02). Subgroup analysis revealed that EyeGPT showed robustness across common diseases, with consistent performance across different users and domains. Among the variants, the model integrating fine-tuning and book retrieval ranked highest, closely followed by the combination of fine-tuning and the manual database, standalone fine-tuning, and pure role-playing methods. EyeGPT demonstrated competitive capabilities in understandability and empathy when compared with human ophthalmologists. With the assistance of EyeGPT, the performance of the ophthalmologist was notably enhanced.
Conclusions
We pioneered and introduced EyeGPT by refining a general domain LLM and conducted a comprehensive comparison and evaluation of different strategies to develop an ophthalmology-specific assistant. Our results highlight EyeGPT’s potential to assist ophthalmologists and patients in medical settings.}
}
@article{CHEN2025106206,
title = {State, society, and market: Interpreting the norms and dynamics of China's AI governance},
journal = {Computer Law & Security Review},
volume = {59},
pages = {106206},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106206},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000781},
author = {Xuechen Chen and Lu Xu},
keywords = {AI governance, Digital governance, China, Legal frameworks, Content regulation, Minor protection, Algorithmic regulation, Norms},
abstract = {This study challenges the prevailing perception of China's AI governance as a monolithic, state-driven model and instead presents a nuanced analysis of its complex governance landscape. Utilizing governance theories, we develop an analytical framework examining key governing nodes, tools, actors, and norms. Through case studies on minor protection and content regulation, this study demonstrates that Chinese AI governance involves a diverse array of stakeholders—including the state, private sector, and society—who co-produce norms and regulatory mechanisms. Contrary to conventional narratives, China's governance approach adapts existing regulatory tools to meet new challenges, balancing political, social, and economic interests. This study highlights how China has rapidly formalized AI regulations, in areas such as minor protection and content regulation, setting a precedent in global AI governance. The findings contribute to a broader understanding of AI regulation beyond ideological binaries and offer insights relevant to international AI policy discussions.}
}
@article{SMITH20241,
title = {Guest editorial: Artificial intelligence and composing just education futures},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {1-5},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-04-2024-202},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000116},
author = {Anna Smith and Jennifer Higgs and José Ramón Lizárraga and Vaughn W.M. Watson}
}
@article{FIGUEIREDO2025,
title = {Hypertrophic cardiomyopathy with sequential intracavitary obstruction resolved by mavacamten},
journal = {Revista Española de Cardiología (English Edition)},
year = {2025},
issn = {1885-5857},
doi = {https://doi.org/10.1016/j.rec.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1885585725002245},
author = {Margarida G. Figueiredo and José Miguel Viegas and Sílvia {Aguiar Rosa}}
}
@article{NORDLINGER2024536,
title = {Rapport 24-03. Systèmes d’IA générative en santé : enjeux et perspectives},
journal = {Bulletin de l'Académie Nationale de Médecine},
volume = {208},
number = {5},
pages = {536-547},
year = {2024},
issn = {0001-4079},
doi = {https://doi.org/10.1016/j.banm.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001407924000943},
author = {Bernard Nordlinger and Claude Kirchner and Olivier {de Fresnoye}},
abstract = {Résumé
La santé est un des domaines majeurs d’application des technologies dites d’intelligence artificielle. Tous les domaines de la santé et toutes les spécialités sont concernés. Les systèmes d’intelligence artificielle générative (SIAgen) impressionnent par leur capacité à produire en quelques secondes des textes souvent pertinents, mais aussi parfois erronés. Leurs champs d’applications dans le domaine de la santé sont vastes et peuvent aller de l’aide à la rédaction de notes d’information à la rédaction de thèses ou de projets de programme de recherche. Pour les utiliser à bon escient il est important d’en connaître les principes de fonctionnement. Les SIAgen fonctionnent à partir d’auto-apprentissage basé sur un nombre extrêmement élevé d’exemples, ce qui est très différent de l’approche humaine, qui s’appuie sur l’expérience, le contexte et un système de valeurs. Ils génèrent des textes avec une grande rapidité mais ne sont pas entraînés à rechercher ou à dire la vérité. Une validation humaine est donc toujours nécessaire. Par ce rapport, l’Académie nationale de médecine explicite plusieurs de ces avancées pour la santé, décrit les enjeux d’éthique associés et recommande des points d’actions à mettre en œuvre sans délai.
Summary
Healthcare is one of the major application fields of Artificial Intelligence technologies. All areas of healthcare and all specialties are concerned. Generative Artificial Intelligence systems are impressive in their ability to produce texts in a matter of seconds, often relevant, but sometimes erroneous. They can be used in a wide range of healthcare applications, from helping to write briefing notes to drafting theses and research programs. To use them properly, it is important to understand how they work. Large Language Models use neural networks trained on massive amounts of text data, which is very different from the human, experience-based approach. They generate language but are not trained to tell or search for the truth. Human validation is therefore always necessary. Through this report, the Académie nationale de médecine explains the resulting progress and discoveries for health, describes associated ethical issues and recommends action points to be implemented without delay.}
}
@article{2024A2,
title = {Table of Contents},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {A2-A3},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/S0039-6257(24)00089-4},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000894}
}
@article{RIZZO2025162753,
title = {The use of the Acellular Dermal Matrix in Microtia Reconstruction to decrease donor site morbidity after temporo-parietal fascia harvest},
journal = {Journal of Pediatric Surgery},
pages = {162753},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162753},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825006001},
author = {Maria Ida Rizzo and Jacopo Maria Frattaroli and Francesca Nascimben and Marco Cirillo and Marta Umbaca and Marta Cajozzo and Gaetano Paolo Dicorato and Francesca Grussu and Rossella Angotti and Simone Faustino Marino and Francesco Molinaro and Giorgio Spuntarelli and Urbano Urbani and Mario Zama},
keywords = {Microtia, Ear reconstruction, Temporal fascia flap, Acellular dermal matrix (ADM)},
abstract = {Purpose
To determine whether and how the use of an acellular dermal matrix (ADM) underneath a scalp flap after temporal fascia harvest reduces postoperative donor-site complications in microtia surgery.
Methods
This case‒control study included patients with congenital microtia who underwent primary ear reconstruction with porous polyethylene implants between 2018 and 2021. Group No-ADM patients (2018–2019), Group ADM patients (2020–2021). The skin quality outcomes of the scalp flap after temporal fascia harvest were analysed through pinch tests and ultrasound imaging. Aesthetical and psychosocial outcomes were tested with standardized questionnaires that were administered to the patients and their parents.
Results
20 patients (60% male), 8 (40%) in the No-ADM group and 12 (60%) in the ADM group. Re-do surgery rate was higher in the No-ADM group than in the ADM group (17.5% vs 5%; p<0.05). The pinch test was used to assess the recovery of tissue elasticity in the 100% ADM group, and it was negative in the 75% No-ADM group (p <0.05). The median US thickness was 4.87 mm in the No-ADM group and 4.48 mm in the ADM group (p=0.37). Aesthetic analysis revealed higher satisfaction levels among patients in the ADM group than in those in the non-ADM group. There was no significant difference in terms of quality of life between the two groups.
Conclusions
ADM use decreases local morbidity after facial harvest in the temporoparietal region. The greater thickness of the skin in the No-ADM group despite the absence of the ADM was probably due to greater fibrogenesis, which was limited by the ADM in the ADM group. In conclusion, ADM reduces the risk of postoperative subcutaneous scar adhesions.}
}
@article{SAPKOTA2024100614,
title = {Synthetic meets authentic: Leveraging LLM generated datasets for YOLO11 and YOLOv10-based apple detection through machine vision sensors},
journal = {Smart Agricultural Technology},
volume = {9},
pages = {100614},
year = {2024},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2024.100614},
url = {https://www.sciencedirect.com/science/article/pii/S2772375524002193},
author = {Ranjan Sapkota and Zhichao Meng and Manoj Karkee},
keywords = {Large language model, YOLO11, YOLOv10, Generative artificial intelligence, Text-to-image generation, Machine learning, Deep learning, YOLO, You Only Look Once, LLM},
abstract = {Training machine learning (ML) models for artificial intelligence (AI) and computer vision-based object detection process typically requires large, labeled datasets, a process often burdened by significant human effort and high costs associated with imaging systems and image acquisition. This research aimed to simplify image data collection for object detection in orchards by avoiding traditional fieldwork with different imaging sensors. Utilizing OpenAI's DALLE, a large language model (LLM) for realistic image generation, we generated and annotated a cost-effective dataset. This dataset, exclusively generated by LLM, was then utilized to train two state-of-the-art deep learning models: YOLOV10 and YOLO11. The YOLO11 model for apple detection was trained with its five configurations (YOLO11n, YOLO11 s, YOLO11 m, YOLO11l and YOLO11x), and YOLOv10 model with its six configurations (YOLOv10n, YOLOv10 s, YOLOv10 m, YOLOv10b, YOLOv10l and YOLOv10x), which was then tested with real-world (outdoor orchard) images captured by a digital (Nikon D5100) camera and a consumer RGB-D camera (Microsoft Azure Kinect). YOLO11 outperformed YOLOv10 as YOLO11x and YOLO11n exhibited superior precision of 0.917 and 0.916, respectively. Furthermore, YOLO11l demonstrated the highest recall among its counterparts, achieving a recall of 0.889. Likewise, the YOLO11n variant excelled in terms of mean average precision (mAP@50), achieving the highest value of 0.958. Validation tests against actual images collected through a digital camera (Nikon D5100) over Scilate apple variety in a commercial orchard environment showed a highest precision of 0.874 for YOLO11 s, recall of 0.877 for YOLO11l and mAP@50 of 0.91 for YOLO11x. Additionally, validation test against actual images collected through a Microsoft Azure camera over the same orchard showed a highest precision, recall and mAP@50 respectively of 0.924, 0.781 and 0.855 with YOLO11x. All variants of YOLO11 surprisingly demonstrated a pre-processing time of just 0.2 milliseconds (ms), which was faster than any variant of YOLOv10. The fastest inference time for the YOLO11n model using the training dataset generated by the language model was 3.2 ms, while YOLOv10n, fastest among YOLOv10 variants, had a longer inference time of 5.5 ms. Likewise, the fastest inference time for the sensor-based images was 7.1 ms (for Nikon D5100 camera images) and 4.7 ms (for Azure images) with YOLO11n. This study presents a pathway for generating large image datasets using LLM in challenging agricultural fields with minimal or no labor-intensive efforts in field data-collection, which could accelerate the development and deployment of computer vision and robotic technologies in orchard environments.}
}
@article{MIRAPALOMINO2025100485,
title = {Pulmonary Nocardiosis in a Patient With COPD and Bronchiectasis},
journal = {Open Respiratory Archives},
volume = {7},
number = {4},
pages = {100485},
year = {2025},
issn = {2659-6636},
doi = {https://doi.org/10.1016/j.opresp.2025.100485},
url = {https://www.sciencedirect.com/science/article/pii/S265966362500089X},
author = {Carmen {Mira Palomino} and Mónica {Babiano Nodal} and Beatriz {Raboso Moreno}},
keywords = {Nocardia, Bronchiectasis, COPD, Opportunistic infection, Nocardia, Bronquiectasias, EPOC, Infecciones oportunistas},
abstract = {Pulmonary nocardiosis is a rare opportunistic infection, often misdiagnosed due to its subacute onset and non-specific clinical and radiological findings. We report an 82-year-old man with severe chronic obstructive pulmonary disease (COPD) and bilateral bronchiectasis, who presented with progressive dyspnoea and productive cough unresponsive to conventional antibiotic therapy. Nocardia pneumoniae was isolated from bronchoalveolar lavage at ≥104CFU/mL. Initial treatment with trimethoprim–sulfamethoxazole (TMP–SMX) was discontinued due to renal impairment and electrolyte disturbances; minocycline was initiated with good tolerance and complete radiological resolution after six months. This case highlights the need to suspect nocardiosis in COPD and bronchiectasis patients, even without classical immunosuppression, particularly after repeated corticosteroid courses. Early diagnosis, communication with the microbiology laboratory, and targeted antibiotic therapy are key to improving outcomes.
Resumen
La nocardiosis pulmonar es una infección oportunista poco frecuente, que a menudo se diagnostica erróneamente debido a su inicio subagudo, y a la inespecificidad de sus hallazgos clínicos y radiológicos. Presentamos el caso de un varón de 82 años con enfermedad pulmonar obstructiva crónica (EPOC) grave y bronquiectasias bilaterales, que acudió por disnea progresiva y tos productiva, sin respuesta a la antibioterapia convencional. Se aisló Nocardia pneumoniae en lavado broncoalveolar con una concentración≥104UFC/ml. El tratamiento inicial con trimetoprim-sulfametoxazol (TMP-SMX) se suspendió por deterioro de la función renal y alteraciones hidroelectrolíticas; se inició tratamiento con minociclina con buena tolerancia y resolución radiológica completa a los 6 meses. Este caso subraya la necesidad de sospechar nocardiosis en los pacientes con EPOC y bronquiectasias, incluso en ausencia de inmunosupresión clásica, especialmente tras cursos repetidos de corticoides. El diagnóstico precoz, la comunicación con el laboratorio de microbiología y la antibioterapia dirigida son claves para mejorar el pronóstico.}
}
@article{GARCIAIBOR2025,
title = {Reversible syphilitic ellipsoiditis},
journal = {Archivos de la Sociedad Española de Oftalmología (English Edition)},
year = {2025},
issn = {2173-5794},
doi = {https://doi.org/10.1016/j.oftale.2025.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S2173579425001690},
author = {F. {Garcia Ibor} and N. {Ruiz del Rio} and A. {Caro Ortega}}
}
@article{REINA20252096,
title = {ABS0878 INTERSTITIAL LUNG DISEASE IN PRIMARY SJÖGREN SYNDROME: PATHOCHRONY, SERONEGATIVE CASES, AND RISK OF PROGRESSIVE PULMONARY FIBROSIS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2096-2097},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1701},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037549},
author = {D. Reina and P. Estrada and D. Roig-Vilaseca and D. Cerdà and V. Navarro and O. Camacho and S. Heredia and M. López-Gómez and S. García and P. Vidal-Montal and P. {Maymo Paituvi} and M. Aguilar-Coll and F.J. {Narváez Garcia}},
keywords = {Descriptive Studies, Lungs, Imaging, Autoantibodies},
abstract = {Background:
Sjögren's disease (SjD) is a chronic inflammatory autoimmune disorder that primarily affects exocrine glands, with interstitial lung disease (ILD) being a significant extraglandular complication. ILD in SjD is associated with substantial morbidity and can complicate patient outcomes. Both rheumatologists and pulmonologists need to better understand this SjD manifestation in order to improve its management.
Objectives:
To examine the main characteristics and clinical course of a cohort of patients with pSS-ILD, specifically evaluating the proportion of cases progressing to pulmonary progressive fibrosis (PPF).
Methods:
Multicenter longitudinal, retrospective, observational study on a cohort of pSS-ILD patients confirmed by thoracic HRCT. In all cases, the diagnosis of pSS was confirmed by either anti-SSA/Ro positivity or a positive salivary gland biopsy or ultrasound (grade 2 or 3 according to the OMERACT SG US task force group definitions).
Results:
Forty-five patients (91% women) were included, with a mean age at ILD diagnosis of 67 years (SD: 11). Their main characteristics are summarised in Table 1. In 78% of cases (35/45), ILD preceded the diagnosis of pSS by a median of 8 months (IQR 25th–75th: 4–17 months). In the remaining 22% (10/45), ILD appeared as a complication after the diagnosis of pSS, with a median interval of 48 months (IQR 25th–75th: 21–64.5). Anti-SSA/Ro antibodies were positive in 38% of cases with available data (16/42), while anti-SSB/La antibodies were positive in 24.5% (11/45). Both antibodies were negative in 38% of patients (17/45). Based on radiological findings, 26 cases (58%) corresponded to nonspecific interstitial pneumonia (NSIP) (14 with a fibrotic subtype), 6 (13%) to usual interstitial pneumonia (UIP), 9 (20%) to organizing pneumonia (OP) or NSIP superimposed with OP, and the remaining 4 (9%) to lymphocytic interstitial pneumonia (LIP). Concomitant follicular bronchiolitis was present in 38% of patients (17/45). At the time of ILD diagnosis, the mean %pFVC was 84.4 ± 21.5 (IQR 70.8–101.7), the mean %pDLCO was 62.2 ± 17.3 (IQR 25th–75th: 48–76), and the mean distance covered in the 6MWT was 371 ± 114 m (IQR 306–422). The mean ESSDAI score was 12 (SD: 5; IQR 25th–75th: 7–16). Treatments included glucocorticoids in 77% of patients (33/43; mean initial dose of prednisone: 32 ± 14 mg/day), immunosuppressants in 77% (33/43; mycophenolate in 31 and azathioprine in 2), and biologic agents in 28% (12/43; rituximab in 11 and abatacept in 1). Antifibrotic agents (nintedanib or pirfenidone) were added in 26% (10/43) of patients due to progression to progressive pulmonary fibrosis (PPF). After a median follow-up of 56 months since ILD diagnosis (IQR 25th–75th: 30–84), 24% of patients (11/45) required oxygen therapy at their last evaluation due to the development of chronic respiratory failure, 4% (2/45) were referred for lung transplantation, and 18% (8/45) died due to ILD progression and infectious complications.
Conclusion:
In 78% of our cases, ILD was either the presenting symptom or the predominant manifestation that led to the diagnosis of pSS. This condition should be considered in patients with ILD and sicca syndrome, even in the absence of characteristic antibodies, as 38% of our cases were seronegative. At least 26% of patients progressed to PPF, requiring antifibrotic treatment.
REFERENCES:
Byrne L, et al. Semin Respir Crit Care Med. 2024 Jun;45(3):397-410. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{KWON2024114570,
title = {Sentiment analysis of the United States public support of nuclear power on social media using large language models},
journal = {Renewable and Sustainable Energy Reviews},
volume = {200},
pages = {114570},
year = {2024},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2024.114570},
url = {https://www.sciencedirect.com/science/article/pii/S136403212400296X},
author = {O. Hwang Kwon and Katie Vu and Naman Bhargava and Mohammed I. Radaideh and Jacob Cooper and Veda Joynt and Majdi I. Radaideh},
keywords = {Sentiment analysis, Natural language processing, Nuclear power, Public policy, Social media, Large language models},
abstract = {This study utilized large language models (LLMs) to analyze public sentiment in the United States (US) regarding nuclear power on social media, focusing on X/Twitter, considering climate change challenges and advancements in nuclear power technology. Approximately, 1.26 million nuclear tweets from 2008–2023 were examined to fine-tune LLMs for sentiment classification. We found the crucial role of accurate data labeling for model performance, with potential implications for a 15% improvement, achieved through high-confidence labels. LLMs demonstrated better performance compared to traditional machine learning classifiers, with reduced susceptibility to overfitting and up to 96% classification accuracy. LLMs are used to segment the US public tweets into policy and energy-related categories, revealing that 68% are politically themed. Policy tweets tended to convey negative sentiment, often reflecting opposing political perspectives and focusing on nuclear deals and international relations. Energy-related tweets covered diverse topics with predominantly neutral to positive sentiment, indicating broad support for nuclear power in 48 out of 50 US states. The US public positive sentiments toward nuclear power stemmed from its high power density, reliability regardless of weather conditions, environmental benefits, application versatility, and recent innovations and advancements in both fission and fusion technologies. Negative sentiments primarily focused on waste management, high capital costs, and safety concerns. The neutral campaign highlighted global nuclear facts and advancements, with varying tones leaning towards positivity or negativity. An interesting neutral theme was the advocacy for the combined use of renewable and nuclear energy to attain net-zero goals.}
}
@article{JONEK20251033,
title = {LLM-based design process for manual assembly},
journal = {Procedia CIRP},
volume = {136},
pages = {1033-1038},
year = {2025},
note = {35th CIRP Design 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.08.175},
url = {https://www.sciencedirect.com/science/article/pii/S221282712500928X},
author = {Michael Jonek and Alexander Gerlach and Martin Manns},
keywords = {Type your keywords here, separated by semicolons},
abstract = {In times of increasing demand for flexible manufacturing, efficient and flexible design processes are crucial for companies in high-wage countries. Therefore, this work deals with the potential of Large Language Models (LLMs) for the creation of assembly instructions based on an assembly design. To evaluate this potential, we present an evaluation method that assesses the contextual accuracy of a set of assembly instructions. The method provides a measure consisting of the three components of correct assembly sequence of components, correct assembly operations and correct positions. To validate the method, we create 50 variants of a sample assembly, simulate them in the CATIA Delmia assembly simulation environment and generated assembly instructions using a ChatGPT-based RAG model. With the proposed evaluation method, the generated assembly instructions are evaluated for contextual correctness and unambiguity and compared with each other. The results show that our evaluation method for AI-generated assembly instructions is a good first indicator to evaluate the quality in terms of contextual correctness. It also shows that LLMs have the potential with the necessary input and fine-tuning to automate the assembly instruction process.}
}
@article{SAEED2025101260,
journal = {Journal of Second Language Writing},
volume = {70},
pages = {101260},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101260},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000852},
author = {Murad Abdu Saeed}
}
@article{HOU2025100559,
title = {DeepSeek R1 excels in diagnosing previously misdiagnosed cases},
journal = {Array},
volume = {28},
pages = {100559},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100559},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625001869},
author = {Chuandong Hou and Haojun Zhang and Peng Zhao and Jinqi Lu and Jie Geng and Hongyi Li and Xin Sun and Tiantian He and Hui Zhang and Yujie Tang and Lizhong Zhang and Yibo Xi and Chenghui Li and Chumeng Gao and Xuechun Lu},
keywords = {Artificial intelligence, Misdiagnose, DeepSeek, Large language model, Diagnostic errors, Diagnostic excellence},
abstract = {Misdiagnosis remains a critical challenge in clinical practice, particularly in complex cases. While artificial intelligence (AI) has shown promise in medical diagnostics, its capability to rectify previously misdiagnosed cases has not been thoroughly examined. This study evaluates the diagnostic performance of five AI models—DeepSeek R1, ChatGPT-4o, Claude 3.5 Sonnet, Gemini 2.0 Flash, and Meta Llama 3.3—using misdiagnosed cases from the China Clinical Case Database. Each model generated ten ranked differential diagnoses per case, and accuracy was scored from 10 (correct diagnosis ranked first) to 0 (not in the top 10). The models' diagnostic performance was compared across disease categories, and inter-model agreement was assessed using Cohen's Kappa. Among 227 analyzed cases, DeepSeek R1 achieved the highest diagnostic accuracy (65.6 %), followed by Claude 3.5 Sonnet (61.2 %), Gemini 2.0 Flash (59.0 %), GPT-4o (39.6 %), and Meta Llama 3.3 (36.1 %). DeepSeek R1 also showed the strongest agreement with Gemini 2.0 Flash (κ = 0.561, 95 % CI: 0.449–0.673). These results indicate that DeepSeek R1 excels in identifying and correcting misdiagnosed cases and highlight the potential of AI models to improve diagnostic accuracy in complex clinical scenarios, emphasizing the importance of model selection in AI-assisted diagnosis.}
}
@article{ZHU2024103800,
title = {Automatic video analytics in tourism: A methodological review},
journal = {Annals of Tourism Research},
volume = {108},
pages = {103800},
year = {2024},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2024.103800},
url = {https://www.sciencedirect.com/science/article/pii/S016073832400077X},
author = {Jingjie Zhu and Mingming Cheng},
keywords = {Video analytics, Video features, Critical review, Destination videos, Travel vlogs, Video analytic framework},
abstract = {While there has been a growing interest in adopting videos as a data source, the use of video analytics, as a method, in gaining deep insights into tourism and hospitality theories and practices is still in its infancy. This study provides a critical review of the progress of automatic video analytics in tourism and hospitality and a guiding framework by detailing theoretical and methodological issues with this new form of knowledge production. The research offers a blueprint for future tourism research endeavors tapping into the potential of videos as a data source.}
}
@article{JOSHI2025100317,
title = {Harnessing the potential of generative AI in digital marketing using the Behavioral Reasoning Theory approach},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100317},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100317},
url = {https://www.sciencedirect.com/science/article/pii/S266709682400106X},
author = {Sujata Joshi and Sonali Bhattacharya and Pankaj Pathak and N.A. Natraj and Juhi Saini and Soumya Goswami},
keywords = {Generative AI (GAI), Digital marketing, Customer experience, Personalization, ChatGPT, Behavioral Reasoning Theory (BRT)},
abstract = {Generative AI (GAI) is an upcoming field and its impact on marketing is indisputable. Very little evidence in academic literature is present regarding the factors affecting the usage of GAI in Digital Marketing (DM). This study addresses this gap by exploring the key drivers and barriers associated with using GAI in DM. Leveraging Behavioral Reasoning Theory (BRT), the research validates prior findings and introduces a conceptual model outlining factors that shape attitudes toward adopting GAI in DM to enhance customer experiences. A qualitative inductive approach was undertaken by conducting expert interviews to investigate the “reasons for” and ‘reasons against’ using GAI in DM and its impact on customer experience. The transcripts generated were manually coded and a deductive thematic analysis was done using the BRT as the theoretical framework. The findings indicate four significant themes for adopting GAI in digital marketing viz: innovation, creative communication and content creation, speed, efficiency and timesaving, enhanced customization and personalization; predictive analytics and simulation. It also indicates five significant themes related to the key barriers were also identified viz: ethics and infringement of Intellectual Property; security and deepfake; learning ecosystem for the adoption of new technology; quality of data; reduced manpower requirement. The study further highlights how GAI influences customer experience in DM. This study contributes to the field by (a) proposing a conceptual framework for applying GAI in DM to improve customer experiences, (b) examining the drivers and challenges of GAI adoption in DM, and (c) presenting a research agenda to guide future studies. These insights offer value to researchers, marketing practitioners, and academics navigating the dynamic intersection of GAI and Digital Marketing}
}
@article{2025A10,
title = {Editors' Selections From This Issue},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {106},
number = {1},
pages = {A10},
year = {2025},
issn = {0003-9993},
doi = {https://doi.org/10.1016/S0003-9993(24)01377-7},
url = {https://www.sciencedirect.com/science/article/pii/S0003999324013777}
}
@article{MCKAY2025S76,
title = {53.2 Generative AI in Psychotherapy: Expanding Access, Personalization, and Engagement},
journal = {Journal of the American Academy of Child & Adolescent Psychiatry},
volume = {64},
number = {10, Supplement },
pages = {S76},
year = {2025},
note = {The Scientific Proceedings of the 2025 Annual Meeting of the American Academy of Child & Adolescent Psychiatry},
issn = {0890-8567},
doi = {https://doi.org/10.1016/j.jaac.2025.07.434},
url = {https://www.sciencedirect.com/science/article/pii/S0890856725007865},
author = {Ian McKay}
}
@article{BENTHAYER2024110007,
title = {Unexpected placental tumor: A case report},
journal = {International Journal of Surgery Case Reports},
volume = {121},
pages = {110007},
year = {2024},
issn = {2210-2612},
doi = {https://doi.org/10.1016/j.ijscr.2024.110007},
url = {https://www.sciencedirect.com/science/article/pii/S2210261224007880},
author = {Maissa {Ben Thayer} and Linda {Bel Hadj Kacem} and Ahlem Blel and Wided Ajouli and Meriem Ksentini and Soumaya Rammeh},
keywords = {Placenta, Placental tumor, Placental non-trophoblastic tumors, Placental teratoma},
abstract = {Introduction and importance
Placental non-trophoblastic tumors (PNTT) are uncommon, consisting mainly of chorangiomas, placental teratomas (PT) and haemangiomas. PT are exceedingly rare, with less than 40 cases reported in the literature. We, herein, present a case of mature PT arising within the membranes, and we aim to discuss the clinico-pathological characteristics of this rare entity.
Case presentation
A 30-year-old female patient, gravida 1, para 1, with no medical history, was admitted at 40 weeks' gestational age. Ultrasound in the third trimester of pregnancy revealed agenesis of the left fetal kidney and a fundal placenta with increased uterine artery resistance. A cesarean section was performed for failure of labor's induction. Gross examination of the placenta revealed a solid polypoid mass, measuring 4 × 2 cm, attached to the membranes and covered by a smooth cutaneous coating. The cut surface was soft, yellowish, and focally heterogenous, with areas of adipose tissue and cartilage. Microscopic examination revealed that the mass was made up of a mature keratinized squamous layer, with skin appendages, adipose and cartilaginous tissues. The diagnosis of PT was established.
Clinical discussion
PT are rarely suspected on prenatal ultrasonography and the diagnosis is made after delivery. Only pathological examination allows the diagnosis of certainty. Their histogenesis is still poorly understood.
Conclusion
We presented a rare case of mature PT arising within the membranes. PT are extremely uncommon tumors. Usually, they are benign, and no fetal or maternal complications. A better knowledge of these uncommon tumors is mandatory to not miss the diagnosis.}
}
@article{YUNG2025,
title = {Examining How Technology Supports Shared Decision-Making in Oncology Consultations: Qualitative Thematic Analysis},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/70827},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000679},
author = {Alan Yung and Tim Shaw and Judy Kay and Anna Janssen},
keywords = {digital health, patient-centered care, person-centered care, shared decision-making, cancer care, oncology, artificial intelligence, AI},
abstract = {Background
Commonly used digital health technologies, such as electronic health record systems and patient portals as well as custom-built digital decision aids, have the potential to enhance person-centered shared decision-making (SDM) in cancer care. SDM is a 2-way exchange of information between at least a clinician and the patient and a shared commitment to make informed decisions. However, there is little evidence in the literature on how technologies are used for SDM or how best they can be designed and integrated into workflows and practice. This may be due to the nature of SDM, which is fundamentally human interactions and conversations that produce desired human outcomes. Therefore, technology must be nonintrusive while supporting the human decision-making process.
Objective
This study examined how digital technologies can help cancer care professionals improve SDM in oncology consultations.
Methods
Health care professionals who treat patients with cancer were invited to participate in online co-design focus group meetings. During these sessions, they shared their experiences using digital technologies for SDM and provided suggestions to improve their use of digital technologies. The session recordings were transcribed and then analyzed using qualitative thematic analysis. The 3-talk SDM model, which consists of 3 steps—team talk, option talk, and decision talk—was used as the guiding framework. This approach was chosen because the 3-talk SDM model has been adopted in Australia. The researchers walked the participants through the SDM model and discussed their routine clinical workflows.
Results
In total, 9 health care professionals with experience treating patients with cancer and using technologies participated in the study. Two focus groups and 2 interviews were conducted in 2024. Three themes and 7 subthemes were generated from the thematic analysis. The findings indicated that various digital technologies, such as electronic health record systems, mobile devices, and patient portals, are used by cancer care professionals to help improve patients’ understanding of their disease and available care options. Digital technologies can both improve and undermine SDM. Current systems are generally not designed to support SDM. Key issues such as data integration and interoperability between systems negatively impact the ability of digital technologies to support SDM. Emerging technologies such as generative artificial intelligence were discussed as potential facilitators of SDM by automating information gathering and sharing with patients and between health professionals.
Conclusions
This research indicates that digital technologies have the potential to impact SDM in oncology consultations. However, this potential has not yet been fully realized, and significant modifications are required to optimize their usefulness in person-centered SDM. Although technology can facilitate information sharing and improve the efficiency of consultation workflows, it is only part of a complex human communication process that needs support from multiple sources, including the broader multidisciplinary cancer team.}
}
@article{GUAN2025,
title = {Classifying the Information Needs of Survivors of Domestic Violence in Online Health Communities Using Large Language Models: Prediction Model Development and Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/65397},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500679X},
author = {Shaowei Guan and Vivian Hui and Gregor Stiglic and Rose Eva Constantino and Young Ji Lee and Arkers Kwan Ching Wong},
keywords = {domestic violence, help seeking, information needs, online health communities, large language models, generative artificial intelligence, multiclass text classification, artificial intelligence},
abstract = {Background
Domestic violence (DV) is a significant public health concern affecting the physical and mental well-being of numerous women, imposing a substantial health care burden. However, women facing DV often encounter barriers to seeking in-person help due to stigma, shame, and embarrassment. As a result, many survivors of DV turn to online health communities as a safe and anonymous space to share their experiences and seek support. Understanding the information needs of survivors of DV in online health communities through multiclass classification is crucial for providing timely and appropriate support.
Objective
The objective was to develop a fine-tuned large language model (LLM) that can provide fast and accurate predictions of the information needs of survivors of DV from their online posts, enabling health care professionals to offer timely and personalized assistance.
Methods
We collected 294 posts from Reddit subcommunities focused on DV shared by women aged ≥18 years who self-identified as experiencing intimate partner violence. We identified 8 types of information needs: shelters/DV centers/agencies; legal; childbearing; police; DV report procedure/documentation; safety planning; DV knowledge; and communication. Data augmentation was applied using GPT-3.5 to expand our dataset to 2216 samples by generating 1922 additional posts that imitated the existing data. We adopted a progressive training strategy to fine-tune GPT-3.5 for multiclass text classification using 2032 posts. We trained the model on 1 class at a time, monitoring performance closely. When suboptimal results were observed, we generated additional samples of the misclassified ones to give them more attention. We reserved 184 posts for internal testing and 74 for external validation. Model performance was evaluated using accuracy, recall, precision, and F1-score, along with CIs for each metric.
Results
Using 40 real posts and 144 artificial intelligence–generated posts as the test dataset, our model achieved an F1-score of 70.49% (95% CI 60.63%-80.35%) for real posts, outperforming the original GPT-3.5 and GPT-4, fine-tuned Llama 2-7B and Llama 3-8B, and long short-term memory. On artificial intelligence–generated posts, our model attained an F1-score of 84.58% (95% CI 80.38%-88.78%), surpassing all baselines. When tested on an external validation dataset (n=74), the model achieved an F1-score of 59.67% (95% CI 51.86%-67.49%), outperforming other models. Statistical analysis revealed that our model significantly outperformed the others in F1-score (P=.047 for real posts; P<.001 for external validation posts). Furthermore, our model was faster, taking 19.108 seconds for predictions versus 1150 seconds for manual assessment.
Conclusions
Our fine-tuned LLM can accurately and efficiently extract and identify DV-related information needs through multiclass classification from online posts. In addition, we used LLM-based data augmentation techniques to overcome the limitations of a relatively small and imbalanced dataset. By generating timely and accurate predictions, we can empower health care professionals to provide rapid and suitable assistance to survivors of DV.}
}
@article{GOROSPE2025448,
title = {Double Trouble in a Breast Cancer Patient Presenting With Dyspnea},
journal = {Archivos de Bronconeumología},
volume = {61},
number = {7},
pages = {448-449},
year = {2025},
issn = {0300-2896},
doi = {https://doi.org/10.1016/j.arbres.2025.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0300289625000900},
author = {Luis Gorospe and Abel González-Huete and Rosa Mariela Mirambeaux-Villalona}
}
@article{FALAHEE20251832,
title = {Digital Approaches to Obesity: Future Directions},
journal = {Canadian Journal of Cardiology},
volume = {41},
number = {9},
pages = {1832-1835},
year = {2025},
note = {Obesity: The Evolving Basic and Clinical Science of a Major Public Health Challenge},
issn = {0828-282X},
doi = {https://doi.org/10.1016/j.cjca.2025.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0828282X25001953},
author = {Bryn E. Falahee and John W. Ostrominski and Alexander J. Blood}
}
@article{MACKAY20251308,
title = {Automated structured data extraction from intraoperative echocardiography reports using large language models},
journal = {British Journal of Anaesthesia},
volume = {134},
number = {5},
pages = {1308-1317},
year = {2025},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2025.01.028},
url = {https://www.sciencedirect.com/science/article/pii/S0007091225000650},
author = {Emily J. MacKay and Shir Goldfinger and Trevor J. Chan and Rachel H. Grasfield and Vikram J. Eswar and Kelly Li and Quy Cao and Alison M. Pouch},
keywords = {artificial intelligence (AI), cardiac surgery, echocardiography, large language models, perioperative medicine},
abstract = {Background
Consensus-based large language model (LLM) ensembles might provide an automated solution for extracting structured data from unstructured text in echocardiography reports.
Methods
This cross-sectional study utilised 600 intraoperative transoesophageal reports (100 for prompt engineering; 500 for testing) randomly sampled from 7106 adult patients undergoing cardiac surgery at two hospitals within the University of Pennsylvania Healthcare System. Three echocardiographic parameters (left ventricular ejection fraction, right ventricular systolic function, and tricuspid regurgitation) were extracted from both the presurgical and postsurgical sections of the reports. LLM ensembles were generated using five open-source LLMs and four voting strategies: (1) unanimous (five out of five in agreement); (2) supermajority (four or more of five in agreement); (3) majority (three or more of five in agreement); and (4) plurality (two or more of five in agreement). Returned LLM ensemble responses were compared with the reference standard dataset to calculate raw accuracy, consensus accuracy, error rate, and yield.
Results
Of the four LLM ensembles, the unanimous LLM ensemble achieved the highest consensus accuracies (99.4% presurgical; 97.9% postsurgical) and the lowest error rates (0.6% presurgical; 2.1% postsurgical) but had the lowest data extraction yields (81.7% presurgical; 80.5% postsurgical) and the lowest raw accuracies (81.2% presurgical; 78.9% postsurgical). In contrast, the plurality LLM ensemble achieved the highest raw accuracies (96.1% presurgical; 93.7% postsurgical) and the highest data extraction yields (99.4% presurgical; 98.9% postsurgical) but had the lowest consensus accuracies (96.7% presurgical; 94.7% postsurgical) and highest error rates (3.3% presurgical; 5.3% postsurgical).
Conclusions
A consensus-based LLM ensemble successfully generated structured data from unstructured text contained in intraoperative transoesophageal reports.}
}
@article{HOBENSACK2024104753,
title = {A rapid review on current and potential uses of large language models in nursing},
journal = {International Journal of Nursing Studies},
volume = {154},
pages = {104753},
year = {2024},
issn = {0020-7489},
doi = {https://doi.org/10.1016/j.ijnurstu.2024.104753},
url = {https://www.sciencedirect.com/science/article/pii/S0020748924000658},
author = {Mollie Hobensack and Hanna {von Gerich} and Pankaj Vyas and Jennifer Withall and Laura-Maria Peltonen and Lorraine J. Block and Shauna Davies and Ryan Chan and Liesbet {Van Bulck} and Hwayoung Cho and Robert Paquin and James Mitchell and Maxim Topaz and Jiyoun Song},
keywords = {Rapid review, Nursing informatics, Large language models, Generative AI, ChatGPT},
abstract = {Background
The application of large language models across commercial and consumer contexts has grown exponentially in recent years. However, a gap exists in the literature on how large language models can support nursing practice, education, and research. This study aimed to synthesize the existing literature on current and potential uses of large language models across the nursing profession.
Methods
A rapid review of the literature, guided by Cochrane rapid review methodology and PRISMA reporting standards, was conducted. An expert health librarian assisted in developing broad inclusion criteria to account for the emerging nature of literature related to large language models. Three electronic databases (i.e., PubMed, CINAHL, and Embase) were searched to identify relevant literature in August 2023. Articles that discussed the development, use, and application of large language models within nursing were included for analysis.
Results
The literature search identified a total of 2028 articles that met the inclusion criteria. After systematically reviewing abstracts, titles, and full texts, 30 articles were included in the final analysis. Nearly all (93 %; n = 28) of the included articles used ChatGPT as an example, and subsequently discussed the use and value of large language models in nursing education (47 %; n = 14), clinical practice (40 %; n = 12), and research (10 %; n = 3). While the most common assessment of large language models was conducted by human evaluation (26.7 %; n = 8), this analysis also identified common limitations of large language models in nursing, including lack of systematic evaluation, as well as other ethical and legal considerations.
Discussion
This is the first review to summarize contemporary literature on current and potential uses of large language models in nursing practice, education, and research. Although there are significant opportunities to apply large language models, the use and adoption of these models within nursing have elicited a series of challenges, such as ethical issues related to bias, misuse, and plagiarism.
Conclusion
Given the relative novelty of large language models, ongoing efforts to develop and implement meaningful assessments, evaluations, standards, and guidelines for applying large language models in nursing are recommended to ensure appropriate, accurate, and safe use. Future research along with clinical and educational partnerships is needed to enhance understanding and application of large language models in nursing and healthcare.}
}
@article{TAKAGI2025,
title = {Panda eyes and elephant trunk in an abdominal aortic aneurysm},
journal = {Revista Española de Cardiología (English Edition)},
year = {2025},
issn = {1885-5857},
doi = {https://doi.org/10.1016/j.rec.2025.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1885585725002683},
author = {Hisato Takagi}
}
@article{GORMAN2025A19,
title = {Generative AI Case Studies in Undergraduate Clinical Nutrition Education},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {125},
number = {10, Supplement },
pages = {A19},
year = {2025},
note = {2025 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2025.06.284},
url = {https://www.sciencedirect.com/science/article/pii/S2212267225006215},
author = {A. Gorman}
}
@article{YANG2024,
title = {Ascle—A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60601},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124006289},
author = {Rui Yang and Qingcheng Zeng and Keen You and Yujie Qiao and Lucas Huang and Chia-Chun Hsieh and Benjamin Rosand and Jeremy Goldwasser and Amisha Dave and Tiarnan Keenan and Yuhe Ke and Chuan Hong and Nan Liu and Emily Chew and Dragomir Radev and Zhiyong Lu and Hua Xu and Qingyu Chen and Irene Li},
keywords = {natural language processing, machine learning, deep learning, generative artificial intelligence, large language models, retrieval-augmented generation, healthcare},
abstract = {Background
Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to automate text processing. In the biomedical field, various toolkits for text processing exist, which have greatly improved the efficiency of handling unstructured text. However, these existing toolkits tend to emphasize different perspectives, and none of them offer generation capabilities, leaving a significant gap in the current offerings.
Objective
This study aims to describe the development and preliminary evaluation of Ascle. Ascle is tailored for biomedical researchers and clinical staff with an easy-to-use, all-in-one solution that requires minimal programming expertise. For the first time, Ascle provides 4 advanced and challenging generative functions: question-answering, text summarization, text simplification, and machine translation. In addition, Ascle integrates 12 essential NLP functions, along with query and search capabilities for clinical databases.
Methods
We fine-tuned 32 domain-specific language models and evaluated them thoroughly on 27 established benchmarks. In addition, for the question-answering task, we developed a retrieval-augmented generation (RAG) framework for large language models that incorporated a medical knowledge graph with ranking techniques to enhance the reliability of generated answers. Additionally, we conducted a physician validation to assess the quality of generated content beyond automated metrics.
Results
The fine-tuned models and RAG framework consistently enhanced text generation tasks. For example, the fine-tuned models improved the machine translation task by 20.27 in terms of BLEU score. In the question-answering task, the RAG framework raised the ROUGE-L score by 18% over the vanilla models. Physician validation of generated answers showed high scores for readability (4.95/5) and relevancy (4.43/5), with a lower score for accuracy (3.90/5) and completeness (3.31/5).
Conclusions
This study introduces the development and evaluation of Ascle, a user-friendly NLP toolkit designed for medical text generation. All code is publicly available through the Ascle GitHub repository. All fine-tuned language models can be accessed through Hugging Face.}
}
@article{ZHANG2025270,
title = {Knowledge Understanding and Citation Ability Improvement Strategy Based on End-to-end GenIR Model},
journal = {Procedia Computer Science},
volume = {261},
pages = {270-278},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.203},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925013055},
author = {Wenyan Zhang},
keywords = {End-To-End Genir Model, Knowledge Understanding, Citation Capability, Information Retrieval},
abstract = {In order to improve the machine’s knowledge understanding and citation capabilities in complex and heterogeneous information environments and ensure accuracy and efficiency, this paper constructs and optimizes an end-to-end GenIR model. The model combines the advantages of generative AI technology and information retrieval technology, aiming to automatically extract, understand and cite relevant knowledge from large amounts of text data. The paper first collects a large amount of text data in related fields, then preprocesses the data, and then builds an end-to-end GenIR model. The model is then trained and the model parameters are optimized using the back propagation algorithm. During the training process, the attention mechanism is used to enhance the model’s ability to capture key information, and adversarial training is used to improve the robustness of the model. After training, the model is fine-tuned. Experimental results show that the GenIR model reaches a maximum MAP value of 99.9% and also has significant advantages in nDCG. The average inference time is about 29% faster than the BM25 model, demonstrating dual optimization in accuracy and efficiency. This study successfully improves the machine’s knowledge understanding and citation capabilities in complex and heterogeneous information environments by building and optimizing an end-to-end GenIR model. It not only achieves optimization in accuracy and efficiency, but also provides a new solution for the field of information retrieval.}
}
@article{CUSSENOT2025,
title = {Reply to Hinpetch Daungsupawong and Viroj Wiwanitkit’s Letter to the Editor re: Olivier Cussenot, Yoann Taille, Jean-Jacques Portal, et al. Eliciting the Impact of Metformin and Statins on Prostate Cancer Outcomes from a Real-life National Database Analysis. Eur Urol Oncol. In press. https://doi.org/10.1016/j.euo.2025.04.024},
journal = {European Urology Oncology},
year = {2025},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2025.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S2588931125001592},
author = {Olivier Cussenot}
}
@article{MEAFA20252166,
title = {Metaverse and Generative AI’s Digital Capabilities For Supply Chain Resilience},
journal = {Procedia Computer Science},
volume = {253},
pages = {2166-2175},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.277},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002856},
author = {Azz-eddine Meafa and Abla Chaouni Benabdellah and Kamar Zekhnini},
keywords = {Metaverse, Generative AI, Digital Capabilities, Supply Chain Resilience},
abstract = {Supply chains (SCs) are facing disruptions and perturbations daily. As a result, building a resilient SC is crucial in such dynamics and conditions. To have the ability to navigate and recover from unexpected challenges has become a strategic imperative for organizations to ensure sustained operations, adaptability, and long-term continuity. Thus, emphasizing the adoption of new technologies to strengthen supply chain resilience (SCR) is not only a proactive way to respond to current turbulences. It is a forward-thinking strategy to prepare the SC networks for unexpected crises that may arise in the future. In this context, this article explores the integration of Metaverse and Generative AI (GenAI) to enhance this ability, focusing on their digital capabilities and fundamentals. To do so, a systematic literature review (SLR) approach was adopted to explore new insights about the subject, identify the digital capabilities of these technologies for SCR, and build on research ideas from the current literature. After reviewing 50 relevant papers from the literature, the study presents a framework that leverages a combination of Metaverse and Generative AI to ensure resilience. Also, it highlights the practical implications for managers about the potential of these technologies to build informed decisions to face uncertain situations and provides some future research perspectives for academics to push the boundaries of knowledge in this research area.}
}
@article{YU2025156006,
title = {Exploring multi-instance learning in whole slide imaging: Current and future perspectives},
journal = {Pathology - Research and Practice},
volume = {271},
pages = {156006},
year = {2025},
issn = {0344-0338},
doi = {https://doi.org/10.1016/j.prp.2025.156006},
url = {https://www.sciencedirect.com/science/article/pii/S0344033825001980},
author = {Jikai Yu and Hongda Chen and Lianxin Hu and Boyuan Wu and Shicheng Zhou and Jiayun Zhu and Yizhen Jiang and Shuwen Han and Zefeng Wang},
keywords = {Deep learning, Multi-instance learning(MIL), MIL applications, Whole slide image},
abstract = {Whole slide images (WSI), due to their gigabyte-scale size and ultra-high resolution, play a significant role in diagnostic pathology. However, the enormous data size makes it difficult to directly input these images into image processing units (GPU) for computation, limiting the development of automated screening and diagnostic algorithms. As an effective computational framework, multi-instance learning (MIL) has provided strong support in addressing this challenge. This review systematically summarizes the research progress and applications of MIL in WSI analysis, based on over 90 articles retrieved from Web of Science, IEEE Xplore and PubMed. It briefly outlines the unique advantages and specific improvements in handling whole slide images, with a focus on analyzing the core characteristics and performance of mainstream techniques in tasks such as cancer detection and subtype classification. The results indicate that methods like data preprocessing, multi-scale feature fusion, representative instance selection, and Transformer-based models significantly enhance the ability of MIL in WSI processing. Furthermore, this paper also summarizes the characteristics of different technologies and proposes future research directions to promote the widespread application of MIL in pathological diagnosis.}
}
@article{LUO2025107881,
title = {The Impact of Distribution Contract Types on the Adoption of Blockchain Strategies by Competitive Brand Sellers in the Field of Public Health},
journal = {American Journal of Preventive Medicine},
volume = {69},
number = {2, Supplement 1},
pages = {107881},
year = {2025},
note = {2024 International Conference on Preventive Medicine and Nursing Science (PMNS2024), July 19-21, 2024, Qingdao, China. This supplement was sponsored by International Association of Applied Science & Engineering Technology},
issn = {0749-3797},
doi = {https://doi.org/10.1016/j.amepre.2025.107881},
url = {https://www.sciencedirect.com/science/article/pii/S0749379725003721},
author = {Zemin Luo and Min Bao and Jingpei Ma and Yujuan Gao},
abstract = {Introduction
This research delves into the transformative role of blockchain technology within a dual-channel supply chain framework, emphasizing its influence on enhancing product transparency in the public health domain. By ensuring the traceability and authenticity of health-related products, blockchain can significantly alter the pricing dynamics for brand manufacturers. The study explores how increased transparency can lead to more informed consumer choices, potentially affecting demand patterns and, consequently, the pricing strategies adopted by brand sellers. Ultimately, the research aims to understand how these pricing adjustments impact the overall profitability and market position of these sellers within the public health sector.
Method
This research uses a model consisting of a platform and upstream brand sellers, focusing on public health products. It analyzes the cost-effectiveness of brand sellers adopting blockchain technology in two channels: direct sales and platform sales, as well as the choice of public health products between two sales models: wholesale and agency.
Results
The study finds that in the field of public health, the cost of adopting blockchain technology has a significant impact on the decision-making of brand sellers. Under low-cost conditions, brand sellers tend to adopt blockchain to improve the transparency of public health products, which can not only attract health-conscious consumers but also increase market share and enhance brand image. The level of on-chain costs also affects the choice of brand sellers between wholesale and agency models, as well as the pricing strategy of public health products. Under the wholesale model, lower retail prices and higher demand help to increase the profits of brand sellers in public health products.
Discussion
We found that the type of distribution contract has a profound impact on the adoption of blockchain strategies by competitive brand sellers in the field of public health. Brand sellers need to choose appropriate sales models and blockchain application strategies based on their own situations and market environments to enhance the transparency of public health products, attract consumers, increase market share, and improve brand image. At the same time, governments and relevant institutions should also actively promote the application and development of blockchain technology in the field of public health to ensure public health and safety.}
}
@article{PEREZGARCIA2025742,
title = {30-Gauge needle Descemet membrane endothelial keratoplasty graft obtention: A novel, safer and cheap technique},
journal = {Archivos de la Sociedad Española de Oftalmología (English Edition)},
volume = {100},
number = {11},
pages = {742-745},
year = {2025},
issn = {2173-5794},
doi = {https://doi.org/10.1016/j.oftale.2025.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S2173579425001677},
author = {P. Pérez-García and J.A. Gegúndez-Fernández and M. Ariño-Gutiérrez and M. Molero-Senosiaín and B. Burgos-Blasco and D. Díaz-Valle},
keywords = {Descemet membrane endothelial keratoplasty, DMEK, Graft preparation, Preparation technique, Needle, Queratoplastia endotelial de Membrana de Descemet, DMEK, Injerto, Preparación, Aguja},
abstract = {This work aims to present a novel technique for obtaining grafts for Descemet Membrane Endothelial Keratoplasty (DMEK) safely and efficiently, thanks to its fast learning curve and reduced risk of graft tears. The technique involves the peripheral dissection of the endothelium starting with a superficial incision made using a 30-Gauge needle, 1 mm inside Schwalbe's line across 360º of the corneal periphery. Trypan Blue is then applied to visualize the dissection boundary, and a DMEK Sinskey hook is used to lift 1 mm of the peripheral graft along the entire circumference. The technique continues with the separation of Descemet's membrane from the stroma, as is commonly performed. This technique reduces costs by employing a standard needle and achieves low failure rates compared to other techniques.
Resumen
El objetivo de este trabajo es presentar esta novedosa técnica para obtener injertos para queratoplastia endotelial de membrana de Descemet (DMEK) de manera segura y eficiente, gracias a su rápida curva de aprendizaje y menor riesgo de desgarros en el injerto. La técnica consiste en la disección periférica del endotelio a partir de una incisión superficial realizada con una aguja de calibre 30 G a 1 mm de la línea de Schwalbe en los 360º de la periferia corneal. A continuación, se aplica azul tripán para visualizar el límite de la disección y mediante un Simskey de DMEK se levanta 1 mm del injerto periférico en toda la circunferencia. La técnica continúa con el pelado de la membrana de Descemet, como es habitual. Esta técnica reduce los costes al utilizar una aguja estándar y logra bajas tasas de fallo en comparación con otras técnicas.}
}
@article{SCIARRA2025e951,
title = {Simulation in the didactic classroom},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {e951},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001179},
author = {Erica Sciarra and Arianna Duncan}
}
@article{MATLI2025718,
title = {Empowering communities through engaged scholarship to Shape AI Development for AI for Social Good},
journal = {Procedia Computer Science},
volume = {256},
pages = {718-722},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.171},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925005289},
author = {Walter Matli},
keywords = {Engaged Scholarship, AI, Social good, Community, Empowerment},
abstract = {The increasing development of Artificial Intelligence for social good brings immense potential to address pressing societal challenges. However, there is a growing recognition that realising this potential requires moving beyond a top-down approach and actively empowering communities to shape AI development. This paper argues that engaged scholarship is essential for facilitating this empowerment and ensuring that AI for social good benefits the communities it aims to serve. The purpose of this paper is to explore how engaged scholarship can bridge the gap between AI expertise and community needs. The findings indicate that engaged scholarship is the key to achieving this empowerment, emphasising collaboration, co-creation, and action-oriented research. The study analyses the challenges and opportunities within this domain; this paper provides a roadmap for researchers, practitioners, and policymakers to foster community empowerment in AI for social good. We argue that by focusing on community voices and priorities, the engaged scholarship can unlock the transformative potential of AI to create more equitable and just societies.}
}
@incollection{KALENDRA202634,
title = {Internet Marketing},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {34-39},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00125-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013001250},
author = {Diane Kalendra and Sumesh Nair and Tareq Rasul},
keywords = {Artificial intelligence, Consumer behavior, Digital platforms, Engagement rates, Internet marketing, Internet of things (IoT), Privacy concerns, SEO (Search engine optimization), Technological evolution, Traditional marketing, User experience},
abstract = {This contribution discusses Internet Marketing, presenting its evolution from basic direct marketing to a sophisticated, data-driven domain shaped by technological advancements like Artificial Intelligence (AI) and the Internet of Things (IoT). It contrasts internet marketing with traditional methods, emphasizing interactive, targeted communication and the integration of various digital strategies. The text delves into the benefits, strategic components, legal-ethical considerations, and the profound impact of customer databases and generative AI on personalization and efficiency. Overall, it presents Internet Marketing as a dynamic, pivotal force in the business world, constantly evolving with technological advancements.}
}
@article{GONZALEZGARCIA2025e41559,
title = {Impact of ChatGPT usage on nursing students education: A cross-sectional study},
journal = {Heliyon},
volume = {11},
number = {1},
pages = {e41559},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41559},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024175901},
author = {Alberto Gonzalez-Garcia and David Bermejo-Martinez and Ana Isabel Lopez-Alonso and Bibiana Trevisson-Redondo and Cristian Martín-Vázquez and Silvia Perez-Gonzalez},
keywords = {ChatGPT, Nursing education, Artificial intelligence, Academic performance, Technological innovations, Student perceptions, Nurse},
abstract = {Background
The use of artificial intelligence tools, such as ChatGPT, is on the rise in nursing education. In the field of healthcare, ChatGPT can offer unique opportunities to enhance the learning and clinical practice of nursing students. However, it is still necessary to explore how this tool affects students' performance and perception in their nursing education.
Objective
The objective of this study was to evaluate the impact of ChatGPT on nursing students' education and determine how it influences their learning outcomes.
Design
This study employed a quantitative cross-sectional design.
Setting
The study was conducted in the Bachelor of Nursing program at the University of León, Spain.
Participants
Ninety-eight nursing students enrolled in the Nursing Care and Services Management course during the second semester of 2024 participated in the study.
Methods
Data were collected using three validated questionnaires that assessed sociodemographic characteristics, knowledge of artificial intelligence, and perceptions of using ChatGPT as an educational tool. The data were analyzed using IBM SPSS Statistics, version 29.1.
Results
Students who used ChatGPT showed a significant improvement in their academic grades (p < 0.05). Additionally, 89.5 % of the students reported significant improvements in their academic performance. Women perceived ChatGPT as especially useful for completing academic tasks (85.14 % versus 50.00 % in men, p = 0.003). A positive correlation was observed between prior use of ChatGPT and GPA (ρ = 0.240, p = 0.026).
Conclusions
ChatGPT is a valuable tool that enhances the learning and satisfaction of nursing students. Its integration into nursing education programs not only boosts academic performance but also promotes the adoption of technological innovations in professional training. Continuous incorporation of AI tools in education is recommended to improve academic outcomes and prepare students for evolving healthcare environments.}
}
@article{ROJAS2024,
title = {Exploring the Performance of ChatGPT Versions 3.5, 4, and 4 With Vision in the Chilean Medical Licensing Examination: Observational Study},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/55048},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000527},
author = {Marcos Rojas and Marcelo Rojas and Valentina Burgess and Javier Toro-Pérez and Shima Salehi},
keywords = {artificial intelligence, AI, generative artificial intelligence, medical education, ChatGPT, EUNACOM, medical licensure, medical license, medical licensing exam},
abstract = {Background
The deployment of OpenAI’s ChatGPT-3.5 and its subsequent versions, ChatGPT-4 and ChatGPT-4 With Vision (4V; also known as “GPT-4 Turbo With Vision”), has notably influenced the medical field. Having demonstrated remarkable performance in medical examinations globally, these models show potential for educational applications. However, their effectiveness in non-English contexts, particularly in Chile’s medical licensing examinations—a critical step for medical practitioners in Chile—is less explored. This gap highlights the need to evaluate ChatGPT’s adaptability to diverse linguistic and cultural contexts.
Objective
This study aims to evaluate the performance of ChatGPT versions 3.5, 4, and 4V in the EUNACOM (Examen Único Nacional de Conocimientos de Medicina), a major medical examination in Chile.
Methods
Three official practice drills (540 questions) from the University of Chile, mirroring the EUNACOM’s structure and difficulty, were used to test ChatGPT versions 3.5, 4, and 4V. The 3 ChatGPT versions were provided 3 attempts for each drill. Responses to questions during each attempt were systematically categorized and analyzed to assess their accuracy rate.
Results
All versions of ChatGPT passed the EUNACOM drills. Specifically, versions 4 and 4V outperformed version 3.5, achieving average accuracy rates of 79.32% and 78.83%, respectively, compared to 57.53% for version 3.5 (P<.001). Version 4V, however, did not outperform version 4 (P=.73), despite the additional visual capabilities. We also evaluated ChatGPT’s performance in different medical areas of the EUNACOM and found that versions 4 and 4V consistently outperformed version 3.5. Across the different medical areas, version 3.5 displayed the highest accuracy in psychiatry (69.84%), while versions 4 and 4V achieved the highest accuracy in surgery (90.00% and 86.11%, respectively). Versions 3.5 and 4 had the lowest performance in internal medicine (52.74% and 75.62%, respectively), while version 4V had the lowest performance in public health (74.07%).
Conclusions
This study reveals ChatGPT’s ability to pass the EUNACOM, with distinct proficiencies across versions 3.5, 4, and 4V. Notably, advancements in artificial intelligence (AI) have not significantly led to enhancements in performance on image-based questions. The variations in proficiency across medical fields suggest the need for more nuanced AI training. Additionally, the study underscores the importance of exploring innovative approaches to using AI to augment human cognition and enhance the learning process. Such advancements have the potential to significantly influence medical education, fostering not only knowledge acquisition but also the development of critical thinking and problem-solving skills among health care professionals.}
}
@article{SHEN2024,
title = {Empathy Toward Artificial Intelligence Versus Human Experiences and the Role of Transparency in Mental Health and Social Support Chatbot Design: Comparative Study},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/62679},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924001057},
author = {Jocelyn Shen and Daniella DiPaola and Safinah Ali and Maarten Sap and Hae Won Park and Cynthia Breazeal},
keywords = {empathy, large language models, ethics, transparency, crowdsourcing, human-computer interaction},
abstract = {Background
Empathy is a driving force in our connection to others, our mental well-being, and resilience to challenges. With the rise of generative artificial intelligence (AI) systems, mental health chatbots, and AI social support companions, it is important to understand how empathy unfolds toward stories from human versus AI narrators and how transparency plays a role in user emotions.
Objective
We aim to understand how empathy shifts across human-written versus AI-written stories, and how these findings inform ethical implications and human-centered design of using mental health chatbots as objects of empathy.
Methods
We conducted crowd-sourced studies with 985 participants who each wrote a personal story and then rated empathy toward 2 retrieved stories, where one was written by a language model, and another was written by a human. Our studies varied disclosing whether a story was written by a human or an AI system to see how transparent author information affects empathy toward the narrator. We conducted mixed methods analyses: through statistical tests, we compared user’s self-reported state empathy toward the stories across different conditions. In addition, we qualitatively coded open-ended feedback about reactions to the stories to understand how and why transparency affects empathy toward human versus AI storytellers.
Results
We found that participants significantly empathized with human-written over AI-written stories in almost all conditions, regardless of whether they are aware (t196=7.07, P<.001, Cohen d=0.60) or not aware (t298=3.46, P<.001, Cohen d=0.24) that an AI system wrote the story. We also found that participants reported greater willingness to empathize with AI-written stories when there was transparency about the story author (t494=–5.49, P<.001, Cohen d=0.36).
Conclusions
Our work sheds light on how empathy toward AI or human narrators is tied to the way the text is presented, thus informing ethical considerations of empathetic artificial social support or mental health chatbots.}
}
@incollection{CHATURVEDI2025197,
title = {10 - Developmental pediatrics progression matched with artificial intelligence: A growth perspective in healthcare},
editor = {Ashish Kumar and Divya Singh},
booktitle = {Revolutionizing Medical Systems using Artificial Intelligence},
publisher = {Academic Press},
pages = {197-212},
year = {2025},
isbn = {978-0-443-32862-6},
doi = {https://doi.org/10.1016/B978-0-443-32862-6.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443328626000109},
author = {Vijit Chaturvedi and Shammi Chaturvedi},
keywords = {Generative AI-based healthcare, deep learning, artificial intelligence in health care, pediatric disease, developmental psychology, health care, administrative procedure},
abstract = {With the rising role of artificial intelligence (AI) and its components in every sphere of development, healthcare is one sector that demands it most. With the availability of huge datasets, apps, wearables, robots as interventionists, deep learning, and neural-based networking, a comprehensive approach toward looking at health has emerged. This chapter aims to understand how these technological innovations have completely transformed one of the foundations of every grown human being, that is, “developmental pediatrics.” This chapter highlights four major components that ensure the significant role of AI in pediatrics. The first section highlights an introduction to pediatrics and its growth, the second section relates to technological advancement in this area, the third section elaborates on generative AI and its growing role across the globe and in pediatric development, the fourth section talks about technology, methods, tools, and progression of AI in the field, and further sections discusses challenges, opportunities as futuristic growth, essentials, and finally the takeaways from the discussion. This chapter holds significant importance specifically in pediatrics and is an important consideration to be understood before expecting groundbreaking results from application and serves as a ready reference for varied aspects of applied benefits in different areas of pediatrics right from cardiology to radiology and the role of precision medicine.}
}