@article{MASSARO2025100841,
title = {Advanced Electronic Controller Circuits Enabling Production Processes and AI-driven KM in Industry 5.0},
journal = {Journal of Industrial Information Integration},
volume = {45},
pages = {100841},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100841},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25000652},
author = {Alessandro Massaro and Francesco Santarsiero and Giovanni Schiuma},
keywords = {AI-driven processes, Electronic machine control, Industry 5.0, PID Controller, BPMN},
abstract = {The proposed paper presents a methodology for mapping electronic manufacturing control processes within a Knowledge Management (KM) framework, aligning with human-centric and transdisciplinary approaches. Specifically, the paper explores a Proportional-Integral-Derivative (PID) process for tuning production machinery, facilitating quality management and predictive maintenance through an AI-driven model. The PID circuit model is designed using the LTspice tool, while the entire production workflow is structured according to the Business Process Model and Notation (BPMN) standard. The model incorporates Artificial Intelligence (AI) to optimize machine control, establishing an advanced Digital Twin (DT) model that enables interactive human-system collaboration. The work further describes Knowledge Base (KB) data sources that support KM within Industry 5.0 environments, emphasizing AI-enhanced, user-centered control systems. Finally, the paper discusses new managerial roles and skill sets necessary for overseeing these integrated, human-centric KM systems in next-generation industrial applications.}
}
@article{MOGHADDAS2025111965,
title = {Explainable data-driven formulation of chloride migration coefficient of eco-friendly concrete based on advanced automatic programming},
journal = {Engineering Applications of Artificial Intelligence},
volume = {160},
pages = {111965},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111965},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625019736},
author = {Seyed Amirhossein Moghaddas and Weina Meng and Yi Bao},
keywords = {Chloride migration coefficient, Expression programming technique, Machine learning, Sustainable concrete, Supplementary cementitious material},
abstract = {Data-driven approaches have demonstrated high efficiency in designing concrete materials with a large design space for desired material properties, but conventional data-driven approaches are inconvenient for practitioners and lack interpretability. This paper presents an explainable data-driven approach to formulate chloride migration coefficients of concrete using Artificial Bee Colony Expression Programming and Gene Expression Programming, aiming to overcome the limitations of black-box machine learning models while achieving high accuracy. The proposed approach integrates concrete domain knowledge with data-driven techniques including feature selection, anomaly detection, and hyperparameter selection. The approach, implemented for both conventional concrete and green concrete that contains fly ash, slag, and silica fume, achieves Pearson correlation coefficients exceeding 0.97 for both conventional concrete and green concrete on training and testing sets, and exhibits Scatter Indexes of 0.1 for conventional concrete and 0.2 for green concrete, demonstrating high accuracy while providing explicit mathematical formulas for engineer-friendly applications.}
}
@article{KARPE2025,
title = {Clotrimazole as a new frontier: Drug repurposing and its efficacy in cancer therapy},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000345},
author = {Shubham C. Karpe and Manjula Kiran and Sukhen Majhi and Jaipal Meena and Rajesh Kumar and Harish Chander and Anupkumar R. Anvikar and Harit Kasana},
keywords = {Clotrimazole, Antineoplastic agents, Neoplasms, Antifungal agents, Immunomodulation},
abstract = {Cancer, ranging from early stages to metastatic spread, is one of the leading causes of death globally. Current treatment options, including chemotherapy, radiotherapy, and targeted drugs, have limitations, such as significant side effects, drug resistance, and high cost. To overcome these challenges, extensive studies have explored the anticancer potential of various drugs such as clotrimazole (CLZ), which has shown promising anticancer effects. CLZ was first developed as an antifungal agent. Recently significant anticancer effects have been observed making it a suitable candidate for drug repurposing. Compared with other azole-based antifungals, CLZ has shown distinct therapeutic effects on cancer cells via several pathways. Its ability to disrupt glycolysis by inhibiting phosphofructokinase (PFK) and hexokinase (HK) distinguishes it from other azoles. Furthermore, CLZ obstructs calcium homeostasis and critical survival pathways, such as extracellular signal-regulated kinase (ERK)-p65, phosphatidylinositol 3-kinase (PI3K), and mitochondrial apoptotic pathways, inhibiting tumor growth, inducing apoptosis, and attenuating metastasis. This review explores the potential of repurposing CLZ in cancer and its well-established safety profile and cost-effectiveness to highlight current treatment gaps. It briefly examines in vitro and in vivo assessments to understand the mechanisms and effects of CLZ on various cancer types. Furthermore, novel strategies such as nanoformulations and combination therapies with existing chemotherapeutic drugs have been highlighted to improve therapeutic outcomes. Preclinical studies have provided promising evidence for the efficacy of CLZ in different cancers, showing tumor regression and improved responses to conventional chemotherapy or targeted therapies. Given its evident preclinical results and diverse mechanisms of action, CLZ may be considered an antineoplastic agent. Further clinical research is required to fully elucidate its anticancer potential, potentially positing it as a valuable addition to currently available cancer treatments.}
}
@article{STIDHAM2025432,
title = {Artificial Intelligence–Enabled Clinical Trials in Inflammatory Bowel Disease: Automating and Enhancing Disease Assessment and Study Management},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {432-443},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.02.039},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005414},
author = {Ryan W. Stidham and Louis R. Ghanem and Joel G. Fletcher and David H. Bruining},
keywords = {Artificial Intelligence, Inflammatory Bowel Disease, Crohn's Disease, Ulcerative Colitis, Computer Vision, Automation, Large Language Models, Natural Language Processing, Digital Twin},
abstract = {Artificial intelligence (AI) will fundamentally improve how we perform clinical trials by addressing issues of standardizing disease scoring, improving the sensitivity and precision of activity and phenotype assessments, and automating laborious and time-consuming study functions. Progress in AI image analysis is quickly proving to replicate expert judgment in endoscopy, histology, and cross-sectional imaging with speed, reproducibility, and reduced bias. However, AI analytics offer the ability to quantify disease characteristics with more detail and precision than human experts. Large language models and generative AI are automating the collection of high-quality data from electronic records and improving our ability to predict patient outcomes. This narrative review will focus on AI tools available today, their expected implementation, and future-facing opportunities for AI to reimagine inflammatory bowel disease clinical trials.}
}
@article{DUDLEY20251145,
title = {Marginal gap measurement of ceramic single crowns before cementation: A systematic review},
journal = {The Journal of Prosthetic Dentistry},
volume = {133},
number = {5},
pages = {1145-1156},
year = {2025},
issn = {0022-3913},
doi = {https://doi.org/10.1016/j.prosdent.2025.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S002239132500040X},
author = {James Dudley and Taseef Hasan Farook},
abstract = {ABSTRACT
Statement of problem
Different instruments have been used to measure the marginal gaps of crowns in vitro. However, a comprehensive systematic review is lacking.
Purpose
The purpose of this systematic review was to evaluate the existing literature on the instruments used for the in vitro marginal gap measurement of ceramic single crowns before cementation and to determine whether the crown material and method of fabrication influenced the marginal gap.
Material and methods
The search was conducted in 2024 across the EBSCO Host, Scopus, PubMed, and Web of Science databases by following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines and predefined eligibility criteria. Eligible articles were screened to evaluate 6 instruments for measuring crown marginal gaps: direct view microscopy, scanning electron microscopy, impression replica, cross-sectioning, microcomputed tomography, and 3-dimensional (3D) superimposition. The normality of the data was assessed by using the Kolmogorov-Smirnov test, and the differences in mean marginal gap were statistically evaluated using the Welch ANOVA (α=.05).
Results
Ninety-two articles were included, with 77 documenting single measurement instruments and 15 using a combination of 2 or more measurement instruments. Direct view microscopy was the most used instrument and appeared in 31 (40%) of the studies. No significant differences in mean marginal gap (F=2.09, P=.077) were found across the 6 measurement instruments. Across all studies, excluding those using 3D superimposition, the mean ±standard deviation number of marginal gap measurements per crown was 34.3 ±50.6. Among the 77 studies using a single measurement instrument, 64 used computer-aided design and computer-aided manufacturing (CAD-CAM) technology to fabricate the crowns. CAD-CAM crowns had a mean ±standard deviation marginal gap of 78.9 ±28.6 µm (n=64) compared with 71.6 ±29.5 µm (n=13) for crowns manufactured using conventional methods. Zirconia and lithium disilicate were the most researched materials. Zirconia crowns recorded a mean ±standard deviation marginal gap of 69.4 ±34.2 µm for 972 crowns, which was significantly different (P=.045) from lithium disilicate with a mean ±standard deviation marginal gap of 92.2 ±42.5 µm for 602 crowns.
Conclusions
Direct view microscopy was the most used marginal gap measurement instrument for ceramic single crowns before cementation, and CAD-CAM was the most used crown fabrication method. No significant differences in mean marginal gap were found among the 6 marginal gap measurement instruments.}
}
@article{KABIR2024101640,
title = {Sea-level rise and mental health among coastal communities: A quantitative survey and conditional process analysis},
journal = {SSM - Population Health},
volume = {25},
pages = {101640},
year = {2024},
issn = {2352-8273},
doi = {https://doi.org/10.1016/j.ssmph.2024.101640},
url = {https://www.sciencedirect.com/science/article/pii/S2352827324000405},
author = {Sajjad Kabir and Elizabeth A. Newnham and Ashraf Dewan and Md. Monirul Islam and Takeshi Hamamura},
keywords = {Sea-level rise, Mental health, Environmental stressor, Resource loss, Coastal community, Climate change},
abstract = {This is the first large-scale empirical study examining the impact of sea-level rise induced by climate change on mental health outcomes among coastal communities. The study focuses on Bangladesh, a country severely affected by salinity ingress, flood risks, and agricultural damage due to sea-level changes. Participants (n = 1,200) randomly selected from three coastal regions each having high, moderate, or low vulnerability to sea-level rise were surveyed during the pre-monsoon season in 2021. The cross-sectional survey included validated measures of psychological distress, depression, anxiety, stress, environmental stressors, resource loss, and demographics. The results indicated significantly higher levels of psychological distress, depression, anxiety, and stress in residents of high-vulnerability areas compared to moderate or low-vulnerability regions. Resource loss served as a mediating variable between environmental stressors and mental health outcomes. Furthermore, demographic analyses showed that older adults and women reported higher levels of psychological distress. These findings align with the Sendai Framework for Disaster Risk Reduction, highlighting urgent need for targeted mental health interventions and sustainable models of care in coastal areas increasingly threatened by sea-level rise.}
}
@article{DURMUSSARIKAHYA2025106755,
title = {The impact of ChatGPT on nursing education: A qualitative study based on the experiences of faculty members},
journal = {Nurse Education Today},
volume = {152},
pages = {106755},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106755},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725001911},
author = {Selma {Durmuş Sarıkahya} and Özkan Özbay and Kemal Torpuş and Galip Usta and Sevil {Çınar Özbay}},
keywords = {ChatGPT, Nursing education, Faculty members, Artificial intelligence},
abstract = {Background
Recent advancements in artificial intelligence technologies particularly ChatGPT have supported learning and fostered critical thinking in nursing education. However, integrating these tools into academic settings requires both ethical and strategic planning.
Aim
This study aims to explore the perspectives of nursing faculty members regarding the integration of ChatGPT into nursing education.
Methods
This descriptive phenomenological study was conducted with 14 nursing faculty members. Data were collected using a socio-demographic information form and a semi-structured interview guide and analyzed using thematic analysis methods. The COREQ checklist was followed.
Results
The average age of the nursing educators was 38.46 ± 5.23 years, and their average professional experience was 14.21 ± 3.35 years. Six main themes and twelve sub-themes were identified from the interviews. The main themes included information accuracy and reliability, contributions to educational processes, ease of use and challenges, development of professional knowledge and skills, integration into nursing practices, and the long-term impacts on nursing education.
Conclusion
ChatGPT has the potential to enhance nursing education by supporting theoretical learning, improving efficiency, and fostering personalized learning experiences. To successfully integrate ChatGPT into nursing curricula, educational institutions should implement specific strategies, such as faculty training programs and AI literacy initiatives, to equip educators and students with the necessary skills to use AI tools effectively.
Implications for nursing and health policy
Educational institutions should develop clear policies for the ethical and strategic integration of AI tools like ChatGPT. Future research should focus on specific methodologies, such as longitudinal studies that assess the impact of ChatGPT on student learning outcomes, as well as its long-term effects on nursing practice and healthcare services.}
}
@article{ABDULAZIZ2024103616,
title = {Plastic litter: A hidden reservoir for antibiotic-resistant pathogens in coastal ecosystems},
journal = {Regional Studies in Marine Science},
volume = {76},
pages = {103616},
year = {2024},
issn = {2352-4855},
doi = {https://doi.org/10.1016/j.rsma.2024.103616},
url = {https://www.sciencedirect.com/science/article/pii/S2352485524002494},
author = {Anas Abdulaziz and Nizam Ashraf and Aseera Manika and Mohammed Nowshad Bilutheth and Abdul Riyas Chekkillam and Idrees Babu Konhamkakkada and Kiran Krishna and Reshmi Chandran Rema and Sujith Athiyanathil and Deepesh Velachery and Dinesh Kumar Periyadan Katinhippally},
keywords = {Plastic, Pathogens, Water associated diseases, Blue flag, Antibiotic resistance, Coral reef, Vibrio},
abstract = {Plastic litter carrying pathogenic bacteria pose serious threats to the health of human and aquatic life. We enumerated the abundance of Escherichia coli and Vibrio species in different types of plastic litter (biomedical, food packages, sanitary, fishing material and miscellaneous) collected from the beaches of Agatti and Kavaratti in the Lakshadweep islands of India using quantitative real-time PCR. Further the antimicrobial resistance profile of E. coli and Vibrio species isolated from these samples were also tested. A very high number (more than three thousand gene copies per gram of plastic litter) of Escherichia coli, and Vibrio spp. were detected in the plastic litter. Vibrio spp. in the plastic litter were identified as V. harveyi, V. neocaledonicus, V. japonicus, V. parahaemolyticus and V. campbelli. More than sixty percentage of E. coli and Vibrio spp. isolated from all samples except the E. coli isolated from fishing gear of Kavaratti had multiple antibiotic resistance index of more than 0.25. Most of the bacteria were resistant towards ampicillin, erythromycin, and moxifloxacin, while least resistance was observed against gatifloxacin, gentamicin, imipenem, meropenem, norfloxacin and trimethoprim. These results indicate that plastic litter may act as a conduit for the attachment and transport of multiple antibiotic resistant pathogens, causing severe setbacks to the global efforts on attaining sustainable development goals 3 (health), 6 (clean water) and 14 (life under water). Therefore, strict implementation of plastic waste management rules, awareness campaigns for cleaning beaches and citizen science initiatives to monitor and remove plastics are proposed for protecting the beaches from the deleterious effects of mismanaged plastics.}
}
@article{ZHANG2025110693,
title = {Language impairment in temporal lobe epilepsy: insights from a meta-analysis of fMRI studies},
journal = {Epilepsy & Behavior},
volume = {172},
pages = {110693},
year = {2025},
issn = {1525-5050},
doi = {https://doi.org/10.1016/j.yebeh.2025.110693},
url = {https://www.sciencedirect.com/science/article/pii/S1525505025004330},
author = {Zheng Zhang},
keywords = {Temporal lobe epilepsy, Language impairment, Broca’s area, fMRI, Neuroplasticity},
abstract = {Temporal lobe epilepsy (TLE) is frequently associated with language impairment. This meta-analysis quantitatively synthesized data from 12 functional neuroimaging studies, including 390 TLE patients and 356 healthy controls (age range: 8.1–70 years; 57.2 % female), to identify language-related brain alterations in TLE. Compared to healthy controls, TLE patients exhibited hypoactivity within the left frontal language regions, including Broca’s area, precentral gyrus, and middle frontal gyrus, suggesting language impairment across syntactic, semantic, and articulatory processes. In parallel, hyperactivity in right-hemisphere regions was observed, reflecting compensatory neuroplastic adaptations to left-hemisphere language dysfunction. This reorganization may partially preserve language function but also indicate language processing inefficiencies. Moderator analyses revealed that in TLE, language comprehension compared with vocabulary elicited occipital hyperactivity and inferior frontal hypoactivity, reflecting posterior compensation and reduced frontal control. Left-sided TLE, compared to right-sided TLE, was more associated with hypoactivity in Broca’s area, reflecting the heightened vulnerability of the language-dominant frontotemporal regions. Greater hyperactivity in the right superior temporal gyrus with longer TLE duration may imply sustained compensatory engagement, whereas diminished hyperactivity in the right hippocampal gyrus with TLE duration may indicate a decline in compensatory capacity due to epileptic disruption. Furthermore, the more severity of language impairment correlated with (1) hypoactivity in Broca’s area, suggesting its role as a neural marker of language dysfunction, and (2) hyperactivity in the left insula, representing neural inefficiency or maladaptive neuroplastic reorganization. Collectively, these findings emphasize the complex interactions between epileptic pathology, compensatory reorganization, and progressive neuroplastic adaptation in shaping language outcomes in TLE.}
}
@article{PANTANOWITZ2024100609,
title = {Regulatory Aspects of Artificial Intelligence and Machine Learning},
journal = {Modern Pathology},
volume = {37},
number = {12},
pages = {100609},
year = {2024},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100609},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224001893},
author = {Liron Pantanowitz and Matthew Hanna and Joshua Pantanowitz and Joe Lennerz and Walter H. Henricks and Peter Shen and Bruce Quinn and Shannon Bennet and Hooman H. Rashidi},
keywords = {artificial intelligence, Food and Drug Administration, laboratory-developed test, machine learning, medical device, regulations},
abstract = {In the realm of health care, numerous generative and nongenerative artificial intelligence and machine learning (AI-ML) tools have been developed and deployed. Simultaneously, manufacturers of medical devices are leveraging AI-ML. However, the adoption of AI in health care raises several concerns, including safety, security, ethical biases, accountability, trust, economic impact, and environmental effects. Effective regulation can mitigate some of these risks, promote fairness, establish standards, and advocate for more sustainable AI practices. Regulating AI tools not only ensures their safe and effective adoption but also fosters public trust. It is important that regulations remain flexible to accommodate rapid advances in this field to support innovation and also not to add additional burden to some of our preexisting and well-established frameworks. This study covers regional and global regulatory aspects of AI-ML including data privacy, software as a medical device, agency approval and clearance pathways, reimbursement, and laboratory-developed tests.}
}
@article{TAJIRIAN2025,
title = {Assessing the Impact on Electronic Health Record Burden After Five Years of Physician Engagement in a Canadian Mental Health Organization: Mixed-Methods Study},
journal = {JMIR Human Factors},
volume = {12},
year = {2025},
issn = {2292-9495},
doi = {https://doi.org/10.2196/65656},
url = {https://www.sciencedirect.com/science/article/pii/S2292949525001130},
author = {Tania Tajirian and Brian Lo and Gillian Strudwick and Adam Tasca and Emily Kendell and Brittany Poynter and Sanjeev Kumar and Po-Yen (Brian) Chang and Candice Kung and Debbie Schachter and Gwyneth Zai and Michael Kiang and Tamara Hoppe and Sara Ling and Uzma Haider and Kavini Rabel and Noelle Coombe and Damian Jankowicz and Sanjeev Sockalingam},
keywords = {electronic health records, health informatics, documentation burden, physician burnout, engagement strategy, evaluation, EHR, burden, physician, cross-sectional survey},
abstract = {Background
The burden caused by the use of electronic health record (EHR) systems continues to be an important issue for health care organizations, especially given human resource shortages in health care systems globally. As physicians report spending 2 hours documenting for every hour of patient care, there has been strong interest from many organizations to understand and address the root causes of physician burnout due to EHR burden.
Objective
This study focuses on evaluating physician burnout related to EHR usage and the impact of a physician engagement strategy at a Canadian mental health organization 5 years after implementation.
Methods
A cross-sectional survey was conducted to assess the perceived impact of the physician engagement strategy on burnout associated with EHR use. Physicians were invited to participate in a web-based survey that included the Mini-Z Burnout questionnaire, along with questions about their perceptions of the EHR and the effectiveness of the initiatives within the physician engagement strategy. Descriptive statistics were applied to analyze the quantitative data, while thematic analysis was used for the qualitative data.
Results
Of the 254 physicians invited, 128 completed the survey, resulting in a 50% response rate. Among the respondents, 26% (33/128) met the criteria for burnout according to the Mini-Z questionnaire, with 61% (20/33) of these attributing their burnout to EHR use. About 52% of participants indicated that the EHR improves communication (67/128) and 38% agreed that the EHR enables high-quality care (49/128). Regarding the physician engagement strategy initiatives, 39% (50/128) agreed that communication through the strategy is efficient, and 75% (96/128) felt more proficient in using the EHR. However, additional areas for improvement within the EHR were identified, including (1) medication reconciliation and prescription processes; (2) chart navigation and information retrieval; (3) longitudinal medication history; and (4) technology infrastructure challenges.
Conclusions
This study highlights the potential impact of EHRs on physician burnout and the effectiveness of a unique physician engagement strategy in fostering positive perceptions and improving EHR usability among physicians. By evaluating this initiative in a real-world setting, the study contributes to the broader literature on strategies aimed at enhancing physician experience following large-scale EHR implementation. However, the findings indicate a continued need for system-level improvements to maximize the value and usage of EHRs. The physician engagement strategy demonstrates the potential to enhance physicians’ EHR experience. Future efforts should prioritize system-level advancements to increase the EHR’s impact on quality of care and develop standardized approaches for engaging physicians on a broader Canadian scale.}
}
@article{FUSHIMI2025107836,
title = {Exposure to mouse dams to bonito broth during gestation or lactation reduces fat intake in offspring},
journal = {Appetite},
volume = {206},
pages = {107836},
year = {2025},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2024.107836},
url = {https://www.sciencedirect.com/science/article/pii/S0195666324006408},
author = {Shunsuke Fushimi and Sho Matsui and Yasuo Oguri and Satoshi Tsuzuki and Tsutomu Sasaki},
keywords = {Fat appetite, Bonito broth, DOHaD, Gestation, Lactation, Lick microstructural analysis},
abstract = {Overconsumption of fat contributes to obesity and low adherence to dietary therapy in patients with obesity. The frequency of consuming soup dishes containing “dashi” (Japanese broth), a characteristic element of the Japanese diet, is negatively associated with obesity indicators. The use of dashi is considered one of the reasons why the low-fat Japanese diet is popular; however, whether and how dashi controls the selection and intake of fat is unknown. In this study, we tested the hypothesis that bonito broth, a typical Japanese dashi, affects fat consumption in a mouse model. First, we examined the long-term or short-term intake of corn oil emulsion in adult mice fed bonito broth. No significant effect was observed. Next, mouse dams were fed bonito broth during gestation or lactation and licking of 0.5, 1, 2.5, 5, and 10% corn oil in their adult pups was evaluated in acute tests. Compared to the control group, there were significant decreases in licks for some corn oil concentrations in the gestation and lactation groups. Finally, corn oil licking was tested in pups fed bonito broth after weaning. No significant effect was detected. This study suggests that dams’ intake of bonito broth during gestation or lactation reduces the intake of fat by their pups in adulthood.}
}
@article{KUCUK2025125246,
title = {Investigation of the molecular interaction between apraclonidine, an α2-adrenergic receptor agonist, and bovine serum albumin using fluorescence and molecular docking techniques},
journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
volume = {326},
pages = {125246},
year = {2025},
issn = {1386-1425},
doi = {https://doi.org/10.1016/j.saa.2024.125246},
url = {https://www.sciencedirect.com/science/article/pii/S1386142524014124},
author = {Ipek Kucuk and Öykü Buket Küçükşahin and Merve Yildirim and Md. Zahirul Kabir and Hülya Silah and Ismail Celik and Bengi Uslu},
keywords = {Apraclonidine, Fluorescence spectroscopy, Bovine serum albumin, Molecular docking, Ligand–protein interaction},
abstract = {Apraclonidine (APR) is a potent and selective α2-adrenergic receptor agonist used in the diagnosis of Horner’s Syndrome, and the residuals of APR that accumulate in tissues of animals can cause central nervous and cardiovascular systems influences in humans. Therefore, to understand the influence of APR on human health, we examined the interaction of APR with the carrier protein in plasma, bovine serum albumin (BSA). The BSA fluorescence signal was quenched due to the APU–BSA complex formation and a weak binding affinity was estimated between APR and BSA. The inclusion of fluorescence, UV–vis absorption, molecular docking, and dynamics simulation techniques employed to broadly investigate the combination of APR with BSA at typical physiological conditions. The thermodynamic results revealed that enthalpy (ΔH0) and entropy (ΔS0) changes were computed as +11.14 kJ mol−1 and +97.56 J mol−1 K−1, respectively, which represented the binding is principally entropy-driven and the hydrophobic forces acting a significant role in the reaction. Analysis of synchronous and 3-D fluorescence signals revealed microenvironmental variations close to BSA’s Trp and Tyr residues upon APR addition. Both the competitive site marker as well as molecular docking results detected that APR exhibited a stronger binding affinity towards Drug Site 2 (DS2) compared to Drug Site 1 (DS1).}
}
@article{RYAN2024100536,
title = {The impact of fluorine-18-fluoroethyltyrosine positron emission tomography scan timing on radiotherapy planning in newly diagnosed patients with glioblastoma},
journal = {Physics and Imaging in Radiation Oncology},
volume = {29},
pages = {100536},
year = {2024},
issn = {2405-6316},
doi = {https://doi.org/10.1016/j.phro.2024.100536},
url = {https://www.sciencedirect.com/science/article/pii/S240563162400006X},
author = {John Ryan and Nicholas Hardcastle and Roslyn Francis and Peter Ferjančič and Sweet Ping Ng and Eng-Siew Koh and Moshi Geso and Jennifer Kelly and Martin A. Ebert},
keywords = {Glioblastoma, PET, CTV, Radiation Therapy, Radiotherapy Planning},
abstract = {Background and purpose
Glioblastoma is one of the most common and aggressive primary brain tumours in adults. Though radiation therapy (RT) techniques have progressed significantly in recent decades, patient survival has seen little improvement. However, an area of promise is the use of fluorine-18-fluoroethyltyrosine positron-emission-tomography (18F-FET PET) imaging to assist in RT target delineation. This retrospective study aims to assess the impact of 18F-FET PET scan timing on the resultant RT target volumes and subsequent RT plans in post-operative glioblastoma patients.
Materials and Methods
The imaging and RT treatment data of eight patients diagnosed with glioblastoma and treated at a single institution were analysed. Before starting RT, each patient had two 18F-FET-PET scans acquired within seven days of each other. The information from these 18F-FET-PET scans aided in the creation of two novel target volume sets. The new volumes and plans were compared with each other and the originals.
Results
The median clinical target volume (CTV) 1 was statistically smaller than CTV 2. The median Dice score for the CTV1/CTV2 was 0.98 and, of the voxels that differ (median 6.5 cc), 99.7% were covered with a 5 mm expansion. Overall organs at risk (OAR) and target dosimetry were similar in the PTV1 and PTV2 plans.
Conclusion
Provided the 18F-FET PET scan is acquired within two weeks of the RT planning and a comprehensive approach is taken to CTV delineation, the timing of scan acquisition has minimal impact on the resulting RT plan.}
}
@article{TUROS2025101275,
title = {Colour analysis of children's drawings of gods using computer vision},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101275},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101275},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000026},
author = {Mátyás Turós},
keywords = {Drawing analysis, RGB, OpenCV, Colour analysis, Colours, K-means clustering},
abstract = {The analysis of children's drawings is an important part of the educational and psychological research toolbox, and in drawing analysis the colours of representation are valuable psychological variables. In our experimental study, we use computer vision to identify the colours of drawings of God in Catholic school children (N = 360) and compare the process and results of analysis using K-means clustering and a classification approach. Our results show that the two methods do not produce the same results. The classification approach is a simpler procedure and is more suitable for comparing the results of different studies on the same topic. The colours of the students' drawings of God are, in descending order (excluding white): acromatic, blue, orange, yellow. The percentages of colours can be used in further analysis for educational and psychological studies of the use of colour.}
}
@article{HUERTACHAVEZ2024137644,
title = {Emotional congruency between faces and words benefits emotional judgments in women: An event-related potential study},
journal = {Neuroscience Letters},
volume = {822},
pages = {137644},
year = {2024},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2024.137644},
url = {https://www.sciencedirect.com/science/article/pii/S0304394024000211},
author = {Vladimir Huerta-Chavez and Julieta Ramos-Loyo},
keywords = {Emotional congruency, ERPs, P3, LPP, Faces, Words},
abstract = {The present study aimed to investigate the effects of emotional congruency between faces and words on word evaluation through event-related brain potentials (ERPs). To this end, 20 women performed a face-word congruency task in which an emotional face was presented simultaneously with an affective word in a non-superimposed format. Participants had to evaluate the emotional valence of the word in three different conditions: congruent, incongruent, and control. The emotionally congruent words were categorized faster and more accurately than the incongruent ones. In addition, the emotionally congruent words elicited higher P3/LPP amplitudes than the incongruent ones. These results indicate a beneficial effect of emotional face-word congruency on emotional judgments of words.}
}
@article{PETROVIC2025,
title = {Ridesharing accessibility: drivers’ intentions to share rides with persons with disabilities},
journal = {Transportation Letters},
year = {2025},
issn = {1942-7867},
doi = {https://doi.org/10.1080/19427867.2025.2554811},
url = {https://www.sciencedirect.com/science/article/pii/S1942786725000578},
author = {Đorđe Petrović and Radomir M. Mijailović and Dalibor Pešić},
keywords = {Mobility, persons with disabilities, ridesharing, transportation accessibility, transportation equity},
abstract = {ABSTRACT
This study has investigated how drivers from the general population are willing to share their driving with persons with disabilities. In order to obtain a clearer image, three groups of disability types were considered: persons with physical disabilities, hearing impairments, and visual impairments. The research was performed on 1,064 valid drivers (42.9% females) in Serbia. The most attractive category of persons with disabilities with whom drivers were willing to share their ride was persons with hearing impairments. We identified simplicity and altruism as key factors that influenced drivers’ intentions to share rides with persons with disabilities. Better results for persons with hearing impairments could be expected if the focus were on employed females. Highly educated drivers in urban areas could serve as a promising focus group for measures aimed at persons with visual impairments. Finally, we proposed specific measures to support decision-makers in implementing ridesharing solutions for persons with disabilities.}
}
@article{JAFARIAN2025100357,
title = {AI-assisted audio-learning improves academic achievement through motivation and reading engagement},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100357},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100357},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001607},
author = {Nanda R. Jafarian and Anne-Wil Kramer},
keywords = {, , , , , , , Generative AI},
abstract = {Artificial intelligence (AI) is transforming education by enabling the creation of innovative learning resources that may cater to diverse learning needs. Students with common forms of neurodiversity, such as ADHD, often face unique challenges in higher education that are not adequately addressed by current educational resources. One potentially helpful resource is audio content, which provides a flexible and accessible supplement to traditional educational materials. While audio content, such as podcasts, is widely popular, its effect on academic achievement remains underexplored. This pre-registered randomized controlled trial investigated the impact of AI-assisted audio-learning modules on academic achievement, with a particular focus on the mediating roles of motivation and reading engagement. Results showed that the audio-learning modules increased student motivation and reading engagement. Importantly, audio-learning driven increases in motivation and reading engagement boosted academic achievement. Furthermore, students with greater ADHD symptom severity particularly benefited from the audio-learning modules, as they played a crucial role in determining course success. Together, this study highlights the potential of AI-assisted audio-learning modules as a valuable tool in digital education environments, catering to diverse learning needs and improving educational outcomes.}
}
@article{YUE2025109945,
title = {Effects of a diet containing glutamine on the slaughter performance, meat quality, and skeletal muscle fiber types of feed-restricted yaks},
journal = {Meat Science},
volume = {230},
pages = {109945},
year = {2025},
issn = {0309-1740},
doi = {https://doi.org/10.1016/j.meatsci.2025.109945},
url = {https://www.sciencedirect.com/science/article/pii/S0309174025002062},
author = {Ziqi Yue and Shanpeng Ke and Liyuan Shi and Rui Hu and Zhisheng Wang and Quanhui Peng and Huawei Zou and Jianxin Xiao and Yahui Jiang and Fali Wu and Yiping Tang},
keywords = {Longissimus thoracis muscle, Glutamine metabolism, Mitochondrial dysfunction, Oxidative stress, AMPK pathway},
abstract = {This experiment aimed to investigate the impact of the diet containing glutamine on muscle fiber types and meat quality of feed restriction yaks. Our findings show that the meat quality and slaughter performance in the feed restriction group decreased relative to the control group. However, diet containing glutamine improved slaughter performance by increasing carcass weight, dressing percentage, net meat weight, and net meat percentage. Moreover, it improved meat quality by increasing L* and reducing drip loss. In addition, dietary glutamine supplementation alleviated the increase in the fast-twitch fibers, abnormal glutamine metabolism, oxidative damage, and mitochondrial dysfunction. Mechanistically, the AMPK/Sirt1/PGC-1α/TAFM pathway might be implicated in glutamine alleviated the feed restriction-induced reduction in meat quality. In summary, our findings suggested that dietary glutamine supplementation of feed-restricted yaks can effectively improve the antioxidant capacity, slow-twitch fiber percentage, and the meat quality of the yak Longissimus thoracis muscle.}
}
@article{ABBAS2025101551,
title = {Management accounting and artificial intelligence: A comprehensive literature review and recommendations for future research},
journal = {The British Accounting Review},
pages = {101551},
year = {2025},
issn = {0890-8389},
doi = {https://doi.org/10.1016/j.bar.2025.101551},
url = {https://www.sciencedirect.com/science/article/pii/S0890838925000010},
author = {Khalid Abbas},
keywords = {Artificial intelligence, Machine learning, Explainable AI, Management accounting, Large language models, Digitalization},
abstract = {Digitalization and artificial intelligence (AI) technologies have the potential to disrupt and transform the management accounting domain and the role of accountants. The study systematically reviews 91 articles, synthesizing scholarly work on digitalization, AI, machine learning (ML), deep learning (DL), explainable AI, generative AI, and large language models (LLMs) in management accounting. In this context, the value of the paper is multi-fold. First, we argue that these technologies transform accounting information and organizational structures, affecting the accounting function's relationship with other organizational functions. Second, they present new challenges for management accountants, including data privacy, confidentiality, security and ethical concerns. Third, digital technologies automate basic accounting tasks and decision-making processes, potentially reshaping management accountants' roles and skills in terms of job elimination, upskilling, deskilling and reskilling. Fourth, these technologies create new opportunities for multidisciplinary collaboration and redefine professional boundaries. This paper contributes by discussing the impact of digitalization and the latest AI technologies on management accounting, illustrating how they can create business value, and highlighting associated challenges and risks for the profession. It proposes research agendas and potential research questions for future studies, providing insight into the potential impacts and implications for the accounting profession and the role of accountants.}
}
@article{XIA2024112426,
title = {Explicit-implicit priori knowledge-based diffusion model for generative medical image segmentation},
journal = {Knowledge-Based Systems},
volume = {303},
pages = {112426},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112426},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124010608},
author = {Bicheng Xia and Bangcheng Zhan and Mingkui Shen and Hejun Yang},
keywords = {Diffusion probabilistic model, Medical image segmentation, Attention mechanism, Deep learning, Generative model},
abstract = {The diffusion probabilistic model (DPM) has achieved unparalleled results in current image generation tasks, and some recent research works employed it in several computer vision tasks, such as image super-resolution, object detection, etc. Thanks to DPM's superior ability to generate fine-grained details, these research efforts have yielded significant successes. In this paper, we propose a new DPM-based generative medical image segmentation method, named EIDiffuSeg. Specifically, we first construct an explicit-implicit aggregation priori knowledge with directional supervision ability by mining the semantic distribution pattern in the frequency and spatial domains. Then, the explicit-implicit aggregation priori knowledge is integrated into the different encoding stages of the denoising backbone network using a novel unsupervised priori knowledge induction strategy, which can guide the model to generate a segmentation mask of the region of interest directionally from a random inference process. We evaluate our method on three medical image segmentation benchmark datasets with different modalities and achieve the best segmentation results compared to state-of-the-art methods. Especially, compared to several current diffusion-based image segmentation methods, we achieved a 9% Dice improvement in the polyp segmentation benchmark. Our code will be available at https://github.com/Notmezhan/EIDiffuSeg.}
}
@article{ZHANG2024103549,
title = {Machine learning-derived blood culture classification with both predictive and prognostic values in the intensive care unit: A retrospective cohort study},
journal = {Intensive and Critical Care Nursing},
volume = {80},
pages = {103549},
year = {2024},
issn = {0964-3397},
doi = {https://doi.org/10.1016/j.iccn.2023.103549},
url = {https://www.sciencedirect.com/science/article/pii/S0964339723001672},
author = {Jin Zhang and Wanjun Liu and Wenyan Xiao and Yu Liu and Tianfeng Hua and Min Yang},
keywords = {Blood culture, Catheters, Classification, Cluster analysis, Intensive Care, Machine learning, Prognosis, Retrospective study},
abstract = {Objectives
Diagnosis and management of intensive care unit (ICU)-acquired bloodstream infections are often based on positive blood culture results. This retrospective cohort study aimed to develop a classification model using data-driven characterisation to optimise the management of intensive care patients with blood cultures.
Setting, methodology/design
An unsupervised clustering model was developed based on the clinical characteristics of patients with blood cultures in the Medical Information Mart for Intensive Care (MIMIC)-IV database (n = 2451). It was tested using the data from the MIMIC-III database (n = 2047).
Main outcome measures
The prognosis, blood culture outcomes, antimicrobial interventions, and trajectories of infection indicators were compared between clusters.
Results
Four clusters were identified using machine learning-based k-means clustering based on data obtained 48 h before the first blood culture sampling. Cluster γ was associated with the highest 28-day mortality rate, followed by clusters α, δ, and β. Cluster γ had a higher fungal isolation rate than cluster β (P < 0.05). Cluster δ was associated with a higher isolation rate of Gram-negative organisms and fungi (P < 0.05). Patients in clusters γ and δ underwent more femoral site vein catheter placements than those in cluster β (P < 0.001, all). Patients with a duration of antibiotics treatment of 4, 6, and 7 days in clusters α, δ, and γ, respectively, had the lowest 28-day mortality rate.
Conclusions
Machine learning identified four clusters of intensive care patients with blood cultures, which yielded different prognoses, blood culture outcomes, and optimal duration of antibiotic treatment. Such data-driven blood culture classifications suggest further investigation should be undertaken to optimise treatment and improve care.
Implications for clinical practice
Intensive care unit-acquired bloodstream infections are heterogeneous. Meaningful classifications associated with outcomes should be described. Using machine learning and cluster analysis could help in understanding heterogeneity. Data-driven blood culture classification could identify distinct physiological states and prognoses before deciding on blood culture sampling, optimise treatment, and improve care.}
}
@article{WANG2025116151,
title = {A simulation method for battery packs based on cell cloning techniques},
journal = {Journal of Energy Storage},
volume = {118},
pages = {116151},
year = {2025},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2025.116151},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X25008643},
author = {Yifan Wang and Tianxin Chen and Kuijie Lu and Yuedong Sun and Xiangjun Li and Feng Dai and Jianfeng Hua and Jia Wang and Yuejiu Zheng},
keywords = {lithium-ion battery pack, Cell cloning, Generative adversarial network, Battery pack dataset generation},
abstract = {Lithium-ion battery packs serve as one of the primary functional units in electric vehicles and energy storage systems, making the monitoring of their various parameters critical. However, acquiring data from battery packs is difficult, and experimental data collection requires substantial time and energy. Thus, the challenge of efficiently and accurately obtaining battery pack data is a pressing issue in the development of Battery Management Systems (BMS). This paper presents a simulation method for battery packs based on real cell cloning, demonstrating the effectiveness of using generative adversarial networks (GANs) to generate cell data reflecting actual charging states. This approach addresses the challenge of temporal data generation for battery packs through image-generating adversarial techniques. Initially, we employ the Pix2Pix GAN to generate battery pack data, followed by fitting the data of cells within the pack using a first-order Gaussian function. The results indicate that our model achieves a sampling point generation error of less than 1 V for the battery pack and less than 5 mV for cells. This advancement can significantly aid researchers in acquiring more effective battery pack data for developing various algorithms and software for BMS functionality testing in Hardware-in-the-Loop (HIL) environments.}
}
@article{ZHU2024100597,
title = {Highly flexible cell membranes are the key to efficient production of lipophilic compounds},
journal = {Journal of Lipid Research},
volume = {65},
number = {8},
pages = {100597},
year = {2024},
issn = {0022-2275},
doi = {https://doi.org/10.1016/j.jlr.2024.100597},
url = {https://www.sciencedirect.com/science/article/pii/S0022227524001020},
author = {Qiyao Zhu and Sijia Wang and Gang Fu and Fengming Guo and Wei Huang and Tengyue Zhang and Huina Dong and Zhaoxia Jin and Dawei Zhang},
keywords = {cell membrane engineering, lipophilic compounds, synthetic biology, microbial cell factories, artificial storage compartments, product outflow},
abstract = {Lipophilic compounds have a variety of positive effects on human physiological functions and exhibit good effects in the prevention and treatment of clinical diseases. This has led to significant interest in the technical applications of synthetic biology for the production of lipophilic compounds. However, the strict selective permeability of the cell membrane and the hydrophobic nature of lipophilic compounds pose significant challenges to their production. During fermentation, lipophilic compounds tend to accumulate within cell membrane compartments rather than being secreted extracellularly. The toxic effects of excessive lipophilic compound accumulation can threaten cell viability, while the limited space within the cell membrane restricts further increases in production yield. Consequently, to achieve efficient production of lipophilic compounds, research is increasingly focused on constructing robust and multifunctional microbial cell factories. Utilizing membrane engineering techniques to construct highly flexible cell membranes is considered an effective strategy to break through the upper limit of lipophilic compound production. Currently, there are two main approaches to cell membrane modification: constructing artificial storage compartments for lipophilic compounds and engineering the cell membrane structure to facilitate product outflow. This review summarizes recent cell membrane engineering strategies applied in microbial cell factories for the production of liposoluble compounds, discussing the challenges and future prospects. These strategies enhance membrane flexibility and effectively promote the production of liposoluble compounds.}
}
@article{SUTCLIFFE2025214153,
title = {Strategies for the design of biomimetic cell-penetrating peptides using AI-driven in silico tools for drug delivery},
journal = {Biomaterials Advances},
volume = {169},
pages = {214153},
year = {2025},
issn = {2772-9508},
doi = {https://doi.org/10.1016/j.bioadv.2024.214153},
url = {https://www.sciencedirect.com/science/article/pii/S2772950824003960},
author = {Rebecca Sutcliffe and Ciaran P.A. Doherty and Hugh P. Morgan and Nicholas J. Dunne and Helen O. McCarthy},
keywords = {Gene delivery, Cell penetrating peptides, AI, Peptide design, Machine learning},
abstract = {Cell-penetrating peptides (CPP) have gained rapid attention over the last 25 years; this is attributed to their versatility, customisation, and ‘Trojan horse’ delivery that evades the immune system. However, the current CPP rational design process is limited, as it requires several rounds of peptide synthesis, prediction and wet-lab validation, which is expensive, time-consuming and requires extensive knowledge in peptide chemistry. Artificial intelligence (AI) has emerged as a promising alternative which can augment the design process, for example by determining physiochemical characteristics, secondary structure, solvent accessibility, disorder and flexibility, as well as predicting in vivo behaviour such as toxicity and peptidase degradation. Other more recent tools utilise supervised machine learning (ML) to predict the penetrative ability of an amino acid sequence. The use of AI in the CPP design process has the potential to reduce development costs and increase the chances of success with respect to delivery. This review provides a survey of in silico tools and AI platforms which can be utilised in the design process, and the key features that should be taken into consideration when designing next generation CPPs.}
}
@article{LI2025131115,
title = {RegionDiffusion: Generative data augmentation for object detection with diffusion models},
journal = {Neurocomputing},
volume = {654},
pages = {131115},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131115},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225017874},
author = {Kesong Li and Shang Luo and Kuo-Kun Tseng},
keywords = {Diffusion models, Layout-to-image generation, Generative data augmentation, Object detection},
abstract = {Recently, research on generative data augmentation based on layout-to-image diffusion models for object detection has made some progress. However, there remain challenges in generated data, such as low visual quality, weak generalization and mismatches between generated images and annotations, which hinder the performance of object detectors. To alleviate these issues, we propose the RegionDiffusion, a novel layout-to-image model that uses an attention block called Region Self-Attention to divide the self-attention operation among visual tokens into several independent regions based on the bounding box of the layout to generate objects accurately in the given locations. Then, we design a pipeline utilizing a series of preprocessing and postprocessing steps to improve the quality of the generated data and then train detectors. With extensive experiments, we demonstrate that RegionDiffusion surpasses state-of-the-art models in layout-to-image generation and our pipeline significantly improves the performance of object detectors in both general domains and specific domains.}
}
@article{2025A16,
title = {Instructions for authors},
journal = {Gastrointestinal Endoscopy},
volume = {101},
number = {1},
pages = {A16-A22},
year = {2025},
issn = {0016-5107},
doi = {https://doi.org/10.1016/S0016-5107(24)03708-8},
url = {https://www.sciencedirect.com/science/article/pii/S0016510724037088}
}
@article{HAGEB2025104863,
title = {Ontogenetic drivers of neutrophil heterogeneity},
journal = {Experimental Hematology},
volume = {151},
pages = {104863},
year = {2025},
issn = {0301-472X},
doi = {https://doi.org/10.1016/j.exphem.2025.104863},
url = {https://www.sciencedirect.com/science/article/pii/S0301472X25001547},
author = {Ali Hageb and Merieme Farjia and Collins Osei-Sarpong and Carlos Silvestre-Roig},
abstract = {Neutrophil development is a tightly regulated, multistep process involving stem cell commitment, differentiation, and maturation in the bone marrow. Chromatin remodeling, transcriptional networks, epigenetic reprogramming, metabolic adaptations, and structural changes collectively govern neutrophil production, shaping both maturation states and functional potential. Although these processes can be leveraged to adapt the neutrophil pool quantitatively and qualitatively during homeostasis or inflammatory stress, their dysregulation often drives disease progression. In this review, we examine how these ontogenetic factors specify neutrophil functions and underscore the significance of functional diversity across different maturation states.}
}
@article{SUN2025107806,
title = {Modeling focused kV X-ray dose kernels via 3D implicit neural functions for small animal brain radiation},
journal = {Biomedical Signal Processing and Control},
volume = {107},
pages = {107806},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2025.107806},
url = {https://www.sciencedirect.com/science/article/pii/S1746809425003179},
author = {Liyan Sun and Chenhui Qiu and Weiyuan Sun and Lei Xing and Dimitre Hristov and Adam S. Wang and Wu Liu},
keywords = {Focused kV X-rays, Machine learning, Implicit neural functions},
abstract = {Precise irradiation is critical in radiation-based neuromodulation and neuro-oncology for small animals like mice. The focused kV x-ray approach was proposed to achieve a restricted target size that is difficult for existing devices. The treatment planning of focused X-ray irradiation requires the dose kernel libraries to produce dose maps. However, the Monte Carlo approach for dose kernel library generation is time- and space-consuming. To optimize spatiotemporal efficiency, we propose a machine learning approach based on 3D implicit neural functions to model focused kV X-ray dose kernels for small animal brain radiation. Based on the rat head phantom model, we define a library spanning a parameter space with proper range and resolution to cover the rat brain size and structure variation. We use the TOPAS-based Monte Carlo simulation for data preparation. Each dose kernel can be characterized by a depth parameter triplet. Implicit neural functions are trained to map spatial coordinates with a depth parameter triplet to their corresponding dose values. We find the periodic activation function of hidden neural layers and coordinate embedding of coordinates are important for accurate modeling. Experimental results show that we compress the training library from 17 GB to only 2.27 MB with high accuracy, and it is also shown to predict dose kernels in the testing dose kernels with an acceleration rate of 50,000 times, which is crucial to study the choice of optimal lens. This work is the first attempt to develop machine-learning techniques for modeling dose kernel libraries for small animal brain radiation.}
}
@article{BHATTARU20241950,
title = {Revolutionizing Cardiology With Words: Unveiling the Impact of Large Language Models in Medical Science Writing},
journal = {Canadian Journal of Cardiology},
volume = {40},
number = {10},
pages = {1950-1958},
year = {2024},
note = {Theme Issue: Rapidly Evolving Clinical Applications of Artificial Intelligence},
issn = {0828-282X},
doi = {https://doi.org/10.1016/j.cjca.2024.05.022},
url = {https://www.sciencedirect.com/science/article/pii/S0828282X24004136},
author = {Abhijit Bhattaru and Naveena Yanamala and Partho P. Sengupta},
abstract = {Large language models (LLMs) are a unique form of machine learning that facilitates inputs of unstructured text/numerical information for meaningful interpretation and prediction. Recently, LLMs have become commercialized, allowing the average person to access these incredibly powerful tools. Early adopters focused on LLM use in performing logical tasks, including—but not limited to—generating titles, identifying key words, summarizing text, initial editing of scientific work, improving statistical protocols, and performing statistical analysis. More recently, LLMs have been expanded to clinical practice and academia to perform higher cognitive and creative tasks. LLMs provide personalized assistance in learning, facilitate the management of electronic medical records, and offer valuable insights into clinical decision making in cardiology. They enhance patient education by explaining intricate medical conditions in lay terms, have a vast library of knowledge to help clinicians expedite administrative tasks, provide useful feedback regarding content of scientific writing, and assist in the peer-review process. Despite their impressive capabilities, LLMs are not without limitations. They are susceptible to generating incorrect or plagiarized content, face challenges in handling tasks without detailed prompts, and lack originality. These limitations underscore the importance of human oversight in using LLMs in medical science and clinical practice. As LLMs continue to evolve, addressing these challenges will be crucial in maximizing their potential benefits while mitigating risks. This review explores the functions, opportunities, and constraints of LLMs, with a focus on their impact on cardiology, illustrating both the transformative power and the boundaries of current technology in medicine.
Résumé
Les grands modèles de langage (LLM; large language models) représentent une forme unique d'apprentissage automatique qui facilite la saisie de textes non structurés et/ou d'informations numériques en vue d'une interprétation et d'une prédiction significatives. Récemment, les LLM ont été commercialisés, permettant au commun des mortels d'accéder à ces outils incroyablement puissants. Les premiers utilisateurs se sont concentrés sur l'utilisation des LLM pour effectuer des tâches logiques, y compris, mais sans s'y limiter, la génération de titres, l'identification de mots-clés, le résumé de textes, l'édition initiale de travaux scientifiques, l'amélioration de protocoles statistiques et l'exécution d'analyses statistiques. Plus récemment, les LLM ont été étendus à la pratique clinique et au monde universitaire pour effectuer des tâches cognitives et créatives de haut niveau. Les LLM fournissent une aide personnalisée à l'apprentissage, facilitent la gestion des dossiers médicaux électroniques et offrent des informations précieuses pour la prise de décision clinique en cardiologie. Ils améliorent l'éducation des patients en expliquant des conditions médicales complexes avec des termes simples, disposent d'une vaste bibliothèque de connaissances pour aider les cliniciens à accélérer les tâches administratives, fournissent un retour d'information utile sur le contenu des écrits scientifiques et participent au processus de révision par les pairs. Malgré leurs capacités impressionnantes, les LLM ne sont pas sans limitations. Ils sont susceptibles de générer des contenus incorrects ou plagiés, sont confrontés à des difficultés pour effectuer des tâches sans instructions détaillées et manquent d'originalité. Ces limitations soulignent l'importance de la surveillance humaine dans l'utilisation des LLM en science médicale et dans la pratique clinique. À mesure que les LLM continuent d'évoluer, il sera essentiel de relever ces défis pour maximiser leurs avantages potentiels tout en atténuant les risques. Cette étude explore les fonctions, les opportunités et les contraintes des LLM, en mettant l'accent sur leur impact en cardiologie, illustrant à la fois le pouvoir de transformation et les limites de la technologie actuelle en médecine.}
}
@article{YAO2025,
title = {Extracting Knowledge From Scientific Texts on Patient-Derived Cancer Models Using Large Language Models: Algorithm Development and Validation Study},
journal = {JMIR Bioinformatics and Biotechnology},
volume = {6},
year = {2025},
issn = {2563-3570},
doi = {https://doi.org/10.2196/70706},
url = {https://www.sciencedirect.com/science/article/pii/S2563357025000042},
author = {Jiarui Yao and Zinaida Perova and Tushar Mandloi and Elizabeth Lewis and Helen Parkinson and Guergana Savova},
keywords = {patient-derived cancer models, large language models, knowledge extraction, in-context learning, soft prompting, prompt tuning, information extraction},
abstract = {Background
Patient-derived cancer models (PDCMs) have become essential tools in cancer research and preclinical studies. Consequently, the number of publications on PDCMs has increased significantly over the past decade. Advances in artificial intelligence, particularly in large language models (LLMs), offer promising solutions for extracting knowledge from scientific literature at scale.
Objective
This study aims to investigate LLM-based systems, focusing specifically on prompting techniques for the automated extraction of PDCM-related entities from scientific texts.
Methods
We explore 2 LLM-prompting approaches. The classic method, direct prompting, involves manually designing a prompt. Our direct prompt consists of an instruction, entity-type definitions, gold examples, and a query. In addition, we experiment with a novel and underexplored prompting strategy—soft prompting. Unlike direct prompting, soft prompts are trainable continuous vectors that learn from provided data. We evaluate both prompting approaches across state-of-the-art proprietary and open LLMs.
Results
We manually annotated 100 abstracts of PDCM-relevant papers, focusing on PDCM papers with data deposited in the CancerModels.Org platform. The resulting gold annotations span 15 entity types for a total 3313 entity mentions, which we split across training (2089 entities), development (542 entities) and held-out, eye-off test (682 entities) sets. Evaluation includes the standard metrics of precision or positive predictive value, recall or sensitivity, and F1-score (harmonic mean of precision and recall) in 2 settings: an exact match setting, where spans of gold and predicted annotations have to match exactly, and an overlapping match setting, where the spans of gold and predicted annotations have to overlap. GPT4-o with direct prompting achieved F1-scores of 50.48 and 71.36 for exact and overlapping match settings, respectively. In both evaluation settings, LLaMA3 soft prompting improved performance over direct prompting (F1-score from 7.06 to 46.68 in the exact match setting; and 12.0 to 71.80 in the overlapping evaluation setting). Results with LLaMA3 soft prompting are slightly higher than GPT4-o direct prompting in the overlapping match evaluation setting.
Conclusions
We investigated LLM-prompting techniques for the automatic extraction of PDCM-relevant entities from scientific texts, comparing the traditional direct prompting approach with the emerging soft prompting method. In our experiments, GPT4-o demonstrated strong performance with direct prompting, maintaining competitive results. Meanwhile, soft prompting significantly enhanced the performance of smaller open LLMs. Our findings suggest that training soft prompts on smaller open models can achieve performance levels comparable to those of proprietary very large language models.}
}
@article{DAKHAVE2024116373,
title = {Advanced integrative molecular platform for high-throughput screening of drug-resistant tuberculosis},
journal = {Diagnostic Microbiology and Infectious Disease},
volume = {109},
number = {4},
pages = {116373},
year = {2024},
issn = {0732-8893},
doi = {https://doi.org/10.1016/j.diagmicrobio.2024.116373},
url = {https://www.sciencedirect.com/science/article/pii/S0732889324002025},
author = {Minal Dakhave and Trupti Rale and Harshada Suryawanshi and Nikita Patil and Abhijeet Suryawanshi and Raju Kumar and Shruti Gadekar and Payal Bhatnagar and Amrita Khaire and Gautam Wankhede},
keywords = {Drug-resistant tuberculosis, Molecular diagnostics, PCR, Tuberculosis},
abstract = {A real time-polymerase chain reaction-based test in lyophilized form, was developed to simultaneously identify Mycobacterium tuberculosis complex (MTC) by targeting IS6110, rrs as dual markers, as well as mutations causing rifampicin and isoniazid resistance. The test was evaluated for pulmonary and non-pulmonary specimens from sample isolation to PCR analysis. The test demonstrated limit of detection of 25 CFU/mL for MTB, 200 CFU/mL for rpoB and inhA/katG targets with >95 % CI. The specificity for MTC was supported by a comprehensive clinical validation (n = 100). This load-and-go molecular platform, with features of high throughput, long shelf-life, room temperature storage provides simultaneous detection of MTC and its drug-resistant mutations in minimal time. The test named “PathoDetect TM MTB-RIF and INH resistance detection kit” has been approved by Central Drugs Standard Control Organisation, Indian Council of Medical Research and would have implications for tuberculosis elimination programs.}
}
@article{MALIK20251556,
title = {Drivers of Industry 5.0 technologies in dairy industry: an exploratory study},
journal = {Sustainable Food Technology},
volume = {3},
number = {5},
pages = {1556-1568},
year = {2025},
issn = {2753-8095},
doi = {https://doi.org/10.1039/d5fb00156k},
url = {https://www.sciencedirect.com/science/article/pii/S2753809525000845},
author = {Mohit Malik and Rahul S Mor and Vijay Kumar Gahlawat and Abdo Hassoun and Sandeep Jagtap},
abstract = {This paper aims to identify and analyse the key drivers affecting the adoption of Industry 5.0 (I5.0) technologies in the dairy industry. The data collected from various dairy stakeholders was analysed using Exploratory Factor Analysis (EFA) to uncover the underlying factors, and Multiple Linear Regression (MLR) was employed to evaluate the impact of the factors on the adoption level of I5.0 technologies. The EFA identified five key factors driving the adoption of I5.0 technologies: operational efficiency and productivity, animal health and product quality, sustainability and environmental impact, data-driven decision-making and compliance, and market competitiveness and collaboration. The MLR analysis revealed that these factors significantly impact the level of adoption (LOA), with operational efficiency and productivity being the most influential factors. The findings indicate that dairy stakeholders recognise the potential benefits of I5.0 technologies in enhancing efficiency, improving product quality, and enabling effective decision-making.}
}
@article{FERRARIS2024100081,
title = {Intelligence as a human life form},
journal = {Journal of Responsible Technology},
volume = {18},
pages = {100081},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100081},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000076},
author = {Maurizio Ferraris},
keywords = {AI, Finalism, Organism, Writing, Intelligence},
abstract = {This text aims to counter the anxieties generated by the recent emergence of AI and the criticisms leveled at it, demanding its moralization. It does so by demonstrating that AI is neither new nor is it true intelligence but rather a tool, akin to many others that have long been serving human intelligence and its objectives. In what follows, I offer a broader reflection on technology that aims to contextualize the novelty and singularity attributed to AI within the history of technological developments. My ultimate goal is to relativize the novelty of AI, seeking to alleviate the moral anxieties it currently elicits and encouraging a more normal, optimistic view of it. The first step in understanding AI is indeed to realize that its novelty is only relative, and that AI has many ancestors that, upon closer examination, turn out to be closely related.}
}
@article{GALLOBUENO2024235505,
title = {Enhancing composite cathode manufacturing with machine learning for polymer electrolyte solid-state batteries},
journal = {Journal of Power Sources},
volume = {623},
pages = {235505},
year = {2024},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2024.235505},
url = {https://www.sciencedirect.com/science/article/pii/S0378775324014575},
author = {A. Gallo-Bueno and R.A.N. Hanifah and L. Fernandez-Diaz and L. Otaegui and A. Villaverde and M.C. Morant-Miñana and J. Carrasco},
keywords = {Solid-state batteries, Composite electrode manufacturing, Machine learning, Data analysis},
abstract = {Solid-state batteries (SSBs) represent a pivotal advancement in battery technology, poised to surpass lithium-ion batteries and drive the electrification of mobility. However, achieving cost-effective, scalable, and sustainable fabrication processes for SSB components remains a challenge. This study integrates machine learning (ML) techniques to optimize manufacturing processes of cathodes for polymer electrolyte based SSBs. The findings reveal strong predictive performance of regression models for active material loading, with support vector machine emerging as the top performer. Multiclassification models exhibit satisfactory precision, particularly in categorizing ideal electrode samples. Analysis of principal component and correlation circles highlight viscosity and wet thickness as critical variables for mixing and coating, respectively. Despite promising metrics, dataset imbalance and size limit model robustness. Further dataset augmentation is recommended before deployment in production. ML techniques offer promise in advancing battery manufacturing, paving the way for enhanced SSB performance and broader application across battery components.}
}
@article{GUO2025135424,
title = {Enhanced green hydrogen production using a novel converter with extremely low current ripple and high step-down ratio},
journal = {Fuel},
volume = {398},
pages = {135424},
year = {2025},
issn = {0016-2361},
doi = {https://doi.org/10.1016/j.fuel.2025.135424},
url = {https://www.sciencedirect.com/science/article/pii/S0016236125011494},
author = {Xiaoqiang Guo and Fanqin Ding and Shiqi Zhang and Yiyina Teng and Naizhe Diao and Vladimir Terzija},
keywords = {Hydrogen production, DC-DC converter, Current ripple, Step-down ratio, Voltage stress},
abstract = {Currently, renewable energy hydrogen production systems are becoming increasingly promoted due to its low emissions advantage. However, the connection between electrolyzers and renewable energy systems requires DC-DC converters with high step-down ratios and low current ripple. The existing researches on DC-DC converters cannot meet the operational requirements of electrolyzers. In order to handle this technical point, a novel non-isolated DC-DC converter for hydrogen production is proposed in this paper. It has the advantages of a higher step-down ratio and low voltage stress. Aside from that, the proposal is able to achieve a negligible output current ripple without the additional active power devices or transformers. Finally, the topology is connected to an electrolyzer in the experiment to verify the effectiveness of the topology.}
}
@article{LIM2025102911,
title = {Editorial for special issue: Digital multimodal composing in the era of artificial intelligence},
journal = {Computers and Composition},
volume = {75},
pages = {102911},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102911},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000872},
author = {Fei Victor Lim and Øystein Gilje and Emilia Djonov}
}
@article{DOU2025109827,
title = {Balancing privacy considerations and customization preferences for consumer: LLMs adoption and coordination strategies in supply chains},
journal = {International Journal of Production Economics},
pages = {109827},
year = {2025},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2025.109827},
url = {https://www.sciencedirect.com/science/article/pii/S0925527325003123},
author = {Runliang Dou and Guofang Nan and Yueming Pan and Xin Liu},
keywords = {Operations and supply chain management (OSCM), Product customization, Consumer uncertainty, Privacy concerns, Large language models (LLMs)},
abstract = {The manufacturer’s motivation to invest in product customization is reduced by consumer uncertainty regarding customized products and the double marginalization effect in supply chains. The emergence of large language models (LLMs), with their enhanced interaction and inference capabilities, offers opportunities to mitigate consumer uncertainty in customized product sales, but simultaneously raises novel privacy concerns. Consequently, supply chain members encounter operational decision complexities in the context of product customization. This study analytically examined a two-tier supply chain and investigated the adoption of LLMs in customized product sales under consumer uncertainty and privacy concerns. We further explored revenue-sharing and cost-sharing contract mechanisms for supply chain coordination. The results demonstrated that adopting LLMs with price discrimination generally benefited the manufacturer, the retailer, consumer surplus, and social welfare, while adopting LLMs without price discrimination only benefited those when privacy costs were low. The product-customization level was not affected by the adoption of LLMs without or with price discrimination in wholesale contracts. Both revenue-sharing and cost-sharing contracts enhanced manufacturers’ profits and increased product-customization level, while retailers benefited only when the revenue-sharing or cost-sharing ratio was low. Privacy costs hindered Pareto improvements only in the adoption of LLMs with price discrimination under revenue-sharing contracts. Finally, we characterized the conditions under which manufacturers and retailers reach contractual agreements regarding wholesale prices, cost-sharing, and revenue-sharing, and we explored the impact of privacy costs on such agreements.}
}
@article{KOWALCZYK2024108046,
title = {Intumescent coatings modified with cocoa shells as a bio-substitute for pentaerythritol},
journal = {Progress in Organic Coatings},
volume = {186},
pages = {108046},
year = {2024},
issn = {0300-9440},
doi = {https://doi.org/10.1016/j.porgcoat.2023.108046},
url = {https://www.sciencedirect.com/science/article/pii/S0300944023006422},
author = {Krzysztof Kowalczyk and Agnieszka Kowalczyk},
keywords = {Fire, Intumescent coating, Pentaerythritol, Cocoa, Bio-based},
abstract = {In order to find a fully natural substitute of pentaerythritol (PER), which is the basic carbon source in thermal swelling systems, a powder of cocoa shells (CS) was tested in intumescent coatings based on poly(vinyl acetate) (ICs). Generally, CS are the main waste by-products of cocoa production, and their utilization is limited. The coating materials were mainly compounded using melamine (a blowing agent), ammonium polyphosphate (a dehydrating agent), and the same doses of PER, CS or their mixtures (PER/CS). They were primarily investigated using a gas flame-heated furnace (according to a cellulosic fire curve), TGA, and DSC techniques. The CS addition markedly affected charring processes of ICs during the fire test and improved intumescence effectiveness and thermal insulation time parameters (from 15.9 to 23.6 a.u. and from 28.2 to 30.9 min, respectively). Moreover, the natural additive increased compression strength of charred ICs on a steel substrate (from 1.48 to 1.88 kPa). The best performance properties were noted for IC with the PER/CS mixture containing 10 wt% of the organic component – in this case all the tested features were improved.}
}
@article{TAN2025230737,
title = {Crustal structure of the Curnamona Province in Australia by ambient noise tomography},
journal = {Tectonophysics},
volume = {906},
pages = {230737},
year = {2025},
issn = {0040-1951},
doi = {https://doi.org/10.1016/j.tecto.2025.230737},
url = {https://www.sciencedirect.com/science/article/pii/S0040195125001234},
author = {Xin Tan and Yingjie Yang and Graham Heinson and Ben Kay and Goran Boren and Xiaozhou Yang},
keywords = {Ambient Noise Tomography, Shear-wave velocity, Curnamona Province},
abstract = {The Curnamona Province in southern Australia is a 90,000 km2 Paleoproterozoic to Mesoproterozoic craton that rifted from the Gawler Craton in the Neoproterozoic and is now separated by the Adelaide Rift Complex sediments in the Flinders Ranges. Three-component passive seismic data were collected over 30 days at 135 stations spaced approximately 25 km with sample rate of 2 ms and a natural frequency of 5 Hz. Cross-correlation functions of ambient noise were calculated between station pairs to determine dispersion curves at a period bandwidth of 3 to 9 s, from which a shear-wave velocity model was constructed to a depth of 20 km. In the top 5 km, low shear-wave velocity < 3400 m/s correlates with low electrical resistivity <100 Ohm.m from a broadband MT inversion of 134 co-located sites, primarily due to fluid-porosity of sediments. In the depth range 5–20 km there are two notable features. Firstly, across the southern part of the Curnamona Province shear-wave velocity increases by >200 m/s from west to east, over ∼200 km, correlated with a trend in Bouguer gravity that increases from −200 μm/s2 to +200 μm/s2. Secondly, there is weaker correlation in dip and spatial extent between a zone of low resistivity <10 Ohm.m and low shear-wave velocity < 3600 m/s. Higher density crust in the eastern margin of the Curnamona Province may be due to Paleoproterozoic-aged mafic crust that was originally subducted and then upthrust to shallower depths during the Olarian Orogeny from 1620 to 1580 Ma. Reduced shear-wave velocity coincident with low-resistivity in the crust may be related to grain-boundary graphitic Paleoproterozoic sediments that would be ductile with slightly lower shear-modulus and be electrically conductive.}
}
@article{SALEH2025113723,
title = {Novel concept-oriented synthetic data approach for training generative AI-Driven crystal grain analysis using diffusion model},
journal = {Computational Materials Science},
volume = {251},
pages = {113723},
year = {2025},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2025.113723},
url = {https://www.sciencedirect.com/science/article/pii/S0927025625000667},
author = {A.S. Saleh and K. Croes and H. Ceric and I. De Wolf and H. Zahedmanesh},
keywords = {Machine Learning, Generative AI, Diffusion Model, Microstructure, TEM, Crystal Grain Boundaries},
abstract = {The traditional techniques for extracting polycrystalline grain structures from microscopy images, such as transmission electron microscopy (TEM) and scanning electron microscopy (SEM), are labour-intensive, subjective, and time-consuming, limiting their scalability for high-throughput analysis. In this study, we present an automated methodology integrating edge detection with generative diffusion models to effectively identify grains, eliminate noise, and connect broken segments in alignment with predicted grain boundaries. Due to the limited availability of adequate images preventing the training of deep machine learning models, a new seven-stage methodology is employed to generate synthetic TEM images for training. This concept-oriented synthetic data approach can be extended to any field of interest where the scarcity of data is a challenge. The presented model was applied to various metals with average grain sizes down to the nanoscale, producing grain morphologies from low-resolution TEM images that are comparable to those obtained from advanced and demanding experimental techniques with an average accuracy of 97.23 %. This represents a notable improvement, surpassing the accuracy of some of the state-of-the-art software-based methods for automated microstructure extraction, including neural network with convex hull and approximate contour (UNet + CHAC) (89 %), richer convolutional features (RCF) (91 %), and richer convolutional features with generative adversarial network (RCF + GAN) (93 %).}
}
@article{RUSSO202568,
title = {Loss of phosphatase and tensin homolog (PTEN) increases Lysyl oxidase-like 2 (LOXL2) expression enhancing the growth of fallopian tube epithelial cells as three-dimensional spheroids},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {1},
pages = {68-75},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000223},
author = {Angela Russo and Junlone Moy and Manead Khin and Timothy R. Dorsey and Alfredo {Lopez Carrero} and Joanna E. Burdette},
keywords = {LOXL2, PTEN, PAX2, Fallopian tube, Ovarian cancer},
abstract = {Background
High-grade serous ovarian cancer (HGSOC) accounts for 70–80% of all ovarian cancer-related deaths. Multiple studies have suggested that the fallopian tube epithelium (FTE) serves as the cell of origin of HGSOC. Phosphatase and tensin homolog (PTEN) is a tumor suppressor and its loss is sufficient to induce numerous tumorigenic changes in FTE, including increased migration, formation of multicellular tumor spheroids (MTSs), and ovarian colonization. In murine oviductal epithelial (MOE) cells (the equivalent of human FTE) loss of PTEN results in the upregulation of transcripts associated with the extracellular matrix, with a specific focus on the elevation of lysyl oxidase-like 2 (LOXL2). Although LOXL2 is known to drive transformation and invasion in solid tumors and is associated with a poor prognosis in ovarian cancer, its specific role in the tumorigenesis of ovarian cancer originating from FTE remains unclear. Therefore, we aim to investigate whether LOXL2 mediates tumorigenesis from the fallopian tube epithelium.
Methods
In this study, we utilized clustered regularly interspaced short palindromic repeats (CRISPR)-CRISPR-associated protein 9 (CAS9) technology to delete LOXL2 in PTEN-deficient MOE cells to understand its role in mediating the oncogenic effects of PTEN loss. In addition, CRISPR-CAS9 was used to delete LOXL2 in OVCAR8 ovarian cancer cells. We monitored the changes in tumorigenic properties, such as migration, invasion, and growth of three-dimensional (3D) spheroids, to assess whether the loss of LOXL2 resulted in any changes.
Results
We found that a reduction in LOXL2 expression did not significantly change the migration or invasive capabilities of PTEN-depleted MOE or human ovarian cancer cells. However, we found that a reduction in LOXL2 expression resulted in a significant reduction in 3D MTS formation and survival in both lines.
Conclusions
These results reveal for the first time that PTEN loss in FTE cells increases LOXL2 expression through downregulation of Pax2, and LOXL2 deletion blocks 3D spheroid formation.}
}
@article{ALI2025166,
title = {Global adoption of generative AI: What matters most?},
journal = {Journal of Economy and Technology},
volume = {3},
pages = {166-176},
year = {2025},
issn = {2949-9488},
doi = {https://doi.org/10.1016/j.ject.2024.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949948824000520},
author = {Hassnian Ali and Atta ul Mustafa and Ahmet Faruk Aysan},
keywords = {Generative AI, Future, Emerging Technologies, Global Adoption},
abstract = {This study investigates the determinants of generative AI adoption across 136 countries, leveraging cross-sectional data from 2023 and employing a negative binomial regression model to address data overdispersion. Generative AI is a transformative technology that enhances operational efficiency, drives innovation, and creates economic value across sectors. Key findings reveal that IT infrastructure, R&D investments, and company investment in emerging technologies significantly foster generative AI adoption, while misaligned government policies may hinder it. The analysis identifies crucial determinants, including technological infrastructure, economic stability, regulatory environments, and workforce readiness, as pivotal to adoption rates. The study provides actionable insights for policymakers, industry leaders, and researchers, advocating for tailored policies, strategic investment in high-speed internet and cloud services, and refining government incentives to align with AI sector needs. This research uniquely contributes by offering a comprehensive, cross-country perspective on factors influencing generative AI adoption.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@article{SINGCHA2024105975,
title = {Durian (Durio zibethinus L.) fruit: A superior dietary source of natural glutathione and γ-glutamylcysteine},
journal = {Journal of Food Composition and Analysis},
volume = {127},
pages = {105975},
year = {2024},
issn = {0889-1575},
doi = {https://doi.org/10.1016/j.jfca.2024.105975},
url = {https://www.sciencedirect.com/science/article/pii/S0889157524000097},
author = {Poorichaya Singcha and Gholamreza Khaksar and Mongkon Sirijan and Supaart Sirikantaramas},
keywords = {Durian ( L.), Cultivar, Heat sensitivity, Glutathione (GSH), γ- Glutamylcysteine (γ-EC), Processed products, Pulp},
abstract = {Numerous age-related degenerative diseases have been linked to diminished intracellular levels of glutathione (GSH), a vital antioxidant in the human body. Unfortunately, exogenous GSH encounters various barriers that prevent its entry into most human cells. γ-Glutamylcysteine (γ-EC), an immediate precursor of GSH, is a potential therapeutic agent that restores cellular GSH levels. Additionally, both compounds can serve as kokumi taste substances and enhance basic taste sensations. Considering the growing interest among health-conscious consumers toward naturally derived diets, the incorporation of fresh fruits and vegetables abundant in GSH and γ-EC presents a promising alternative for supplementation. Screening of various plant samples, including fruits, vegetables, and mushrooms, revealed that ripe durian pulp exhibited the highest levels of GSH (∼2.6) and γ-EC (∼14) per milligram per gram of dry weight. Owing to the popularity of durian-related products, we extended our investigation to analyze GSH and γ-EC contents in processed products. Notably, durian chips and pastes displayed a significant decrease in GSH and γ-EC levels, suggesting their sensitivity to heat. This observation was further validated by the observed instability of GSH and γ-EC standards during heat treatment. Our findings underscore the potential of durian fruit as a rich dietary source of GSH and γ-EC.}
}
@article{TIAN2025101111,
title = {Data-augmented machine learning models for oxynitride glasses via Wasserstein generative adversarial network with gradient penalty and content constraint},
journal = {Journal of Materiomics},
pages = {101111},
year = {2025},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2025.101111},
url = {https://www.sciencedirect.com/science/article/pii/S2352847825001017},
author = {Jing Tian and Yuan Li and Min Guan and Jijie Zheng and Jingyuan Chu and Yong Liu and Gaorong Han},
keywords = {Oxynitride glasses, Machine learning, Generative Adversarial Network, Data augmentation, SHAP analysis},
abstract = {Data-driven machine learning methods have been proven highly successful in predicting glass properties, but hampered when dealing with small datasets, such as oxynitride glasses with excellent mechanical properties and chemical stability. Here, a data augmentation method based on the Wasserstein Generative Adversarial Network with Gradient Penalty (GP) and Content Constraint Penalty (CP) terms, a generative deep-learning model via the adversarial training of a generator and a discriminator, was established, in which the GP and CP terms ensure training stability and the physical rationality of the generated samples. The results indicate that the generated samples improve the performance of the oxynitride glass composition-property models trained with the XGBoost algorithm in terms of prediction accuracy and generalization capability. Furthermore, the augmented models outperform the general glass prediction model, GlassNet, over 101 experimental samples not included in the training datasets. Based on SHAP's single feature analysis and feature interaction analysis, the interpretability study further sheds light on the contributions of elements and the interactive effects of element pairs on the properties of oxynitride glasses. These achievements not only provide reliable models for the composition-property studies of oxynitride glasses but also offer a novel strategy for developing high-performance data-driven models under data scarcity scenarios.}
}
@article{RAZ2024101598,
title = {Open and closed-ended problem solving in humans and AI: The influence of question asking complexity},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101598},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101598},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001366},
author = {Tuval Raz and Roni Reiter-Palmon and Yoed N. Kenett},
keywords = {Question asking, Problem-solving, AI, Creativity},
abstract = {Question-asking, an underexplored aspect of creativity, is integral to creative problem-solving and information-seeking. Previous research reveals that lower creativity correlates with asking simpler, closed questions, while higher creativity correlates with complex, open-ended inquiries. The present study explores the relation between question asking complexity and problem-solving tasks involving open- and close-ended thinking and how these abilities generalize and compare to AI. In Study 1, participants (N = 89) completed the alternative questions task (AQT), a close-ended riddles task (Stumpers), and the alternate uses task (AUT), a creativity measure. Our results show AQT question complexity wasn't correlated with stumpers performance, although it correlated with AUT originality (r = .3). In Study 2, participants (N = 100) completed the AQT, AUT, and open-ended creative problem-solving (CPS) task. CPS responses were evaluated for originality and quality. A positive correlation was observed between CPS quality and AQT complexity (r = .29) and originality (r = .34). In study 3, AI agents (N = 100) completed the AQT, AUT, stumpers, and CPS tasks. Like humans, AI's AQT originality and complexity were related with open, but not closed problem-solving. AI questions were also significantly more creative and complex, it solved more stumpers and gave higher quality CPS solutions. Surprisingly, human and AI CPS originality didn't differ. We find significant links between question complexity and open—but not closed-ended—problem-solving in humans, which generalize to AI. Our results highlight the significance of complex and creative question-asking in everyday life and as an integral part of our problem-solving toolkit.}
}
@article{MAHBOUB2025117258,
title = {General Extended Kalman filter with considering all random effects for integrated navigation},
journal = {Measurement},
volume = {251},
pages = {117258},
year = {2025},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2025.117258},
url = {https://www.sciencedirect.com/science/article/pii/S0263224125006177},
author = {Vahid Mahboub},
keywords = {General nonlinear dynamic model, General Extended Kalman filter, Random effects, Integrated navigation},
abstract = {General Extended Kalman filter (GEKF) is developed in which a general nonlinear dynamic model with all random effects (GNDRE) is rigorously solved for integrated navigation, although it can be applied to all dynamic problems. In the GNDRE model, not only are the observation equations and/or system equations functionally nonlinear, but also random effects may appear in any part of the problem. This situation can be seen when one has to fuse the data from different sensors, including a Global Positioning System (GPS) receiver, an Inertial Navigation System (INS) and vision sensors. In other words, here we consider not only the random noise in the observation vector, but also the random errors that may appear in all parts of the functional model. These scattered noises can be, for example, due to ground vision data. The GEKF algorithm is developed based on condition equations. It helps us to obtain the predicted residuals directly. Also, a rigorous posterior dispersion (variance–covariance) matrix of the unknown parameters is obtained. Therefore, considering all possible random noises and a rigorous approach including a proper linearization of functional model and prediction of posterior dispersion are the two main characteristics of the proposed algorithm. The results of the integration navigation for a GNSS/Vision/INS system approve the efficiency of the proposed approach. In particular, the new GEKF is implemented in the integrated navigation of two low-cost tightly coupled GNSS/Vision/INS systems in which random effects can play an important role, particularly, in some cases there is lack of reliable data.}
}
@article{DUNHAM2025100205,
title = {The threat of synthetic harmony: The effects of AI vs. human origin beliefs on listeners' cognitive, emotional, and physiological responses to music},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {6},
pages = {100205},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000891},
author = {Rohan L. Dunham and Gerben A. {van Kleef} and Eftychia Stamkou},
keywords = {Music, Artificial intelligence, Vagal withdrawal, Psychophysiology},
abstract = {People generally evaluate music less favourably if they believe it is created by artificial intelligence (AI) rather than humans. But the psychological mechanisms underlying this tendency remain unclear. Prior research has relied entirely on self-reports that are vulnerable to bias. This leaves open the question as to whether negative reactions are a reflection of motivated reasoning – a controlled, cognitive process in which people justify their scepticism about AI's creative capacity – or whether they stem from deeper, embodied feelings of threat to human creative uniqueness manifested physiologically. We address this question across two lab-in-field studies, measuring participants' self-reported and physiological responses to the same piece of music framed either as having AI or human origins. Study 1 (N = 50) revealed that individuals in the AI condition appreciated music less, reported less intense emotions, and experienced decreased parasympathetic nervous system activity as compared to those in the human condition. Study 2 (N = 372) showed that these effects were more pronounced among individuals who more strongly endorsed the belief that creativity is uniquely human, and that this could largely be explained by the perceived threat posed by AI. Together, these findings suggest that unfavourable responses to AI-generated music are not driven solely by controlled cognitive justifications but also by automatic, embodied threat reactions in response to creative AI. They suggest that strategies addressing perceived threats posed by AI may be key to fostering more harmonious human-AI collaboration and acceptance.}
}
@article{LIU2025104337,
title = {Computational multi-layered wood carving art},
journal = {Computers & Graphics},
volume = {131},
pages = {104337},
year = {2025},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2025.104337},
url = {https://www.sciencedirect.com/science/article/pii/S0097849325001785},
author = {Haochen Liu and Zhi Li and Kang Wu and Youcheng Cai and Xiaoya Zhai and Ketian Zhang and Ligang Liu and Yi Min Xie and Xiao-Ming Fu},
keywords = {Computational design, Laser cutting, Wooden artworks, Path generation, Image vectorization, Personalized fabrication},
abstract = {We present a computational framework for designing Multi-layered Wood Carving Artwork (MWCA), where intricately carved, colored wooden layers are stacked to create visually striking compositions. Each laser-cut layer must preserve global connectivity and minimize fine branching to maintain structural integrity. Traditionally reliant on artisanal trial-and-error, MWCA design has been time-consuming and labor-intensive. Our method is driven by a key observation: during connectivity analysis, the region of an upper layer can be treated as part of the lower layers. Leveraging this insight, we develop an iterative greedy algorithm to jointly determine the color assignment and geometric shape of each layer. To facilitate processing, we perform an image pre-processing step that reduces the input to a limited color palette. Additionally, a post-processing step is incorporated to enhance the structural integrity of the final output. We demonstrate the effectiveness and practical viability of our approach through 18 examples, including 3 fabrication results.}
}
@article{WANG2024261,
title = {Mechanical properties of hierarchical porous lattices with microscopic porosity fabricated by combination of lattice design and HSSH process},
journal = {Journal of Manufacturing Processes},
volume = {118},
pages = {261-268},
year = {2024},
issn = {1526-6125},
doi = {https://doi.org/10.1016/j.jmapro.2024.03.063},
url = {https://www.sciencedirect.com/science/article/pii/S1526612524002846},
author = {Xin Wang and Dongyun Zhang and Ang Li and Tianci Li and Weiliang Zhang and Xuefeng Liu},
keywords = {SLM, Hierarchically porous materials, Additive manufacturing, Implant},
abstract = {The hierarchical porous lattice implant with microscopic porosity, which resembles the original human bone structure, has significant potential application value. The microscopic porosity in the hierarchical porous lattice implant plays a crucial role in transporting nutrients and promoting tissue regeneration. However, it is difficult to fabricate microscopic pores smaller than 200 μm by powder bed fusion (PBF) processes due to the limitations of the laser spot size. In this study, the preparation of a hierarchical porous lattice implant with microscopic porosity is proposed by coupling structure design with the high scanning speed - short hatch spacing (HSSH) process formation. The structure-versus-process relationship is used to control the size and distribution of the microscopic pores, which meets the requirements of modulus and high biocompatibility. This proposed process breaks the inherent law where the higher the porosity, the higher the modulus of the lattice for the same lattice type. The modulus and porosity of the hierarchical porous implants could be flexibly tuned over a wide range (0.1–1.8 GPa and 63–84 %, respectively). The microscopic porosity is mainly distributed near the contour of the core rod, and the macroscopic porosity and microscopic porosity are approximately 73.70 % and 8.22 %, respectively. The problem of large errors in fitting the hierarchical porous lattice modulus calculation model according to the Gibson-Ashby equation has been solved. The mechanism of microscopic porosity formation was also analyzed. Furthermore, this method has the advantage of universal applicability, providing a feasible way for the development and application of porous materials.}
}
@article{COOPMANS2025,
title = {Collaborating Across Organizational Boundaries to Develop, Evaluate, and Implement eHealth: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67839},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125008003},
author = {Aafke G Coopmans and Remco S Mannak and Anna M Braspenning and Eveline J M Wouters and Inge M B Bongers},
keywords = {eHealth, digital health, development, evaluation, implementation, interorganizational collaboration, organizational boundaries, dialogical learning mechanisms, boundary spanning},
abstract = {Background
The success of eHealth relies on interorganizational collaboration (IOC) throughout the development, evaluation, and implementation phases of eHealth deployment. This IOC is complex, as it involves a diversity of organizations from different sectors, such as technological, academic, health care, and governmental organizations, collaborating to deploy eHealth. Between these organizations, organizational boundaries, defined as the demarcation of an organization from its environment, arise. When these boundaries are perceived as aligned and enable complementarity, IOC is facilitated. By contrast, misalignment of organizational boundaries can hinder IOC. A dialogical learning mechanism, defined as a learning process that occurs when boundaries hinder IOC, can support learning how to navigate such boundaries. However, it is difficult to determine whether and when organizational boundaries facilitate or hinder IOC, and which dialogical learning mechanisms can be used to address these challenges during eHealth deployment. Previous literature presents the barriers and facilitators of IOC during eHealth deployment only for subsets of organizations or specific phases, leaving their generic versus phase specific applicability uncharted.
Objective
This scoping review aims to identify whether, and under what circumstances, organizational boundaries facilitate or hinder IOC during the development, evaluation, and implementation of eHealth.
Methods
A scoping review was conducted using searches in the PubMed, PsycINFO, CINAHL, and Web of Science databases. Articles were eligible for inclusion if they were empirical studies written in English or Dutch and contained findings on factors influencing IOC during the development, evaluation, or implementation phases of eHealth deployment. The search yielded 11,867 articles, of which 16 met the inclusion criteria. Open and axial coding of the extracted findings was performed to identify organizational boundaries and dialogical learning mechanisms that hindered or facilitated IOC during eHealth deployment.
Results
In each phase, different organizational boundaries either hindered or facilitated IOC. The dialogical learning mechanism identification was crucial for enhancing IOC and was supported by training or by establishing IOC from previous relationships. Additionally, the learning mechanism coordination improved IOC and depended on the involvement of boundary spanners (ie, individuals who span organizational boundaries) and the use of boundary objects (ie, objects which help bridge different social worlds). Furthermore, the mechanism reflection, fostered through open and frequent communication, facilitated IOC. The dialogical learning mechanism transformation did not influence IOC during any phase of eHealth deployment.
Conclusions
IOC in eHealth deployment is a dynamic process that depends on the dialogical learning mechanisms identification, coordination, and reflection to navigate organizational boundaries. This review is the first to present organizational boundaries and dialogical learning mechanisms that influence IOC across the different phases of eHealth deployment. However, further research that explicitly considers these phases is needed to deepen the understanding of IOC in eHealth deployment.}
}
@article{KEMMOCHI2025227,
title = {Optimal frequency of platelet-rich plasma injections for managing osteoarthritis: A longitudinal study},
journal = {Regenerative Therapy},
volume = {29},
pages = {227-236},
year = {2025},
issn = {2352-3204},
doi = {https://doi.org/10.1016/j.reth.2025.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S235232042500032X},
author = {Masahiko Kemmochi},
keywords = {Optimal frequency, Platelet-rich plasma, Multiple injections, Knee osteoarthritis, Longitudinal study},
abstract = {Introduction
Recent reviews suggest that PRP injections can improve pain and function more effectively than other treatments; however, consensus on the optimal number of injections is lacking. We aimed to determine the optimal administration frequency and number of PRP injections for management of osteoarthritis (OA) symptoms, to examine long-term effects and structural improvements with PRP, and to determine correlations between clinical outcomes and imaging findings.
Methods
This longitudinal study included 167 patients with knee OA, categorized using the Kellgren–Lawrence (KL) grading system. Participants received up to six PRP injections and were followed-up for 24 months. Pain levels were assessed using the visual analog scale (VAS); functional recovery was measured using the Knee Injury and Osteoarthritis Outcome Score (KOOS). To determine whether PRP can induce sustained structural improvements, we used the MRI Osteoarthritis Knee Score (MOAKS) to monitor changes in bone-marrow lesions (BMLs). Data were analyzed using repeated-measures analysis of variance to identify significant changes in pain and functional outcomes.
Results
VAS and KOOS scores significantly improved after PRP treatment. Patients with KL grades 1 and 2 exhibited maximum pain relief after the fourth injection; those with KL grades 3 and 4 showed optimal results after the fifth injection. Improvements were maintained or enhanced at the 24-month follow-up. The effect size increased as the number of treatments progressed, and especially after the fourth treatment, with a Cohen's d values of −1.22, −1.28, and −0.99 (p < 0.0001).
Conclusions
PRP injections administered at specific intervals can significantly reduce pain and improve function in patients with OA, with the required frequency depending on disease severity. These findings support the customization of PRP-treatment protocols based on individual patient profiles to maximize therapeutic benefits.
Trial registration
This study has been registered with the clinical trial register of the Japan Medical Association Center for Clinical Trials (JMA-IIA00351).
Unblinded study registration
This study has been registered with the clinical trial register of the Japan Medical Association Center for Clinical Trials (JMA-IIA00351).
Level of evidence
II.}
}
@article{GASSER20253693,
title = {A novel decoding strategy for ProteinMPNN to design with less visibility to cytotoxic T-lymphocytes},
journal = {Computational and Structural Biotechnology Journal},
volume = {27},
pages = {3693-3703},
year = {2025},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2025.07.055},
url = {https://www.sciencedirect.com/science/article/pii/S2001037025003198},
author = {Hans-Christof Gasser and Ajitha Rajan and Javier A. Alfaro},
keywords = {Protein deimmunization, MHC Class I, Protein design, ProteinMPNN, Decoding strategy},
abstract = {Due to their versatility and diverse production methods, proteins have attracted a lot of interest for industrial as well as therapeutic applications. Designing new therapeutics requires careful consideration of immune responses, particularly the cytotoxic T-lymphocyte (CTL) reaction to intra-cellular proteins. In this study, we introduce CAPE-Beam, a novel decoding strategy for the established ProteinMPNN protein design model. Our approach minimizes CTL immunogenicity risk by limiting designs to only consist of kmers that are either predicted not to be presented to CTLs or are subject to central tolerance that prevents CTLs from attacking self-peptides. We compare CAPE-Beam to the standard way of sampling from ProteinMPNN and the state of the art (SOTA) technique CAPE-MPNN. We find that our novel decoding strategy can produce structurally similar proteins while incorporating more human like kmers. This significantly lowers CTL immunogenicity risk in precision medicine, and represents a key step towards reducing this risk in protein therapeutics targeting a wider patient population. Source: https://github.com/hcgasser/CAPE_Beam.}
}
@article{WU2025,
title = {Game on! Digital Gaming and Augmented Reality/Virtual Reality in Language Learning},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.367601},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000015},
author = {Junjie Gavin Wu and Danyang Zhang and Sangmin-Michelle Lee and Junhua Xian},
keywords = {AR, Digital Game-Based Language Learning, Model, Suggestions, VR},
abstract = {ABSTRACT
Digital games have become an important educational tool for learning and teaching. The development of such games has advanced from 2D, desktop-based technologies to 3D, augmented reality (AR) / virtual reality (VR)-based technologies. Yet digital game-based language learning (DGBLL) with AR/VR has only recently started to be investigated, owing to the emerging availability of these new technologies. This position paper begins with a short review of the educational benefits of DGBLL, followed by a discussion of the use of AR/VR in language learning. To illustrate the potential use of AR/VR in DGBLL, recent empirical studies are reviewed. Based on this analysis, a new model for integrating AR/VR in DGBLL is proposed. The paper ends with suggestions for how DGBLL with AR/VR technologies can be used in future educational endeavors.}
}
@article{LU2024283,
title = {LLMs and generative agent-based models for complex systems research},
journal = {Physics of Life Reviews},
volume = {51},
pages = {283-293},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524001386},
author = {Yikang Lu and Alberto Aleta and Chunpeng Du and Lei Shi and Yamir Moreno},
abstract = {The advent of Large Language Models (LLMs) offers to transform research across natural and social sciences, offering new paradigms for understanding complex systems. In particular, Generative Agent-Based Models (GABMs), which integrate LLMs to simulate human behavior, have attracted increasing public attention due to their potential to model complex interactions in a wide range of artificial environments. This paper briefly reviews the disruptive role LLMs are playing in fields such as network science, evolutionary game theory, social dynamics, and epidemic modeling. We assess recent advancements, including the use of LLMs for predicting social behavior, enhancing cooperation in game theory, and modeling disease propagation. The findings demonstrate that LLMs can reproduce human-like behaviors, such as fairness, cooperation, and social norm adherence, while also introducing unique advantages such as cost efficiency, scalability, and ethical simplification. However, the results reveal inconsistencies in their behavior tied to prompt sensitivity, hallucinations and even the model characteristics, pointing to challenges in controlling these AI-driven agents. Despite their potential, the effective integration of LLMs into decision-making processes —whether in government, societal, or individual contexts— requires addressing biases, prompt design challenges, and understanding the dynamics of human-machine interactions. Future research must refine these models, standardize methodologies, and explore the emergence of new cooperative behaviors as LLMs increasingly interact with humans and each other, potentially transforming how decisions are made across various systems.}
}
@incollection{2025299,
title = {Index},
editor = {Miltiadis D. Lytras and Abdulrahman Housawi and Basim S. Alsaywid and Naif Radi Aljohani},
booktitle = {Next Generation eHealth},
publisher = {Academic Press},
pages = {299-305},
year = {2025},
series = {Next Generation Technology Driven Personalized Medicine And Smart Healthcare},
isbn = {978-0-443-13619-1},
doi = {https://doi.org/10.1016/B978-0-443-13619-1.20001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443136191200019}
}
@article{LEE2025103368,
title = {Font conversion for steel product number recognition: A conditioned diffusion model approach},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103368},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103368},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625002617},
author = {Taehan Lee and Hyeyeon Choi and Bum Jun Kim and Hyeonah Jang and Donggeon Lee and Sang Woo Kim},
keywords = {Steel product number recognition, Product management, Image editing, Deep learning, Diffusion model},
abstract = {In the steel manufacturing industry, it is crucial to automatically recognize semi-finished product numbers to avoid mix-ups and ensure that each product is processed according to its specific material properties. The advancement of deep learning has significantly improved the recognition of steel product numbers, particularly those printed by machines with consistent thickness and spacing, resulting in high recognition accuracy. Conversely, handwritten numbers by workers are often challenging to recognize due to varying thickness, spacing, being too thin, partially erased, or overwritten with scribbles. This inconsistency causes low recognition accuracy of steel product number recognition models for fonts with insufficient training data or fonts not seen during training. The models must be updated periodically whenever a new font is used and remain vulnerable to new fonts until sufficient data is accumulated and updated. In this paper, we propose a Font Changer that converts various fonts into a representative font to address these issues. Font Changer is designed to learn the trajectory from a Gaussian distribution to the data distribution of images generated in a representative font with clean background. Font Changer, composed of a conditional image encoder and a diffusion model, extracts location, size, and number information from the original image containing the steel product number. The extracted information is then used as a condition for the diffusion model, allowing it to generate the closest sample within the data distribution. Images processed by the Font Changer exhibit uniformity, ensuring the consistency of steel product number images. Experiments demonstrate that the Font Changer enhances number recognition by removing background noise and converting even messy and damaged images into a consistent representative font. Our proposed method advances the steel manufacturing industry by standardizing fonts in work environments with diverse handwritten fonts.}
}
@article{ASADOLLAHPOUR2025,
title = {Investigating the Effect of Semi-Occluded Vocal Tract Training With a Free-End Tube on Acoustic Characteristics and Glottal Performance in Dysphonic Adults: A Systematic Review},
journal = {Journal of Voice},
year = {2025},
issn = {0892-1997},
doi = {https://doi.org/10.1016/j.jvoice.2025.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0892199725000086},
author = {Faezeh Asadollahpour and Kowsar Baghban and Seyede Saghar Hashemnia and Mohammad-Sadegh Seifpanahi and Ali Moshtagh},
keywords = {Dysphonia—Voice therapy—Tube phonation—Acoustic—Electroglottography},
abstract = {Summary
Objective
Investigating the effect of semi-occluded vocal tract training with a free-end tube on acoustic characteristics and glottal performance in dysphonic adults.
Study Design
A systematic review.
Methods
This systematic review adhered to Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines and was guided by the population, intervention, comparison, results and study design framework. Adults with dysphonia were included, while studies with psychiatric, cognitive, or cancer-related conditions were excluded. The intervention involved semi-occluded vocal tract training (SVOT) with a free-end straw, and outcomes included acoustic parameters (eg, jitter, shimmer, HNR, CPP, and F0) and contact quotient. A comprehensive search across multiple databases identified studies, and two independent reviewers screened and assessed them for inclusion. Bias was evaluated using the Cochrane RoB-2 tool, with results visualized via Robvis.
Results
This section outlines the inclusion of three studies with 127 participants from an initial pool of 5752 records. The studies varied in their methodologies, with one utilizing electroglottography evaluation and two employing acoustic assessments, while all reported different durations of vocal training. The Cochrane Risk of Bias-2 tool indicated a high risk of bias across the studies, primarily due to missing outcome data and randomization issues.
Conclusions
This systematic review highlights the beneficial effects of SVOT using a free-end tube in improving acoustic characteristics and glottal performance in dysphonic adults. The technique enhances vocal fold coordination, reduces tension, and promotes efficient phonation. Further research is recommended to explore its long-term effects and efficacy across various dysphonia subtypes.}
}
@article{MUN2025106719,
title = {Advancements in simulation-based nursing education: Insights from a bibliometric analysis of temporal trends},
journal = {Nurse Education Today},
volume = {151},
pages = {106719},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106719},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725001558},
author = {Minji Mun and Minsung Kim and Kyungmi Woo},
keywords = {Simulation, Nursing education, Bibliometric analysis, Trends analysis, Virtual reality},
abstract = {Background
Simulations are used in nursing education to create realistic clinical practice environments. With rapid changes in educational demands and the growing importance of simulation in nursing, understanding the evolution of its application will provide critical insights into how educational strategies have undergone adaptive changes over time to meet the needs of nursing students and healthcare settings.
Aims
This study aimed to identify temporal trends in simulation-based nursing education, map key research themes, and examine changes in the educational landscape over time.
Design
This is a bibliometric study of simulation-based nursing education.
Methods
The analysis was conducted using VOSviewer. A total of 12,083 publications retrieved from PubMed, the Excerpta Medica Database, and the Cumulative Index to Nursing and Allied Health Literature were analyzed. To identify temporal shifts in simulation-based nursing education, articles were categorized into four periods based on the progression of simulation usage and technological advancements. Co-occurrence analysis was performed for each period.
Results
Our analysis revealed a substantial increase in research on simulation-based nursing education after 2014, with a surge following the COVID-19 pandemic. The results show an increasing adoption of advanced techniques, such as standardized patients, in-situ simulations, and virtual reality. Core keywords, such as CPR, critical thinking, and team training, highlight the diverse applications of simulations in technical and psychological training. Temporal trends highlight significant shifts in keywords driven by technological advancements and evolving pedagogical approaches. Integrating advanced technology and realistic scenarios provides learners with immersive experiences that can substantially enhance their nursing competencies.
Conclusions
This study revealed that simulation-based nursing education has evolved substantially, reflecting technological progress and changes in educational priorities. This underscores the need to integrate advanced technology with innovative simulation methods to prepare nursing students for real-world clinical challenges.}
}
@article{LI2024135599,
title = {GraphNABP: Identifying nucleic acid-binding proteins with protein graphs and protein language models},
journal = {International Journal of Biological Macromolecules},
volume = {280},
pages = {135599},
year = {2024},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2024.135599},
url = {https://www.sciencedirect.com/science/article/pii/S0141813024064079},
author = {Xiang Li and Zhuoyu Wei and Yueran Hu and Xiaolei Zhu},
keywords = {Nucleic acid binding protein, AlphaFold, Protein language model},
abstract = {The computational identification of nucleic acid-binding proteins (NABP) is of great significance for understanding the mechanisms of these biological activities and drug discovery. Although a bunch of sequence-based methods have been proposed to predict NABP and achieved promising performance, the structure information is often overlooked. On the other hand, the power of popular protein language models (pLM) has seldom been harnessed for predicting NABPs. In this study, we propose a novel framework called GraphNABP, to predict NABP by integrating sequence and predicted 3D structure information. Specifically, sequence embeddings and protein molecular graphs were first obtained from ProtT5 protein language model and predicted 3D structures, respectively. Then, graph attention (GAT) and bidirectional long short-term memory (BiLSTM) neural networks were used to enhance feature representations. Finally, a fully connected layer is used to predict NABPs. To the best of our knowledge, this is the first time to integrate AlphaFold and protein language models for the prediction of NABPs. The performances on multiple independent test sets indicate that GraphNABP outperforms other state-of-the-art methods. Our results demonstrate the effectiveness of pLM embeddings and structural information for NABP prediction. The codes and data used in this study are available at https://github.com/lixiangli01/GraphNABP.}
}
@article{SANCHEZQUINONES2024,
title = {Development and Implementation of an eHealth Oncohematonootric Program: Descriptive, Observational, Prospective Cohort Pilot Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/49574},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24001975},
author = {Beatriz Sánchez-Quiñones and Cristina Antón-Maldonado and Nataly {Ibarra Vega} and Isabel {Martorell Mariné} and Amparo Santamaria},
keywords = {Nootric app, oncohematology patient, physical-nutritional well-being, multidisciplinary team},
abstract = {Background
In oncohematology, both the development of the disease and the side effects of antineoplastic treatment often take a toll on patients’ physical and nutritional well-being. In this era of digital transformation, we launched a pioneering project for oncohematologic patients to promote adherence to a healthy lifestyle and improve their physical and nutritional well-being. We aim to achieve this goal by involving doctors and nutritionists through the Nootric app.
Objective
This study aims to assess the impact of the use of eHealth tools to facilitate nutrition and well-being in oncohematologic patients. We also aim to determine the usefulness of physical-nutritional management in improving tolerance to chemotherapy treatments within routine clinical practice.
Methods
We designed a descriptive, observational, longitudinal, prospective cohort pilot study that included a total of 22 patients from March to May 2022 in the Vinalopó University Hospital. The inclusion criteria were adults over 18 years of age diagnosed with oncohematological pathology in active chemotherapy treatment. An action plan was created to generate alerts between the doctor and the nutritionist. In the beginning, the patients were trained to use the app and received education highlighting the importance of nutrition and physical exercise. Sociodemographic, clinical-biological-analytical (eg, malnutrition index), health care impact, usability, and patient adherence data were collected. Tolerance to chemotherapy treatment and its health care impact were evaluated.
Results
We included 22 patients, 11 (50%) female and 11 (50%) male, ranging between 42 and 84 years of age. Among them, 13 (59%) were adherents to the program. The most frequent diseases were lymphoproliferative syndromes (13/22, 59%) and multiple myeloma (4/22, 18%). Moreover, 15 (68%) out of 22 patients received immunochemotherapy, while 7 (32%) out of 22 patients received biological treatment. No worsening of clinical-biological parameters was observed. Excluding dropouts and abandonments (n=9/22, 41%), the adherence rate was 81%, established by calculating the arithmetic mean of the adherence rates of 13 patients. No admission was observed due to gastrointestinal toxicity or discontinuation of treatment related to alterations in physical and nutritional well-being. In addition, only 5.5% of unscheduled consultations were increased due to incidents in well-being, mostly telematic (n=6/103 consultation are unscheduled). Additionally, 92% of patients reported an improvement in their nutritional habits (n=12/13), and up to 45% required adjustment of medical supportive treatment (n=5/11). There were no cases of grade 3 or greater gastrointestinal toxicity. All of this reflects improved tolerance to treatments. Patients reported a satisfaction score of 4.3 out of 5, while professionals rated their satisfaction at 4.8 out of 5.
Conclusions
We demonstrated the usefulness of integrating new technologies through a multidisciplinary approach. The Nootric app facilitated collaboration among the medical team, nutritionists, and patients. It enabled us to detect health issues related to physical-nutritional well-being, anticipate major complications, and mitigate potentially avoidable risks. Consequently, there was a decrease in unscheduled visits and admissions related to this condition.}
}
@article{KOBAYASHI2025100700,
title = {Uncovering new psychoactive substances research trends using large language model-assisted text mining (LATeM)},
journal = {Journal of Hazardous Materials Advances},
volume = {18},
pages = {100700},
year = {2025},
issn = {2772-4166},
doi = {https://doi.org/10.1016/j.hazadv.2025.100700},
url = {https://www.sciencedirect.com/science/article/pii/S2772416625001123},
author = {Yoshiyuki Kobayashi and Takumi Uchida and Itsuki Kageyama and Yusuke Iwasaki and Rie Ito and Kazuhiko Tsuda and Hiroshi Akiyama and Kota Kodama},
keywords = {New psychoactive substances (NPS), research trend analysis, natural language processing (NLP), large language model (LLM), text mining, large Language Model-assisted Text mining (LATeM)},
abstract = {The emergence of new psychoactive substances (NPS) has become a significant public health concern over the past few decades. This study employed text-mining techniques and large language models (LLMs) to examine NPS research trends from 1990 to 2024. Over 12,000 publications from the Web of Science database were analyzed using the proposed Large Language-assisted Text Mining (LATeM) method to identify key patterns and shifts in research focus. The results indicated an evolution in NPS research from basic pharmacological studies in the 1990s to more diverse approaches encompassing public health, policies, and advanced analytical methods in recent years. The opioid crisis, particularly the emergence of fentanyl, has significantly influenced research priorities since 2020. A notable increase in NPS-related publications was observed, growing from 105 in the 1990s to over 6000 in the 2020s. Furthermore, the research focus shifted from traditional drugs to synthetic cannabinoids and stimulants in the 2000s and 2010s, and subsequently to opioids in the 2020s. Emerging areas of study include forensic applications, environmental impacts, and advanced analytical techniques. This study demonstrates the efficacy of integrating LLMs with text mining to identify emerging trends in NPS research. Our findings underscore the need for continued interdisciplinary collaboration and the development of novel strategies to address the evolving NPS challenges. Future research should prioritize enhancing early detection methods, investigating the long-term health consequences of NPS use, and developing effective prevention and treatment programs.}
}
@article{MUKUKA2024110307,
title = {Data on mathematics teacher educators’ proficiency and willingness to use technology: A structural equation modelling analysis},
journal = {Data in Brief},
volume = {54},
pages = {110307},
year = {2024},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2024.110307},
url = {https://www.sciencedirect.com/science/article/pii/S2352340924002762},
author = {Angel Mukuka},
keywords = {Mathematics teacher educators, Perceived ease of use, Perceived usefulness, Proficiency and willingness, Structural equation modelling, Technology integration},
abstract = {The role of Mathematics Teacher Educators (MTEs) in preparing future teachers to effectively integrate technology into their mathematics instruction is of paramount importance yet remains an underexplored domain. Technology has the potential to enhance the development of 21st-century skills, such as problem-solving and critical thinking, which are essential for students in the era of the fourth industrial revolution. However, the rapid evolution of technology and the emergence of new trends like data analytics, the Internet of Things, machine learning, cloud computing, and artificial intelligence present new challenges in the realm of mathematics teaching and learning. Consequently, MTEs need to equip prospective teachers with the knowledge and skills to harness technology in innovative ways within their future mathematics classrooms. This paper presents and describes data from a survey of 104 MTEs in Zambia. The study focuses on MTEs' proficiency, perceived usefulness, perceived ease of use, and willingness to incorporate technology in their classrooms. This data-driven article aims to unveil patterns and trends within the dataset, with the objective of offering insights rather than drawing definitive conclusions. The article also highlights the data collection process and outlines the procedure for assessing the measurement model of the hypothesised relationships among variables through structural equation modelling analysis. The data described in this article not only sheds light on the current landscape but also serves as a valuable resource for mathematics teacher training institutions and other stakeholders seeking to understand the requisites for MTEs to foster technological skills among prospective teachers of mathematics.}
}
@article{FERRARO2025995,
title = {Zoogeochemical niche construction: how animal-mediated biogeochemistry affects evolution},
journal = {Trends in Ecology & Evolution},
volume = {40},
number = {10},
pages = {995-1009},
year = {2025},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0169534725001934},
author = {Kristy M. Ferraro and Shawn J. Leroux and Mark A. Bradford and Oswald J. Schmitz and Eric {Vander Wal}},
keywords = {animal-ecosystem dynamics, biogeochemistry, evolutionary ecology, nutritional ecology},
abstract = {Animals exert control over biogeochemical processes within their ecosystems – the study of which is called zoogeochemistry. However, most zoogeochemical research stops short of examining how animal-driven biogeochemical processes feed back to influence the fitness and population dynamics of organisms. We outline how to use niche construction theory to investigate these feedbacks, introducing zoogeochemical niche construction to explicitly link zoogeochemistry with fitness and evolution trajectories. We specifically highlight how this framework reveals the capacity of animals to influence their own nutritional landscapes, creating closed zoogeochemical loops. To identify and test instances of zoogeochemical niche construction, we present experimental, correlative, and comparative tools. The novel application of niche construction theory provides alternative and complementary explanations for animal trait evolution.}
}
@article{BADANO2025838,
title = {Advanced echocardiography and cluster analysis to identify secondary tricuspid regurgitation phenogroups at different risk},
journal = {Revista Española de Cardiología (English Edition)},
volume = {78},
number = {10},
pages = {838-847},
year = {2025},
issn = {1885-5857},
doi = {https://doi.org/10.1016/j.rec.2025.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S188558572500057X},
author = {Luigi P. Badano and Marco Penso and Michele Tomaselli and Kyu Kim and Alexandra Clement and Noela Radu and Geu-Ru Hong and Diana R. Hădăreanu and Alexandra Buta and Caterina Delcea and Samantha Fisicaro and Gianfranco Parati and Chi {Young Shim} and Denisa Muraru},
keywords = {Secondary tricuspid regurgitation, Unsupervised cluster analysis, Phenogroups, Outcomes, Machine learning, 3-dimensional echocardiography, Speckle-tracking echocardiography, Insuficiencia tricuspídea secundaria, Análisis de conglomerados no supervisado, Fenogrupos, Resultados, Aprendizaje automático, Ecocardiografía tridimensional, Ecocardiografía },
abstract = {Introduction and objectives
Significant secondary tricuspid regurgitation (STR) is associated with poor prognosis, but its heterogeneity makes predicting patient outcomes challenging. Our objective was to identify STR prognostic phenogroups.
Methods
We analyzed 758 patients with moderate-to-severe STR: 558 (74±14 years, 55% women) in the derivation cohort and 200 (73±12 years, 60% women) in the external validation cohort. The primary endpoint was a composite of heart failure hospitalization and all-cause mortality.
Results
We identified 3 phenogroups. The low-risk phenogroup (2-year event-free survival 80%, 95%CI, 74%-87%) had moderate STR, preserved right ventricular (RV) size and function, and a moderately dilated but normally functioning right atrium. The intermediate-risk phenogroup (HR, 2.20; 95%CI, 1.44-3.37; P<.001) included older patients with severe STR, and a mildly dilated but uncoupled RV. The high-risk phenogroup (HR, 4.67; 95%CI, 3.20-6.82; P<.001) included younger patients with massive-to-torrential tricuspid regurgitation, as well as severely dilated and dysfunctional RV and right atrium. Multivariable analysis confirmed the clustering as independently associated with the composite endpoint (HR, 1.40; 95%CI, 1.13-1.70; P=.002). A supervised machine learning model, developed to assist clinicians in assigning patients to the 3 phenogroups, demonstrated excellent performance both in the derivation cohort (accuracy=0.91, precision=0.91, recall=0.91, and F1 score=0.91) and in the validation cohort (accuracy=0.80, precision=0.78, recall=0.78, and F1 score=0.77).
Conclusions
The unsupervised cluster analysis identified 3 risk phenogroups, which could assist clinicians in developing more personalized treatment and follow-up strategies for STR patients.
Resumen
Introducción y objetivos
La insuficiencia tricuspídea secundaria (ITS) significativa se asocia a un mal pronóstico, pero su heterogeneidad dificulta la predicción de los resultados de los pacientes. Nuestro objetivo fue identificar fenogrupos pronósticos de ITS.
Métodos
Se analizó a 758 pacientes con ITS moderada a grave: 558 (74±14 años, 55% mujeres) en la cohorte de derivación y 200 (73±12 años, 60% mujeres) en la cohorte de validación externa. El criterio de valoración principal fue una combinación de hospitalización por insuficiencia cardiaca y mortalidad por todas las causas.
Resultados
Se identificaron 3 fenogrupos. El fenogrupo de bajo riesgo (supervivencia libre de acontecimientos a 2 años 80%, IC95%, 74-87%) tenía ITS moderada, tamaño y función del ventrículo derecho (VD) conservados, y aurícula derecha moderadamente dilatada, pero con funcionamiento normal. El fenogrupo de riesgo intermedio (HR=2,20; IC95%, 1,44-3,37; p<0,001) incluyó a pacientes mayores con ITS grave y VD levemente dilatado pero desacoplado. El fenogrupo de riesgo alto (HR=4,67; IC95%, 3,20-6,82; p<0,001) incluyó a pacientes más jóvenes con insuficiencia tricuspídea masiva a torrencial, y el VD y la aurícula derecha gravemente dilatados y disfuncionales. El análisis multivariable confirmó que la agrupación se asoció de forma independiente con el criterio de valoración compuesto (HR=1,40; IC95%, 1,13-1,70; p=0,002). Un modelo de aprendizaje automático supervisado, desarrollado para ayudar a los médicos a asignar pacientes a los 3 fenogrupos, demostró un excelente desempeño tanto en la derivación (exactitud=0,91, precisión=0,91, recuerdo=0,91 y puntuación F1=0,91) como en la cohorte de validación (exactitud=0,80, precisión=0,78, recuerdo=0,78 y puntuación F1=0,77).
Conclusiones
El análisis de conglomerados no supervisado identificó 3 fenogrupos de riesgo, que podrían ayudar a los médicos a desarrollar estrategias de seguimiento y tratamiento más personalizadas para los pacientes con ITS.}
}
@article{GUPTA2024101017,
title = {Integrating generative AI in management education: A mixed-methods study using social construction of technology theory},
journal = {The International Journal of Management Education},
volume = {22},
number = {3},
pages = {101017},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101017},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724000880},
author = {Pragya Gupta and Renuka Mahajan and Usha Badhera and Pooja.S. Kushwaha},
keywords = {Generative AI, Mixed-method, Teaching-learning, Management education, Assessment, Pedagogy, Curriculum-design, Ethical concerns, Sentiment analysis, ‘X’ platform, ChatGPT},
abstract = {Generative AI tools are revolutionizing various sectors, including management education, and assessing their effectiveness is crucial to unlock their full potential. The study explores the perspectives of management educators in utilizing Generative AI tools, as they face a dilemma in balancing technology usage while maintaining relevance and fostering authentic learning. This article utilizes the Social Construction of Technology (SCOT) theory, which emphasizes the influence of human interventions and discourses on Generative AI technology. The study utilized a mixed-methods approach to evaluate the impact of Generative AI on teaching-learning compared to the traditional method. Initially, it analyzed news stories and found the frequently used words like management education, ChatGPT, AI, ethics, B-schools etc. in form of word cloud. Further, sentiment analysis of tweets from the ‘X’ platform was conducted to understand the ongoing discussions. The analysis revealed positive and negative emotions which were associated with specific terms related to management education. Thereafter, the qualitative insights gathered from management education experts helped in identifying various focal themes like assessment, curriculum, pedagogy, and regulation considering early adopters' perspectives. The study shed light on how Generative AI tools can be judiciously embraced through research and application and how they can reshape the management education landscape. It provides evidence-based guidance for educators and researchers to effectively utilize this technology while addressing administrative and ethical issues.}
}
@article{PINO2025685,
title = {Will consumers pay for e-fashion? A multi-study investigation},
journal = {International Journal of Retail & Distribution Management},
volume = {53},
number = {7},
pages = {685-698},
year = {2025},
issn = {0959-0552},
doi = {https://doi.org/10.1108/IJRDM-10-2023-0583},
url = {https://www.sciencedirect.com/science/article/pii/S095905522500004X},
author = {Giovanni Pino and Marco Pichierri and Kokho Jason Sit},
keywords = {Digital clothes, Product uniqueness, Sensation-seeking, Need for touch, Willingness to pay},
abstract = {Purpose
Digital clothes (DCs) are an emerging product category whose commercial success will heavily depend on consumers’ perception of their economic and symbolic value. However, existing studies have overlooked the empirical assessment of consumers’ willingness to pay (WTP) for such products. As a result, the factors underlying consumers’ motivation to pay for them are still a matter of debate.
Design/methodology/approach
We ran three quantitative studies, including one involving participants in a real consumption context that assessed: (1) whether the perceived uniqueness of DCs increases consumers’ WTP for these products and (2) whether this effect depends on consumers’ sensation-seeking tendency (SST) and the instrumental need for touch (NFT).
Findings
We found that the higher the perceived uniqueness of DCs, the higher the consumers’ WTP for them. This effect was stronger for consumers who exhibited high SST and NFT.
Practical implications
DC developers and retailers should consider uniqueness as a key driver of DC consumption. They should target sensation seekers with high instrumental NFT who perceive DCs as unique products.
Originality/value
This research extends the understanding of the determinants of DC consumption by developing a framework that simultaneously accounts for the effects determined by a distinctive feature of these products (i.e. their uniqueness) as well as consumers’ personal characteristics.}
}
@article{LONGO20252688,
title = {Democratizing human-AI collaborative decision-making in agri-food supply chains: a trust-building framework},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {2688-2693},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.452},
url = {https://www.sciencedirect.com/science/article/pii/S2405896325012157},
author = {Francesco Longo and Antonio Padovano and Chiara Sammarco and Dmitry Ivanov and Ilya Jackson},
keywords = {supply chain management, agri-food, explainable Artificial intelligence, industry 5.0, human-AI collaboration, human-centricity, large language models},
abstract = {The black-box nature of Artificial Intelligence (AI) hinders stakeholder trust and comprehension, limiting practical adoption in business contexts. This study draws on findings from a case study in the agri-food sector applying Explainable AI (XAI) tools to support decision-making in case of SC disruptions. It proposes a trust-building framework that integrates ensemble learning models, interpretation tools (e.g., SHapley Additive exPlanations (SHAP), Large Language Models), interactive visualizations, and dynamic feedback mechanisms. These elements enhance transparency, enabling users to comprehend and act on AI-generated insights tailored to their expertise levels. By emphasizing human-AI collaboration, the framework addresses key gaps in accessibility and usability, empowering diverse stakeholders to engage with and benefit from XAI systems.}
}
@article{ALMOOSA2025100629,
title = {The AI paradox in marketing: Fascination, resistance, and reinvention},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {4},
pages = {100629},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2025.100629},
url = {https://www.sciencedirect.com/science/article/pii/S2199853125001647},
author = {Hayem A. {Al Moosa} and Abu Elnasr E. Sobaih and Imed Zaiem and Thamer Alzahrani and Eya A. Zouari and Ali Saleh Alshebami and Hussein N.E. Edrees and Amer A. Al-Qutaish},
keywords = {Artificial intelligence, AI in marketing, AI benefits, AI paradox, AI resistance, Automation, Professional perceptions, Technology acceptance model (TAM)},
abstract = {Grounded in the Technology Acceptance Model (TAM), this research explores how marketing professionals perceive AI adoption, examining the paradoxical tensions between technological fascination and professional resistance that challenge traditional TAM assumptions. This study draws on an exploratory qualitative approach involving 24 international marketing professionals (with 3–30 years of experience) from Africa, Europe, the United States, and the Gulf region. Data was collected through semi-structured interviews, using purposive sampling, and continued until theoretical saturation was achieved. Data analysis is based on a thematic content analysis method. Our analysis reveals three paradoxical perceptions (favorable, unfavorable, ambivalent) and identifies a novel five-category benefit taxonomy (technological, organizational, psychological, economic, communicational) alongside six barrier categories, challenging the linear adoption models prevalent in existing literature. The results show that professionals perceive AI primarily as a complementary tool that improves their individual performance while fundamentally transforming their profession. Theoretically, this study extends TAM by incorporating professional resistance and paradoxical adoption patterns, highlighting the limitations of linear acceptance models when applied to AI adoption within creative professional contexts. The study identifies the marketing experts’ perspectives on the future of their profession, the areas with high potential for AI impact, as well as the skills needed to remain relevant in the face of increasing integration of this technology. Practically, our findings provide a framework for managing AI adoption resistance in emerging markets and guidelines for organizations navigating the AI transformation paradox. Managerial implications are formulated to guide marketing professionals in the investment and use of AI, integrating it consistently into their daily practice.}
}
@article{HADLEY2026101993,
title = {Embedded entrepreneurship pedagogy: Six key practices for an entrepreneurial classroom},
journal = {Thinking Skills and Creativity},
volume = {59},
pages = {101993},
year = {2026},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101993},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002421},
author = {Gregory R.L. Hadley},
keywords = {Entrepreneurship education, Creativity in education, Pedagogy, Entrepreneurial mindset, youth entrepreneurship},
abstract = {This paper explores youth entrepreneurship education, most suitable at the secondary school level, through the mobilization of embedded entrepreneurship pedagogy. The paper is informed by a two, recently completed research projects, involving classroom teachers, and practicing entrepreneurs. Those projects, which examined how secondary schools can sharpen their entrepreneurial offerings to students, and in addition to their primary findings, hinted at the possibility of infusing key entrepreneurial principles into all curricular learning experiences. To illustrate this approach, this paper will examine how embedded entrepreneurship education can be included as part of the curricular and pedagogical planning of any subject area. It introduces six key practices for embedded entrepreneurship and explores, with examples, their curricular and cross-curricular potential.}
}
@article{BARBER2024428,
title = {Possibilities and missed opportunities for generative dialogue: professional networking, online platforms and the English classroom},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {4},
pages = {428-441},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-04-2024-0054},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000360},
author = {Chelsey Barber and Bob Fecho},
keywords = {Reddit, Teacher professional networks, Generative dialogue, Social media, Dialogical self theory, ELA educators},
abstract = {Purpose
Social media is increasingly vital for educators to extend their professional networks and engage in meaningful conversations. This study aims to explore how Reddit facilitates these interactions as a platform for generative dialogical exchange. For English educators, generative dialogue is paramount for professional development and classroom practice.
Design/methodology/approach
To better understand this dynamic, we outline Hermans and Hermans-Konopka’s (2010) framework of generative dialogical exchange, review relevant literature related to the implications of social media use by educators and argue for the importance of Reddit as a site of exploration into dialogical exchange. After describing our artifact selection, we offer relevant data and conclude with understanding and implications.
Findings
We argue that although online educator communities, particularly those on Reddit, offer opportunities for broad dialogical exchange for English educators, these can be marked by a push and pull between the expansion of the dialogical space and a tendency to rein it back in through reinforcing traditional power dynamics.
Originality/value
Reddit is an understudied site for extending professional networks and fostering conversations among educators, providing a novel approach to understanding these dynamics through dialogical theory.}
}
@article{HASSELL2025100765,
title = {Toward Optimizing the Impact of Digital Pathology and Augmented Intelligence on Issues of Diagnosis, Grading, Staging, and Classification},
journal = {Modern Pathology},
volume = {38},
number = {7},
pages = {100765},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2025.100765},
url = {https://www.sciencedirect.com/science/article/pii/S0893395225000614},
author = {Lewis A. Hassell and Marika L. Forsythe and Ami Bhalodia and Thanh Lan and Tasnuva Rashid and Astin Powers and Marilyn M. Bui and Arlen Brickman and Qiangqiang Gu and Andrey Bychkov and Ian Cree and Liron Pantanowitz},
keywords = {artificial intelligence, classification systems, competency, diagnosis, digital pathology, grading, training sets, validation},
abstract = {The introduction of new diagnostic information in pathology requires effective dissemination and adoption strategies. Although traditional methods like journals, meetings, and atlases have been used, they pose challenges in accessibility, interactivity, and performance validation. Digital pathology (DP) and artificial or augmented intelligence (AI) offer promising solutions to address these limitations. This paper advocates the use of DP and AI tools to facilitate the introduction of new diagnostic information in pathology. It highlights the importance of standardized training and validation sets, digital slide libraries, and AI-enhanced diagnostic tools. Although AI can improve efficiency and accuracy, it is crucial to address potential pitfalls such as over-reliance on AI, bias, and the need for human oversight. By leveraging DP and AI, the efficiency and accuracy of diagnosis, grading, staging, and classification can be augmented, ultimately improving patient care.}
}
@article{MA2025809,
title = {Leveraging large language models in next generation intelligent manufacturing: Retrospect and prospect},
journal = {Journal of Manufacturing Systems},
volume = {82},
pages = {809-840},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525001943},
author = {Yunfei Ma and Shuai Zheng and Zheng Yang and Pai Zheng and Jiewu Leng and Jun Hong},
keywords = {Industry 5.0, Large language model, Human–robot collaboration, Human centered intelligent manufacturing},
abstract = {Industry 5.0, as the guiding ideology of the new generation intelligent manufacturing, points the way for global industrial transformation. It emphasizes the collaborative cooperation between humans, machines and intelligent systems, and places humans at the core of the industrial production process, aiming to create a more flexible, personalized and sustainable production paradigm. Large language model, as an advanced natural language processing technology, has received attention from researchers related to Industry 5.0 due to its ease of use and powerful language processing capability. LLM is considered to be one of the key enabling technologies to drive the development of Industry 5.0 and has great application potential. After a rigorous review of existing approaches, we find there is few existing survey papers that focuses on how LLM will drive the development of Industry 5.0 applications. Therefore, this paper provides a comprehensive review of the application of LLM in the field of Industry 5.0. Firstly, we conduct a literature review to explore the current state of research related to Industry 5.0. Subsequently, we analyze LLM-based technologies, synergizing LLMs with Industry 5.0 enablers and the applications of LLM in various domains of intelligent manufacturing. Finally, we explore the challenges of LLM in real-world scenarios and future research directions in the context of Industry 5.0. It is hoped that this study will contribute to the further development of LLM-based solutions in the context of Industry 5.0 and unite various efforts to achieve the vision of Industry 5.0.}
}
@article{KAUR2025118290,
title = {Interface engineering of Al2O3 nanoparticle-decorated BiOBr nanorod photocatalysts},
journal = {Materials Science and Engineering: B},
volume = {318},
pages = {118290},
year = {2025},
issn = {0921-5107},
doi = {https://doi.org/10.1016/j.mseb.2025.118290},
url = {https://www.sciencedirect.com/science/article/pii/S0921510725003137},
author = {Amandeep Kaur and Sushil Kumar Kansal and K. {Priyanga Kangeyan} and Sandeep Kumar Lakhera and Jai Prakash and Junghyun Cho},
keywords = {AlO/BiOBr, Composite, RhB dye, Solar light irradiation, Photodegradation},
abstract = {Background
Synthetic dyes in industrial wastewater pose significant threats to the environment, aquatic ecosystems, and human health. Rhodamine B (RhB) is one such dye that is extensively used in the varied industries, highlighting its economic importance but also its prevalence as a pollutant. RhB has proven carcinogenic and mutagenic effects on living communities and induces numerous other ecological problems. It is therefore crucial to develop a practical and affordable technique to remove this dye from industrial wastewater. Advancements in technology have facilitated the development of photocatalysis, as an inexpensive and environmentally friendly method that indeed must be explored for the degradation of RhB.
Methods
This study introduces the synthesis of Al2O3/BiOBr composite via a facile approach. The as-synthesized composite was systematically characterized by using various structural and morphological analytical techniques. The as synthesized Al2O3/BiOBr composite was then evaluated in terms of its efficacy as photocatalyst in degrading RhB under direct sunlight.
Significant findings
The composite achieves a peak degradation efficiency of 99.6 % under direct sunlight within 160 min at optimal conditions i.e. pH 9, initial dye solution concentration of 0.010 g L−1, and a catalyst dose of 0.035 g L−1. Its recyclability was also demonstrated for five cycles. The findings position the Al2O3/BiOBr composite as a promising and effective photocatalyst, showcasing superior performance under direct sunlight irradiation. The high performance of the Al2O3/BiOBr composite was attributed to the synergism between the Al2O3 and BiOBr. The analysis revealed that Al2O3/BiOBr composite enhanced light absorption, and charge (electrons–holes) separation. The reactive radical test revealed that the ●OH, and ●O2– reactive oxygen species were dominant. The Z-scheme heterojunction mechanism for photocatalytic degradation was also deduced. Al2O3/BiOBr composite is shown to be an effective and sustainable photocatalyst and may be used for other photocatalytic-based energy and environmental applications.}
}
@article{HANBEYOGLUAKTURK2025112654,
title = {Printability of bigel inks as fat analogs: Impact of gelators on structure},
journal = {Journal of Food Engineering},
volume = {400},
pages = {112654},
year = {2025},
issn = {0260-8774},
doi = {https://doi.org/10.1016/j.jfoodeng.2025.112654},
url = {https://www.sciencedirect.com/science/article/pii/S026087742500189X},
author = {Gamze Hanbeyoglu-Akturk and Evren Demircan and Beraat Ozcelik},
keywords = {Hybrid gels, Animal fat analogue, Rheological properties, Textural properties, Microstructure, Long-term stability, Printability},
abstract = {Bigels are biphasic systems that mimic the structural and functional properties of animal fat, making them promising adipose tissue analogs for plant-based meat alternatives. This study investigates the impact of gelator selection on the structure and three-dimensional (3D) printing performance of bigels. Formulations included a lipid-based low molecular weight gelator, glycerin monostearate (GMS), or a non-lipidic polymeric gelator, ethylcellulose (EC), in combination with thermally reversible hydrocolloids, sodium alginate (SA) or low acyl gellan gum (GG). The textural, rheological, thermal, and microstructural properties of bigels were evaluated to determine their suitability as 3D-printed adipose tissue analogs. Results demonstrated that GMS bigels formed a bicontinuous structure with higher viscosity, yield stress, and mechanical strength, whereas EC-based bigels exhibited a W/O structure with lower rigidity. GMS bigels effectively replicate the thermal softening of adipose tissue, closely mimicking its behavior under varying temperature conditions. Additionally, GMS bigels with smaller particle sizes demonstrated enhanced long-term structural stability. SA exhibited better printing performance than GG by enhancing self-supporting ability and shape retention after extrusion. GMS-SA resulted in the most structurally stable and printable bigels, characterized by smooth surfaces, strong appearance, and excellent extrusion fidelity. In contrast, EC-based bigels, while printable, demonstrated inferior mechanical properties and weaker structural integrity. These findings highlight the critical role of gelator selection in defining the functional properties of bigels, particularly in optimizing their performance as 3D-printable adipose tissue analogs. This study provides new insights into the formulation of plant-based fat analogs, contributing to the advancement of sustainable meat alternatives.}
}
@article{KRAJEWSKI20243753,
title = {An implementation of the YOLO algorithm for the recognition of flags of the International Code of Signals},
journal = {Procedia Computer Science},
volume = {246},
pages = {3753-3760},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.181},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924021896},
author = {Jakub Krajewski and Ireneusz Czarnowski},
keywords = {International Code of Signals, image recognition, convolutional neural network, YOLO algorithm},
abstract = {The International Code of Signals (INTERCO) consists of codes and signals used to communicate messages regarding the safety of navigation. These codes are used by vessels, and the signals can be sent in various ways, including flaghoist, signal lamp, flag semaphore, or as a radio message. This paper focuses only on flag signals, proposing their detection and classification using deep learning algorithms. The paper also addresses a specific scenario, where the detection and classification of flag signals are necessary for verifying the current status, operations, and behaviours of vessels, in line with the intention conveyed by the flag signal. The system discussed is regarded as a component of a larger system for ensuring navigation safety and monitoring ship behaviours near critical infrastructure such as ports, offshore wind farms, or other offshore constructions. To tackle this challenge, a convolutional neural network (CNN) has been employed. The paper delves into the process of preparing the image dataset, including annotation and augmentation, and discusses the CNN learning process based on the YOLO algorithm implementation, finally discussing the results of the computational experiment.}
}
@article{ECHEVERRIA2025780,
title = {Impact of early SGLT2 inhibitors prescription on acute decompensated heart failure outcomes: insights from a real-world setting},
journal = {Revista Española de Cardiología (English Edition)},
volume = {78},
number = {9},
pages = {780-788},
year = {2025},
issn = {1885-5857},
doi = {https://doi.org/10.1016/j.rec.2025.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1885585725000775},
author = {Luis E. Echeverría and Lyda Z. Rojas and Angie Yarlady Serrano-García and Daniel R. Botero and María Cantillo-Reines and Adriana M. Jurado and Karen Andrea García-Rueda and Ángela Torres-Bustamante and Diana Ivonne Cañón-Gómez and Carolina Idrovo-Turbay and Robinson Sánchez-García and Jaime {Alberto Rodríguez} and Sergio A. Gómez-Ochoa},
keywords = {SGLT2 inhibitors, Acute decompensated heart failure, Mortality, Hospitalization, Inhibidores de SGLT2, Insuficiencia cardiaca aguda descompensada, Mortalidad, Hospitalización},
abstract = {Introduction and objectives
Although sodium-glucose cotransporter 2 inhibitors (SGLT2i) have shown benefits in acute decompensated heart failure (ADHF), the extrapolability of clinical trial results to general populations remains limited. This study evaluated the impact of early in-hospital SGLT2i prescription on ADHF outcomes in a real-world setting.
Methods
Prospective cohort study. Adults with ADHF from a third-level cardiovascular center were included. The primary analysis compared early SGLT2i (prescribed within 48hours of admission) versus late SGLT2i (prescribed after 48hours). A secondary analysis included patients not receiving in-hospital SGLT2i. The primary outcome was in-hospital mortality. Secondary outcomes included the length of hospital stay, 30-day improvement in the Minnesota Living with Heart Failure Questionnaire score, 30-day rehospitalization due to heart failure, and 30-day all-cause mortality.
Results
Of 2016 patients, early SGLT2i (≤ 48h) was initiated in 1275 (63.2%) patients, late SGLT2i in 346 (17.2%), and 395 (19.6%) did not receive in-hospital SGLT2i. After multivariate adjustment, early versus late SGLT2i use was associated with decreased in-hospital mortality (RR, 0.37; 95%CI, 0.17-0.77) and reduced hospital stay (mean difference −5.70 days; 95%CI, −7.05 to −4.34). Similarly, early versus late or no in-hospital SGLT2i use was associated with decreased in-hospital mortality (RR, 0.25; 95%CI, 0.14-0.44), reduced hospital stay (mean difference −2.99 days; 95%CI, −4.05 to −1.92), and lower 30-day combined mortality/heart failure rehospitalization (RR, 0.72; 95%CI, 0.53-0.98).
Conclusions
Early in-hospital SGLT2i prescription was associated with improved cardiovascular outcomes in ADHF in a real-world setting.
Resumen
Introducción y objetivos
Aunque los inhibidores del cotransportador de sodio-glucosa tipo 2 (iSGLT2) han mostrado beneficios en la insuficiencia cardiaca aguda descompensada (ICAD), la extrapolabilidad de los beneficios observados en los ensayos clínicos a la población general sigue siendo limitada. Este estudio evaluó el impacto de la prescripción temprana de iSGLT2 durante la estancia hospitalaria sobre los desenlaces de la ICAD en un contexto del mundo real.
Métodos
Estudio de cohorte prospectiva. Se incluyeron adultos con ICAD de un centro cardiovascular de tercer nivel. El análisis primario comparó iSGLT2 temprano (prescrito en las 48 horas siguientes al ingreso) frente a iSGLT2 tardío (prescrito después de 48 horas). Un análisis secundario incluyó a los pacientes que no recibieron iSGLT2 durante su estancia. El desenlace primario fue la mortalidad intrahospitalaria. Los desenlaces secundarios incluyeron la duración de la estancia hospitalaria, la mejoría a los 30 días en la puntuación del Minnesota Living with Heart Failure Questionnaire, la rehospitalización a los 30 días por IC y la mortalidad por todas las causas a los 30 días.
Resultados
De 2.016 pacientes, se inició iSGLT2 temprano (≤ 48h) en 1.275 (63,2%) pacientes, iSGLT2 tardío en 346 (17,2%), y 395 (19,6%) no recibieron iSGLT2 intrahospitalario. Tras el ajuste multivariante, el uso temprano frente al tardío de iSGLT2 se asoció con una disminución de la mortalidad intrahospitalaria (RR=0,37; IC95%, 0,17-0,77) y una reducción de la estancia hospitalaria (diferencia media −5,70 días; IC95%, −7,05 a −4,34). Del mismo modo, el uso temprano de iSGLT2 en comparación con el uso tardío o la ausencia de uso se asoció con una disminución de la mortalidad hospitalaria (RR=0,25; IC95%, 0,14-0,44), una reducción de la estancia hospitalaria (diferencia media −2,99 días; IC95%, −4,05 a −1,92) y una reducción de la combinación de mortalidad y rehospitalización por IC a los 30 días (RR=0,72; IC95%, 0,53-0,98).
Conclusiones
La prescripción temprana intrahospitalaria de iSGLT2 se asoció con mejores desenlaces cardiovasculares en la ICAD en un contexto del mundo real.}
}
@article{WOOD2025100232,
title = {“We stole her back too” - Acts of resistance and restoration when traditional governance and authority of child and family matters is reclaimed by the grandmothers of a First Nation community},
journal = {Child Protection and Practice},
volume = {7},
pages = {100232},
year = {2025},
issn = {2950-1938},
doi = {https://doi.org/10.1016/j.chipro.2025.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2950193825001408},
author = {Val Wood and Catherine Twinn and Connie Santos and Bob Lonne},
keywords = {C-92, Colonization, Community mobilization, Culture, Indigenous, Indigenous laws, Traditional family support},
abstract = {Canada's 2015 Truth and Reconciliation Commission's findings concerning child welfare highlighted impacts resulting in Indigenous people's dispossession, trauma, separation, and relational upheavals through forced removals and lasting harm to children, families and communities. Canadian Provincial government legislation over child welfare authority dominates and these outcomes continue today through child apprehensions. In 2020 the Canadian Federal Government enacted Bill C-92 respecting First Nations, Inuit and Métis children, youth and families; a legal framework intended to reduce the gross over-representation of Indigenous children in care. It affirms the inherent jurisdictional authority of Indigenous communities over their child and family matters. In 2024 following some Provincial Governments' legal challenges, the Supreme Court of Canada unanimously confirmed C-92 is constitutional in its entirety. This article chronicles the efforts of a team of Indigenous Dene, provincially-delegated workers with extensive experience working within provincial child and family legislative frameworks. Within 15-months 47 children taken by Alberta Children's Services from their rural community were returned and re-connected to their families, kin and culture. Culturally-based practices such as inclusion of ceremonial practices, using circle processes to conduct meetings and problem solve and respecting the traditional authority of matriarchs within the Indigenous Dene kinship system were key strategies in resisting and challenging the status quo of provincial child welfare authorities. These actions can encourage other communities to transform current child welfare approaches by restoring and reclaiming their own laws and traditional practices which offer alternative, humane and culturally-connected ways to protect children, support healing and rebuild communities.}
}
@article{QU2025103949,
title = {Is new technology always good? Artificial intelligence and corporate tax avoidance: Evidence from China},
journal = {International Review of Economics & Finance},
volume = {98},
pages = {103949},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.103949},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025001121},
author = {Guimin Qu and Hao Jing},
keywords = {Artificial intelligence, Tax avoidance, Labor cost, Text analysis},
abstract = {Corporate tax avoidance is an enduring topic. With the advent of the intelligent era, how artificial intelligence affects corporate tax avoidance has become an important topic of existing researches. We take Chinese A-share enterprises from 2008 to 2023 as the research samples, and empirically test the impact and mechanisms of artificial intelligence on corporate tax avoidance. Based on the perspective of corporate governance costs, we discuss the influence and function mechanism of artificial intelligence on corporate tax avoidance. The results show that artificial intelligence can promote tax avoidance for enterprises by increasing high-skilled labor cost and intelligent input cost. Heterogeneity analysis reveals that artificial intelligence exerts a more influence on corporate tax avoidance in circumstances where tax regulatory intensity is diminished, and the tax burden is escalated. This study enriches the research on the development of enterprise intelligence in the new era, opens the "black box" between artificial intelligence and tax avoidance, and provides evidence for the logic between them.}
}
@incollection{2024419,
title = {Index},
editor = {Ting-Chao Chou},
booktitle = {Mass-Action Law Dynamics Theory and Algorithm for Translational and Precision Medicine Informatics},
publisher = {Academic Press},
pages = {419-423},
year = {2024},
isbn = {978-0-443-28874-6},
doi = {https://doi.org/10.1016/B978-0-443-28874-6.09975-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443288746099753}
}
@article{WATSON2025e218,
title = {Translating learning from simulation to clinical: a narrative study of nursing students’ experiences},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {1},
pages = {e218-e226},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2024.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S1557308724002208},
author = {Adrianna L. Watson and Chelsey D. Young and Daphne Thomas and Daluchukwu Megwalu Tapp and Saydie Holyoak and Tali Gardner},
keywords = {nursing education, nursing simulation, experiential learning, narrative analysis, Kolb's experiential learning theory},
abstract = {Background
Simulation in nursing education significantly impacts clinical practice. However, transitioning experiential learning from simulated environments to real-world clinical settings can be challenging for nursing students.
Aim
This study aims to explore nursing students’ experiences in simulation and their application of learned skills in real-world clinical settings.
Methods
The authors employed a narrative study design involving nursing students as participants. Data were collected via semi-structured, recorded interviews. Narrative analysis was conducted to interpret the experiences within the framework of Kolb's Experiential Learning Theory.
Results
Key findings revealed that simulation effectively prepared students for clinical practice by enhancing their ability to recognize and respond to adverse events and cope with unexpected outcomes, increasing preparedness, and improving leadership skills. The narratives highlighted the continuity of learning from simulation to clinical setting application.
Conclusions
The study underscores the importance of simulation in nursing education and its role in helping students transfer knowledge from simulation to real-world clinical experiences. The findings suggest practical implications for educators to enhance simulation-based learning and to support effective transitions to clinical settings.}
}
@article{JAVAID202589,
title = {The impact of artificial intelligence on biomarker discovery},
journal = {Emerging Topics in Life Sciences},
volume = {8},
number = {2},
pages = {89-105},
year = {2025},
issn = {2397-8562},
doi = {https://doi.org/10.1042/ETLS20243003},
url = {https://www.sciencedirect.com/science/article/pii/S2397856225000047},
author = {Hira Javaid and Constantin Cezar Petrescu and Lisa J. Schmunk and Jack M. Monahan and Paul O'Reilly and Manik Garg and Leona McGirr and Mahmoud T. Khasawneh and Mustafa {Al Lail} and Deepak Ganta and Thomas M. Stubbs and Benjamin B. Sun and Dimitrios Vitsios and Daniel E. Martin-Herranz},
keywords = {biomarkers, diagnostics, biomarker discovery, artificial intelligence, multi-omics, electronic health records, multi-modal data},
abstract = {Artificial intelligence (AI) is transforming many fields, including healthcare and medicine. In biomarker discovery, AI algorithms have had a profound impact, thanks to their ability to derive insights from complex high-dimensional datasets and integrate multi-modal datatypes (such as omics, electronic health records, imaging or sensor and wearable data). However, despite the proliferation of AI-powered biomarkers, significant hurdles still remain in translating them to the clinic and driving adoption, including lack of population diversity, difficulties accessing harmonised data, costly and time-consuming clinical studies, evolving AI regulatory frameworks and absence of scalable diagnostic infrastructure. Here, we provide an overview of the AI toolkit available for biomarker discovery, and we discuss exciting examples of AI-powered biomarkers across therapeutic areas. Finally, we address the challenges ahead of us to ensure that these technologies reach patients and users globally and unlock a new era of fast innovation for precision medicine.}
}
@article{DOLLINGBOREHAM2024,
title = {Identifying Psychosocial and Ecological Determinants of Enthusiasm In Youth: Integrative Cross-Sectional Analysis Using Machine Learning},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/48705},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024002680},
author = {Roberta M Dolling-Boreham and Akshay Mohan and Mohamed Abdelhack and Tara Elton-Marshall and Hayley A Hamilton and Angela Boak and Daniel Felsky},
keywords = {subjective well-being, Ontario Student Drug Use and Health Survey (OSDUHS), machine learning, Shapley additive explanations (SHAP), extreme gradient boosting (XGBoost), psychosocial, ecological, determinants, enthusiasm, mental health, well-being, youth, public health, student, self-reported},
abstract = {Background
Understanding the factors contributing to mental well-being in youth is a public health priority. Self-reported enthusiasm for the future may be a useful indicator of well-being and has been shown to forecast social and educational success. Typically, cross-domain measures of ecological and health-related factors with relevance to public policy and programming are analyzed either in isolation or in targeted models assessing bivariate interactions. Here, we capitalize on a large provincial data set and machine learning to identify the sociodemographic, experiential, behavioral, and other health-related factors most strongly associated with levels of subjective enthusiasm for the future in a large sample of elementary and secondary school students.
Objective
The aim of this study was to identify the sociodemographic, experiential, behavioral, and other health-related factors associated with enthusiasm for the future in elementary and secondary school students using machine learning.
Methods
We analyzed data from 13,661 participants in the 2019 Ontario Student Drug Use and Health Survey (OSDUHS) (grades 7-12) with complete data for our primary outcome: self-reported levels of enthusiasm for the future. We used 50 variables as model predictors, including demographics, perception of school experience (i.e., school connectedness and academic performance), physical activity and quantity of sleep, substance use, and physical and mental health indicators. Models were built using a nonlinear decision tree–based machine learning algorithm called extreme gradient boosting to classify students as indicating either high or low levels of enthusiasm. Shapley additive explanations (SHAP) values were used to interpret the generated models, providing a ranking of feature importance and revealing any nonlinear or interactive effects of the input variables.
Results
The top 3 contributors to higher self-rated enthusiasm for the future were higher self-rated physical health (SHAP value=0.62), feeling that one is able to discuss problems or feelings with their parents (SHAP value=0.49), and school belonging (SHAP value=0.32). Additionally, subjective social status at school was a top feature and showed nonlinear effects, with benefits to predicted enthusiasm present in the mid-to-high range of values.
Conclusions
Using machine learning, we identified key factors related to self-reported enthusiasm for the future in a large sample of young students: perceived physical health, subjective school social status and connectedness, and quality of relationship with parents. A focus on perceptions of physical health and school connectedness should be considered central to improving the well-being of youth at the population level.}
}
@article{SWEENEY2023100818,
title = {Who wrote this? Essay mills and assessment – Considerations regarding contract cheating and AI in higher education},
journal = {The International Journal of Management Education},
volume = {21},
number = {2},
pages = {100818},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100818},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000563},
author = {Simon Sweeney},
keywords = {Essay mills, Artificial intelligence (AI), Academic dishonesty, Assessment, Ethics, Student well-being},
abstract = {The growing incidence of academic dishonesty (AD) involving students using commercial essay writing services (essay mills) or Artificial Intelligence (AI) risks the credibility of assessment approaches within higher education (HE) worldwide. Reflecting on experience from a UK business school, the article explores the potential for novel assessment design and feedback to reduce the prevalence of AD. Speculating on success and failure rates of students undertaking formal assessment, the article evaluates the broader ethical implications for universities in recruitment and learner support, particularly within contemporary discourses on international student attainment, mental health, and well-being.}
}
@article{CAO2025,
title = {AI and Machine Learning Terminology in Medicine, Psychology, and Social Sciences: Tutorial and Practical Recommendations},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/66100},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011203},
author = {Bo Cao and Russell Greiner and Andrew Greenshaw and Jie Sui},
keywords = {artificial intelligence, machine learning, terminology, medicine, psychology, social sciences, prediction, regression, deep learning, tutorial, prospective prediction, validation},
abstract = {Recent applications of artificial intelligence (AI) and machine learning in medicine, psychology, and social sciences have led to common terminological confusions. In this paper, we review emerging evidence from systematic reviews documenting widespread misuse of key terms, particularly “prediction” being applied to studies merely demonstrating association or retrospective analysis. We clarify when “prediction” should be used and recommend using “prospective prediction” for future prediction; explain validation procedures essential for model generalizability; discuss overfitting and generalization in machine learning and traditional regression methods; clarify relationships between features, independent variables, predictors, risk factors, and causal factors; and clarify the hierarchical relationship between AI, machine learning, deep learning, large language models, and generative AI. We provide evidence-based recommendations for terminology use that can facilitate clearer communication among researchers from different disciplines and between the research community and the public, ultimately advancing the rigorous application of AI in medicine, psychology, and social sciences.}
}
@article{QIU2023137496,
title = {Differential modulation on neural activity related to flankers during face processing: A visual crowding study},
journal = {Neuroscience Letters},
volume = {815},
pages = {137496},
year = {2023},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2023.137496},
url = {https://www.sciencedirect.com/science/article/pii/S030439402300455X},
author = {Zeguo Qiu and Dihua Wu and Benjamin J. Muehlebach},
keywords = {Visual crowding, Visual awareness, Fearful faces, ERP, P300},
abstract = {In this visual crowding study, we manipulated the perceivability of a central crowded face (a fearful or a neutral face) by varying the similarity between the central face and the surrounding flanker stimuli. We presented participants with pairs of visual clutters and recorded their electroencephalography during an emotion judgement task. In an upright flanker condition where both the central target face and flanker faces were upright faces, participants were less likely to report seeing the target face, and their P300 was weakened, compared to a scrambled flanker condition where scrambled face images were used as flankers. Additionally, at ∼ 120 ms post-stimulus, a posterior negativity was found for the upright compared to scrambled flanker condition, however only for fearful face targets. We concluded that early neural responses seem to be affected by the perceptual characteristics of both target and flanker stimuli whereas later-stage neural activity is associated with post-perceptual evaluation of the stimuli in this visual crowding paradigm.}
}
@article{HU2025111417,
title = {Three-dimensional reconstruction image generation of traditional Chinese painting elements},
journal = {Engineering Applications of Artificial Intelligence},
volume = {158},
pages = {111417},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111417},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625014198},
author = {Qiyao Hu and Jingyu Wang and Xianlin Peng and Tengfei Li and Rui Cao},
keywords = {Three-dimensional reconstruction, Traditional Chinese painting, Neural radiance field, Diffusion model},
abstract = {This paper presents a comprehensive pipeline for generating detailed three-dimensional (3D) models from single images of traditional Chinese painting elements. This task is particularly challenging due to the lack of 3D datasets for Chinese paintings and the limited research on their 3D reconstruction. As a result, direct access to multiple views is precluded. We propose a novel method for the 3D reconstruction of Traditional Chinese Painting Elements, termed TCPE-3D, which has three components of the process. The first component is a multi-view synthesis module named One To Six (OTX) - Multi-View Generating (MVG) Module. This module creates six fixed-view images through a series of preprocessing steps. These images are used to generate the Local Light Field Fusion (LLFF) dataset within the Neural Radiance Fields (NeRF) synthesis module. This process leads to the creation of detailed mesh structures in the final Mesh Generation module. Comparison with several state-of-the-art 3D reconstruction methods shows that our framework achieves better visualization results and higher technical specifications. Additionally, it solves the Janus problem encountered by other algorithms for Chinese painting data. Our dataset is available at https://github.com/LPDLG/3DTCP-Dataset.}
}
@article{PICKEL2025659,
title = {A survey on the utilization of ontologies for decision-making in industrial product development},
journal = {Procedia CIRP},
volume = {136},
pages = {659-664},
year = {2025},
note = {35th CIRP Design 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.08.113},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125008662},
author = {Jessica Pickel and Stefan Goetz and Sandro Wartzack},
keywords = {Knowledge Management, Ontology, Decision-Making, Product Development Process},
abstract = {Several studies highlight the potential of ontologies for effectively connecting knowledge in complex industrial environments. However, their practical application in decision-making remains insufficiently explored, limiting their adoption in industry. This paper addresses this gap by conducting an empirical study with two objectives: (1) examining the current use of knowledge management solutions and ontologies in industrial product development, and (2) identifying key challenges in their utilization for decision-making. The study compares the theoretical advantages of ontologies with their practical applications, highlighting discrepancies and barriers to adoption. Key challenges include data issues, implementation difficulties, and cultural barriers. Based on these findings, this paper proposes strategic measures to overcome these obstacles and facilitate ontology-driven decision support.}
}
@article{2024iii,
title = {Contents},
journal = {Procedia Computer Science},
volume = {251},
pages = {iii-ix},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/S1877-0509(24)03430-6},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924034306}
}
@article{YI2024448,
title = {Biomass-derived mesoporous core-shell Fe3C@graphene oxide nanospheres for electrochemical energy storage},
journal = {International Journal of Hydrogen Energy},
volume = {64},
pages = {448-454},
year = {2024},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2024.03.311},
url = {https://www.sciencedirect.com/science/article/pii/S0360319924011637},
author = {Xinli Yi and Wen He and Xudong Zhang and Kwan San Hui and Wangwang Xu},
keywords = {mFeC@GO NSs, Biomass-derived compounds, Nanostructured electrode, Lithium-ion battery, Electrochemical energy storage},
abstract = {The biomass-derived mesoporous core-shell Fe3C@graphene oxide nanospheres (mFe3C@GO NSs) was synthesized with high-quality lignins and applied for electrochemical energy storage. The synthesis conditions of mFe3C@GO NSs are optimized and its formation mechanism is proposed. The mFe3C@GO NSs homogeneously dispersed in GO conductive network and maintained the structural integrity of the electrode during the electrochemical process. Benefiting from the advantages of the core-shell construction and graphene oxide network, the mFe3C@GO NSs exhibits extensible exploration in electrochemical energy storage (EES).}
}
@article{LI2025143775,
title = {Co-surfactant roles of amino acids at oil-water interface: Application in low-pH emulsions to regulate physical and oxidative stabilities},
journal = {Food Chemistry},
volume = {479},
pages = {143775},
year = {2025},
issn = {0308-8146},
doi = {https://doi.org/10.1016/j.foodchem.2025.143775},
url = {https://www.sciencedirect.com/science/article/pii/S030881462501026X},
author = {Peilong Li and Yinan Huang and Melanie Marshall and Anne Brooks and Megan Chin and Jieying Li and Yu Wang and Da Som No and Yuan Fang and Alireza Abbaspourrad},
keywords = {Sucrose ester, Emulsion, Amino acid, Co-surfactant, Acid stability, Lipid oxidation},
abstract = {Sucrose monopalmitate (SMP) is an effective surfactant for emulsification, but exhibits poor stability in low pH environments, due to neutralized surface charges. To improve SMP-based emulsions, we used food-grade amino acids as co-surfactants. Lysine, histidine, phenylalanine, and tryptophan lowered the water-oil interfacial tension. Tryptophan was the most effective, providing sufficient electrostatic repulsion to stabilize emulsion droplets by adsorbing onto the oil surface and becoming protonated at pH 3. However, tryptophan was counterproductive to stabilize SMP-based emulsions between pH 4 and 5. A minimum concentration (0.4 w/v%) of tryptophan prevented droplet coalescence and creaming. Incorporating tryptophan with SMP before emulsification resulted in larger droplets compared to post-emulsification addition. Tryptophan-costabilized emulsions induced flocculation with κ-carrageenan via electrostatic adsorption but showed higher compatibility with polysaccharides with weaker charges. Tryptophan enhanced oxidative stability of unsaturated lipids creating a cationic shield to repel transition metals in the aqueous phase and stabilizing cleavage of lipid hydroperoxides.}
}
@article{CHICA2024109254,
title = {Success-driven opinion formation determines social tensions},
journal = {iScience},
volume = {27},
number = {3},
pages = {109254},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109254},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224004759},
author = {Manuel Chica and Matjaž Perc and Francisco C. Santos},
keywords = {Computational mathematics, Social sciences, Decision science},
abstract = {Summary
Polarization is common in politics and public opinion. It is believed to be shaped by media as well as ideologies, and often incited by misinformation. However, little is known about the microscopic dynamics behind polarization and the resulting social tensions. By coupling opinion formation with the strategy selection in different social dilemmas, we reveal how success at an individual level transforms to global consensus or lack thereof. When defection carries with it the fear of punishment in the absence of greed, as in the stag-hunt game, opinion fragmentation is the smallest. Conversely, if defection promises a higher payoff and also evokes greed, like in the prisoner’s dilemma and snowdrift game, consensus is more difficult to attain. Our research thus challenges the top-down narrative of social tensions, showing they might originate from fundamental principles at individual level, like the desire to prevail in pairwise evolutionary comparisons.}
}
@article{PALSA2025100384,
title = {Technologies of and for performance: A frame analysis of recreational runners' technology use},
journal = {Performance Enhancement & Health},
volume = {13},
number = {4},
pages = {100384},
year = {2025},
issn = {2211-2669},
doi = {https://doi.org/10.1016/j.peh.2025.100384},
url = {https://www.sciencedirect.com/science/article/pii/S2211266925000672},
author = {Lauri Palsa and Pekka Mertala},
keywords = {Running, Technology, Frame analysis, Performance, Goffman},
abstract = {This study explores recreational runners' use of digital technologies by applying Goffman's frame analysis. The research question is: from which frames recreational runners approach technology use. The objective is twofold: First, we aim to move beyond the dominant reductive approach of userism and provide a more comprehensive understanding of recreational runners' relationships with digital technologies. Second, by approaching the concept of digital technology inclusively, we seek to elaborate on scholarly knowledge related to technology convergence, that is, the spillover and blending of technologies, in recreational sports. The data consist of qualitative online survey responses from 1011 runners and were analyzed via abductive content analysis. As a result, we identified three dispositional frames (running for training, health and recreation, and sociality) and three technological frames (technology as verificator, motivator, and safeguard), the combinations of which highlight the often multifaceted, layered, and situational relationship people have with recreational running and technology use.}
}
@article{UTTLEY2025111616,
title = {Research culture influences in health and biomedical research: rapid scoping review and content analysis},
journal = {Journal of Clinical Epidemiology},
volume = {178},
pages = {111616},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111616},
url = {https://www.sciencedirect.com/science/article/pii/S089543562400372X},
author = {Lesley Uttley and Louise Falzon and Jennifer A. Byrne and Andrea C. Tricco and Marcus R. Munafò and David Moher and Thomas Stoeger and Limbanazo Matandika and Cyril Labbé and Florian Naudet},
keywords = {Research culture, Research integrity, Scoping review, Academia, Incentives, Conflicts of interest},
abstract = {Background
Research culture is strongly influenced by academic incentives and pressures such as the imperative to publish in academic journals, and can influence the nature and quality of the evidence we produce.
Objective
The purpose of this rapid scoping review is to capture the breadth of differential pressures and contributors to current research culture, drawing together content from empirical research specific to the health and biomedical sciences.
Study Design and Setting
PubMed and Web of Science were searched for empirical studies of influences and impacts on health and biomedical research culture, published between January 2012 and April 2024. Data charting extracted the key findings and relationships in research culture from included papers such as workforce composition; equitable access to research; academic journal trends, incentives, and reproducibility; erroneous research; questionable research practices; biases vested interests; and misconduct. A diverse author network was consulted to ensure content validity of the proposed framework of i) inclusivity, ii) transparency, iii) rigor, and iv) objectivity.
Results
A growing field of studies examining research culture exists ranging from the inclusivity of the scientific workforce, the transparency of the data generated, the rigor of the methods used and the objectivity of the researchers involved. Figurative diagrams are presented to storyboard the links between research culture content and findings.
Conclusion
The wide range of research culture influences in the recent literature indicates the need for coordinated and sustained research culture conversations. Core principles in effective research environments should include inclusive collaboration and diverse research workforces, rigorous methodological approaches, transparency, data sharing, and reflection on scientific objectivity.}
}
@article{ALESSANDRIBONETTI20259,
title = {Soft tissue flap reconstruction in infected or exposed total knee arthroplasty: A systematic review and network meta-analysis},
journal = {The Knee},
volume = {52},
pages = {9-21},
year = {2025},
issn = {0968-0160},
doi = {https://doi.org/10.1016/j.knee.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0968016024001960},
author = {Mario Alessandri-Bonetti and Riccardo Giorgino and Andrea Costantino and Francesco Amendola and Armando {De Virgilio} and Laura Mangiavini and Giuseppe M. Peretti and Luca Vaienti and Saïd C. Azoury and Francesco M. Egro},
keywords = {Knee, Arthroplasty, Revision, Complication, Flap, Reconstruction},
abstract = {Background
Total knee arthroplasty (TKA) infection or exposure associated with soft tissue deficiency represents a challenging scenario for the reconstructive surgeon. The aim of the study is to determine the most successful reconstructive option for infected or exposed TKA comparing local muscle flaps (LMF), local fasciocutaneous flaps (LFF), and free muscle flaps (FMF).
Methods
A systematic review and single-arm network meta-analysis (PRISMA) was conducted to compare outcomes of complicated TKA requiring soft tissue coverage with either LMF, LFF and FMF. The protocol was registered on PROSPERO (CRD42023388731). PubMed, Embase, Web of Science and Cochrane Library were queried. MINORS criteria were employed for bias assessment. Outcomes included infection recurrence, TKA failure, above-knee amputation, and arthrodesis.
Results
A total of 30 studies and 555 flaps were included. Pooled prevalence was 0.18 (95% CI: 0.11–0.26) for infection recurrence, 0.18 (95% CI: 0.11–0.28) for arthroplasty failure, 0.10 (95% CI: 0.08–0.13) for above-knee amputation and 0.10 (95% CI: 0.08–0.13) for arthrodesis. Local fasciocutaneous flaps demonstrated the lowest risk of infection recurrence (LFF = 0.04 ± 0.037, LMF = 0.27 ± 0.043, FMF = 0.26 ± 0.092), arthroplasty failure (LFF = 0.11 ± 0.068, LMF = 0.28 ± 0.045, FMF = 0.22 ± 0.094) and knee arthrodesis (LFF = 0.03 ± 0.027, LMF = 0.14 ± 0.03, FMF = 0.08 ± 0.06) after flap coverage of infected TKA. Free muscle flaps were associated with the lowest risk of above knee amputation (FMF = 0.08 ± 0.07, LFF = 0.10 ± 0.07, LMF = 0.11 ± 0.03). The mean MINORS score was 11.1 (95% CI: 11–12) with major weakness being the lack of prospective enrollment of the patients.
Conclusion
Based on the available literature, when appropriate, LFF appear to be the best reconstructive choice for soft tissue reconstruction in complicated TKA.}
}
@article{MASELLI2025103420,
title = {The Italian version of the University of Wisconsin Running Injury and Recovery Index (UWRI): cross-cultural adaptation, validity and reliability},
journal = {Musculoskeletal Science and Practice},
volume = {80},
pages = {103420},
year = {2025},
issn = {2468-7812},
doi = {https://doi.org/10.1016/j.msksp.2025.103420},
url = {https://www.sciencedirect.com/science/article/pii/S2468781225001687},
author = {Filippo Maselli and Leonardo Pellicciari and Marco Testa and Valerio Barbari and Fabrizio Brindisino and Firas Mourad and Lorenzo Storari},
keywords = {Running, Musculoskeletal diseases, Reproducibility of results, Patient reported outcome measures},
abstract = {Objectives
To translate, cross-culturally adapt and study the psychometric properties of the Wisconsin Running Injury and Recovery Index (UWRI) in Italian runners with running-related injuries (RRI).
Design
clinometric study.
Setting
5 private outpatient physical therapy clinics.
Participants
144 subjects with RRI.
Main outcome measures
UWRI translation was performed following international guidelines. Structural validity (confirmatory factor analysis [CFA]), internal consistency (Cronbach's alpha [α]), test-retest reliability (intraclass correlation coefficient [ICC]), measurement error (minimal detectable change [MDC]), and construct validity (hypothesis testing).
Results
UWRI translation was performed without issues. CFA showed a two-factor structure (i.e., running progression and symptom surveillance subscale) (comparative fit index = 0.988; Tucker–Lewis index = 0.977; root mean square error of approximation = 0.049; standardized root mean square residual = 0.042). Each subscale presented high internal consistency (α = 0.92 and 0.75 for the running progression and symptom surveillance subscales, respectively), excellent and good test-retest reliability (ICC = 0.99 and 0.89 for the running progression and symptom surveillance subscales, respectively), and acceptable measurement error (MDC = 0.33 and 2.3 points for the running progression and symptom surveillance subscales, respectively). Construct validity was moderate for both subscales as 50.0 % (2/4) of a-priori hypotheses were satisfied.
Conclusion
The validation process revealed acceptable psychometric properties of the UWRI Italian version, which can be used for research and clinical purposes.}
}
@article{DINH2024524,
title = {The influence of implicit self-theories on ChatGPT usage},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {5},
pages = {524-538},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-02-2024-0026},
url = {https://www.sciencedirect.com/science/article/pii/S2056488024000118},
author = {Tam Duc Dinh},
keywords = {ChatGPT, ChatGPT usage, ChatGPT adoption, Attitude, AI, Implicit belief, Self-theories},
abstract = {Purpose
The advent of ChatGPT has fundamentally changed the way people approach and access information. While we are encouraged to embrace the tool for its various benefits, it is yet to be known how to drive people to adopt this technology, especially to improve their life skills. Using implicit self-theories, the current research delineated the distinct way incremental (vs entity) theorists use ChatGPT, which in turn influences their attitude and hence the behavioural intention towards this technology.
Design/methodology/approach
The research employed a between-subject experimental design with 100 prolific participants. The manipulation materials were also pre-tested (N = 50). No confound effects such as content clarity, personal interest, and cognitive load were found. For the mediating effect, PROCESS Model 4 with bootstraps 5,000 and CI 95% were employed.
Findings
Individuals who believed that human ability to use technological applications was malleable, i.e. incremental theorists, were more likely to use ChatGPT to improve their life skills. On the other hand, when people believed that such an ability was fixed, i.e. entity theorist, they were less likely to use this new technology. The reason was that through the implicit belief, attitude towards ChatGPT was (more vs less) positively influenced which in turn motivated the behavioural intention. Further, the effect held beyond the impact of demographic factors such as age, gender, occupation, and educational level.
Originality/value
Even though implicit self-theories have received tremendous interest and empirical support, be it generic or domain-specific, the effect of implicit belief in technological applications was not clearly determined. The current research helps to extend the implicit self-theories into the technological domain, and in this case, the usage of ChatGPT. Moreover, the full mediating effect of attitude offers some thought about the revised models of technology acceptance. That is, perhaps it is the combination of (implicit) belief and attitude that may have better predictive power for technological adoption behaviour.}
}
@article{DOYLE2025450,
title = {Advancing Mental Health Research Through Strategic Integration of Transdiagnostic Dimensions and Genomics},
journal = {Biological Psychiatry},
volume = {97},
number = {5},
pages = {450-460},
year = {2025},
note = {Mechanisms of Social Cognition Deficits in Autism Spectrum Disorder},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2024.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0006322324016640},
author = {Alysa E. Doyle and Carrie E. Bearden and Raquel E. Gur and David H. Ledbetter and Christa L. Martin and Thomas H. McCoy and Bogdan Pasaniuc and Roy H. Perlis and Jordan W. Smoller and Lea K. Davis},
keywords = {Biology, Clinical translation, CNVs, Polygenic risk, Psychopathology, Transdiagnostic},
abstract = {Genome-wide studies are yielding a growing catalog of common and rare variants that confer risk for psychopathology. However, despite representing unprecedented progress, emerging data also indicate that the full promise of psychiatric genetics—including understanding pathophysiology and improving personalized care—will not be fully realized by targeting traditional dichotomous diagnostic categories. The current article provides reflections on themes that emerged from a 2021 National Institute of Mental Health–sponsored conference convened to address strategies for the evolving field of psychiatric genetics. As anticipated by the National Institute of Mental Health’s Research Domain Criteria framework, multilevel investigations of dimensional and transdiagnostic phenotypes, particularly when integrated with biobanks and big data, will be critical to advancing knowledge. The path forward will also require more diverse representation in source studies. Additionally, progress will be catalyzed by a range of converging approaches, including capitalizing on computational methods, pursuing biological insights, working within a developmental framework, and engaging health care systems and patient communities.}
}
@article{OEDING2025588,
title = {ChatGPT-4 Performs Clinical Information Retrieval Tasks Using Consistently More Trustworthy Resources Than Does Google Search for Queries Concerning the Latarjet Procedure},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {3},
pages = {588-597},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324004079},
author = {Jacob F. Oeding and Amy Z. Lu and Michael Mazzucco and Michael C. Fu and Samuel A. Taylor and David M. Dines and Russell F. Warren and Lawrence V. Gulotta and Joshua S. Dines and Kyle N. Kunze},
abstract = {Purpose
To assess the ability of ChatGPT-4, an automated Chatbot powered by artificial intelligence, to answer common patient questions concerning the Latarjet procedure for patients with anterior shoulder instability and compare this performance with Google Search Engine.
Methods
Using previously validated methods, a Google search was first performed using the query “Latarjet.” Subsequently, the top 10 frequently asked questions (FAQs) and associated sources were extracted. ChatGPT-4 was then prompted to provide the top 10 FAQs and answers concerning the procedure. This process was repeated to identify additional FAQs requiring discrete-numeric answers to allow for a comparison between ChatGPT-4 and Google. Discrete, numeric answers were subsequently assessed for accuracy on the basis of the clinical judgment of 2 fellowship-trained sports medicine surgeons who were blinded to search platform.
Results
Mean (± standard deviation) accuracy to numeric-based answers was 2.9 ± 0.9 for ChatGPT-4 versus 2.5 ± 1.4 for Google (P = .65). ChatGPT-4 derived information for answers only from academic sources, which was significantly different from Google Search Engine (P = .003), which used only 30% academic sources and websites from individual surgeons (50%) and larger medical practices (20%). For general FAQs, 40% of FAQs were found to be identical when comparing ChatGPT-4 and Google Search Engine. In terms of sources used to answer these questions, ChatGPT-4 again used 100% academic resources, whereas Google Search Engine used 60% academic resources, 20% surgeon personal websites, and 20% medical practices (P = .087).
Conclusions
ChatGPT-4 demonstrated the ability to provide accurate and reliable information about the Latarjet procedure in response to patient queries, using multiple academic sources in all cases. This was in contrast to Google Search Engine, which more frequently used single-surgeon and large medical practice websites. Despite differences in the resources accessed to perform information retrieval tasks, the clinical relevance and accuracy of information provided did not significantly differ between ChatGPT-4 and Google Search Engine.
Clinical Relevance
Commercially available large language models (LLMs), such as ChatGPT-4, can perform diverse information retrieval tasks on-demand. An important medical information retrieval application for LLMs consists of the ability to provide comprehensive, relevant, and accurate information for various use cases such as investigation about a recently diagnosed medical condition or procedure. Understanding the performance and abilities of LLMs for use cases has important implications for deployment within health care settings.}
}