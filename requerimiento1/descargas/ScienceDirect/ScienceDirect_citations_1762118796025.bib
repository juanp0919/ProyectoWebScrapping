@article{NING2025109828,
title = {Value-based or one-time? Optimal pricing modes for generative AI services in e-commerce platforms},
journal = {International Journal of Production Economics},
pages = {109828},
year = {2025},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2025.109828},
url = {https://www.sciencedirect.com/science/article/pii/S0925527325003135},
author = {Yu Ning and Zexuan Shi and Yang Tong},
keywords = {GAI services, Pricing mode choice, Two-part tariff, e-commerce platform, Game theory},
abstract = {With the rapid advancement of generative artificial intelligence (GAI) technology, e-commerce platforms are increasingly integrating GAI services to enhance product design, manufacturing, and sales processes. Despite this trend, the extant literature lacks systematic investigation into platform pricing for such services, particularly in choosing between a one-time fixed fee mode (a fixed fee for adopting GAI services) and a value-based commission mode (a fixed fee plus a commission on sales above a threshold). To address this gap, this study develops a novel two-part tariff contract to optimize the pricing mode for GAI services. Incorporating factors such as platform investment in GAI, investment cost coefficient, commission rate, and sales quantity threshold, our game-theoretic analysis reveals nuanced insights. Interestingly, our findings reveal that a value-based commission mode may not always align with the platform's interest. As the investment cost coefficient increases, the platform tends to favor a one-time fixed fee mode. Moreover, under the value-based commission mode, a higher sales quantity threshold does not necessarily benefit the manufacturer. We also identify a win-win region in which the value-based commission mode benefits both the platform and the manufacturer. Finally, additional analyses extend our findings to scenarios involving enhanced GAI efficiency and competitive market settings. This research advances the literature on AI pricing and two-part tariff theory, while offering practical insights for platform operators and manufacturers.}
}
@article{HICHAM2026146,
title = {Synergizing transformer-based models and financial sentiment analysis: A framework for generative AI in economic decision-making},
journal = {Journal of Economy and Technology},
volume = {4},
pages = {146-170},
year = {2026},
issn = {2949-9488},
doi = {https://doi.org/10.1016/j.ject.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949948825000265},
author = {Nouri Hicham and Nassera Habbat},
keywords = {Generative AI, Large Language Models, Sentiment analysis, Financial markets},
abstract = {This study introduces a new way to analyze financial sentiment by combining advanced transformer-based models with generative artificial intelligence (AI) to better understand the language and context of financial discussions. The objective is to enhance the predictive accuracy of market behavior through improved understanding of investor sentiment. The proposed sentiment analysis framework leverages six domain-specific datasets: Social Sentiment Indices (X-Scores), Fin-SoMe, SemEval-2017 Task 5, Fin-Lin, Sanders, and Taborda. These datasets, primarily sourced from social media, reflect diverse investor perspectives. Generative AI models, like GPT-3.5 and GPT-4, are used to create more data, and the meaning of words is enhanced using techniques like BERT and Word2Vec. The model is trained with a cross-entropy loss function and fine-tuned using Few-shot Learning, Chain-of-Thought reasoning, and ReAct strategies, ensuring computational efficiency. Experimental results show consistent improvements across all datasets in accuracy, precision, recall, specificity, and F1 score. The use of generative AI and transformer architectures makes the model stronger and better at understanding how investors feel in real financial situations. This research contributes to the field of explicable AI in finance by demonstrating the impact of domain-adapted models and generative techniques in advancing sentiment analysis. The findings offer practical value for investors and analysts seeking data-driven insights into market dynamics and decision-making processes.}
}
@article{SMITH2025102896,
title = {Multimodal composing with generative AI: Examining preservice teachers’ processes and perspectives},
journal = {Computers and Composition},
volume = {75},
pages = {102896},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102896},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000720},
author = {Blaine E. Smith and Amanda Yoshiko Shimizu and Sarah K. Burriss and Melanie Hundley and Emily Pendergrass},
keywords = {Multimodality, Generative AI, Teacher education, Writing processes, Digital literacies},
abstract = {The question of how generative Artificial Intelligence (Gen AI) will reshape communication is causing questions and concerns across the field of education, particular literacy and writing classrooms. Although important questions have surfaced surrounding the varied effects on writing instruction and ethical implications of AI in the classroom, there are calls for deeper investigations about how these tools might shape multimodal composing processes. This study builds upon this developing field by exploring how 21 university students in literacy education courses multimodally composed with generative AI and their perspectives on the use of AI in the classroom. Data sources included screen capture and video observations, design interviews, pre- and post- surveys, and multimodal products. Through qualitative and multimodal analysis, four main themes emerged for understanding preservice teachers’ multimodal composing processes: (1) composing was an iterative process of prompting guided by the AI tools, (2) composers exhibited two distinct processes when designing their projects, (3) AI shaped creative possibilities, and (4) play, humor, and surprise served a key function while composing. Preservice teachers’ perspectives also revealed insights into how AI shaped engagement with content, the importance of scaffolding AI in the classroom, and how ethics were intertwined with technical function and teaching beliefs.}
}
@article{SPALLEK2023,
title = {Can we use ChatGPT for Mental Health and Substance Use Education? Examining Its Quality and Potential Harms},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/51243},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000831},
author = {Sophia Spallek and Louise Birrell and Stephanie Kershaw and Emma Krogh Devine and Louise Thornton},
keywords = {artificial intelligence, generative artificial intelligence, large language models, ChatGPT, medical education, health education, patient education handout, preventive health services, educational intervention, mental health, substance use},
abstract = {Background
The use of generative artificial intelligence, more specifically large language models (LLMs), is proliferating, and as such, it is vital to consider both the value and potential harms of its use in medical education. Their efficiency in a variety of writing styles makes LLMs, such as ChatGPT, attractive for tailoring educational materials. However, this technology can feature biases and misinformation, which can be particularly harmful in medical education settings, such as mental health and substance use education. This viewpoint investigates if ChatGPT is sufficient for 2 common health education functions in the field of mental health and substance use: (1) answering users’ direct queries and (2) aiding in the development of quality consumer educational health materials.
Objective
This viewpoint includes a case study to provide insight into the accessibility, biases, and quality of ChatGPT’s query responses and educational health materials. We aim to provide guidance for the general public and health educators wishing to utilize LLMs.
Methods
We collected real world queries from 2 large-scale mental health and substance use portals and engineered a variety of prompts to use on GPT-4 Pro with the Bing BETA internet browsing plug-in. The outputs were evaluated with tools from the Sydney Health Literacy Lab to determine the accessibility, the adherence to Mindframe communication guidelines to identify biases, and author assessments on quality, including tailoring to audiences, duty of care disclaimers, and evidence-based internet references.
Results
GPT-4’s outputs had good face validity, but upon detailed analysis were substandard in comparison to expert-developed materials. Without engineered prompting, the reading level, adherence to communication guidelines, and use of evidence-based websites were poor. Therefore, all outputs still required cautious human editing and oversight.
Conclusions
GPT-4 is currently not reliable enough for direct-consumer queries, but educators and researchers can use it for creating educational materials with caution. Materials created with LLMs should disclose the use of generative artificial intelligence and be evaluated on their efficacy with the target audience.}
}
@article{TRANG2025100774,
title = {Moderating the AI Revolution: Perceived threat and generative AI implementation in Vietnamese hospitals},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100774},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100774},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001897},
author = {Ta Thi Nguyet Trang and Pham Chien Thang and Tam An Vo},
keywords = {Generative artificial intelligence, UTAUT model, Perceived AI threat, Healthcare professionals, Human-AI collaboration},
abstract = {Generative artificial intelligence (AI) has the potential to revolutionize healthcare by improving diagnostic accuracy, streamlining administrative tasks, and enhancing patient communication. However, healthcare professionals often harbor concerns about AI-related job displacement, data security, and ethical implications, creating a perceived AI threat that may impede its widespread adoption. This study integrates the unified theory of acceptance and use of technology with perceived AI threat as both a direct and moderating factor, thereby examining how threat perceptions interact with established adoption drivers in the context of healthcare in Vietnam. A cross-sectional survey was administered to 573 healthcare professionals from major hospitals across Hanoi, Vietnam. Partial least squares structural equation modeling was employed to test the proposed framework, which included performance expectancy (PE), effort expectancy (EE), social influence (SI), facilitating conditions (FC), and perceived AI threat. The results indicate that PE, EE, and SI had significant positive effects on behavioral intention, whereas FC was not a significant predictor. Perceived AI threat demonstrated a strong negative impact on adoption intentions, particularly by moderating and weakening the positive effects of PE and SI. The model explained 79.8 % of the variance in AI adoption intention, suggesting a substantial predictive power. Overall, the findings highlight the importance of addressing existential fears regarding AI in healthcare. Interventions targeting user training, transparent communication, and regulatory support may help mitigate perceived threats and harness AI's benefits. Interventions targeting user training, transparent communication, and regulatory support may help mitigate perceived threats and harness AI's benefits.}
}
@article{BOUKHENNOUFA2025107493,
title = {NM-USNet: A novel generative model for parathyroid glands detection in nuclear medicine},
journal = {Biomedical Signal Processing and Control},
volume = {104},
pages = {107493},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2025.107493},
url = {https://www.sciencedirect.com/science/article/pii/S1746809425000047},
author = {Ouassim Boukhennoufa and Laurent Comas and Jean-Marc Nicod and Noureddine Zerhouni and Hatem Boulahdour},
keywords = {Generative Artificial Intelligence, U-Net, Siamese network, Nuclear medicine, Hyperparathyroidism},
abstract = {Recent advances in Generative Artificial Intelligence (GAI) have revolutionized various fields, notably medical imaging. In the context of Parathyroid Glands detection in Nuclear Medicine, physicians rely on a subtraction process involving two different images. Consequently, the subtracted image depends entirely on the two images. This methodology is manual, time-consuming, and depends entirely on medical expertise. Conditional GAI, a sub-field of GAI, generates new data based on input specifications, enabling more controlled results. However, generative models require a large amount of data and still present limitations in precisely controlling outputs over inputs. This paper presents a new model named Nuclear Medicine U-Net Siamese Network (NM-USNet) based on a combination of U-Net and Siamese networks. The U-Net takes two input images and generates one, while the Siamese network distinguishes between the generated and the reference images. The proposed methodology achieves a mean correlation of 0.956 compared to reference images, showing its potential as a reliable medical tool to assist physicians in the detection of parathyroid glands. This advancement not only improves the accuracy of diagnosis, but also represents a significant step forward in integrating GAI into medical practice. The proposed approach gives high results despite the limited data size.}
}
@article{AGBON2024102761,
title = {Who speaks through the machine? Generative AI as discourse and implications for management},
journal = {Critical Perspectives on Accounting},
volume = {100},
pages = {102761},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102761},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000601},
author = {Gildas Agbon},
keywords = {Generative AI, ChatGPT, Discourse, Technological solutionism, Management, Organization},
abstract = {This article draws on the Foucauldian concept of “discursive formation” to conceptualize generative artificial intelligence (GAI)’s potential influence on management. It shows how ChatGPT, a typical GAI, can affect practices, decision-making responsibility and the management disciplines through a dual discourse. The first one emanates from technological solutionism, a belief that any problem can be solved with the assistance of technology (the technosolutionist discourse), and the second one concerns the utterances generated by ChatGPT itself, which are shaped by various algorithmic, epistemic and linguistic influences (the generative discourse). In simpler terms, what ChatGPT can do to management appears to depend on “what is said about it” and “what it says”. In contrast to the existing literature on ChatGPT’s potential influence on organizations, this article, through its discursive approach, takes a non-normative position, to reveal the subtler influences of generative artificial intelligence, and highlight the individual and organizational responsibilities of actors interacting with these two discourses. The conclusions may be of interest to management readers in general, and of more particular interest to the accounting profession, as the conceptualization is based more broadly on examples taken from accounting, given the close link between the accounting profession and information technologies.}
}
@article{WANG2025,
title = {Evaluating Generative AI in Mental Health: Systematic Review of Capabilities and Limitations},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/70014},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925000484},
author = {Liying Wang and Tanmay Bhanushali and Zhuoran Huang and Jingyi Yang and Sukriti Badami and Lisa Hightow-Weidman},
keywords = {LLM, mental health, clinical skills, digital mental health intervention, evaluation, large language model, generative artificial intelligence},
abstract = {Background
The global shortage of mental health professionals, exacerbated by increasing mental health needs post COVID-19, has stimulated growing interest in leveraging large language models to address these challenges.
Objectives
This systematic review aims to evaluate the current capabilities of generative artificial intelligence (GenAI) models in the context of mental health applications.
Methods
A comprehensive search across 5 databases yielded 1046 references, of which 8 studies met the inclusion criteria. The included studies were original research with experimental designs (eg, Turing tests, sociocognitive tasks, trials, or qualitative methods); a focus on GenAI models; and explicit measurement of sociocognitive abilities (eg, empathy and emotional awareness), mental health outcomes, and user experience (eg, perceived trust and empathy).
Results
The studies, published between 2023 and 2024, primarily evaluated models such as ChatGPT-3.5 and 4.0, Bard, and Claude in tasks such as psychoeducation, diagnosis, emotional awareness, and clinical interventions. Most studies used zero-shot prompting and human evaluators to assess the AI responses, using standardized rating scales or qualitative analysis. However, these methods were often insufficient to fully capture the complexity of GenAI capabilities. The reliance on single-shot prompting techniques, limited comparisons, and task-based assessments isolated from a context may oversimplify GenAI’s abilities and overlook the nuances of human–artificial intelligence interaction, especially in clinical applications that require contextual reasoning and cultural sensitivity. The findings suggest that while GenAI models demonstrate strengths in psychoeducation and emotional awareness, their diagnostic accuracy, cultural competence, and ability to engage users emotionally remain limited. Users frequently reported concerns about trustworthiness, accuracy, and the lack of emotional engagement.
Conclusions
Future research could use more sophisticated evaluation methods, such as few-shot and chain-of-thought prompting to fully uncover GenAI’s potential. Longitudinal studies and broader comparisons with human benchmarks are needed to explore the effects of GenAI-integrated mental health care.}
}
@article{OZMEN2025102385,
title = {Digital marketing of standard essential patent licensing programs},
journal = {World Patent Information},
volume = {82},
pages = {102385},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2025.102385},
url = {https://www.sciencedirect.com/science/article/pii/S0172219025000523},
author = {Gülfem Özmen and Jussi Heikkilä and Matti Karvonen and Ville Ojanen},
keywords = {Standard essential patent, Licensing program, Patent pool, Asymmetric information, Digital marketing, Marketing Mix},
abstract = {We present empirical evidence on the digital marketing choices of standard essential patent licensing programs on patent pool and licensor websites. We highlight the importance of dynamic learning in licensing negotiation events and strategic information revelation in the presence of asymmetric information. We document licensing schemes and licensed units adopted in patent licensing programs. We analyze the marketing strategies of licensing programs using applicable elements of the Marketing Mix framework. We observe significant variation in publicly available information across licensing programs. This suggests that licensors face trade-offs in deciding what information is revealed and anchored in pre-negotiations, as part of licensing program marketing, and during confidential licensing negotiations. Future studies could analyze how generative artificial intelligence (AI) systems may promote marketing and transparency of patent licensing programs.}
}
@article{BANNISTER2024173,
title = {Transnational higher education cultures and generative AI: a nominal group study for policy development in English medium instruction},
journal = {Journal for Multicultural Education},
volume = {18},
number = {12},
pages = {173-191},
year = {2024},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-10-2023-0102},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X24000181},
author = {Peter Bannister and Elena {Alcalde Peñalver} and Alexandra {Santamaría Urbieta}},
keywords = {Generative artificial intelligence, English as a medium of instruction, Higher education, Academic integrity policy development, Nominal group technique},
abstract = {Purpose
This purpose of this paper is to report on the development of an evidence-informed framework created to facilitate the formulation of generative artificial intelligence (GenAI) academic integrity policy responses for English medium instruction (EMI) higher education, responding to both the bespoke challenges for the sector and longstanding calls to define and disseminate quality implementation good practice.
Design/methodology/approach
A virtual nominal group technique engaged experts (n = 14) in idea generation, refinement and consensus building across asynchronous and synchronous stages. The resulting qualitative and quantitative data were analysed using thematic analysis and descriptive statistics, respectively.
Findings
The GenAI Academic Integrity Policy Development Blueprint for EMI Tertiary Education is not a definitive mandate but represents a roadmap of inquiry for reflective deliberation as institutions chart their own courses in this complex terrain.
Research limitations/implications
If repeated with varying expert panellists, findings may vary to a certain extent; thus, further research with a wider range of stakeholders may be necessary for additional validation.
Practical implications
While grounded within the theoretical underpinnings of the field, the tool holds practical utility for stakeholders to develop bespoke policies and critically re-examine existing frameworks.
Social implications
As texts produced by students using English as an additional language are at risk of being wrongly accused of GenAI-assisted plagiarism, owing to the limited efficacy of text classifiers such as Turnitin, the policy recommendations encapsulated in the blueprint aim to reduce potential bias and unfair treatment of students.
Originality/value
The novel blueprint represents a step towards bridging concerning gaps in policy responses worldwide and aims to spark discussion and further much-needed scholarly exploration to this end.}
}
@article{KIM2025100214,
title = {Navigating the human-AI divide: Boundary work in the age of generative AI},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {6},
pages = {100214},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100214},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000982},
author = {Young Ji Kim and Ceciley Xinyi Zhang and Chengyu Fang},
keywords = {Generative AI, Human-machine communication, Boundary work, Human-computer interaction, Ontological boundaries},
abstract = {Generative artificial intelligence (GenAI), such as ChatGPT, has recently attracted vast public attention for its remarkable ability to produce sophisticated, human-like content. As these technologies increasingly blur the boundaries between artificial and human intelligence, understanding how users perceive and manage this boundary becomes essential. Drawing on the concept of boundary work, this paper examines how GenAI users discursively and practically navigate the ontological boundaries between human intelligence and GenAI. Through a qualitative analysis of nine focus groups involving 45 college students from diverse academic backgrounds, this study identifies three types of human-GenAI boundaries: complementary, competitive, and co-evolving. Complementary boundaries highlight GenAI's supportive and instrumental role and competitive boundaries emphasize human superiority and concerns over GenAI's threats, while co-evolving boundaries acknowledge dynamic interplay and reflective collaboration between humans and GenAI. The paper contributes theoretically by demonstrating that human-machine boundaries are dynamic, multifaceted, and actively negotiated. Practically, it offers insights into user strategies and implications for responsible adoption of GenAI technologies in educational and organizational contexts.}
}
@article{HOCUTT2024102829,
title = {Composing with generative AI on digital advertising platforms},
journal = {Computers and Composition},
volume = {71},
pages = {102829},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102829},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000057},
author = {Daniel L. Hocutt},
keywords = {Generative artificial intelligence, Composition, Persuasion, Digital advertising, Search engine, Online marketing, Positionality, Privilege, Power},
abstract = {This study introduces online advertising platforms as digital composing tools where persuasive rhetoric encourages users to follow links and take action on landing pages. It frames these platforms as digital spaces where human actors work alongside non-human AI agents (Duin & Pedersen, 2021 & 2023) and where rhetorical agency emerges through the activity of machine learning and artificial intelligence. It theorizes a (human) user-centered approach to composing digital ads in digital advertising platforms built around Walton, Moore & Jones’ (2019) framework of positionality, position, and power. It provides guidance for technical and professional writers in placing human users at the center of an abstracted, algorithm-driven partnership where generative AI appears poised to wrest power from both composers and users.}
}
@article{LLEDO2025105275,
title = {Assessing the performance of generative AI chatbots in preimplantation genetic testing: a comparative study of expert evaluations},
journal = {Reproductive BioMedicine Online},
pages = {105275},
year = {2025},
issn = {1472-6483},
doi = {https://doi.org/10.1016/j.rbmo.2025.105275},
url = {https://www.sciencedirect.com/science/article/pii/S1472648325004821},
author = {Belén Lledo and Paola Carbone and Jose A. Ortiz and Ruth Morales and Adoración Rodríguez-Arnedo and Leyre Herrero and Elisa Alvarez and Jorge Ten and Lydia Luque and Juan C. Castillo and Jordi Suñol and Annalisa Racca and Andrea Bernabeu},
keywords = {Generative AI, chatbots, PGT and embryo mosaicism},
abstract = {Research Question
How reliable are generative artificial intelligence (AI) chatbots in responding to patient-relevant questions about preimplantation genetic testing (PGT), as evaluated by reproductive medicine specialists?
Design
A prospective evaluation was conducted comparing three publicly available generative AI models—ChatGPT-3.5, Gemini-1.5, and Llama-2. Twelve reproductive medicine specialists from different clinics assessed chatbot-generated responses to 13 PGT-related questions, divided into simple and controversial categories. Each response was scored from 0 to 5 using predefined criteria. Assuming all answers were excellent, the maximum score was 25 points for simple questions and 40 points for controversial ones.
Results
A total of 156 evaluations were completed. Among simple questions, the lowest-rated response was to “What are the types and techniques used for PGT?” (mean score: 2.83±0.94). For controversial questions, “What is the percentage of aneuploidy that allows an embryo to be defined as mosaic?” scored lowest (2.67±1.22). ChatGPT performed best across both categories (simple: 16.83±1.80; controversial: 27.75±4.49), followed by Gemini (14.92±2.02; 26.08±3.99) and Llama (13.58±3.60; 16.92±4.96). Statistically significant differences were observed, particularly between ChatGPT and Llama (p=0.027 for simple, p<0.001 for controversial), and between Gemini and Llama for controversial questions (p<0.001). No significant performance differences were noted across participating specialists.
Conclusions
Generative AI shows moderate reliability in addressing PGT-related inquiries, with ChatGPT and Gemini outperforming Llama. While performance was higher for simple than for controversial questions, the variability underscores the need for clinical oversight. Further refinement and validation are essential before widespread integration of AI tools in reproductive medicine.}
}
@article{SHEN2025102168,
title = {EFL students’ writing engagement and AI attitude in GenAI-assisted contexts: A mixed-methods study grounded in SDT and TAM},
journal = {Learning and Motivation},
volume = {92},
pages = {102168},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102168},
url = {https://www.sciencedirect.com/science/article/pii/S002396902500075X},
author = {Lei Shen and Siyi Wang and Yihang Xin},
keywords = {Engagement, AI attitude, EFL writing, Mixed-methods, SDT, TAM},
abstract = {While engagement has been widely recognized as a key factor in improving students’ learning outcomes, the role of attitudes toward generative artificial intelligence (GenAI) in shaping engagement, particularly in the context of writing, remains underexplored. Grounded in self-determination theory (SDT) and the technology acceptance model (TAM), the present study employs latent profile analysis (LPA), a person-centered approach that identifies distinct profiles of EFL learners’ engagement in GenAI-assisted writing. A one-way ANOVA is subsequently conducted to examine whether students’ attitudes toward GenAI differed across these engagement profiles. In addition, semi-structured interviews are conducted to investigate university teachers’ perceptions of how GenAI can enhance students’ writing engagement. The LPA identifies three engagement profiles as high engagement (31.9 %), medium engagement (50.8 %), and low engagement (17.3 %). However, GenAI attitude did not show a significant relationship with writing engagement. Qualitative findings indicate that teachers are aware of GenAI’s potential in improving students’ behavioral, emotional, and cognitive engagement, though few have actively integrated such tools into their teaching. This study offers new insights into the relationship between writing engagement and GenAI attitudes. It provides practical implications for students, instructors, and educational institutions seeking to implement GenAI technologies in English as a foreign language (EFL) learning and teaching.}
}
@article{BLEASE2025,
title = {Placebo, Nocebo, and Machine Learning: How Generative AI Could Shape Patient Perception in Mental Health Care},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/78663},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925000800},
author = {Charlotte Blease},
keywords = {ChatGPT, generative language models, large language models, placebo effects, nocebo effects, ethics, artificial intelligence, health disparities},
abstract = {The emergence of generative artificial intelligence (GenAI) in clinical settings—particularly in health documentation and communication—presents a largely unexplored but potentially transformative force in shaping placebo and nocebo effects. These psychosocial phenomena are especially potent in mental health care, where outcomes are closely tied to patients’ expectations, perceived provider competence, and empathy. Drawing on conceptual understanding of placebo and nocebo effects and the latest research, this Viewpoint argues that GenAI may amplify these effects, both positive and negative. Through tone, assurance, and even the rapidity of responses, GenAI-generated text—either co-written with clinicians or peers, or fully automated—could influence patient perceptions in ways that mental health clinicians may not currently fully anticipate. When embedded in clinician notes or patient-facing summaries, AI language may strengthen expectancies that underlie placebo effects, or conversely, heighten nocebo effects through subtle cues, inaccuracies, or potentially via loss of human nuance. This article explores the implications of AI-mediated clinical communication particularly in mental health care, emphasizing the importance of transparency, ethical oversight, and psychosocial awareness as these technologies evolve.}
}
@article{DANIEL2024100168,
title = {Responsible use of Generative AI in chemical engineering},
journal = {Digital Chemical Engineering},
volume = {12},
pages = {100168},
year = {2024},
issn = {2772-5081},
doi = {https://doi.org/10.1016/j.dche.2024.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2772508124000309},
author = {Thorin Daniel and Jin Xuan},
keywords = {Responsible technology, Ethics, Generative AI},
abstract = {Generative Artificial Intelligence is a rapidly developing area being used to create powerful tools which have the potential to change a wide range of professional practices in chemical engineering. As this area develops, new principles on responsible use of Generative AI in chemical engineering are required to ensure that traditional engineering ethics are able to accommodate the new landscape. In this perspective, we assess the current state of engineering ethics, responsible AI principles and suggest how they can combine to ensure that Generative AI can be used responsibly within the chemical engineering sector. Whilst there are many aspect to engineering ethics and responsible AI use, the core principles which include transparency, integrity, and accountability are omnipresent and provide a shared foundation of good practice on which new regulations may be built as the need arises. Future breakthrough will require development on the AI technology itself, the people-centre approach and regulation changes.}
}
@article{TANI202520,
title = {Prompt Engineering P2X Business Ecosystem with Generative AI},
journal = {Procedia Computer Science},
volume = {256},
pages = {20-27},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.091},
url = {https://www.sciencedirect.com/science/article/pii/S187705092500448X},
author = {Toni Tani and Antti Yläkujala and Lasse Metso and Tiina Sinkkonen and Timo Kärri},
keywords = {Generative AI, Prompt Engineering, Power-to-X, Business Ecosystem, GPT-4, AI Data Visualization, Sustainability},
abstract = {This study examines the potential of generative Artificial Intelligence (AI) in visualizing and sketching Power-to-X (P2X) business ecosystems via the Business Ecosystem Prompt2X Method (BEP2X). Utilizing advancements in GPT technology, this approach offers a dynamic alternative to traditional static visualization methods. Guided by the research questions, this study investigates the role of generative AI in ecosystem categorization, led by prompt engineering for detailed visualization, and culminates in the creation of a tangible artifact through this process. Using the DSR framework, BEP2X is introduced as a new method for applying generative AI to draw complex business ecosystems. The synthetic methanol plant project in Finland serves as a case study in its development, illustrating BEP2X’s practical utility.}
}
@article{CUI2024583,
title = {How to build a competitive advantage for your brand using generative AI},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {583-594},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000636},
author = {Yuanyuan (Gina) Cui and Patrick {van Esch} and Steven Phelan},
keywords = {Artificial intelligence, Generative AI, Brand persona, Competitive advantage, Large language models, Organizational strategy},
abstract = {Generative artificial intelligence—defined as AI-enabled technology that analyzes and learns from existing data and generates novel, humanlike content—has emerged as a revolutionary technology for firms seeking sustainable competitive advantage. We highlight the evolution of generative AI (GenAI) from generic, domain-tailored and collaborative systems, which are democratized and only offer demand-driven insights, to the next frontier of alternative perceptual systems. Managers who integrate current large language models into building their brand personae will empower their firms to experiment along the evolutionary journey. By embedding alternative perceptual systems into GenAI platforms, firms can achieve novel, interactive, and personalized insights that their competitors may find difficult to replicate.}
}
@article{KRISHNAMURTHYGANGA2025108443,
title = {Accelerating drug discovery targeting dihydroorotate dehydrogenase using machine learning and generative AI approaches},
journal = {Computational Biology and Chemistry},
volume = {118},
pages = {108443},
year = {2025},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108443},
url = {https://www.sciencedirect.com/science/article/pii/S1476927125001033},
author = {Gayathri {Krishnamurthy Ganga}},
keywords = {DHODH, GCN, Pyrimidine, Machine learning, Inhibitor},
abstract = {Dihydroorotate dehydrogenase (DHODH) is a key enzyme in pyrimidine biosynthesis, making it an attractive drug target for cancer, autoimmune diseases, and infections. Traditional DHODH inhibitor discovery is slow and costly. Our study integrated machine learning (ML) and generative artificial intelligence (AI) to accelerate this process, enhancing efficiency and reducing costs. We employed Random Forest (RF), XGBoost (XGB), and Logistic Regression (LR) to predict pIC50 values, with RF achieving the highest accuracy (93 % test accuracy, 81 % on unseen molecules), demonstrating superior generalization. Using a Graph Convolutional Network-based Variational Autoencoder (GCN-VAE), we generated 59 unique drug-like molecules, five with pIC50 > 7, expanding the chemical space beyond conventional screening. Docking studies confirmed strong binding affinities, with the most promising newly generated molecule showing a binding energy of –11.1 kcal/mol and an inhibition constant (Ki) of 269.8 nM. Key interactions with residues such as ALA59, PHE36, TYR38, GLN47, and ARG36 further validated stability and inhibitory potential. This AI-driven workflow accelerates DHODH inhibitor discovery by significantly reducing screening time, enhancing molecular diversity, and improving predictive accuracy. Our approach presents a scalable, cost-effective strategy for developing novel therapeutics, offering a transformative shift in drug discovery.}
}
@article{YILDIZ2025105938,
title = {What is a “good” website for communicating biosecurity information to farmers and veterinarians?},
journal = {Research in Veterinary Science},
pages = {105938},
year = {2025},
issn = {0034-5288},
doi = {https://doi.org/10.1016/j.rvsc.2025.105938},
url = {https://www.sciencedirect.com/science/article/pii/S0034528825004126},
author = {Ramazan Yildiz and Georgios Batikas and Anna Maria Iatrou and Alberto Oscar Allepuz Palau and Blerta Mehmedi Kastrati and Rreze M. Gecaj and Marco {De Nardi} and Ina Toppari and Constance Wielick and Claude Saegerman and Maria-Eleni Filippitzi and Tarmo Niine and Jarkko K. Niemi},
keywords = {Biosecurity, webpage, Internet, World Café, review, communication},
abstract = {Although many websites provide biosecurity information, there is no structured guidance on what constitutes an effective biosecurity website. This study aimed to understand what is a good biosecurity website for farmers and veterinarians, and to what extent different websites meet the proposed good features. The study included three steps: i) A World Café activity was conducted to identify the features of a “good” biosecurity website. ii) A sample of biosecurity websites was identified through an online survey and generative artificial intelligence and then screened by researchers. iii) The main improvement needs of biosecurity websites were detected by comparing the screened websites with the features of a “good” biosecurity website. Based on the World Café, the features of a good biosecurity website targeted to farmers were ease of use, cost-free access, availability in local languages and content including, for example, biosecurity lessons with media, examples of farm practices, biosecurity guidelines, self-evaluation tests of person's knowledge and farm's biosecurity level, and news about disease outbreaks and regulations. A good website for veterinarians should contain more detailed protocols, guidelines and tools than a website for farmers, and resources for creating biosecurity plans and enhancing veterinarian-farmer communication. The depth and breadth of information available on the screened websites varied. Most websites had a limited number of “good” features present. The comparison step suggested that the greatest improvement potential among the websites was in adding information on how to communicate about biosecurity, biosecurity's costs and benefits, self-evaluation tests, and videos and illustrations about biosecurity measures.}
}
@article{SCHMITT2024389,
title = {Measurability of quality characteristics identified in latent spaces of Generative AI Models},
journal = {CIRP Annals},
volume = {73},
number = {1},
pages = {389-392},
year = {2024},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2024.04.073},
url = {https://www.sciencedirect.com/science/article/pii/S0007850624000866},
author = {Robert H. Schmitt and Dominik Wolfschläger and Jan-Henrik Woltersmann and Lennart Stohrer},
keywords = {Metrology, Artificial intelligence, Generative artificial intelligence},
abstract = {Deep Learning can learn complex properties from image datasets, which are difficult to model with traditional machine vision algorithms, inherently in the form of disentangled latent spaces. With latent spaces of Generative AI models, a feature extraction method to access these properties can be implemented. This work evaluates whether the learned properties can be measured in the latent space. Quantity and quantity-value scale properties and the measurability of the dimensional quality characteristic ‘filling degree’ using a linear calibration function are demonstrated for an industrial machine vision application. An uncertainty indicator between 0.4–0.9 mm is estimated for the latent space measurements.}
}
@article{WANG2024100326,
title = {Generative AI in higher education: Seeing ChatGPT through universities' policies, resources, and guidelines},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100326},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100326},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001292},
author = {Hui Wang and Anh Dang and Zihao Wu and Son Mac},
keywords = {Generative Artificial Intelligence, AI in education (AIED), Technology in education, Higher education, Educational resources},
abstract = {The advancements in Generative Artificial Intelligence (GenAI) can provide opportunities for enriching educational experiences, but at the same time raise concerns regarding academic integrity. Many educators have expressed anxiety and hesitation when it comes to integrating GenAI in their teaching practices. Thus, recommendations and guidance from institutions are needed to support instructors in this new and emerging GenAI era. In response to this need, this study explores different U.S. universities' academic policies and guidelines regarding the use of GenAI tools (e.g., ChatGPT) for teaching and learning, and from there, gains understanding of how these universities respond and adapt to the development of GenAI in their academic contexts. Data sources include academic policies, statements, guidelines, and relevant resources provided by the top 100 universities in the U.S. Results show that the majority of these universities adopt an open but cautious approach towards GenAI. Primary concerns lie in ethical usage, accuracy, and data privacy. Most universities actively respond and provide diverse types of resources, such as syllabus templates, workshops, shared articles, and one-on-one consultations; focusing on a range of topics, namely general technical introduction, ethical concerns, pedagogical applications, preventive strategies, data privacy, limitations, and detective tools. The findings provide four practical pedagogical implications for educators when considering GenAI in teaching practices: 1) accepting GenAI presence, 2) aligning GenAI use with learning objectives, 3) evolving curriculum to prevent misuse of GenAI, and 4) adopting multifaceted evaluation strategies. For recommendations toward policy making, the article suggests two possible directions for the use of GenAI tools: 1) establishing discipline-specific policies and guidelines, and 2) managing students' sensitive information in a transparent and careful manner.}
}
@article{POTTHOFF2024194,
title = {Exploring Generative AI’s Role in Manual Assembly: Application Potentials and Use Concepts},
journal = {Procedia CIRP},
volume = {130},
pages = {194-199},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.075},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124012289},
author = {Leonie Potthoff and Rolf Naussedat and Lisa Gunnemann},
keywords = {Generative AI, Manual Assembly, Industry 5.0},
abstract = {This article investigates the potential applications and strategic implications of integrating generative artificial intelligence (GenAI) within manual assembly. With the widespread adoption of AI technologies in different sectors, there is an increasing interest in employing GenAI in manufacturing. Looking ahead, GenAI is poised to play an increasingly pivotal role, particularly in reshaping manufacturing paradigms, as we move towards a future marked by Industry 5.0’s emphasis on human-centered approaches and intelligent automation. Despite the rising importance, research on the application of GenAI in manual assembly remains limited. However, manual assembly presents numerous opportunities for potential utilization. This paper aims to examine the diverse roles of GenAI in supporting manual assembly processes by examining various scenarios where it could be beneficial and discussing strategic considerations. Additionally, it strives to point out the significance of GenAI in the context of Industry 5.0, emphasizing its focus on human-centered approaches. First, the fundamental principles of GenAI are examined, highlighting its ability to generate outputs independently using input data and predefined parameters. Comprehensive research into the state of the art is carried out then, with the aim of identifying possible existing approaches for the use of GenAI in manual assembly as well as other possible applications that can be adapted and transferred. Subsequently, an initial conceptual approach for possible applications of GenAI in manual assembly is presented.}
}
@article{ALBASHRAWI2025100751,
title = {Generative AI for decision-making: A multidisciplinary perspective},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {4},
pages = {100751},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100751},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25000964},
author = {Mousa Albashrawi},
keywords = {GenAI, Decisions making, Health, Responsible AI, Ethical governance},
abstract = {Generative artificial intelligence (GenAI) is rapidly reshaping decision-making across multiple domains, including health, law, business, education, and tourism. This study synthesizes the fragmented research on GenAI to provide a comprehensive framework for understanding its role in enhancing decision-making accuracy, efficiency, and personalization. Employing a systematic literature review and thematic analysis, this study categorizes diverse applications, from clinical diagnostics and legal reasoning to financial advisement and educational support, highlighting both innovative practices and persistent challenges. The analysis of 101 articles reveals that, while GenAI significantly improves data processing and decision support, mitigating issues such as inherent bias, misinformation, and transparency deficits requires careful attention. The integration of multi-agent frameworks and human oversight is critical for ensuring ethical and reliable outcomes. Ultimately, this synthesis highlights the transformative potential of GenAI as a decision-making tool by presenting a cross-disciplinary framework that reveals its impact and uncovers gaps across various domains. The study also advocates the development of robust regulatory and technological strategies to harness the benefits and address the limitations of GenAI.}
}
@article{CARNAT2024106067,
title = {Addressing the risks of generative AI for the judiciary: The accountability framework(s) under the EU AI Act},
journal = {Computer Law & Security Review},
volume = {55},
pages = {106067},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.106067},
url = {https://www.sciencedirect.com/science/article/pii/S026736492400133X},
author = {Irina Carnat},
keywords = {Large Language Models, Generative Artificial Intelligence, Accountability, Automation bias, Judicial decision-making},
abstract = {The rapid advancements in natural language processing, particularly the development of generative large language models (LLMs), have renewed interest in using artificial intelligence (AI) for judicial decision-making. While these technological breakthroughs present new possibilities for legal automation, they also raise concerns about over-reliance and automation bias. Drawing insights from the COMPAS case, this paper examines the implications of deploying generative LLMs in the judicial domain. It identifies the persistent factors that contributed to an accountability gap when AI systems were previously used for judicial decision-making. To address these risks, the paper analyses the relevant provisions of the EU Artificial Intelligence Act, outlining a comprehensive accountability framework based on the regulation's risk-based approach. The paper concludes that the successful integration of generative LLMs in judicial decision-making requires a holistic approach addressing cognitive biases. By emphasising shared responsibility and the imperative of AI literacy across the AI value chain, the regulatory framework can help mitigate the risks of automation bias and preserve the rule of law.}
}
@article{TALEBYAHVANOOEY2025111319,
title = {A novel framework for assessing determinant risk factors on cyber (dis)trust behaviors of netizens in deepfakes},
journal = {Engineering Applications of Artificial Intelligence},
volume = {159},
pages = {111319},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111319},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625013211},
author = {Milad {Taleby Ahvanooey} and Wojciech Mazurczyk and Zefan Wang and Jun Zhao},
keywords = {Multi-criteria-multi-decision makers, Spherical fuzzy sets, Strategic information management, Socio-economic risks of deepfakes, Generative artificial intelligence risks, Game-theoretic framework},
abstract = {Nowadays, Generative Artificial Intelligence (GenAI) tools or trainable agents can craft synthetic media (hereafter referred to as deepfakes) in the form of realistic texts, images, videos, and audios, incorporating events or things that never occurred in real life. These GenAI tools empower marketers and malicious actors to create deepfakes, both authorized and weaponized multimedia, which allows them to include celebrities without appearing in front of cameras or creating seductive phishing scams. Although GenAI tools can reduce the cost of content construction, they enable new risky opportunities (e.g., deepfake phishing and cyberbullying) that negatively impact netizens’ learning and (dis)trust behaviors in cyberspace. To address such risks, this study proposes a Multi-Criteria-Multi-Decision-Makers (MCMDM)-based Deepfake Risk Assessment Framework (DeepFakeR-MF) to evaluate determinant factors that impact the cyber (dis)trust behaviors of netizens in deepfakes. Moreover, DeepFakeR-MF deploys a combination of a novel optimized spherical fuzzy analytic hierarchy process method and a game theory-based MCMDM approach to prioritize and recommend alternative strategies that can be taken by five management sectors (e.g., industrial enterprises, governmental organizations, media outlets, social non-profit, and educational institutes) to mitigate GenAI-associated risks. Then, we collect 100 experts’ judgments by analyzing their responses to our questionnaire and prioritize the importance of determinant factors considering their preferences. To validate the prioritized factors on the performance of DeepFakeR-MF, we conduct a sensitivity analysis applying Monte Carlo statistical modeling. Finally, our results confirm that DeepFakeR-MF provides effective strategic alternatives for policymakers, educators, media professionals, engineers, and netizens, hopefully reducing the socio-economic risks of deepfakes.}
}
@article{ABDALLA2025101310,
title = {Understanding ChatGPT adoption for data analytics learning: A UTAUT perspective among social science students in Oman},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101310},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101310},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000373},
author = {Suliman Zakaria Suliman Abdalla},
keywords = {Generative artificial intelligence, ChatGPT, UTAUT model, Data analytics learning, Social sciences, Higher education},
abstract = {Generative artificial intelligence tools, particularly ChatGPT, have shown the potential to reshape education by providing personalized, efficient, and accessible learning experiences across various academic disciplines. Despite concerns about academic integrity and AI-driven misconduct, its potential to revolutionize how students engage with and master complex subjects is undeniable. This study explores the key factors that influence social science students' adoption of ChatGPT as a transformative tool to enhance their learning of data analytics. Using a descriptive quantitative research design, data were collected from a sample of 413 Omani students. The study utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as a guiding theoretical framework. Through ordinal logistic regression analysis, the study identifies performance expectancy, facilitating conditions, social influence, self-efficacy, and effort expectancy as significant predictors of students' decisions to adopt ChatGPT for their learning needs. Descriptive findings reveal that students highly value ChatGPT's capability to simplify complex data analytics concepts and assist in selecting appropriate analytical methods. This demonstrates its effectiveness in enhancing conceptual understanding. However, the tool received lower ratings for tasks such as data pre-processing and cleaning, suggesting some limitations in its effectiveness in these aspects of data analytics learning. The study's findings highlight ChatGPT's substantial potential to enhance academic performance in data analytics and provide practical recommendations for students, instructors and institutions. The focus is on strategically integrating AI technologies to optimize instructional effectiveness and foster deeper student engagement with data analytics curricula.}
}
@article{ILAGAN20241124,
title = {A prototype of a conversational virtual university support agent powered by a large language model that addresses inquiries about policies in the student handbook},
journal = {Procedia Computer Science},
volume = {239},
pages = {1124-1131},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.278},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015217},
author = {Joseph Benjamin Ilagan and Jose Ramon Ilagan},
keywords = {Conversational User Experience, Conversational agents, Natural language processing, Large language model, Chatbot},
abstract = {Universities gain a competitive advantage by deliberately improving overall service, student, faculty, and staff experience, leading to attractiveness, retention, and improved outcomes. Quality services are achieved partly by addressing employee satisfaction, specifically in the work environment. This paper presents a prototype study of a virtual university support agent, a system grounded in a Large Language Model (LLM) engineered to address inquiries from university students, faculty and staff related to the student handbook. The study investigates the integration of generative artificial intelligence and natural conversation properties inherent in LLMs to overcome customer service shortcomings identified in previous chatbot applications. The LLMs’ susceptibility to ‘hallucination’ is mitigated through a combined approach of few-shot learning and chain of thought libraries in the training phase. The information core of this system comprises student handbook PDF files, from which an algorithm extracts and structures data to be utilized by the LLM. As a result, the university support agent facilitates a viable Q&A interface for students, faculty, and administrators to inquire about university guidelines and policies.}
}
@article{DANG2024101157,
title = {Ethical use of generative AI for writing practices: Addressing linguistically diverse students in U.S. Universities' AI statements},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101157},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101157},
url = {https://www.sciencedirect.com/science/article/pii/S106037432400064X},
author = {Anh Dang and Hui Wang},
keywords = {Generative AI, ChatGPT, L2 Writing and Generative AI, GenAI Statements, University, Policies, Critical AI Literacy},
abstract = {Given the rapid development in Generative Artificial Intelligence (GenAI) technologies, conversations regarding how these tools will shape the teaching and learning of writing can be difficult to unpack. Thus, higher-ed institutions across the U.S. are paying more attention to the discussion of GenAI in their own contexts and also establishing guidelines to support instructors and students in this GenAI era. To understand more about the direction of these universities, this research brief examines publicly available statements and resources from 100 U.S. universities on the teaching of writing and GenAI usage, and from there, guide institutions in developing effective strategies for the responsible implementation of these tools. This report also highlights the importance of including L2 students as a focus in the process of crafting these statements, especially when viewing GenAI through the lens of critical pedagogy, social justice and inequalities.}
}
@article{YAN2025100465,
title = {Beyond tool use: Tracking the evolution of generative AI literacy among university students through a process-oriented investigation},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100465},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100465},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001055},
author = {Wanxin Yan and Taira Nakajima and Ryo Sawada},
keywords = {Generative artificial intelligence, AI literacy, Higher education, Prompt engineering, Metacognition},
abstract = {This study addresses the gap between the theoretical framework of Generative Artificial Intelligence (GenAI) literacy and its practical development, by investigating how university students in the humanities acquire and refine GenAI-related knowledge, skills, and attitudes. Through a 16-week intervention structured into three progressive phases, 16 students engaged with multiple GenAI tools while developing competencies in research and academic writing. The data collection included structured GenAI dialogues, periodic questionnaires, reflective assignments, and in-depth interviews. The findings revealed three interconnected dimensions of GenAI literacy development. Students internalized and recreated GenAI knowledge through practice, developed sophisticated prompt engineering skills grounded in metacognitive abilities including a critical awareness of their own values and learning goals, and evolved from viewing GenAI as a mere tool to seeing it as a context-sensitive partner requiring both exploration and caution. Notably, students learned to craft personalized GenAI workflows, critically evaluate GenAI outputs, and establish ethical boundaries that preserved their intellectual growth. This study extends the current GenAI literacy frameworks by empirically demonstrating how knowledge, skills, and attitudes coevolve through sustained engagement. This suggests that effective GenAI literacy education requires iterative practice, metacognitive development, and exposure to diverse tools to ensure that GenAI serves as a catalyst for creativity while maintaining human agency in learning.}
}
@article{LIU2025108569,
title = {Enhancing student GAI literacy in digital multimodal composing through development and validation of a scale},
journal = {Computers in Human Behavior},
volume = {166},
pages = {108569},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108569},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000160},
author = {Meilu Liu and Lawrence Jun Zhang and Donglan Zhang},
keywords = {Generative artificial intelligence, Digital multimodal composing, Literacy},
abstract = {It is widely acknowledged that Generative Artificial Intelligence (GAI) has exerted a greater influence on EFL learners' digital multimodal composing (DMC) process. GAI focuses on creating new textual and multimodal content using large language models (LLMs), and it puts different demands on EFL learners. Although much research has been conducted on EFL learners' AI literacy in various socio-cultural contexts, more attention should now be paid to EFL learners' GAI literacy in the DMC context, a new autonomous model of literacy. It should be noted that even though some studies may concentrate on users' perceptions and experiences with GAI, which may be closely tied to GAI literacy, there lacks the development of a scale for assessing GAI literacy in DMC. Thus, this study attempted to fill these research gaps by developing and validating an applicable and generalizable instrument to measure Chinese EFL learners' multimodal GAI literacy in their DMC process. Two subsamples (n1 = 296, n2 = 294) were randomly invited to respond to the GAIDMCS, and the data were subjected to exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) to test the validity and reliability of the instrument. The findings suggested that a four-factor solution with 17 items can help explain Chinese EFL learners’ GAI literacy in DMC in terms of affective learning, behavior learning, cognitive learning, and ethical learning. Our GAI literacy in DMC scale may help improve GAI education for researchers and practitioners by providing a comprehensive and plausible framework that can serve as an outline for further syllabus design.}
}
@article{V2025101633,
title = {Bioinspired small language models in edge systems for bee colony monitoring and control},
journal = {Internet of Things},
volume = {32},
pages = {101633},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101633},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525001477},
author = {Juan M. Nún̄ez V. and Diana M. Giraldo and Sebastián Gómez Segura and Juan M. Corchado and Fernando De la Prieta},
keywords = {GenAI, Bio-inspired algorithms, Beehives, Edge AIoT},
abstract = {This paper proposes a hybrid IoT architecture based on Generative Artificial Intelligence (Gen-AIoT) for the intelligent monitoring and control of beehives, designed with processing capabilities both at the edge and in the cloud, thus adapting to environments with or without internet connectivity. Through an IoT sensor network, the system collects critical data on environmental parameters and hive conditions, such as temperature, humidity, wind speed, and hive weight, processing them locally at the edge or centrally in the cloud. The architecture incorporates a recommendation system that uses a small language model (SLM) to generate real-time alerts based on data provided by the IoT sensors. This system implements two distinct SLM models, Phi-3.5 and Tinyllama, enabling hardware performance measurement and optimizing efficiency for edge processing. To establish optimal environmental ranges, the recommendation system uses bio-inspired algorithms, such as ant colony optimization, genetic algorithms, and bee swarm algorithms. Additionally, LSTM neural networks are included to predict honey production and plan hive placement based on climate and weight projections, allowing for precise and personalized adjustments. This dual processing capability (edge and cloud) reduces the need for human intervention, optimizes hive inspection times, and minimizes false positives in monitoring, making it especially beneficial for large-scale beekeeping, where weekly inspection times can exceed 50 h. With this architecture, inspection time is reduced by 80%, significantly improving efficiency in hive management and promoting sustainable practices for bee conservation through intelligent agriculture.}
}
@article{JIA2025,
title = {Dependability of Large Language Models in Cardiovascular Medicine: A Scoping Review},
journal = {Journal of Cardiothoracic and Vascular Anesthesia},
year = {2025},
issn = {1053-0770},
doi = {https://doi.org/10.1053/j.jvca.2025.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S1053077025006214},
author = {Ying Ying Jia and Lin Yan Pang and Ming Ming Bi and Xiang Lu Yang and Jian Ping Song},
keywords = {cardiovascular, large language models, generative artificial intelligence, ChatGPT, trustworthiness, reliability},
abstract = {Background
The adoption of large language models (LLMs) in both clinical and consumer healthcare settings has surged exponentially. However, there remains limited evidence on their reliability and impact in cardiovascular practice.
Objectives
This scoping review was designed to consolidate the existing biomedical literature on applicability, reliability, and quality improvement strategies for the integration of LLMs into the cardiovascular domain. Following Cochrane methodology and Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, three electronic databases (PubMed, Web of Science, and Embase) were systematically searched to identify pertinent studies published between August 2020 and February 2025. Articles addressing the development, implementation, and assessment of LLMs in cardiovascular medicine were selected for comprehensive analysis.
Results
Twenty-five eligible publications evaluated the performance of LLMs in responding to cardiology-related questions, encompassing parameters such as accuracy, response latency, indirectness, completeness, and so on. The assessment methodology varied considerably across studies. LLMs demonstrated potential utility in cardiovascular decision-making, myocarditis management, cardiac arrest diagnosis and treatment, and image differentiation.
Conclusions
Although some LLM-generated responses to cardiovascular-related questions exhibit acceptable levels of quality, significant drawbacks persist. These include verbosity, inaccuracies, occasional misinformation, inconsistent outputs to identical questions, bias, and poor reproducibility. Overall, this work highlights the urgent need for continued refinement and validation.}
}
@article{GOLABANDRZEJAK20241790,
title = {AI-powered Customer Relationship Management – GenerativeAI-based CRM – Einstein GPT, Sugar CRM, and MS Dynamics 365},
journal = {Procedia Computer Science},
volume = {246},
pages = {1790-1799},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.683},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402742X},
author = {Edyta Gołąb-Andrzejak},
keywords = {Generative AI (GenAI), Customer Relationship Management (CRM), GenAI CRM, Einstein GPT, Sugar CRM, Microsoft Dynamics 365},
abstract = {Generative artificial intelligence (GenAI) and its implementation in successive business management support systems is a rapidly growing area of theoretical consideration, ongoing research, discourse and application in practice. Recently, the implementation of of GenAI in customer relationship management (CRM) systems has been observed. Accordingly, the aim of this article is to identify areas where GenAI can enhance CRM systems, using Einstain GPT, Sugar CRM or Microsoft Dynamics 365 as examples. To this end, a research question was formulated: how can GenAI improve the effective use of CRM systems? Accordingly, a preliminary study based on secondary data analysis as well as software analysis was conducted to identify areas of GenAI use in CRM systems where we see an increase in the effective application of CRM. The results of the analysis showed that GenAI-powered CRM systems support the effectiveness and efficiency of marketing, sales, commerce, service and system user success. This is because they provide numerous advantages in terms of developing, expanding and strengthening customer relationships through highly advanced personalisation, closely linked to customer segmentation, which allows unique experiences to be provided to individual segments. As a result, this translates into building a company’s competitive advantage and increasing the profitability of its CRM efforts.}
}
@article{EBIHARA2025,
title = {Development of a Clinical Clerkship Mentor Using Generative AI and Evaluation of Its Effectiveness in a Medical Student Trial Compared to Student Mentors: 2-Part Comparative Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/76702},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001138},
author = {Hayato Ebihara and Hajime Kasai and Ikuo Shimizu and Kiyoshi Shikino and Hiroshi Tajima and Yasuhiko Kimura and Shoichi Ito},
keywords = {artificial intelligence, AI, mentoring, clinical clerkship, medical students, social support},
abstract = {Background
At the beginning of their clinical clerkships (CCs), medical students face multiple challenges related to acquiring clinical and communication skills, building professional relationships, and managing psychological stress. While mentoring and structured feedback are known to provide critical support, existing systems may not offer sufficient and timely guidance owing to the faculty’s limited availability. Generative artificial intelligence, particularly large language models, offers new opportunities to support medical education by providing context-sensitive responses.
Objective
This study aimed to develop a generative artificial intelligence CC mentor (AI-CCM) based on ChatGPT and evaluate its effectiveness in supporting medical students’ clinical learning, addressing their concerns, and supplementing human mentoring. The secondary objective was to compare AI-CCM’s educational value with responses from senior student mentors.
Methods
We conducted 2 studies. In study 1, we created 5 scenarios based on challenges that students commonly encountered during CCs. For each scenario, 5 senior student mentors and AI-CCM generated written advice. Five medical education experts evaluated these responses using a rubric to assess accuracy, practical utility, educational appropriateness (5-point Likert scale), and safety (binary scale). In study 2, a total of 17 fourth-year medical students used AI-CCM for 1 week during their CCs and completed a questionnaire evaluating its usefulness, clarity, emotional support, and impact on communication and learning (5-point Likert scale) informed by the technology acceptance model.
Results
All results indicated that AI-CCM achieved higher mean scores than senior student mentors. AI-CCM responses were rated higher in educational appropriateness (4.2, SD 0.7 vs 3.8, SD 1.0; P=.001). No significant differences with senior student mentors were observed in accuracy (4.4, SD 0.7 vs 4.2, SD 0.9; P=.11) or practical utility (4.1, SD 0.7 vs 4.0, SD 0.9; P=.35). No safety concerns were identified in AI-CCM responses, whereas 2 concerns were noted in student mentors’ responses. Scenario-specific analysis revealed that AI-CCM performed substantially better in emotional and psychological stress scenarios. In the student trial, AI-CCM was rated as moderately useful (mean usefulness score 3.9, SD 1.1), with positive evaluations for clarity (4.0, SD 0.9) and emotional support (3.8, SD 1.1). However, aspects related to feedback guidance (2.9, SD 0.9) and anxiety reduction (3.2, SD 1.0) received more neutral ratings. Students primarily consulted AI-CCM regarding learning workload and communication difficulties; few students used it to address emotional stress–related issues.
Conclusions
AI-CCM has the potential to serve as a supplementary educational partner during CCs, offering comparable support to that of senior student mentors in structured scenarios. Despite challenges of response latency and limited depth in clinical content, AI-CCM was received well by and accessible to students who used ChatGPT’s free version. With further refinements, including specialty-specific content and improved responsiveness, AI-CCM may serve as a scalable, context-sensitive support system in clinical medical education.}
}
@article{TEIXEIRADASILVA2025244,
title = {Letters to the editor generated by AI in neuroscience: The role of neuroethics},
journal = {Neuroscience},
volume = {573},
pages = {244-246},
year = {2025},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2025.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0306452225002428},
author = {Jaime A. {Teixeira da Silva} and Timothy Daly},
keywords = {Accountability, Editorial responsibility, Ethics, Retraction, Transparency},
abstract = {The letter to the editor (LTE) is a correspondence forum that allows a journal’s readers to comment on published research and also publish data and arguments in a brief way. The LTE has vital functions as an accessible comment forum, including holding authors and editors accountable for published content. Yet, there is also the possibility of misuse of the LTE format, as was evidenced by a recent mass retraction of 129 LTEs at a neurosurgery journal suspected to have been mass produced by the undeclared use of generative artificial intelligence (GAI). We argue in favor of a more interventionist stance on the part of neuroethicists to engage with, analyze, and propose solutions to the issue of low quality and GAI-generated neuroscience.}
}
@article{FENG2025104499,
title = {Integrating generative AI with neurophysiological methods in psychiatric practice},
journal = {Asian Journal of Psychiatry},
volume = {108},
pages = {104499},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104499},
url = {https://www.sciencedirect.com/science/article/pii/S187620182500142X},
author = {Yi Feng and Yuan Zhou and Jian Xu and Xinquan Lu and Ruolei Gu and Zhihong Qiao},
keywords = {Generative artificial intelligence, Large language models, Psychiatry, Neuroscience, Physiology, Biomarkers},
abstract = {This paper explores the potential integration of generative AI (e.g., large language models) with neuroscientific and physiological approaches in psychiatric practice. Renowned for its advanced natural language processing capabilities, generative AI has shown promise in psychological counseling, emotional support, and clinical interventions. However, its application alongside neuroscience and physiology in psychiatry remains underexplored. We propose that generative AI can facilitate translations and adaptive explanations, streamline experimental preparation, enhance multi-modal data analysis, and improve clinical applications through real-time communication, content generation, and data synthesis. Furthermore, we examine how generative AI, as a specialized application of deep learning, can identify new biomarkers and construct neurophysiological models of psychiatric symptoms. We also discuss the synergistic relationship between neuroscience and AI development, particularly in improving AI's emotional recognition and learning mechanisms. While acknowledging the potential benefits, we address the challenges and risks associated with generative AI in psychiatry, including data reliability, privacy concerns, and resource constraints. This perspective advocates for a balanced approach to leveraging AI's capabilities while safeguarding mental health.}
}
@article{PASEIRO2025101498,
title = {Testing the Limits: Revisiting Standardized Testing in Pharmacy Education},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {10},
pages = {101498},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101498},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925001433},
author = {Paula Paseiro and Wendy Cox},
keywords = {Test-optional, Admissions, Recruitment, Pharmacy College Admission Test (PCAT)},
abstract = {Standardized tests have long served as tools in higher education admissions to assess academic readiness and predict student success. The Pharmacy College Admission Test (PCAT), established in 1974, historically played a crucial role in evaluating prospective student pharmacists. Research consistently linked higher PCAT scores with stronger academic performance in pharmacy programs. However, criticisms of standardized testing, such as biases against underrepresented and low-income students, prompted a shift toward test-optional policies in many institutions. The COVID-19 pandemic, along with a declining number of applicants, accelerated this trend and led numerous pharmacy schools to adopt PCAT-optional admissions policies, ultimately resulting in the examination’s official retirement in January 2024. This paradigm shift raises pertinent questions about the efficacy of current admissions practices amidst evolving educational landscapes marked by grade inflation, reliance on remote learning, and the use of generative artificial intelligence. Concurrently, other health professions, such as medicine and dentistry, continue to use standardized tests for admissions decisions. This commentary explores the impact of discontinuing standardized tests in pharmacy school admissions, highlighting challenges faced and proposing the development of a new, unbiased standardized assessment tool to aid in identifying students equipped to meet the demands of pharmacy education and practice.}
}
@article{CHEN2024519,
title = {Exploration of Brand Visual Communication Innovation Design Method Based on AIGC Technology},
journal = {Procedia Computer Science},
volume = {247},
pages = {519-528},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.062},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402862X},
author = {Tiantian Chen and Bingnan Pang and Chuhua Ma and Wenwen Shao},
keywords = {AIGC Technology, Branding, Visual Communication, Creative Design, Innovative Design},
abstract = {This paper discusses the innovative application and challenges of generative artificial intelligence technology (AIGC) in brand visual communication and creative design of advertisements. AIGC has subverted the traditional communication method by virtue of its high efficiency and intelligence, realizing personalized customization and precise push ads, effectively improving the conversion effect and saving costs, and enhancing the brand's rapid response to the market and the efficiency of creative output. At the same time, this technology can promote the digitalization and intelligence of the advertising industry by tapping into big data resources. Accompanied by issues such as data security, privacy protection, talent shortage, creative quality control, brand image maintenance and regulatory adaptability, the industry needs to strengthen data security protection, cultivate cross-discipline AIGC technology and design talents, and establish a rigorous content audit system, so as to inject a strong impetus for brand visual innovation and design, and lead the brand visual communication and advertising creative design into a new stage of AI empowerment.}
}
@article{AKAKPO2025103067,
title = {Towards digital information literacy guidelines for African libraries: a survey of the relationship between digital and information literacy of university students in Ghana},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {4},
pages = {103067},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103067},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000631},
author = {Martin Gameli Akakpo and Dorothy Owusuah Ahardy and Sita Sarpong Kumankumah},
keywords = {Digital information literacy, Higher education, Generative artificial intelligence, ChatGPT, Access to technology, Use intention, African academic librarians, Ghana},
abstract = {The relationship between digital literacy and information literacy has been suggested in many studies. Despite this suggestion, research providing context-related data and research findings for university librarians and educators in Ghana is inadequate. This has left many academic librarians with the difficult task of training students for the digital world on their own, with insufficient resources to provide guidance. The insufficient resources include context-relevant data to guide policy, clear research findings to support actions and evidence to convince university policy makers about the need for course reform and increased access to technology. This paper uses a correlational design in a sample of Ghanaian university students. It investigates the relationship between digital literacy, information literacy, access to and use of technology and intention to use technology. Pearson correlation coefficients were computed for pairwise relationships between the variables. The relationship between information literacy and digital literacy was conceptualized as digital information literacy and backed with data from the study. Correlations between digital literacy and information literacy were supported, and a simple linear regression further showed that information literacy predicts digital literacy. A correlation between the intention to use technology and digital literacy, as well as information literacy and intention to use technology, was supported. The findings suggest that academic librarians in Africa improve information literacy training to cover digital topics. University policy makers are advised to improve access to and use of digital technology, be open to the ethical use of digital sources of information and ensure that all students receive training in digital sources of information and new approaches.}
}
@article{SUMMERS2024104062,
title = {Navigating challenges and opportunities: Nursing student's views on generative AI in higher education},
journal = {Nurse Education in Practice},
volume = {79},
pages = {104062},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104062},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324001914},
author = {Anthony Summers and May El Haddad and Roslyn Prichard and Karen-Ann Clarke and Joanne Lee and Florin Oprescu},
keywords = {Generative artificial intelligence, ChatGPT, Nursing education, Higher education, Student perspectives, Ethical usage, Patient care, Technology integration},
abstract = {Aim
This qualitative study aims to explore the perspectives of nursing students regarding the application and integration of generative Artificial Intelligence (AI) tools in their studies.
Background
With the increasing prevalence of generative AI tools in academic settings, there is a growing interest in their use among students for learning and assessments.
Design
Employing a qualitative descriptive design, this study used semi-structured interviews with nursing students to capture the nuanced insights of the participants.
Methods
Semi-structured interviews were digitally recorded and then transcribed verbatim. The research team reviewed all the data independently and then convened to discuss and reach a consensus on the identified themes.
Results
This study was conducted within the discipline of nursing at a regional Australian university. Thirteen nursing students, from both first and second year of the programme, were interviewed as part of this study. Six distinct themes emerged from the data analysis, including the educational impact of AI tools, equitable learning environment, ethical considerations of AI use, technology integration, safe and practical utility and generational differences.
Conclusions
This initial exploration sheds light on the diverse perspectives of nursing students concerning the incorporation of generative AI tools in their education. It underscores the potential for both positive contributions and challenges associated with the integration of generative AI in nursing education and practice.}
}
@article{CHUNG2025104054,
title = {Satiation of generative AI images},
journal = {Annals of Tourism Research},
volume = {115},
pages = {104054},
year = {2025},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2025.104054},
url = {https://www.sciencedirect.com/science/article/pii/S0160738325001604},
author = {Chanho Chung and Seunghun Shin and Namho Chung},
keywords = {Generative AI, Tourism images, Satiation, Hedonic adaptation theory, Experimental design},
abstract = {Generative artificial intelligence (AI) has shown efficiency in creating novel images. However, limited studies have undertaken further questions, to what extent should generative AI created images be used, and do they surpass the effect of real ones? Based on hedonic adaptation theory, two experimental studies were conducted to determine the satiation effect of generative AI and real images. Study 1 found that generative AI images evoked a high level of inspiration in the beginning, which then steadily declined and showed the returning phase to the initial level. Study 2, which provided empirical evidence of the satiation effect, obtained identical results. However, mixed images showed lower inspirational levels in most repetition sets. Theoretical and practical implications are indicated.}
}
@article{PRESCOTT2024,
title = {Comparing the Efficacy and Efficiency of Human and Generative AI: Qualitative Thematic Analyses},
journal = {JMIR AI},
volume = {3},
year = {2024},
issn = {2817-1705},
doi = {https://doi.org/10.2196/54482},
url = {https://www.sciencedirect.com/science/article/pii/S2817170524000425},
author = {Maximo R Prescott and Samantha Yeager and Lillian Ham and Carlos D {Rivera Saldana} and Vanessa Serrano and Joey Narez and Dafna Paltin and Jorge Delgado and David J Moore and Jessica Montoya},
keywords = {GenAI, generative artificial intelligence, ChatGPT, Bard, qualitative research, thematic analysis, digital health},
abstract = {Background
Qualitative methods are incredibly beneficial to the dissemination and implementation of new digital health interventions; however, these methods can be time intensive and slow down dissemination when timely knowledge from the data sources is needed in ever-changing health systems. Recent advancements in generative artificial intelligence (GenAI) and their underlying large language models (LLMs) may provide a promising opportunity to expedite the qualitative analysis of textual data, but their efficacy and reliability remain unknown.
Objective
The primary objectives of our study were to evaluate the consistency in themes, reliability of coding, and time needed for inductive and deductive thematic analyses between GenAI (ie, ChatGPT and Bard) and human coders.
Methods
The qualitative data for this study consisted of 40 brief SMS text message reminder prompts used in a digital health intervention for promoting antiretroviral medication adherence among people with HIV who use methamphetamine. Inductive and deductive thematic analyses of these SMS text messages were conducted by 2 independent teams of human coders. An independent human analyst conducted analyses following both approaches using ChatGPT and Bard. The consistency in themes (or the extent to which the themes were the same) and reliability (or agreement in coding of themes) between methods were compared.
Results
The themes generated by GenAI (both ChatGPT and Bard) were consistent with 71% (5/7) of the themes identified by human analysts following inductive thematic analysis. The consistency in themes was lower between humans and GenAI following a deductive thematic analysis procedure (ChatGPT: 6/12, 50%; Bard: 7/12, 58%). The percentage agreement (or intercoder reliability) for these congruent themes between human coders and GenAI ranged from fair to moderate (ChatGPT, inductive: 31/66, 47%; ChatGPT, deductive: 22/59, 37%; Bard, inductive: 20/54, 37%; Bard, deductive: 21/58, 36%). In general, ChatGPT and Bard performed similarly to each other across both types of qualitative analyses in terms of consistency of themes (inductive: 6/6, 100%; deductive: 5/6, 83%) and reliability of coding (inductive: 23/62, 37%; deductive: 22/47, 47%). On average, GenAI required significantly less overall time than human coders when conducting qualitative analysis (20, SD 3.5 min vs 567, SD 106.5 min).
Conclusions
The promising consistency in the themes generated by human coders and GenAI suggests that these technologies hold promise in reducing the resource intensiveness of qualitative thematic analysis; however, the relatively lower reliability in coding between them suggests that hybrid approaches are necessary. Human coders appeared to be better than GenAI at identifying nuanced and interpretative themes. Future studies should consider how these powerful technologies can be best used in collaboration with human coders to improve the efficiency of qualitative research in hybrid approaches while also mitigating potential ethical risks that they may pose.}
}
@article{ZHANG2025105449,
title = {Enhancing responsive teaching through in-the-moment interpretations of student resources: A study in AI-supported virtual simulation},
journal = {Computers & Education},
volume = {239},
pages = {105449},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105449},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002179},
author = {Nuodi Zhang and Fengfeng Ke and Chih-Pu Dai and Alex Barrett and Saptarshi Bhowmik and Sherry A. Southerland and Luke A. West and Xin Yuan},
keywords = {AI-Supported teaching simulation, Simulation-based learning, Preservice teachers, Science and mathematics, Responsive teaching},
abstract = {Responsive teaching, a pedagogical approach that foregrounds and builds instruction on student ideas, requires teachers to attend to and build on student resources. However, teachers' interpretations of student resources, especially during live teaching, remain understudied. In this study, we examined in-the-moment interpretations, teachers' real-time sense-making of and reflection on students' epistemic and emotional resources, and explored how teachers' in-the-moment interpretations can support their responsive teaching talk moves and knowledge. Employing a convergent mixed-methods research design, we designed and implemented a generative artificial intelligence (AI)-supported virtual simulation as a pedagogical sandbox for 40 preservice teachers (PSTs) to practice teaching with virtual students, interpret student resources, and act on these interpretations in real time. Linear regression analysis was conducted and found that PSTs’ in-the-moment interpretations are significant predictors of their responsive teaching talk moves and knowledge. Qualitative thematic analysis identified themes that corroborated and extended the findings of the quantitative component. Implications for teacher education and simulation design are discussed.}
}
@article{ZHANG2026102020,
title = {Factors influencing attitudes and behavioral intentions toward GenAI in creative collaboration: A cross-cultural comparison via a hybrid multistage approach},
journal = {Thinking Skills and Creativity},
volume = {59},
pages = {102020},
year = {2026},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.102020},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002688},
author = {Longyu Zhang and Cong Fang and Huan Lin and Guanbo Liang and Shijian Luo},
keywords = {Creative collaboration, Generative artificial intelligence (GenAI), Technology acceptance behavior, Creative thinking, Cross-cultural comparison, Hybrid multistage approach},
abstract = {The integration of Generative Artificial Intelligence (GenAI) into creative tasks offers strong potential to enhance team creativity and collaborative competence. However, the factors shaping attitudes and behavioral intentions toward GenAI in creative collaboration have received limited attention, particularly in cross-cultural contexts. To address these gaps, this study has developed and validated an integrated theoretical framework via a hybrid multistage approach. First, focus group interviews (N = 15) informed the extension of the TAM-TPB model by incorporating perceived risk, openness to experience, and AI literacy. Then, cross-cultural survey data from China (N = 529) and the USA (N = 544) were analyzed using structural equation modeling (SEM), multi-group analysis (MGA), and artificial neural networks (ANN). Results showed that subjective norm influenced user attitudes in both countries. In China, perceived usefulness and risk were key predictors, whereas in the USA, ease of use and openness to experience were more influential. Attitude, subjective norm, and perceived behavioral control were found to be critical determinants of behavioral intentions across both groups. By integrating perspectives from creativity research, this study provides theoretical and practical implications for the adoption of GenAI in creative domains, informing educators, industry practitioners, and technology developers.}
}
@article{WANG2024103533,
title = {The impact of different conversational generative AI chatbots on EFL learners: An analysis of willingness to communicate, foreign language speaking anxiety, and self-perceived communicative competence},
journal = {System},
volume = {127},
pages = {103533},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103533},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24003154},
author = {Chenghao Wang and Bin Zou and Yiran Du and Zixun Wang},
keywords = {Generative artificial intelligence (GenAI), GenAI chatbot, Avatar, Willingness to communicate (WTC), Foreign language speaking anxiety (FLSA), Self-perceived communicative competence (SPCC), English Speaking},
abstract = {Based on the Interaction Hypothesis, the study investigates the impact of different conversational Generative Artificial Intelligence (GenAI) chatbots on English as a Foreign Language (EFL) learners’ willingness to communicate (WTC), foreign language speaking anxiety (FLSA), self-perceived communicative competence (SPCC) and speaking performance. Three groups of Chinese undergraduate students were recruited: a control group (CG, N = 33) and two experimental groups (EG1, N = 33; EG2, N = 33). The CG interacted with the teacher and classmates during the speaking class. In contrast, EG1 interacted with a text- and voice-based conversational GenAI chatbot called Typebot, while EG2 engaged with a conversational GenAI chatbot that featured both text and voice interaction along with human-like avatars named D-ID Agent. Quantitative analysis using multilevel modelling revealed that EG2 showed significant improvements in WTC and SPCC and a notable reduction in FLSA levels compared to CG. However, the pre- and post-speaking test results showed no significant differences in speaking performance across the groups. Qualitative data from semi-structured interviews supported these findings, highlighting the immersive learning experience and emotional support provided by the human-like avatars. These results suggest that visually embodied GenAI chatbots can effectively enhance the emotional experience during the language learning. The study provides practical insights for language educators on integrating GenAI technologies in language teaching, emphasising the benefits of human-like avatars in fostering a more engaging and supportive learning environment.}
}
@article{XU2024703,
title = {LLM enabled generative collaborative design in a mixed reality environment},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {703-715},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.04.030},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524000967},
author = {Shengyang Xu and Yao Wei and Pai Zheng and Jia Zhang and Chunyang Yu},
keywords = {Large language model, Generative artificial intelligence, Mixed reality, Collaborative design},
abstract = {In the collaborative design process, diverse stakeholder backgrounds often introduce inefficiencies in collaboration, such as delays in design delivery and decreased creativity, primarily due to misunderstandings and communication barriers caused by this diversity. To respond, this study proposes an AI-augmented Multimodal Collaborative Design (AI-MCD) framework. This framework utilizes Large Language Models (LLM) to establish an iterative prompting mechanism that provides professional design prompts for Generative AI (GAI) to generate precise visual schemes. On this basis, the GAI cooperates with Mixed Reality (MR) technology to form an interactive and immersive environment for enabling full participation in the design process. By integrating these technologies, the study aims to help stakeholders form a unified cognition and optimize the traditional collaborative design process. Through a case study involving the development of heart education products for children, the effectiveness of the framework is emphasized, and the practical application and effectiveness of the proposed method innovation are demonstrated.}
}
@incollection{GAUR202639,
title = {Chapter 3 - Calibrating generative AI models for healthcare},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {39-56},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000035},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {AI calibration, AI in medicine, Generative AI, Healthcare, Healthcare AI, Model calibration, Predictive modeling},
abstract = {The integration of generative artificial intelligence (AI) models into healthcare has the potential to transform disease diagnosis, treatment planning, and patient care. Generative models can enhance the efficiency of information collection and reporting, medical image generation, and data analysis, leading to improved diagnostic speed and accuracy. However, the successful adoption of this technology requires careful calibration to ensure transparency, accountability, and alignment with ethical principles. This chapter delves into the intricacies of calibrating generative AI models for healthcare applications. It explores the definition and importance of model calibration, examines the impact of biases on healthcare predictions, and discusses various calibration techniques and their suitability for different use cases. The chapter also covers the implementation of calibration in healthcare AI, the evaluation of calibration performance, and the ethical considerations involved.}
}
@article{HUANG2025100977,
title = {Predicting post-VR game experiences with wearable physiological sensors},
journal = {Entertainment Computing},
volume = {55},
pages = {100977},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2025.100977},
url = {https://www.sciencedirect.com/science/article/pii/S1875952125000576},
author = {Wen Huang and Jiayi Gao and Xinyuan Chen},
keywords = {Virtual reality, Post-game experience, Electrodermal activity, Depersonalization, Derealization, Game Experience Questionnaire},
abstract = {Players’ post-game experiences determine their loyalty to a virtual reality (VR) game. However, methods for identifying players’ post-game experiences in the early stages have received far less attention than those for in-game experiences. In this study, we explored the potential of using measurements from wearable physiological sensors to predict players’ post–VR game experiences. The methods employed were correlation analyses and machine learning techniques. The results showed that electrodermal activity (EDA) measurements, particularly the mean EDA and mean EDA peak, are associated with players’ post-VR game experiences after accounting for noise. By utilizing machine learning technology, physiological metrics can forecast players’ diverse reactions after playing VR games with high accuracy. The symptoms of depersonalization/derealization experienced after VR gaming are attributed to being induced by actions within the virtual environment. This research makes significant contributions to the field of user experience recognition and the progression of VR gaming by demonstrating the potential for future VR game centers to analyze player emotions remotely and cost-effectively. This achievement provides the prerequisite for these centers to create tailored new 3D game scenarios to enhance players’ post-game experiences with the support of future advanced generative artificial intelligence technologies.}
}
@article{MARTIN2025102723,
title = {Integrating generative AI and load reduction instruction to individualize and optimize students' learning},
journal = {Learning and Individual Differences},
volume = {121},
pages = {102723},
year = {2025},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2025.102723},
url = {https://www.sciencedirect.com/science/article/pii/S1041608025000998},
author = {Andrew J. Martin and Rebecca J. Collie and Roger Kennett and Danny Liu and Paul Ginns and Lala B. Sudimantara and Ema W. Dewi and Lilith G. Rüschenpöhler},
keywords = {Generative AI, Load reduction instruction, Memory, Information processing, Cognitive load theory},
abstract = {Generative artificial intelligence (genAI) is significantly influencing teaching and learning. The uptake of genAI in schools and universities/colleges has been rapid. But it has also been ad hoc and often ineffectively implemented, with little recognition of the need to manage cognitive burden to account for individual differences between novice and expert learners. Harnessing cognitive and instructional psychology principles, load reduction instruction (LRI) offers guidance for implementing genAI in ways that accommodate differences among novice and expert learners. LRI comprises five principles aimed at productively easing the cognitive burden on learners: (1) difficulty reduction as appropriate to prior learning, (2) support and scaffolding, (3) structured practice, (4) feedback-feedforward, and (5) independent practice and problem-solving. We suggest that the future of genAI-related learning can benefit from synthesizing genAI implementation with the core principles underpinning LRI to effectively manage the cognitive burden on diverse students as they engage with genAI to learn.}
}
@article{QIU2025,
title = {Physician Use of Large Language Models: A Quantitative Study Based on Large-Scale Query-Level Data},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/76941},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011537},
author = {Lin Qiu and Chuang Tang and Xuan Bi and Gordon Burtch and Yanmin Chen and Heping Zhang},
keywords = {generative AI, large language models, health care, generative AI usage, privacy, artificial intelligence, generative artificial intelligence},
abstract = {Background
Generative artificial intelligence (GenAI) has rapidly emerged as a promising tool in health care. Despite its growing adoption, how physicians make use of it in medical practice has not been qualitatively studied. Existing literature has largely focused on theoretical applications or experimental validations, with limited insight into real-world physician engagement with GenAI technologies.
Objective
The aim of this study was to leverage a fine-grained dataset at the query level to quantitatively examine how physicians incorporate GenAI into their clinical and research workflows. The primary objective was to analyze usage patterns over time and across physician demographics. A secondary goal was to assess potential risks to patient privacy arising from physicians’ interactions with GenAI platforms.
Methods
This study collected 106,942 query-and-answer pairs by 989 physicians between August 29, 2023, and April 16, 2024. We performed topic classification to identify the most prevalent use cases, examining how these use cases evolved over time and across demographics. We also developed sensitivity classifiers to detect personally identifiable information in physicians’ queries to explore the potential privacy breach risks around physicians’ use of GenAI.
Results
Approximately 40% (396/989) of the enrolled physicians were female, 45.9% (454/989) were younger than 25 years, and 54.1% (535/989) were between 25 and 56 years of age. The majority of them worked in clinical departments (680/989, 68.8%) or medical technology departments (127/989, 12.8%). Our classification-based quantitative analyses suggest the following. First, physicians use GenAI predominantly for medical research (64,379/106,942, 60.2%) rather than clinical practice (13,100/106,942, 12.25%). Second, physicians focus more on health care–related questions (rising from 64,165/106,942, 60% to 83,415/106,942, 78%) within the first 15% (16,041/106,942) of their query sequence. Third, the use of GenAI differed across physician demographics and features. Specifically, female physicians asked a larger proportion of clinical questions (female: 0.154 vs male: 0.108; P<.001) and administration questions (female: 0.027 vs male: 0.018; P<.001) than male physicians; younger physicians posed more clinical questions (age ≤25: 0.146 vs age ∈ (25, 40]: 0.115 vs age >40: 0.103; P<.001) but fewer research questions (age ≤25: 0.580 vs age ∈ (25, 40]: 0.607 vs age >40: 0.664; P<.001) than senior physicians; and physicians accessing GenAI via computers asked more research questions (computer: 0.637 vs mobile: 0.296; P<.001), whereas physicians using mobile devices asked more clinical questions (computer: 0.107 vs mobile: 0.264; P<.001). Fourth, only 2.68% (2866/106,942) of physician queries contained sensitive information, the majority of which were primarily derived from writing and editing.
Conclusions
Physicians are actively integrating GenAI into their professional routines, primarily leveraging it for research but also increasingly for clinical support. Usage patterns vary significantly across demographic lines, including gender, age, and device preference. Despite the presence of sensitive information in some queries, the risk of privacy breaches appears to be low.}
}
@article{MAO2026109464,
title = {Visual process monitoring of biomass conversion reactors using transfer learning and generative AI},
journal = {Computers & Chemical Engineering},
volume = {205},
pages = {109464},
year = {2026},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109464},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425004673},
author = {Qiangqiang Mao and Boris Yip and Chuanhao Xu and Sagar Garg and Pengcheng Guo and Yankai Cao},
keywords = {Visual process monitoring, Biomass-to-bioproduct conversion, Shuffled video-based smoke classification, Virtual sample augmentation, Transfer learning, Explainable visual representation},
abstract = {Thermochemical reaction system, particularly in the form of small-scale, low-cost bioreactor, offers a promising solution for efficient biomass-to-bioproduct conversion. The bioreactor potentially revolutionizes biomass conversion and keep rural communities into the loop of biomass-based circular economy. However, its continuous operation remains a significant concern. A primary concern arises from the unexpected reaction condition, which is typically indicated by smoke emanating from the bioreactor. This expected issue can be resolved by minor adjustments to ensure proper reaction environment. In this regard, an automated visual process monitoring for smoke detection is crucial. This can be achieved by developing a convolutional neural network (CNN)-based smoke classifier. However, shuffled video-based smoke classification, where a model trained on video recordings from field experiments is applied to monitor new biomass reaction processes with unseen scenarios, poses great challenges due to limited number of field experiments, particularly given the diversity of field backgrounds. Considering the limited diversity issue, this study explore the potential of generative artificial intelligence (GenAI) to generate virtual training images with smoke and without smoke. With augmented training data, a tailored transfer learning strategy is applied to fine tune the CNN model for smoke detection. To assist field operators in understanding classifier decisions and correcting erroneous predictions, an explainable visual representation is provided by smoke localization heatmaps. The results show that the proposed method significantly improve smoke detection accuracy and prediction reliability, which is essential for the continuous operation of biomass conversion reactors and the success of decarbonization within biomass-based circular economy.}
}
@article{LIM2025108761,
title = {How warm-versus competent-toned AI apologies affect trust and forgiveness through emotions and perceived sincerity},
journal = {Computers in Human Behavior},
volume = {172},
pages = {108761},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108761},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225002080},
author = {Joon Soo Lim and Nalae Hong and Erika Schneider},
keywords = {Generative artificial intelligence, Crisis communication, Machine heuristics, Relational tone, Forgiveness intentions, Sincerity},
abstract = {As generative artificial intelligence (GenAI) becomes more integrated into corporate communication, its role in crisis messaging raises critical questions about audience perception and trust. Drawing on theories of machine heuristics, this study explores how relational cues in AI-authored crisis apologies shape emotional and cognitive responses that ultimately influence trust and forgiveness. A 3 (authorship attribution: AI vs. human vs. control) x 2 (relational tone: warmth vs. competence) between-subjects factorial design with 464 participants was conducted to assess if and how incorporating a warm tone into AI-generated apologies can help overcome AI's inherent limitations associated with machine heuristics. Results show that human-authored apologies are perceived as more sincere, with warmth enhancing their positive impact. AI authorship elicited more negative emotions and reduced perceived sincerity compared to human authorship; however, relational tone was found to moderate the indirect effects of authorship on trust and forgiveness through negative emotions and perceived sincerity. These findings highlight the importance of both emotional and cognitive mechanisms in AI-mediated communication. This research advances an understanding of AI-mediated communication, identifying relational tone as a critical moderator of machine heuristic effects in crisis communication contexts. By integrating both emotional (negative affect) and cognitive (perceived sincerity) mediators into the model, this research provides a deeper understanding of how audiences evaluate and respond to AI-generated apologies in crisis contexts. Additionally, it offers a novel application of machine heuristic theory, extending its relevance to reputational management and organizational transparency.}
}
@article{GENES2025100031,
title = {Addressing Note Bloat: Solutions for Effective Clinical Documentation},
journal = {JACEP Open},
volume = {6},
number = {1},
pages = {100031},
year = {2025},
issn = {2688-1152},
doi = {https://doi.org/10.1016/j.acepjo.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2688115224013456},
author = {Nicholas Genes and Joseph Sills and Heather A. Heaton and Bradley D. Shy and Jean Scofi},
keywords = {clinical informatics, documentation, electronic medical records, reimbursement},
abstract = {Clinical documentation in the United States has grown longer and more difficult to read, a phenomenon described as “note bloat.” This issue is especially pronounced in emergency medicine, where high diagnostic uncertainty and brief evaluations demand focused, efficient chart review to inform decision-making. Note bloat arises from multiple factors: efforts to enhance billing, mitigate malpractice risk, and leverage electronic health record tools that improve speed and completeness. We discuss best practices based on available evidence and expert opinion to improve note clarity and concision. Recent E/M coding reforms aim to streamline documentation by prioritizing medical decision-making over details of historical and physical examination, though implementation varies. New technologies such as generative artificial intelligence present opportunities and challenges for documentation practices. Addressing note bloat will require ongoing effort from clinical leadership, electronic health record vendors, and professional organizations.}
}
@article{CAMPBELL2025,
title = {An Examination of Generative AI Response to Suicide Inquires: Content Analysis},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/73623},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925000794},
author = {Laurie O Campbell and Kathryn Babb and Glenn W Lambie and B Grant Hayes},
keywords = {chatbots, adolescent suicide, artificial intelligence, school counseling, LIWC, Linguistic Inquiry and Word Count},
abstract = {Background
Generative artificial intelligence (AI) chatbots are an online source of information consulted by adolescents to gain insight into mental health and wellness behaviors. However, the accuracy and content of generative AI responses to questions related to suicide have not been systematically investigated.
Objective
This study aims to investigate general (not counseling-specific) generative AI chatbots’ responses to questions regarding suicide.
Methods
A content analysis was conducted of the responses of generative AI chatbots to questions about suicide. In phase 1 of the study, generative chatbots examined include: (1) Google Bard or Gemini; (2) Microsoft Bing or CoPilot; (3) ChatGPT 3.5 (OpenAI); and (4) Claude (Anthropic). In phase 2 of the study, additional generative chatbot responses were analyzed, which included Google Gemini, Claude 2 (Anthropic), xAI Grok 2, Mistral AI, and Meta AI (Meta Platforms). The two phases occurred a year apart.
Results
Findings included a linguistic analysis of the authenticity and tone within the responses using the Linguistic Inquiry and Word Count program. There was an increase in the depth and accuracy of the responses between phase 1 and phase 2 of the study. There is evidence that the responses by the generative AI chatbots were more comprehensive and responsive during phase 2 than phase 1. Specifically, the responses were found to provide more information regarding all aspects of suicide (eg, signs of suicide, lethality, resources, and ways to support those in crisis). Another difference noted in the responses between the first and second phases was the emphasis on the 988 suicide hotline number.
Conclusions
While this dynamic information may be helpful for youth in need, the importance of individuals seeking help from a trained mental health professional remains. Further, generative AI algorithms related to suicide questions should be checked periodically to ensure best practices regarding suicide prevention are being communicated.}
}
@article{GARCIALOPEZ2025100401,
title = {Challenges of implementing ChatGPT on education: Systematic literature review},
journal = {International Journal of Educational Research Open},
volume = {8},
pages = {100401},
year = {2025},
issn = {2666-3740},
doi = {https://doi.org/10.1016/j.ijedro.2024.100401},
url = {https://www.sciencedirect.com/science/article/pii/S2666374024000839},
author = {Iván Miguel García-López and Carina Soledad {González González} and María-Soledad Ramírez-Montoya and José-Martín Molina-Espinosa},
keywords = {Higher education, Educational innovation, Chatgpt, Generative artificial intelligence, Education 4.0},
abstract = {Since its launch in 2022, ChatGPT has sparked considerable interest in higher education, raising debates about its benefits, challenges, and ethical implications. This systematic literature review, spanning January 2019 to January 2024, analyzes 42 articles from Web of Science and Scopus to identify key opportunities and challenges in its academic integration. Four core issues emerge: (a) technological integration and obsolescence, emphasizing the need for scalable, modular infrastructures; (b) personalization and equity, focusing on the balance between individualized learning and avoiding algorithmic bias; (c) data quality and security, highlighting the importance of transparent data management and robust encryption to protect sensitive information; and (d) ethics and human-AI collaboration, stressing the importance of institutional policies and continuous teacher intervention to ensure responsible and effective use. This study advances the discourse by recommending sustainable strategies for AI adoption, including professional development and fairness audits, while underscoring the critical role of human oversight in maximizing ChatGPT's educational impact. Ultimately, it offers actionable insights for institutions to align AI use with ethical principles and long-term educational goals.}
}
@article{XYLOGIANNOPOULOS2025114151,
title = {Is AI-assisted paraphrase the new tool for fake review creation? Challenges and remedies},
journal = {Knowledge-Based Systems},
volume = {327},
pages = {114151},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114151},
url = {https://www.sciencedirect.com/science/article/pii/S095070512501192X},
author = {Konstantinos F. Xylogiannopoulos and Petros Xanthopoulos and Panagiotis Karampelas and Georgios A. Bakamitsos},
keywords = {Plagiarism, Artificial intelligence, AI-assisted paraphrasing, Fake online reviews, pattern matching},
abstract = {Fake review detection is a substantive problem that affects businesses and consumers who form purchase opinions about products or services. With the recent advances of generative artificial intelligence (GAN) and more specifically large language models (LLMs) there is a new kind of fake review creation mechanism that is now available to malicious users. Paraphrasing existing reviews is a new form of AI assisted plagiarism that can be used to artificially manipulate the online reputation of a product, service, or business. In this paper, we describe these new challenges, we provide a pattern detection-based methodology that can be used to strengthen current information systems management algorithms. and we perform a comparison against commercial and open-source AI text detection tools. We demonstrate the use of the proposed methodology with a review dataset from real reviews from TripAdvisor mixed with paraphrased reviews with ChatGPT 4.0. The classification performance of the proposed method achieves high scores in confusion matrix metrics, where accuracy, precision, sensitivity, specificity, and F1-score are above 90 %.}
}
@article{PRILOP2025100471,
title = {Generative AI in teacher education: Educators’ perceptions of transformative potentials and the triadic nature of AI literacy explored through AI-enhanced methods},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100471},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100471},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001110},
author = {Christopher Neil Prilop and Dana-Kristin Mah and Lucas Jasper Jacobsen and Rasmus R. Hansen and Kira Elena Weber and Fabian Hoya},
keywords = {Teacher education, Generative artificial intelligence, AI literacy, Perceptions, Mixed-methods research},
abstract = {The release of ChatGPT in November 2022 has sparked discussions about integrating Generative Artificial Intelligence (GenAI) into teacher education. Teacher educators, as key facilitators of pre-service teacher learning, play a critical role in shaping the successful adoption of GenAI. Their perceptions guide curriculum redesign, define promoted practices, and shape how pre-service teachers experience educational uses of GenAI tools, potentially multiplying its impact across future classrooms. This mixed-methods study explored Danish teacher educators’ perceptions of GenAI (n = 91), focusing on its transformative potential and the knowledge pre-service teachers need to acquire. Innovative methods, including GenAI-supported thematic analysis and Natural Language Processing, were used to analyze qualitative and quantitative survey data. Findings reveal diverse perceptions, ranging from enthusiasm for fostering innovative teaching to concerns about ethics, assessment, and safeguarding basic skills. Concerning GenAI’s potential, three key themes emerged: AI literacy, AI didactics, and AI assessment. Regarding required knowledge, teacher educators emphasized multifaceted AI literacies (AI as a teaching tool, as teaching content, and as a learning tool) framed within ethical, cultural, and democratic contexts. Mediation analyses showed that GenAI use mediated the link between both intrinsic motivation and confidence, and perceptions of its potential. Importantly, teacher educators identified a pressing need for both formal professional development and informal, collaborative learning opportunities. This study extends the TPACK framework by incorporating the triadic nature of AI literacy and emphasizes the importance of preparing educators to engage critically and responsibly with GenAI in education.}
}
@article{REN2025,
title = {Generative Semantic Communication: Architectures, Technologies, and Applications},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004291},
author = {Jinke Ren and Yaping Sun and Hongyang Du and Weiwen Yuan and Chongjie Wang and Xianda Wang and Yingbin Zhou and Ziwei Zhu and Fangxin Wang and Shuguang Cui},
keywords = {Semantic communication, Generative artificial intelligence, Large language model, Variational autoencoder, Generative adversarial network, Diffusion model},
abstract = {Semantic communication (SemCom) has emerged as a transformative paradigm for future wireless networks, aiming to improve communication efficiency by transmitting only the semantic meaning (or its encoded version) of the source data rather than the complete set of bits (symbols). However, traditional deep learning-based SemCom systems present challenges such as limited generalization, low robustness, and inadequate reasoning capabilities, primarily due to the inherently discriminative nature of deep neural networks. To address these limitations, generative artificial intelligence (GAI) is seen as a promising solution, offering notable advantages in learning complex data distributions, transforming data between high- and low-dimensional spaces, and generating high-quality content. This paper explores the applications of GAI in SemCom and presents a comprehensive study. It begins by introducing three widely used SemCom systems enabled by classical GAI models: variational autoencoders, generative adversarial networks, and diffusion models. For each system, the fundamental concept of the GAI model, the corresponding SemCom architecture, and a literature review of recent developments are provided. Subsequently, a novel generative SemCom system is proposed, incorporating cutting-edge GAI technology—large language models (LLMs). This system features LLM-based artificial intelligence (AI) agents at both the transmitter and receiver, which act as “brains” to enable advanced information understanding and content regeneration capabilities, respectively. Unlike traditional systems that focus on bitstream recovery, this design allows the receiver to directly generate the desired content from the coded semantic information sent by the transmitter. As a result, the communication paradigm shifts from “information recovery” to “information regeneration,” marking a new era in generative SemCom. A case study on point-to-point video retrieval is presented to demonstrate the effectiveness of the proposed system, showing a 99.98% reduction in communication overhead and a 53% improvement in average retrieval accuracy compared to traditional communication systems. Furthermore, four typical application scenarios for generative SemCom are described, followed by a discussion of three open issues for future research. In summary, this paper provides a comprehensive set of guidelines for applying GAI in SemCom, laying the groundwork for the efficient deployment of generative SemCom in future wireless networks.}
}
@article{HSU2025,
title = {A Configurational Exploration on the Promise and Perils of Generative AI in Project-Based Language Learning},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {15},
number = {1},
year = {2025},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.382182},
url = {https://www.sciencedirect.com/science/article/pii/S2155709825000131},
author = {Liwei Hsu},
keywords = {Generative Artificial Intelligence, Project-Based Language Learning, fsQCA, Learner Autonomy, Collaborative Learning, EFL Development, Configurational Analysis, Necessity Analysis},
abstract = {ABSTRACT
This study employs fuzzy-set Qualitative Comparative Analysis to investigate how generative artificial intelligence (GAI) integration affects English as a Foreign Language development in project-based learning (PjBL) contexts. This study examined configurations of learner autonomy, collaborative learning, GAI-supported language learning, and GAI-supported project-based learning among 43 undergraduate students engaged in a 12-week intervention. Results identified four pathways to enhanced language development: autonomy with GAI language support, synergistic integration of autonomy and collaboration with GAI in projects, comprehensive GAI integration with collaborative practices, and an individualistic pathway combining autonomy with GAI tools. Necessity analysis revealed that absence of GAI-supported language learning consistently predicted failure. These findings demonstrate the configurational nature of effective GAI integration in language education and provide guidance for implementing these tools across diverse instructional settings.}
}
@article{MORADI20251681,
title = {A Critical Review of Methods and Challenges in Large Language Models},
journal = {Computers, Materials and Continua},
volume = {82},
number = {2},
pages = {1681-1698},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.061263},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825000992},
author = {Milad Moradi and Ke Yan and David Colwell and Matthias Samwald and Rhona Asgari},
keywords = {Large language models, artificial intelligence, natural language processing, machine learning, generative artificial intelligence},
abstract = {This critical review provides an in-depth analysis of Large Language Models (LLMs), encompassing their foundational principles, diverse applications, and advanced training methodologies. We critically examine the evolution from Recurrent Neural Networks (RNNs) to Transformer models, highlighting the significant advancements and innovations in LLM architectures. The review explores state-of-the-art techniques such as in-context learning and various fine-tuning approaches, with an emphasis on optimizing parameter efficiency. We also discuss methods for aligning LLMs with human preferences, including reinforcement learning frameworks and human feedback mechanisms. The emerging technique of retrieval-augmented generation, which integrates external knowledge into LLMs, is also evaluated. Additionally, we address the ethical considerations of deploying LLMs, stressing the importance of responsible and mindful application. By identifying current gaps and suggesting future research directions, this review provides a comprehensive and critical overview of the present state and potential advancements in LLMs. This work serves as an insightful guide for researchers and practitioners in artificial intelligence, offering a unified perspective on the strengths, limitations, and future prospects of LLMs.}
}
@article{DESAGE20243,
title = {A Revised Framework for Evaluating the Quality of Mental Health Artificial Intelligence-Based Chatbots},
journal = {Procedia Computer Science},
volume = {248},
pages = {3-7},
year = {2024},
note = {International Society for Research on Internet Interventions 12th Scientific Meeting (ISRII 12)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.356},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031880},
author = {Christina Desage and Bautista Bunge and Eduardo L. Bunge},
keywords = {Artificial Intelligence, chatbot, conversational agent, mental health, evaluation},
abstract = {With the emergence of generative artificial intelligence (Gen AI) and conversational agents (CAs), a rigorous assessment process of the quality of the conversations delivered by the agents is needed. In previous work, we proposed a framework (i.e., the Thera-Turing Test - TTT) for measuring the quality of conversations between users and CAs by independent (potentially blind) therapists, comparing the performance of CAs to human therapists. In this paper, we revised and expanded upon the TTT; by including a new stage of assessment (i.e. testing simulated conversations) and providing further guidance on the phases of the TTT. First, the CA is tested in a safe environment with simulated clients (with Gen AI), instead of human clients; second, the TTT is conducted with a selected sample of actual users; and third, the TTT is conducted with a large sample of users. Adopting this innovative assessment method will guide the future development of mental health CAs, ensuring AI-led interventions meet the rigorous standards expected of human therapists.}
}
@article{DUNLOP2025102057,
title = {Faking on personality assessments in high-stakes settings: A critical review},
journal = {Current Opinion in Psychology},
volume = {65},
pages = {102057},
year = {2025},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2025.102057},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X25000703},
author = {Patrick D. Dunlop and Mengting (Rachel) Xia and Jeromy Anglim},
abstract = {Faking—deliberately self-presenting in an overly favorable light—is a persistent challenge for personality assessments in high-stakes contexts such as personnel selection. This review examines recent research on the impact of faking, strategies for its prevention and detection, and future directions. Meta-analytic evidence supports the theory of validity declines from faking, but meaningful predictive utility remains. Research on prevention has grown, covering approaches such as forced-choice formats, neutralized items, warnings, gamified, and implicit measures. However, many methods involve practical or psychometric trade-offs. Although the literature is substantial, we encourage research involving larger samples, real applicants, and within-subjects designs. Finally, novel assessment methods, including those using generative artificial intelligence, warrant further investigation both as potential solutions and as tools for faking.}
}
@article{PEREZ2025100063,
title = {Streetscape Analysis with Generative AI (SAGAI): Vision-language assessment and mapping of urban scenes},
journal = {Geomatica},
volume = {77},
number = {2},
pages = {100063},
year = {2025},
issn = {1195-1036},
doi = {https://doi.org/10.1016/j.geomat.2025.100063},
url = {https://www.sciencedirect.com/science/article/pii/S1195103625000199},
author = {Joan Perez and Giovanni Fusco},
keywords = {Vision-language models, Street View imagery, Streetscape Analysis, Geospatial AI, Zero-shot inference},
abstract = {Streetscapes are an essential component of urban space. Their assessment is presently either limited to morphometric properties of their mass skeleton or requires labor-intensive qualitative evaluations of visually perceived qualities. This paper introduces SAGAI: Streetscape Analysis with Generative Artificial Intelligence, a modular workflow for scoring street-level urban scenes using open-access data and vision-language models. SAGAI integrates OpenStreetMap geometries, Google Street View imagery, and a lightweight version of the LLaVA model to generate structured spatial indicators from images via customizable natural language prompts. The pipeline includes an automated mapping module that aggregates visual scores at both the point and street levels, enabling direct cartographic interpretation. It operates without task-specific training or proprietary software dependencies, supporting scalable and interpretable analysis of urban environments. Two exploratory case studies in Nice and Vienna illustrate SAGAI’s capacity to produce geospatial outputs from vision-language inference. The initial results show strong performance for binary urban–rural scene classification, moderate precision in commercial feature detection, and lower estimates, but still informative, of sidewalk width. Fully deployable by any user, SAGAI can be easily adapted to a wide range of urban research themes, such as walkability, safety, or urban design, through prompt modification alone.}
}
@article{SALUJA2025101101,
title = {Loafing in the era of generative AI},
journal = {Organizational Dynamics},
volume = {54},
number = {3, Part 2},
pages = {101101},
year = {2025},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101101},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000743},
author = {Smridhi Saluja and Shuchi Sinha and Sanjay Goel},
keywords = {Generative AI, Loafing, GenAI loafing, Effort loafing, Time loafing},
abstract = {Generative artificial intelligence (GenAI) is being increasingly integrated into organizational workflows as employees explore its capabilities. Though GenAI offers several possibilities, it can also have a negative impact on individual behavior and the work culture of organizations. In this article, we explore how the use of GenAI can potentially increase the prevalence of effort and time loafing at work, thereby adversely impacting employees and organizations. We identify the prominent factors that can influence time and effort loafing by employees who are using GenAI and discuss the ramifications of GenAI loafing. We also suggest appropriate measures to help organizations mitigate such loafing behavior before it becomes a norm.}
}
@article{BORROMEO2025e1002,
title = {Harnessing generative AI in nursing education: A bibliometric review},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {e1002-e1011},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001349},
author = {Alex S. Borromeo and Allan M. Manaloto and Mark Jerome M. Delos Santos and Ronilo P. Antonio and Magdalena D. Soyosa and Walton Wider},
keywords = {AI for inclusive healthcare education, Generative AI, Healthcare innovation, Nursing education, Education quality},
abstract = {Background
The integration of generative artificial intelligence (AI) in nursing education offers opportunities for personalized learning, clinical decision-making support, and simulation- based training. However, concerns remain about pedagogical, ethical, and practical implications.
Aim
This study aimed to map the existing literature and identify key trends, gaps, and emerging themes in the use of generative AI in nursing education.
Methods
A bibliometric review was conducted using Scopus-indexed publications. Co-citation and co- word analyses were performed to examine the intellectual structure and conceptual development of the field.
Results
Co-citation analysis revealed five thematic clusters, including ChatGPT integration, clinical competence development, and ethical concerns. Co-word analysis identified four clusters focusing on innovation, curriculum reform, and psychological aspects. A rise in publications was observed after 2020, with focal areas including adaptive learning and AI literacy. Barriers include lack of standard implementation frameworks and concerns over overreliance.
Conclusions
This review proposes a framework for ethical and effective AI integration in nursing education and outlines future research directions related to clinical impact, faculty readiness, and regulation.}
}
@article{DOSAJH2025102990,
title = {Modern machine learning methods for protein property prediction},
journal = {Current Opinion in Structural Biology},
volume = {90},
pages = {102990},
year = {2025},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2025.102990},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X25000089},
author = {Arjun Dosajh and Prakul Agrawal and Prathit Chatterjee and U. Deva Priyakumar},
abstract = {Recent progress and development of artificial intelligence and machine learning (AI/ML) techniques have enabled addressing complex biomolecular problems. AI/ML models learn the underlying distribution of data they are trained on and when exposed to new inputs, they make predictions based on patterns and relationships previously observed in the training set. Further, generative artificial intelligence (GenAI) can be used to accurately generate protein structure or sequence from specific selected properties. This review specifically focuses on the applications of AI/ML in predicting important functional properties of proteins, and the potential prospects of reverse-engineering in depicting the sequence and structure, from available protein-property information.}
}
@incollection{NNADILI20243037,
title = {Combining Predictive Models and Reinforcement Learning for Tailored Molecule Generation},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {3037-3042},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50507-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328824150507X},
author = {Miriam Nnadili and Andrew N. Okafor and David Akinpelu and Teslim Olayiwola and Jose Romagnoli},
keywords = {Molecular design, Predictive modelling, Reinforcement learning},
abstract = {This study introduces a three-fold methodology that harnesses the capabilities of generative artificial intelligence (AI), predictive modelling, and reinforcement learning to craft customized molecules with desired properties. The model seamlessly integrates deep learning techniques with Self-Referencing Embedded Strings (SELFIES) molecular representation, constructing a generative model for producing valid molecules. In the framework, a graph neural network model was used to predict molecular properties and a combined Variational Autoencoder and reinforcement learning model to generate new molecules with specific attributes. Experimental data from a surfactant study validates the effectiveness of the framework. This innovative approach not only streamlines molecular design for surfactant systems but also anticipates transformative advancements in diverse scientific and industrial domains.}
}
@article{LIU2025102207,
title = {Profiles of AI anxiety among Chinese public administration students and the predictive role of resilience: A self-determination theory perspective},
journal = {Learning and Motivation},
volume = {92},
pages = {102207},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102207},
url = {https://www.sciencedirect.com/science/article/pii/S0023969025001146},
author = {Peizhong Liu},
keywords = {AI anxiety, Resilience, Self-determination theory, Public administration students, Latent profile analysis},
abstract = {As generative artificial intelligence tools increasingly permeate higher education, students face new psychological challenges alongside technological opportunities. Guided by Self-Determination Theory, this study examined patterns and predictors of AI anxiety among 1247 Chinese university students majoring in public administration. Using Latent Profile Analysis, four distinct anxiety profiles were identified: Minimally Affected, Societal Risk-Oriented, Sociotechnical Sensitive, and Hypervigilant. Chi-square tests revealed significant group differences by gender, age, and AI usage frequency. Multinomial logistic regression showed that higher psychological resilience significantly reduced the likelihood of belonging to any elevated anxiety group. These findings underscore the importance of need-supportive learning environments and psychological resources in helping students adapt to AI-enhanced education. The study advances the application of SDT in digital contexts and offers practical guidance for designing inclusive and emotionally supportive AI-integrated curricula.}
}
@article{MOHAWESH2025100580,
title = {A data-driven risk assessment of cybersecurity challenges posed by generative AI},
journal = {Decision Analytics Journal},
volume = {15},
pages = {100580},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100580},
url = {https://www.sciencedirect.com/science/article/pii/S2772662225000360},
author = {Rami Mohawesh and Mohammad Ashraf Ottom and Haythem Bany Salameh},
keywords = {Generative AI, Cybersecurity, Risk mitigation, Data poisoning, Privacy concerns, Bias},
abstract = {Generative artificial intelligence (GenAI) refers to machines that can create new ideas and generate outputs similar to human cognition. This technology has ushered in a new era, offering remarkable learning capabilities and producing unique results. In this paper, we explore the role of GenAI in cybersecurity, highlighting potential risks such as data poisoning attacks, privacy concerns, and bias in decision-making. The study aims to examine how GenAI can enhance cybersecurity by improving AI algorithms and propose strategies for mitigating associated risks. As GenAI continues to gain significance across industries, especially healthcare, it is crucial to understand its potential benefits and the risks it may pose to ensure safe and responsible deployment.}
}
@article{GIORDANO2024123389,
title = {The impact of ChatGPT on human skills: A quantitative study on twitter data},
journal = {Technological Forecasting and Social Change},
volume = {203},
pages = {123389},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123389},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524001859},
author = {Vito Giordano and Irene Spada and Filippo Chiarello and Gualtiero Fantoni},
keywords = {ChatGPT, Generative Artificial Intelligence, Natural Language Processing, Skills, ESCO},
abstract = {The novel generative Artificial Intelligence (AI) developed by OpenAI, i.e., ChatGPT, rised a great interest in both scientific and business contexts. This new wave of technological advancement typically produces deep transformation in the workplace, requiring new skills. However, none of the studies in literature provide quantitative analysis and measures on the impact of ChatGPT on human skills. To address this gap, we collected a database of 616,073 tweets about ChatGPT, and used Natural Language Processing techniques to identify the tasks users requested ChatGPT to perform, and the sentiment related to these tasks. Then, we compared these tasks with a standard taxonomy of skills (i.e., ESCO) using BERT. The results of the study underline that ChatGPT impacts 185 different skills. Moreover, we proposed a model to represent the interaction of the user and ChatGPT, useful to define four skills which are emerging for using this new technology.}
}
@article{MILLEN2025,
title = {Using generative AI for interview simulations to enhance student research skills in biology education},
journal = {Journal of Microbiology & Biology Education},
volume = {26},
number = {2},
year = {2025},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00122-25},
url = {https://www.sciencedirect.com/science/article/pii/S1935787725000413},
author = {Jonathan I. Millen},
keywords = {interview simulation, generative artificial intelligence, course-based undergraduate research experience (cure), educational technology, AI in the classroom},
abstract = {ABSTRACT

The Longevity Games Interview Simulator provides an innovative approach to preparing students for real-world research interactions by leveraging the capabilities of large language models (LLMs) like OpenAI’s GPT-4o and Claude-3.7. This paper outlines the development and demonstrates the benefits of the simulator, designed to mimic interviews with older adults to enhance students’ interviewing skills, empathy, and cultural competence. Key outcomes included preparing students for real-world interactions with interview subjects, improving their ability to identify and properly document protected health information (PHI), gaining experience in asking relevant follow-up questions, and directing conversations to achieve interview goals. The simulator used generative AI models to create realistic interview scenarios based on demographic data from Rochester, NY. Components of the simulator included a student interview-question selection and creation portion, an interview-guide worksheet, a post-simulation quiz on the materials, and a reflective exercise focusing on information gathering and ethical considerations regarding PHI. This tool was designed for the Science of Aging course’s CURE (Course-Based Undergraduate Research Experience) to provide students with practical, repeatable interview practice. A small pilot study with senior nursing students indicated that the simulator improved students’ confidence, preparedness, and understanding of ethical considerations. This paper also discusses how the simulator has potential for adaptation across educational contexts and encourages educators to develop their own custom interview simulations.}
}
@article{HUANG2025100526,
title = {Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin},
journal = {Environmental Science and Ecotechnology},
volume = {24},
pages = {100526},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000043},
author = {Jeffrey Huang and Simon Elias Bibri and Paul Keel},
keywords = {Sustainable smart cities, Generative artificial intelligence, Generative spatial artificial intelligence, Foundation models, Large flow model, Urban digital twin, Urban planning and design},
abstract = {Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.}
}
@article{ALDUAIJ2025104565,
title = {VeracOS: An operating system extension for the veracity of files},
journal = {Computers & Security},
volume = {157},
pages = {104565},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104565},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825002548},
author = {Naser AlDuaij},
keywords = {Mobile and ubiquitous computing, Operating systems, Systems security, Internet of Things, Other services and applications topics, File authentication, Generative artificial intelligence, Deepfake},
abstract = {As generative artificial intelligence has improved, there is a growing trend of generating false media for spreading misinformation, driving propaganda, and theft through enhanced social engineering. This creates a global concern, leading to a heavy demand for verification and fact-checking of information. Existing solutions aim at educating users or using artificial intelligence to fact-check and detect false documents or media. While these methods provide a measure for combating misinformation, many of these existing methods are inaccurate. Methods such as deepfake detection for videos are an uphill battle as deepfake generation keeps improving and newer methods are created to subvert deepfake detection techniques. VeracOS is introduced and presented as an operating system modification that is easily deployed, can certify files that are created, and ensures that any user can automatically check the authenticity of files across any existing application or platform. VeracOS invents a unique algorithm for certifying and verifying files. VeracOS aims to revolutionize the war against misinformation and exploitation of fake content by introducing several key features: VeracOS allows users or corporations to easily and automatically certify their media. Unlike existing solutions, VeracOS avoids intensive computations, specialized hardware, and private data sharing. VeracOS also allows any user to automatically be notified if the file they are viewing is verified to be authentic. VeracOS does not require the modification of existing applications nor does it require the sharing of private information such as what files or media are being viewed by a user. These key features provide a highly portable and easily deployed system for users of any operating system, including Internet of Things devices and mobile operating systems. Using media files such as images and videos as exemplary file types and using Android as an exemplary operating system, a VeracOS prototype was implemented to allow any user to automatically certify or verify their media files. The results show that VeracOS is easy to use and can be easily run on smartphones without the need for specialized systems, applications, or hardware.}
}
@article{FONTOURA2025102847,
title = {Energy Gen-AI technology framework: A perspective of energy efficiency and business ethics in operation management},
journal = {Technology in Society},
volume = {81},
pages = {102847},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102847},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000375},
author = {Leonardo Fontoura and Daniel {Luiz de Mattos Nascimento} and Julio Vieira Neto and Rodrigo Goyannes {Gusmão Caiado}},
keywords = {Generative artificial intelligence, Energy efficiency, Industry 4.0, Corporate social responsibility, Business ethics, Fuzzy DEMATEL},
abstract = {Considering the mounting request for viable energy solutions emphasising sustainability, this study addresses the context by positioning Generative Artificial Intelligence (Gen-AI) as a pivotal remedy for improved process efficiency. Concerns about its uncontrolled use and ethical implications prompted a thorough examination of problems and gaps in this domain. This study innovates by positioning Gen-AI as a critical solution for improving energy efficiency amidst rising demand for sustainable energy at the operation and supply chain management levels. Based on technological determinism, it introduces an Energy Gen-AI Technology Framework (EnGen-AI) that integrates Gen-AI, energy efficiency, Business Ethics (BE), and Corporate Social Responsibility (CSR) principles for implementing Gen-AI to enhance sustainable energy management. The methodology includes a scoping review, a multi-criteria analysis, and a technology framework. The study harmonises BE-CSR with Gen-AI practices, offering essential guidance for management implementing Gen-AI in sustainable energy solutions whilst observing its impacts on ethical and social aspects.}
}
@article{KASAR2024905,
title = {Digital Twin and Generative AI for Product Development},
journal = {Procedia CIRP},
volume = {128},
pages = {905-910},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.043},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124007881},
author = {Riddhi Kasar and Tarun Kumar},
keywords = {Smart Manufacturing, Design for Manufacturability, Digital Twin, Generative AI},
abstract = {Optimisation of the product design and development cycle is crucial for maintaining product quality and ensuring lower production costs. It is necessary to intervene at early stages to prevent future expenses. Leveraging rapid digitalisation to achieve the desired goals and bringing in ‘smart manufacturing’ will benefit industries with large-scale productions. This paper proposes a novel approach to enhance ‘design for manufacturability (DfM)’ paradigm. Integrating digital twins and generative artificial intelligence (AI), a software is proposed that not only simulates real-world environments for testing and visualisation of potential processes but also provides designs to optimise the manufacturing process, maintain cost, and enhance the product’s appeal to the target market. The proposed model uses sensors to replicate the product in a digital environment to run a simulation. Meanwhile, a generative AI model embedded in the software provides creative and effective solutions based on user requirements and market data. When incorporated into the product development cycle, this process will ensure cost efficiency and improve the time required to develop quality products, enabling quicker launches. Thus, combining these emerging technologies yields a powerful, innovative model that enhances design for manufacturability.}
}
@article{DORON2025104272,
title = {Generative AI: driving productivity and scientific breakthroughs in pharmaceutical R&D},
journal = {Drug Discovery Today},
volume = {30},
number = {1},
pages = {104272},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2024.104272},
url = {https://www.sciencedirect.com/science/article/pii/S1359644624003970},
author = {Guy Doron and Sam Genway and Mark Roberts and Sai Jasti},
abstract = {The rapid advancement of generative artificial intelligence (AI) is reshaping pharmaceutical research and development (R&D), offering opportunities across drug discovery and development. Generative AI (GenAI) enhances productivity by enabling virtual assistants, which help automate routine tasks. It advances novel small-molecule drug design and drives new machine learning (ML) applications through synthetic data generation. Further impact is anticipated in drug development from improving operational efficiencies to novel digital innovations. Converging technologies enable rich data set capture, and next-generation AI will enable rapid, automated hypothesis generation and testing. Here, we assess the current and future applications, and the mid-term and long-term transformative potential, of GenAI in pharmaceutical R&D.}
}
@article{MA2025100832,
title = {STEP: A structured prompt optimization method for SCADA system tag generation using LLMs},
journal = {Journal of Industrial Information Integration},
volume = {45},
pages = {100832},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100832},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25000561},
author = {Fuyu Ma and Dong Li and Yu Liu and Dapeng Lan and Zhibo Pang},
keywords = {Large language models, SCADA systems, Prompt engineering, Code generation},
abstract = {In the domain of industrial control, supervisory control and data acquisition (SCADA) systems are essential for real-time monitoring and efficient data acquisition. However, as industrial systems grow in scale and complexity, conventional tag configuration methods face challenges in balancing precision and operational efficiency. Addressing these challenges requires innovative solutions. The rapid evolution of generative artificial intelligence, particularly large language models (LLMs), offers a transformative approach. This study introduces a structured prompt optimization strategy, termed structured tag engineering prompt (STEP), to increase the ability of LLMs to generate high-quality tag files. To validate the STEP method, we assessed five mainstream LLMs on basic tag generation tasks via the CodeBERTScore and pass@k metrics. The results revealed that performance of all models has been improved, thus validating the effectiveness of the proposed optimization method. On the basis of these findings, a tag generation framework grounded in the STEP method was developed and validated through case studies and practical industrial scenarios. These validations confirmed the STEP method’s applicability, demonstrating its value and potential to advance prompt engineering for SCADA systems. In summary, this study contributes to the automation and intelligence of industrial control systems while providing unique insights through the application of LLMs combined with prompt engineering in addressing complex industrial tasks.}
}
@article{STEVENS2024,
title = {Lightening the Load: Generative AI to Mitigate the Burden of the New Era of Obesity Medical Therapy},
journal = {JMIR Diabetes},
volume = {9},
year = {2024},
issn = {2371-4379},
doi = {https://doi.org/10.2196/58680},
url = {https://www.sciencedirect.com/science/article/pii/S2371437924000296},
author = {Elizabeth R Stevens and Arielle Elmaleh-Sachs and Holly Lofton and Devin M Mann},
keywords = {obesity, artificial intelligence, AI, clinical management, GLP-1, glucagon-like peptide 1, medical therapy, antiobesity, diabetes, medication, agonists, glucose-dependent insulinotropic polypeptide, treatment, clinician, health care delivery system, incretin mimetic},
abstract = {Highly effective antiobesity and diabetes medications such as glucagon-like peptide 1 (GLP-1) agonists and glucose-dependent insulinotropic polypeptide/GLP-1 (dual) receptor agonists (RAs) have ushered in a new era of treatment of these highly prevalent, morbid conditions that have increased across the globe. However, the rapidly escalating use of GLP-1/dual RA medications is poised to overwhelm an already overburdened health care provider workforce and health care delivery system, stifling its potentially dramatic benefits. Relying on existing systems and resources to address the oncoming rise in GLP-1/dual RA use will be insufficient. Generative artificial intelligence (GenAI) has the potential to offset the clinical and administrative demands associated with the management of patients on these medication types. Early adoption of GenAI to facilitate the management of these GLP-1/dual RAs has the potential to improve health outcomes while decreasing its concomitant workload. Research and development efforts are urgently needed to develop GenAI obesity medication management tools, as well as to ensure their accessibility and use by encouraging their integration into health care delivery systems.}
}
@article{HUGHES2026102982,
title = {Beyond the hype: Organisational adoption of Generative AI through the lens of the TOE framework–A mixed methods perspective},
journal = {International Journal of Information Management},
volume = {86},
pages = {102982},
year = {2026},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102982},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225001148},
author = {Laurie Hughes and Fern Davies and Keyao Li and Senali Madugoda Gunaratnege and Tegwen Malik and Yogesh K Dwivedi},
keywords = {Generative Artificial Intelligence, IS/IT adoption, Technology-Organisation-Environment framework},
abstract = {It is widely accepted that the impact of Generative Artificial Intelligence (GenAI) has been nothing short of transformational, with tangible impacts on industry, education, healthcare and government. But beyond the headlines, how are organisations actually using GenAI, what are the key challenges experienced by decision makers and has the reality on the ground matched the hype? This study adopts a mixed-methods approach, utilising the Technology-Organisation-Environment (TOE) framework to reveal greater insights to how organisations are adopting GenAI, the drivers that affect decision making and the key challenges associated with greater use of the technology. This research adopts a mixed method approach incorporating an explorative qualitative step with industry participants followed by a survey of 304 (three hundred and four) decision makers from a cross section of industry sectors from around the world including: North America, Europe, Africa, Australia and Asia, to gain further insight to the underlying factors that drive GenAI adoption. The research model was validated using Structural Equation Modelling (SEM) and reveals the intricate and inherent complexities related to greater levels of GenAI adoption. The analysis highlights the critical role of change capacity of the organisation in moderating complexity and staff skills. This research provides valuable and timely insights for senior management and policy makers that are attempting to better understand the interdependencies and perspectives on the key challenges facing organisations looking to deliver greater impact on organisational performance through GenAI.}
}
@article{WANG2025,
title = {The Impact of Generative AI on Chinese Poetry Instruction:},
journal = {International Journal of Online Pedagogy and Course Design},
volume = {15},
number = {1},
year = {2025},
issn = {2155-6873},
doi = {https://doi.org/10.4018/IJOPCD.375626},
url = {https://www.sciencedirect.com/science/article/pii/S2155687325000033},
author = {Sunyar Bishuang Wang and Sandy I Ching Wang and Eric Zhi Feng Liu},
keywords = {Generative AI, Text-to-Image, Image-to-Poetry, Chinese Poetry Writing, Educational Technology},
abstract = {ABSTRACT
This study examines the potential of generative artificial intelligence (AI) to enhance Chinese poetry instruction by investigating its impact on students’ learning interest, collaborative perception, and writing abilities. Through AI’s text-to-image and image-to-poetry translation capabilities, the research explores how AI-generated visuals can deepen students’ understanding of poetic imagery and foster creative expression in poetry writing. Using a mixed-methods approach, the study analyzes pre-test, mid-test, and post-test assessments, student surveys, and student-generated poetry to evaluate the effectiveness of this innovative pedagogical approach. The findings contribute to the growing field of educational technology in humanities education, offering insights into how AI can support multimodal learning, enhance students’ linguistic creativity, and enrich their poetic sensibilities. By integrating AI technology with traditional literary instruction, this study provides a foundation for further research on the role of generative AI in language and arts education.}
}
@article{GUPTA2024100066,
title = {Generative AI: A systematic review using topic modelling techniques},
journal = {Data and Information Management},
volume = {8},
number = {2},
pages = {100066},
year = {2024},
note = {Systematic Review and Meta-analysis in Information Management Research - Part II},
issn = {2543-9251},
doi = {https://doi.org/10.1016/j.dim.2024.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2543925124000020},
author = {Priyanka Gupta and Bosheng Ding and Chong Guan and Ding Ding},
keywords = {Generative artificial intelligence, Systemic review, Topic modeling, BERTopic, ChatGPT, Use cases},
abstract = {Generative artificial intelligence (GAI) is a rapidly growing field with a wide range of applications. In this paper, a thorough examination of the research landscape in GAI is presented, encompassing a comprehensive overview of the prevailing themes and topics within the field. The study analyzes a corpus of 1319 records from Scopus spanning from 1985 to 2023 and comprises journal articles, books, book chapters, conference papers, and selected working papers. The analysis revealed seven distinct clusters of topics in GAI research: image processing and content analysis, content generation, emerging use cases, engineering, cognitive inference and planning, data privacy and security, and Generative Pre-Trained Transformer (GPT) academic applications. The paper discusses the findings of the analysis and identifies some of the key challenges and opportunities in GAI research. The paper concludes by calling for further research in GAI, particularly in the areas of explainability, robustness, cross-modal and multi-modal generation, and interactive co-creation. The paper also highlights the importance of addressing the challenges of data privacy and security in GAI and responsible use of GAI.}
}
@article{PARK2025101119,
title = {Code suggestions and explanations in programming learning: Use of ChatGPT and performance},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101119},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101119},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001903},
author = {Arum Park and Taekyung Kim},
keywords = {Future of education, Education, OpenAI, ChatGPT, Management education, Programming skills},
abstract = {This study investigates the role of generative artificial intelligence (AI) chatbots, particularly ChatGPT, in enhancing programming education for university students, specifically in big data analytics. The research addresses the growing need for innovative educational practices, especially in developed East Asian countries like South Korea, where declining university enrollment presents new challenges. Using a sample size of N = 343 students, this mixed-methods research employed controlled experiments and surveys to compare student performance in programming tasks across three groups: those using ChatGPT, those using Stack Overflow, and a control group without external assistance. Results showed that students using ChatGPT significantly outperformed those relying on Stack Overflow or no assistance, particularly in hands-on coding tasks. This research contributes to the ongoing discourse on AI in education by providing empirical evidence of generative AI's effectiveness in improving learning outcomes and engagement, while also highlighting the challenges associated with integrating AI into educational settings. The findings emphasize the potential of ChatGPT to personalize learning experiences, improve performance, and offer real-time support, underscoring the need for a balanced curriculum design that incorporates AI while maintaining academic integrity and human oversight.}
}
@article{ZHOU2025109721,
title = {Can Gen-AI promote community group buying? A tripartite evolutionary game analysis},
journal = {International Journal of Production Economics},
pages = {109721},
year = {2025},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2025.109721},
url = {https://www.sciencedirect.com/science/article/pii/S0925527325002063},
author = {Fuli Zhou and Chenchen Zhang and Sunil Tiwari and Xingjun Huang and Preetam Basu},
keywords = {Generative Artificial Intelligence (Gen-AI), Community group buying (CGB), Tripartite evolutionary game, Strategic behaviors},
abstract = {As a new retail model, community group buying (CGB) quickly caught consumers' attention with its relatively preferential prices and high delivery efficiency. However, issues such as delayed response and unsatisfactory after-sales service have severely plagued the further development of CGB. Generative AI (Gen-AI), as a disruptive innovation of artificial intelligence, offers significant potential for CGB promotion due to its excellent performance. This paper endeavors to introduce Gen-AI to the CGB scenario, and a tripartite evolutionary game model is formulated to help better understand the stakeholders' behavior including the supplier, CGB platform, and group leaders. The evolutionary stable strategies of participants under different constraints are scrutinized, which assists in exploring the impact of Gen-AI empowerment on the decision strategies of the three involved parties. Besides, simulation experiments are performed to investigate the impact of different parameter changes on the game's tripartite decisions. Results indicate that the costs, profits, and potential risks associated with Gen-AI empowerment are crucial considerations for the supplier and platform. Moreover, even with Gen-AI empowerment, the platform's revenue may decline if customers reduce their purchase frequency due to passive service from the group leader. As a result, the platform is more inclined to adopt Gen-AI empowerment when the group leader provides active service.}
}
@article{SALAZAR2025101882,
title = {Comparison of Qualitative Analyses Conducted by Artificial Intelligence Versus Traditional Methods},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {12},
pages = {101882},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101882},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925005285},
author = {Marcela Salazar and May Chaw and Yvette Hellier and Stephanie Hsia and Katherine Gruenberg},
keywords = {Artificial intelligence (AI), Qualitative research, Health professions education},
abstract = {Objective
Qualitative research remains underutilized in health professions education, in part due to insufficient training and time-intensive analytic methods. Recent advances in generative artificial intelligence offer new opportunities to streamline the qualitative research process using large language models such as GPT-4. However, the accuracy of GPT-4-generated codes and themes remains underexplored in health professions education research. This study characterizes qualitative analyses assisted by a general-purpose GPT-4 compared to traditional human-conducted analyses.
Methods
Two health professions datasets were previously analyzed using content or thematic analysis and then reanalyzed using a version of GPT-4. Researchers compared the accuracy, alignment, relevance, and appropriateness of codebooks and themes produced by GPT-4 with the prior findings. Dichotomous numerical ratings and explanations were assessed independently and then discussed collaboratively to identify strengths and weaknesses associated with GPT-4 qualitative analysis.
Results
In total, 36 survey responses and seven 1-h interview transcripts were analyzed using GPT-4. The codebooks and themes generated by GPT-4 generally aligned with human-identified concepts. Challenges included failure to detect low-frequency codes, difficulty constructing coherent code relationships, and a lack of nuance in theme descriptions and quote selection.
Conclusion
GPT-4 can support, though not replace, human-led qualitative analysis. A general understanding of qualitative research processes and the dataset is necessary for researchers to identify potential gaps, limitations, and redundancies in qualitative findings generated by GPT-4.}
}
@article{WONG2025725,
title = {Generative AI: a partner for genetic counseling?},
journal = {Trends in Genetics},
volume = {41},
number = {9},
pages = {725-729},
year = {2025},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2025.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0168952525001659},
author = {Kenny Wong and Vivian Pan and Colleen Caleshu},
abstract = {Generative artificial intelligence (AI)'s arrival in genetic counseling presents both opportunities and challenges. While offering the potential to ease burdens (e.g., by automating routine screening and summarizing patient histories) and expand access (e.g., through AI-driven preliminary education and interactive counseling), its integration demands careful evaluation, ethical design focusing on equity and privacy, and robust collaboration to ensure increased access and improved patient outcomes.}
}
@article{ALI2025104318,
title = {Beyond the hype: Evaluating the impact of generative AI on brand authenticity, image, and consumer behavior in the restaurant industry},
journal = {International Journal of Hospitality Management},
volume = {131},
pages = {104318},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104318},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925002415},
author = {Laiba Ali and Faizan Ali and Moh’d Juma Abdalla and Salman Alotaibi},
keywords = {Brand authenticity, Brand image, E-WOM, Generative artificial intelligence, Behavioral intention and self-brand congruity},
abstract = {Grounded in the Stimulus-Organism-Response (S-O-R) framework, this study investigates the impact of Generative Artificial Intelligence (GenAI) adoption on brand authenticity, brand image, and self-brand congruity and their subsequent effects on consumer behavior, including electronic word-of-mouth (e-WOM) and behavioral intention, within the restaurant industry. A scenario-based experimental design was employed, presenting participants with hypothetical situations of restaurants utilizing AI-generated and human-created social media content. MANOVA results revealed that perceived brand authenticity, image, and self-brand congruity were significantly lower in the GenAI condition compared to the human-generated content condition. Multigroup analysis further indicated that while brand authenticity and image had diminished effects on consumer behavior under the GenAI condition, self-brand congruity played a significantly stronger role in driving e-WOM and behavioral intentions. These findings suggest that AI-generated content may weaken traditional brand perception cues, prompting consumers to rely more on internal identity alignment. The study contributes to S–O–R theory by demonstrating how content source (AI vs. human) moderates the pathways from brand perception to behavior and provides actionable guidance for hospitality marketers seeking to balance GenAI integration with consumer expectations for authenticity and personal resonance.}
}
@article{LIM2023100790,
title = {Generative AI and the future of education: Ragnarök or reformation? A paradoxical perspective from management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {2},
pages = {100790},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100790},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000289},
author = {Weng Marc Lim and Asanka Gunasekara and Jessica Leigh Pallant and Jason Ian Pallant and Ekaterina Pechenkina},
keywords = {Academic integrity, Bard, ChatGPT, Critical analysis, DALL-E, Ethics, Future of education, Generative AI, Generative artificial intelligence, Google, Education, Educator, Management education, Management educator, OpenAI, Paradox, Paradox theory, Ragnarök, Reformation, Transformation, Transformative education},
abstract = {Generative artificial intelligence (AI) has taken the world by storm, with notable tension transpiring in the field of education. Given that Generative AI is rapidly emerging as a transformative innovation, this article endeavors to offer a seminal rejoinder that aims to (i) reconcile the great debate on Generative AI in order to (ii) lay the foundation for Generative AI to co-exist as a transformative resource in the future of education. Using critical analysis as a method and paradox theory as a theoretical lens (i.e., the “how”), this article (i) defines Generative AI and transformative education (i.e., the “ideas”), (ii) establishes the paradoxes of Generative AI (i.e., the “what”), and (iii) provides implications for the future of education from the perspective of management educators (i.e., the “so what”). Noteworthily, the paradoxes of Generative AI are four-fold: (Paradox #1) Generative AI is a ‘friend’ yet a ‘foe’, (Paradox #2) Generative AI is ‘capable’ yet ‘dependent’, (Paradox #3) Generative AI is ‘accessible’ yet ‘restrictive’, and (Paradox #4) Generative AI gets even ‘popular’ when ‘banned’ (i.e., the “what”). Through a position that seeks to embrace rather than reject Generative AI, the lessons and implications that emerge from the discussion herein represent a seminal contribution from management educators on this trending topic and should be useful for approaching Generative AI as a game-changer for education reformation in management and the field of education at large, and by extension, mitigating a situation where Generative AI develops into a Ragnarök that dooms the future of education of which management education is a part of (i.e., the “so what”).}
}
@article{BANDEIRA2025,
title = {Viewpoint on the Intersection Among Health Information, Misinformation, and Generative AI Technologies},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/69474},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000556},
author = {António Bandeira and Luis Henrique Gonçalves and Felix Holl and Juliet Ugbedeojo Shaibu and Mariana Laranjo Gonçalves and Ronan Payinda and Sagun Paudel and Alessandro Berionni and Tina D Purnat and Tim Mackey},
keywords = {generative artificial intelligence, infodemics, public health, Health Information, Misinformation},
abstract = {In recent years, artificial intelligence (AI) has seen rapid advancements, with innovations such as large language models and generative AI evolving at a rapid pace. While this progress offers tremendous opportunities, it also presents risks, particularly in the creation, consumption, and amplification of information and its impact on population health and health program delivery. Thoughtful approaches are necessary to navigate the consequences of advances in AI for different health care professionals and patient populations and from a policy and governance perspective. Through a collaboration between the World Federation of Public Health Associations working groups, this Viewpoint article brings together perspectives, concerns, and aspirations from young adult professionals across 5 continents and from diverse backgrounds to explore the future of public health and AI in the context of the changing health information environment. Our discussion is divided into 2 parts, specifically examining aspects of disinformation and AI, and also the role of public health and medical professionals in a growing AI-driven health information ecosystem. This Viewpoint concludes with 5 key recommendations on how to potentially address issues such as information and disinformation overload; misinformation propagation; and resultant changes in health practices, research, ethics, and the need for robust policies that can dynamically address current and future challenges.}
}
@article{FLANAGAN2025973,
title = {Large language models can accurately populate Vascular Quality Initiative procedural databases using narrative operative reports},
journal = {Journal of Vascular Surgery},
volume = {81},
number = {4},
pages = {973-982},
year = {2025},
issn = {0741-5214},
doi = {https://doi.org/10.1016/j.jvs.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0741521424021980},
author = {Colleen P. Flanagan and Karen Trang and Joyce Nacario and Peter A. Schneider and Warren J. Gasper and Michael S. Conte and Elizabeth C. Wick and Allan M. Conway},
keywords = {Generative artificial intelligence, Large language models, Quality reporting},
abstract = {Objective
Participation in the Vascular Quality Initiative (VQI) provides important resources to surgeons, but the ability to do so is often limited by time and data entry personnel. Large language models (LLMs) such as ChatGPT (OpenAI) are examples of generative artificial intelligence products that may help bridge this gap. Trained on large volumes of data, the models are used for natural language processing and text generation. We evaluated the ability of LLMs to accurately populate VQI procedural databases using operative reports.
Methods
A single-center, retrospective study was performed using institutional VQI data from 2021 to 2023. The most recent procedures for carotid endarterectomy (CEA), endovascular aneurysm repair (EVAR), and infrainguinal lower extremity bypass (LEB) were analyzed using Versa, a HIPAA (Health Insurance Portability and Accountability Act)-compliant institutional version of ChatGPT. We created an automated function to analyze operative reports and generate a shareable VQI file using two models: gpt-35-turbo and gpt-4. Application of the LLMs was accomplished with a cloud-based programming interface. The outputs of this model were compared with VQI data for accuracy. We defined a metric as “unavailable” to the LLM if it was discussed by surgeons in <20% of operative reports.
Results
A total of 150 operative notes were analyzed, including 50 CEA, 50 EVAR, and 50 LEB. These procedural VQI databases included 25, 179, and 51 metrics, respectively. For all fields, gpt-35-turbo had a median accuracy of 84.0% for CEA (interquartile range [IQR]: 80.0%-88.0%), 92.2% for EVAR (IQR: 87.2%-94.0%), and 84.3% for LEB (IQR: 80.2%-88.1%). A total of 3 of 25, 6 of 179, and 7 of 51 VQI variables were unavailable in the operative reports, respectively. Excluding metric information routinely unavailable in operative reports, the median accuracy rate was 95.5% for each CEA procedure (IQR: 90.9%-100.0%), 94.8% for EVAR (IQR: 92.2%-98.5%), and 93.2% for LEB (IQR: 90.2%-96.4%). Across procedures, gpt-4 did not meaningfully improve performance compared with gpt-35 (P = .97, .85, and .95 for CEA, EVAR, and LEB overall performance, respectively). The cost for 150 operative reports analyzed with gpt-35-turbo and gpt-4 was $0.12 and $3.39, respectively.
Conclusions
LLMs can accurately populate VQI procedural databases with both structured and unstructured data, while incurring only minor processing costs. Increased workflow efficiency may improve center ability to successfully participate in the VQI. Further work examining other VQI databases and methods to increase accuracy is needed.}
}
@article{SEO2025105182,
title = {AI-infused video marketing: Exploring the influence of AI-generated tourism videos on tourist decision-making},
journal = {Tourism Management},
volume = {110},
pages = {105182},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105182},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725000524},
author = {Ilsoo Todd Seo and Hongbo Liu and Hengyun Li and Jin-Soo Lee},
keywords = {AI-generated video, Generative AI, AI-generated content, Topic modeling, Thematic analysis},
abstract = {As Generative Artificial Intelligence (AI) becomes increasingly integrated into daily experiences, AI-generated content (AIGC) is gaining prominence in marketing. Despite the significant potential of AI-generated videos to transform the tourism industry, there has been limited exploration of their impact in both practical and academic contexts. This paper addresses this gap by applying topic modeling and thematic analysis to social media comments and survey responses. This study proposes a conceptual framework for AI-generated tourism destination videos, identifying 17 themes. The findings highlight key differences compared to human-generated tourism videos, particularly in terms of authenticity and trustworthiness. This paper also contributes to the literature on tourism videos by presenting a pioneering study of AIGC. Furthermore, this research offers practical insights for tourism marketers seeking to effectively integrate AIGC into their marketing strategies.}
}
@article{YIM2024,
title = {Preliminary Evidence of the Use of Generative AI in Health Care Clinical Services: Systematic Narrative Review},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/52073},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000267},
author = {Dobin Yim and Jiban Khuntia and Vijaya Parameswaran and Arlen Meyers},
keywords = {generative artificial intelligence tools and applications, GenAI, service, clinical, health care, transformation, digital},
abstract = {Background
Generative artificial intelligence tools and applications (GenAI) are being increasingly used in health care. Physicians, specialists, and other providers have started primarily using GenAI as an aid or tool to gather knowledge, provide information, train, or generate suggestive dialogue between physicians and patients or between physicians and patients’ families or friends. However, unless the use of GenAI is oriented to be helpful in clinical service encounters that can improve the accuracy of diagnosis, treatment, and patient outcomes, the expected potential will not be achieved. As adoption continues, it is essential to validate the effectiveness of the infusion of GenAI as an intelligent technology in service encounters to understand the gap in actual clinical service use of GenAI.
Objective
This study synthesizes preliminary evidence on how GenAI assists, guides, and automates clinical service rendering and encounters in health care The review scope was limited to articles published in peer-reviewed medical journals.
Methods
We screened and selected 0.38% (161/42,459) of articles published between January 1, 2020, and May 31, 2023, identified from PubMed. We followed the protocols outlined in the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to select highly relevant studies with at least 1 element on clinical use, evaluation, and validation to provide evidence of GenAI use in clinical services. The articles were classified based on their relevance to clinical service functions or activities using the descriptive and analytical information presented in the articles.
Results
Of 161 articles, 141 (87.6%) reported using GenAI to assist services through knowledge access, collation, and filtering. GenAI was used for disease detection (19/161, 11.8%), diagnosis (14/161, 8.7%), and screening processes (12/161, 7.5%) in the areas of radiology (17/161, 10.6%), cardiology (12/161, 7.5%), gastrointestinal medicine (4/161, 2.5%), and diabetes (6/161, 3.7%). The literature synthesis in this study suggests that GenAI is mainly used for diagnostic processes, improvement of diagnosis accuracy, and screening and diagnostic purposes using knowledge access. Although this solves the problem of knowledge access and may improve diagnostic accuracy, it is oriented toward higher value creation in health care.
Conclusions
GenAI informs rather than assisting or automating clinical service functions in health care. There is potential in clinical service, but it has yet to be actualized for GenAI. More clinical service–level evidence that GenAI is used to streamline some functions or provides more automated help than only information retrieval is needed. To transform health care as purported, more studies related to GenAI applications must automate and guide human-performed services and keep up with the optimism that forward-thinking health care organizations will take advantage of GenAI.}
}
@article{BAZZANO2025,
title = {AI Can Be a Powerful Social Innovation for Public Health if Community Engagement Is at the Core},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/68198},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125000974},
author = {Alessandra N Bazzano and Andrea Mantsios and Nicholas Mattei and Michael R Kosorok and Aron Culotta},
keywords = {Artificial Intelligence, Generative Artificial Intelligence, Citizen Science, Community Participation, Innovation Diffusion},
abstract = {There is a critical need for community engagement in the process of adopting artificial intelligence (AI) technologies in public health. Public health practitioners and researchers have historically innovated in areas like vaccination and sanitation but have been slower in adopting emerging technologies such as generative AI. However, with increasingly complex funding, programming, and research requirements, the field now faces a pivotal moment to enhance its agility and responsiveness to evolving health challenges. Participatory methods and community engagement are key components of many current public health programs and research. The field of public health is well positioned to ensure community engagement is part of AI technologies applied to population health issues. Without such engagement, the adoption of these technologies in public health may exclude significant portions of the population, particularly those with the fewest resources, with the potential to exacerbate health inequities. Risks to privacy and perpetuation of bias are more likely to be avoided if AI technologies in public health are designed with knowledge of community engagement, existing health disparities, and strategies for improving equity. This viewpoint proposes a multifaceted approach to ensure safer and more effective integration of AI in public health with the following call to action: (1) include the basics of AI technology in public health training and professional development; (2) use a community engagement approach to co-design AI technologies in public health; and (3) introduce governance and best practice mechanisms that can guide the use of AI in public health to prevent or mitigate potential harms. These actions will support the application of AI to varied public health domains through a framework for more transparent, responsive, and equitable use of this evolving technology, augmenting the work of public health practitioners and researchers to improve health outcomes while minimizing risks and unintended consequences.}
}
@article{UDDIN2025,
title = {Health Communication on the Internet: Promoting Public Health and Exploring Disparities in the Generative AI Era},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/66032},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003322},
author = {Jamal Uddin and Cheng Feng and Junfang Xu},
keywords = {internet, generative AI, artificial intelligence, ChatGPT, health communication, health promotion, health disparity, health, communication, internet, AI, generative, tool, genAI, gratification theory, gratification, public health, inequity, disparity},
abstract = {Health communication and promotion on the internet have evolved over time, driven by the development of new technologies, including generative artificial intelligence (GenAI). These technological tools offer new opportunities for both the public and professionals. However, these advancements also pose risks of exacerbating health disparities. Limited research has focused on combining these health communication mediums, particularly those enabled by new technologies like GenAI, and their applications for health promotion and health disparities. Therefore, this viewpoint, adopting a conceptual approach, provides an updated overview of health communication mediums and their role in understanding health promotion and disparities in the GenAI era. Additionally, health promotion and health disparities associated with GenAI are briefly discussed through the lens of the Technology Acceptance Model 2, the uses and gratifications theory, and the knowledge gap hypothesis. This viewpoint discusses the limitations and barriers of previous internet-based communication mediums regarding real-time responses, personalized advice, and follow-up inquiries, highlighting the potential of new technology for public health promotion. It also discusses the health disparities caused by the limitations of GenAI, such as individuals’ inability to evaluate information, restricted access to services, and the lack of skill development. Overall, this study lays the groundwork for future research on how GenAI could be leveraged for public health promotion and how its challenges and barriers may exacerbate health inequities. It underscores the need for more empirical studies, as well as the importance of enhancing digital literacy and increasing access to technology for socially disadvantaged populations.}
}
@article{HIROSAWA2024,
title = {Comparative Study to Evaluate the Accuracy of Differential Diagnosis Lists Generated by Gemini Advanced, Gemini, and Bard for a Case Report Series Analysis: Cross-Sectional Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/63010},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001352},
author = {Takanobu Hirosawa and Yukinori Harada and Kazuki Tokumasu and Takahiro Ito and Tomoharu Suzuki and Taro Shimizu},
keywords = {artificial intelligence, clinical decision support, diagnostic excellence, generative artificial intelligence, large language models, natural language processing},
abstract = {Background
Generative artificial intelligence (GAI) systems by Google have recently been updated from Bard to Gemini and Gemini Advanced as of December 2023. Gemini is a basic, free-to-use model after a user’s login, while Gemini Advanced operates on a more advanced model requiring a fee-based subscription. These systems have the potential to enhance medical diagnostics. However, the impact of these updates on comprehensive diagnostic accuracy remains unknown.
Objective
This study aimed to compare the accuracy of the differential diagnosis lists generated by Gemini Advanced, Gemini, and Bard across comprehensive medical fields using case report series.
Methods
We identified a case report series with relevant final diagnoses published in the American Journal Case Reports from January 2022 to March 2023. After excluding nondiagnostic cases and patients aged 10 years and younger, we included the remaining case reports. After refining the case parts as case descriptions, we input the same case descriptions into Gemini Advanced, Gemini, and Bard to generate the top 10 differential diagnosis lists. In total, 2 expert physicians independently evaluated whether the final diagnosis was included in the lists and its ranking. Any discrepancies were resolved by another expert physician. Bonferroni correction was applied to adjust the P values for the number of comparisons among 3 GAI systems, setting the corrected significance level at P value <.02.
Results
In total, 392 case reports were included. The inclusion rates of the final diagnosis within the top 10 differential diagnosis lists were 73% (286/392) for Gemini Advanced, 76.5% (300/392) for Gemini, and 68.6% (269/392) for Bard. The top diagnoses matched the final diagnoses in 31.6% (124/392) for Gemini Advanced, 42.6% (167/392) for Gemini, and 31.4% (123/392) for Bard. Gemini demonstrated higher diagnostic accuracy than Bard both within the top 10 differential diagnosis lists (P=.02) and as the top diagnosis (P=.001). In addition, Gemini Advanced achieved significantly lower accuracy than Gemini in identifying the most probable diagnosis (P=.002).
Conclusions
The results of this study suggest that Gemini outperformed Bard in diagnostic accuracy following the model update. However, Gemini Advanced requires further refinement to optimize its performance for future artificial intelligence–enhanced diagnostics. These findings should be interpreted cautiously and considered primarily for research purposes, as these GAI systems have not been adjusted for medical diagnostics nor approved for clinical use.}
}
@article{GARCIAALARCIA2025348,
title = {Generative AI for the Design of Complex Systems: Roadmap and Space Mission Case Study},
journal = {Procedia Computer Science},
volume = {268},
pages = {348-356},
year = {2025},
note = {Complex Adaptive Systems 2025: Transdisciplinary Systems and Solutions for Adaptability},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.08.213},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925025554},
author = {Ramón María {García Alarcia} and Alessandro Golkar},
keywords = {generative artificial intelligence, complex adaptive systems, space systems, engineering design},
abstract = {This paper sets the foundation for a roadmap aimed at improving the efficiency of designing complex systems by leveraging generative AI. Our focus is on integrating generative AI, specifically LLMs, with semantic system models and computation engines to improve system design capabilities. We introduce a prototype assistant tool for the design of space systems, validate it and demonstrate an improvement in the efficiency of the design process with a comprehensive case study, that includes the design of Earth Observation missions benchmarked to the European Sentinel infrastructure and the EventSat mission we are developing. The tool generates, among others, typical design artifacts such as System Requirements Specifications, Product Breakdown Structures, and Interface Control Documents. We validate it through the cosine similarity of the produced text to the ground truth, a design structure matrix to compare system dependencies and strength and manual evaluation with experts. Validation results align closely with the ground truth. Design time and associated development costs are significantly reduced when using the tool, promising an improvement in efficiency. We contextualize our work in the broader context of developing generative AI for the design of complex systems, by presenting a technology roadmap with our vision of future developments. We discuss the potential of incorporating generative AI into the design of complex systems, the status of technology and the necessary developments. Generative AI integration will enable efficient complexity management, paving the way for innovative advancements in systems engineering.}
}
@article{WANG2026103082,
title = {Governance efficiency and upgrade pathways of international generative AI policies and regulations},
journal = {Technology in Society},
volume = {84},
pages = {103082},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103082},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002726},
author = {Xu Wang and Fang Xie and Binbin Liu},
keywords = {Generative AI, Policies and regulations, Governance efficiency, Upgrade paths, fsQCA, NCA},
abstract = {Analyzing the governance efficiency of policies and regulations on generative artificial intelligence (GAI) not only facilitates the advancement of GAI technological innovation and theoretical research but also enhances the precision and efficiency of information governance across nations. First, based on governance theory, institutional theory, resource-based theory, and administrative ecology theory, this paper analyzes the factors influencing the governance efficiency of GAI policies & regulations from three dimensions: government governance, resource endowment, and technology environment. Second, this paper examines the policies and regulations on GAI from 24 countries as samples. Employing the fsQCA and NCA method, along with PMC index evaluation results, this paper explores potential pathways to enhance the governance efficiency of GAI policies and regulations. Third, the configurational pathway analysis of governance efficiency in GAI policies and regulations identifies six critical influencing factors: policy and regulatory quality, government actions, venture capital investment, AI governance capacities, public stakeholder engagement, and AI safety mechanisms. Finally, through necessity analysis, configurational analysis, and robustness testing of these six factors, the paper reveals that technology-resource driven, policy-actor coordinated, and government-resource mediated implementation configurations can effectively achieve high-level governance efficiency in GAI policies and regulations. Therefore, it provides a reference for optimizing the governance practice of GAI policies and regulations.}
}
@article{OCCHIPINTI2024109645,
title = {Navigating a stable transition to the age of intelligence: A mental wealth perspective},
journal = {iScience},
volume = {27},
number = {5},
pages = {109645},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109645},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224008678},
author = {Jo-An Occhipinti and Ante Prodan and William Hynes and Harris A. Eyre and Alex Schulze and Goran Ujdur and Marcel Tanner},
keywords = {Public health, Artificial intelligence, Social sciences},
abstract = {Summary
In the grand narrative of technological evolution, we are transitioning from the “Age of Information” to the “Age of Intelligence.” Rapid advancements in generative artificial intelligence (AI) are set to reshape society, revolutionize industries, and change the nature of work, challenging our traditional understanding of the dynamics of the economy and its relationship with human productivity and societal prosperity. As we brace for this transformative shift, promising advancements in healthcare, education, productivity, and more, there are concerns of large-scale job loss, mental health repercussions, and risks to social stability and democracy. This paper proposes the concept of Mental Wealth as an action framework that supports nations to proactively position themselves for a smooth transition to the Age of Intelligence while fostering economic and societal prosperity.}
}
@article{YANG2025100599,
title = {Research on the precise design of lung cancer-specific receptors and intelligent optimization strategies for sensing interfaces based on the fusion technology of chemical sensors and generative AI},
journal = {Chinese Journal of Analytical Chemistry},
pages = {100599},
year = {2025},
issn = {1872-2040},
doi = {https://doi.org/10.1016/j.cjac.2025.100599},
url = {https://www.sciencedirect.com/science/article/pii/S1872204025001082},
author = {Yu Yang and Li Dingqi and Song Guilin and Gao Yan and Wang Dong and Xi Chongcheng and Feng Quansheng},
keywords = {chemical sensors, generative AI, lung cancer-specific receptors, intelligent optimization of sensing interfaces},
abstract = {Lung cancer is one of the deadliest malignant tumors globally, and innovative early diagnostic technologies are crucial for improving patient prognosis. This study innovatively integrates chemical sensors with generative artificial intelligence (AI) technologies to construct a research paradigm for the intelligent design of lung cancer-specific receptors and the optimization of sensor interfaces. In terms of technological innovation, on one hand, an electrochemical sensing system based on nano-composite materials and an optical enhancement detection platform are built to achieve ultra-trace detection of lung cancer markers, aiming to break through the sensitivity bottleneck of traditional methods; on the other hand, multi-modal generative models are utilized to deeply mine multi-omics data, designing intelligent receptors with topological adaptability, significantly improving the accuracy and binding efficiency of biomolecule recognition. Clinical validation results show that this technology greatly enhances diagnostic efficacy in early lung cancer screening, and personalized treatment strategies based on AI effectively extend patient survival. In terms of technical translation and application, the developed portable detection devices and wearable monitoring technologies can reduce detection costs, providing a widely applicable screening solution for areas with limited medical resources. The study also reveals core challenges such as the explainability of generative AI and the environmental stability of sensors, proposing forward-looking directions such as quantum-biological interface integration and biomimetic adaptive sensing. This research establishes a new paradigm of "intelligent perception - dynamic optimization - precise intervention" for early lung cancer diagnosis, with significant clinical translational value.}
}
@article{ENCARNACAO2025106872,
title = {Artificial intelligence in wound care education: Scoping review},
journal = {Nurse Education Today},
volume = {155},
pages = {106872},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106872},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725003090},
author = {Rúben Encarnação and José Alves and Ana Marques and João Neves-Amado and Paulo Alves},
keywords = {Artificial intelligence, Education, Health Education, Nursing Education Research, Review, Wounds, Injuries},
abstract = {Background
Artificial intelligence is transforming healthcare education, offering innovative teaching and skill development approaches. However, its implementation and effectiveness in wound care education remain unclear.
Objective
To map and analyze the available evidence on the potential impact of artificial intelligence in wound care education, identify knowledge gaps, and provide recommendations for future research.
Design/methods
This scoping review followed the Joanna Briggs Institute guidelines for scoping reviews and the PRISMA-ScR guidelines. The search was first conducted in December 2023 and updated on 30 November 2024 across the following databases: CINAHL Ultimate, MEDLINE, Cochrane Library, Academic Search Complete, Scientific Electronic Library Online (Scielo), Scopus, and Web of Science. Grey literature was accessed through Scientific Open Access Scientific Repositories of Portugal (RCAAP), ProQuest Dissertations and Theses, OpenAIRE, and Open Dissertations. Additional searches were performed in Google Scholar and specific journals, including the International Wound Journal, Skin Research and Technology, Journal of Wound Care, and Wound Repair and Regeneration. Eligibility criteria encompassed any study design exploring the use of artificial intelligence in wound care education, published in English, Portuguese, or Spanish, with no restrictions on publication date.
Results
This review revealed diverse artificial intelligence applications in wound care education, including adaptive e-learning platforms, virtual and augmented reality simulations, generative artificial intelligence for educational content, and diagnostic and treatment tools. These technologies offer personalized learning experiences, real-time feedback, and interactive engagement to enhance clinical skills. Despite their promise, most studies lacked empirical validation, highlighting significant gaps in integrating artificial intelligence into wound care education.
Conclusions
This review highlights artificial intelligence's transformative potential to revolutionize wound care education by fostering interactive and evidence-based learning environments. This work highlights the need for collaboration among educators, policymakers, and researchers. Future research is needed to ensure effective, ethical, and equitable integration of artificial intelligence in wound care education.}
}