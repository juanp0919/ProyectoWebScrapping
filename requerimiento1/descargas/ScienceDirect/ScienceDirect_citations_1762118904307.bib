@article{SHIRSHAHI20241606,
title = {Identification of propagation path and root cause of faults based on generative adversarial networks in industrial systems},
journal = {Process Safety and Environmental Protection},
volume = {187},
pages = {1606-1617},
year = {2024},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2024.05.143},
url = {https://www.sciencedirect.com/science/article/pii/S0957582024006670},
author = {Amir Shirshahi and Behzad Moshiri and Mahdi Aliyari-Shoorehdeli},
keywords = {Fault propagation, Causality analysis, Machine learning, Latent space, Generative networks},
abstract = {Fault diagnosis and detection (FDD) improves product quality, process safety, and profitability in modern industrial plants. Faults can propagate between different parts of plants due to connections between devices and control loops. As a result, control room operators may receive multiple alarms that distract their attention from addressing the main causes of abnormal situations. Therefore, investigating causal relationships between process variables is essential in determining the root cause of faults. This study proposes a new systematic approach for causality analysis to identify the propagation path and root cause of faults in industrial plants. The research's innovations are categorized into two main parts. Initially, the study utilizes machine learning algorithms to identify causal relationships using probabilistic concepts. Additionally, it introduces a novel architecture by merging the generative adversarial network (GAN) with the variational auto-encoder (VAE). The process variables are mapped to a latent space, where an adversarial generative network will investigate the causal relationship between variables. Finally, the Tennessee Eastman Process simulation and gas turbine industrial data are used to evaluate the proposed algorithm.}
}
@article{PATEL2025104642,
title = {Use of ChatGPT for patient education involving HPV-associated oropharyngeal cancer},
journal = {American Journal of Otolaryngology},
volume = {46},
number = {4},
pages = {104642},
year = {2025},
issn = {0196-0709},
doi = {https://doi.org/10.1016/j.amjoto.2025.104642},
url = {https://www.sciencedirect.com/science/article/pii/S0196070925000456},
author = {Terral A. Patel and Gillian Michaelson and Zoey Morton and Alexandria Harris and Brandon Smith and Richard Bourguillon and Eric Wu and Arturo Eguia and Jessica H. Maxwell},
keywords = {Artificial intelligence, Chatbox, Education, Oropharyngeal cancer, HPV},
abstract = {Objective
This study aims to investigate the ability of ChatGPT to generate reliably accurate responses to patient-based queries specifically regarding oropharyngeal squamous cell carcinoma (OPSCC) of the head and neck.
Study design
Retrospective review of published abstracts.
Setting
Publicly available generative artificial intelligence.
Methods
ChatGPT 3.5 (May 2024) was queried with a set of 30 questions pertaining to HPV-associated oropharyngeal cancer that the average patient may ask. This set of questions was queried a total of four times preceded by a different prompt. The answer prompts for each question set were reviewed and graded on a four-part Likert scale. A Flesch-Kincaid reading level was also calculated for each prompt.
Results
For all answer prompts (n = 120), 6.6 % were graded as mostly inaccurate, 7.5 % were graded as minorly inaccurate, 41.7 % were graded as accurate, and 44.2 % were graded as accurate and helpful. The average Flesch-Kincaid reading grade level was lowest for the responses without any prompt (11.77). Understandably, the highest grade levels were found in the physician-friend prompt (12.97). Of the 30 references, 25 (83.3 %) were found to be authentic published studies. Of the 25 authentic references, the answers accurately cited information found within the original source for 14 of the references (56 %).
Conclusion
ChatGPT was able to produce relatively accurate responses to example patient questions, but there was a high rate of false references. In addition, the reading level of the answer prompts was well above the Centers for Disease Control and Prevention (CDC) recommendations for the average patient.}
}
@article{MING2025109685,
title = {Benchmarking neural radiance fields for autonomous robots: An overview},
journal = {Engineering Applications of Artificial Intelligence},
volume = {140},
pages = {109685},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109685},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624018438},
author = {Yuhang Ming and Xingrui Yang and Weihan Wang and Zheng Chen and Jinglun Feng and Yifan Xing and Guofeng Zhang},
keywords = {Neural radiance fields, Autonomous robots, Robotic perception, Localization, Navigation, Decision-making},
abstract = {Neural Radiance Field (NeRF) has emerged as a powerful paradigm for scene representation, offering high-fidelity renderings and reconstructions from a set of sparse and unstructured sensor data. In the context of autonomous robotics, where perception and understanding of the environment are pivotal, NeRF holds immense promise for improving performance. However, few survey has discussed such a potential. To fill this gap, we have collected over 200 papers since the publication of original NeRF in 2020 and present a thorough analysis of how NeRF can be used to enhance the capabilities of autonomous robots. We especially focus on the perception, localization and navigation, and decision-making modules of autonomous robots and delve into tasks crucial for autonomous operation, including 3-dimensional reconstruction, segmentation, pose estimation, simultaneous localization and mapping, navigation and planning, and interaction. Our survey meticulously benchmarks existing NeRF-based methods, comparing their reported performance, and providing insights into their strengths and limitations. Moreover, we target the existing challenges of applying NeRF in autonomous robots, including real-time processing, sparse input views, and explore promising avenues for future research and development in this domain. We especially discuss potential of integrating advanced deep learning techniques like 3-dimensional Gaussian splatting, large language models, and generative artificial intelligence. This survey serves as a roadmap for researchers seeking to leverage NeRF to empower autonomous robots, paving the way for innovative solutions that can navigate and interact seamlessly in complex environments.}
}
@article{AGUINIS2024101029,
title = {How to use generative AI as a human resource management assistant},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101029},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101029},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000020},
author = {Herman Aguinis and Jose R. Beltran and Amando Cope},
keywords = {Artificial intelligence, Human resource management, Leadership, The future of work, Technology, Talent management},
abstract = {Human resource management (HRM) professionals are often overworked, and their jobs are increasingly complex. Therefore, many suffer from job burnout, and only some can allocate the necessary time to strategic issues. We show how generative artificial intelligence (AI), particularly ChatGPT, can be a helpful HRM assistant for both strategic and operational tasks. But, for this to happen, we demonstrate the need to create valuable prompts that result in specific, helpful, and actionable HRM recommendations. Accordingly, we provide eight guidelines for creating high-quality and effective prompts and illustrate their usefulness in general across eight critical HRM domains and in more depth in the particular areas of workforce diversity and strategic HRM. We also provide recommendations and demonstrate how to implement a critical verification process to check on ChatGPT’s suggestions. We conclude with a list of “dos and don’ts” and that when used by sufficiently trained HRM professionals, it is a very useful tool because it helps complete tasks faster, hopefully reducing their job burnout and allowing them to allocate more time to strategic and long-term issues. In turn, these benefits will likely result in helping achieve the as-of-yet-unrealized aspiration of “having a seat at the table.”}
}
@article{PANAGIOTOU2025106287,
title = {Generative AI-augmented offshore jacket design: Integrated approach for mixed tabular data generation under scarcity and imbalance},
journal = {Automation in Construction},
volume = {177},
pages = {106287},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106287},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003279},
author = {Emmanouil Panagiotou and Han Qian and Steffen Marx and Eirini Ntoutsi},
keywords = {Artificial intelligence, Generative AI, Machine learning, Multi-objective optimization, Mixed tabular data, Data scarcity, Data imbalance, Offshore wind turbines, Industrial design, Offshore jacket substructure},
abstract = {Generative Artificial Intelligence (AI) has found various applications in domains like computer vision and natural language processing. However, limited research exists in the engineering domain, where prevailing challenges involve mixed tabular data, data scarcity, and imbalances. This paper focuses on generating synthetic offshore jacket designs to improve the data quality of a scarce and imbalanced existing dataset. Data quality is quantified by evaluating the machine-learning efficiency of the synthetic data on a domain-specific downstream task. An integrated method is proposed for generating jacket designs, combining modern data-driven techniques with traditional multi-objective-driven approaches. The method addresses challenges related to mixed attributes, data scarcity, and class imbalances. Experimental results demonstrate improved predictive performance on the downstream task when models are trained on synthetic data compared to using only real data. These findings contribute to the advancement of generative AI in offshore engineering and related fields, offering valuable insights and potential applications.}
}
@article{JURGENSMEIER2024468,
title = {Generative AI for scalable feedback to multimodal exercises},
journal = {International Journal of Research in Marketing},
volume = {41},
number = {3},
pages = {468-488},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167811624000430},
author = {Lukas Jürgensmeier and Bernd Skiera},
keywords = {Generative AI, Automated Feedback, Marketing Analytics, Learning, Education},
abstract = {Detailed feedback on exercises helps learners become proficient but is time-consuming for educators and, thus, hardly scalable. This manuscript evaluates how well Generative Artificial Intelligence (AI) provides automated feedback on complex multimodal exercises requiring coding, statistics, and economic reasoning. Besides providing this technology through an easily accessible web application, this article evaluates the technology’s performance by comparing the quantitative feedback (i.e., points achieved) from Generative AI models with human expert feedback for 4,349 solutions to marketing analytics exercises. The results show that automated feedback produced by Generative AI (GPT-4) provides almost unbiased evaluations while correlating highly with (r = 0.94) and deviating only 6 % from human evaluations. GPT-4 performs best among seven Generative AI models, albeit at the highest cost. Comparing the models’ performance with costs shows that GPT-4, Mistral Large, Claude 3 Opus, and Gemini 1.0 Pro dominate three other Generative AI models (Claude 3 Sonnet, GPT-3.5, and Gemini 1.5 Pro). Expert assessment of the qualitative feedback (i.e., the AI’s textual response) indicates that it is mostly correct, sufficient, and appropriate for learners. A survey of marketing analytics learners shows that they highly recommend the app and its Generative AI feedback. An advantage of the app is its subject-agnosticism—it does not require any subject- or exercise-specific training. Thus, it is immediately usable for new exercises in marketing analytics and other subjects.}
}
@article{KIM2025111109,
title = {Non-contrast CT-based pulmonary embolism detection using GAN-generated synthetic contrast enhancement: Development and validation of an AI framework},
journal = {Computers in Biology and Medicine},
volume = {198},
pages = {111109},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.111109},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525014623},
author = {Young-Tak Kim and So Hyeon Bak and Seon-Sook Han and Yunsik Son and Jinkyeong Park},
keywords = {Generative artificial intelligence, Non-contrast CT imaging, Pulmonary embolism, Synthetic contrast-enhanced imaging},
abstract = {Acute pulmonary embolism (PE) is a life-threatening condition often diagnosed using CT pulmonary angiography (CTPA). However, CTPA is contraindicated in patients with contrast allergies or at risk for contrast-induced nephropathy. This study explores an AI-driven approach to generate synthetic contrast-enhanced images from non-contrast CT scans for accurate diagnosis of acute PE without contrast agents. This retrospective study used dual-energy and standard CT datasets from two institutions. The internal dataset included 84 patients: 41 PE-negative cases for generative model training and 43 patients (30 PE-positive) for diagnostic evaluation. An external dataset of 62 patients (26 PE-positive) was used for further validation. We developed a generative adversarial network (GAN) based on U-Net, trained on paired non-contrast and contrast-enhanced images. The model was optimized using contrast-enhanced L1-loss with hyperparameter λ to improve anatomical accuracy. A ConvNeXt-based classifier trained on the RSNA dataset (N = 7,122) generated per-slice PE probabilities, which were aggregated for patient-level prediction via a Random Forest model. Diagnostic performance was assessed using five-fold cross-validation on both internal and external datasets. The GAN achieved optimal image similarity at λ = 0.5, with the lowest mean absolute error (0.0089) and highest MS-SSIM (0.9674). PE classification yielded AUCs of 0.861 and 0.836 in the internal dataset, and 0.787 and 0.680 in the external dataset, using real and synthetic images, respectively. No statistically significant differences were observed. Our findings demonstrate that synthetic contrast CT can serve as a viable alternative for PE diagnosis in patients contraindicated for CTPA, supporting safe and accessible imaging strategies.}
}
@article{NEMS2025e01348,
title = {A review of artificial intelligence to thermal energy storage and heat transfer improvement in phase change materials},
journal = {Sustainable Materials and Technologies},
volume = {44},
pages = {e01348},
year = {2025},
issn = {2214-9937},
doi = {https://doi.org/10.1016/j.susmat.2025.e01348},
url = {https://www.sciencedirect.com/science/article/pii/S2214993725001162},
author = {Artur Nemś and Sindu Daniarta and Magdalena Nemś and Piotr Kolasiński and Svetlana Ushak},
keywords = {New material discovery, Machine learning, Figure of merit, Convolutional neural networks, Generative artificial intelligence},
abstract = {This paper examines the applications of artificial intelligence (AI) in predicting and optimizing phase change material (PCM) parameters for heat storage and transport systems. The study reviews research on material parameters, focusing on the role of machine learning (ML) in shaping the characteristics of modified PCMs. It summarizes the input and output parameters, as well as the figures of merit criteria, employed in various PCM-related studies. The paper explores AI's role in enhancing heat transfer and storage in PCMs, highlighting models used to predict the amount of heat stored in PCM-based storage tanks. Also, the application of genetic algorithms (GAs) to optimize the operating parameters of these storage systems is discussed. AI techniques for improving heat transfer processes in PCMs are also reviewed. The prediction quality of different ML methods is analyzed. Other deviations used to evaluate the accuracy of these methods are presented. A third area of focus is the application of AI in systems and energy systems utilizing PCMs. These applications include temperature stabilization in solar systems, maintaining thermal comfort in buildings, ensuring consistent vaccine storage temperatures, and other uses. The study outlines the types of PCMs used in various thermal systems, the AI methods applied, and the criteria for prediction and optimization. Finally, the paper identifies knowledge gaps and research areas requiring further investigation to better understand the potential of ML and GA in optimizing PCM parameters and thermal systems containing PCMs.}
}
@article{LIANG2025101366,
title = {The widespread adoption of large language model-assisted writing across society},
journal = {Patterns},
pages = {101366},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101366},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925002144},
author = {Weixin Liang and Yaohui Zhang and Mihai Codreanu and Jiayu Wang and Hancheng Cao and James Zou},
keywords = {large language model, writing},
abstract = {Summary
This paper systematically analyzes the adoption of large language models (LLMs), such as ChatGPT, across consumer complaints, corporate press releases, job postings, and United Nations (UN) press releases, covering extensive datasets from January 2022 to September 2024. By late 2024, roughly 18% of financial consumer complaints, 24% of corporate press releases, nearly 10% of job postings in small firms, and 14% of UN press releases involve LLM-assisted writing. Adoption surged rapidly post-ChatGPT release but stabilized by 2024, highlighting generative artificial intelligence (AI)’s broad societal impact and its widespread use across sectors.}
}
@article{MARABELLI2025101921,
title = {Artificial intelligence and the environment: ethical challenges and strategic opportunities for organizations},
journal = {The Journal of Strategic Information Systems},
volume = {34},
number = {3},
pages = {101921},
year = {2025},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2025.101921},
url = {https://www.sciencedirect.com/science/article/pii/S0963868725000368},
author = {Marco Marabelli and Robert M. Davison},
keywords = {Artificial intelligence, GAI and AI strategizing, Global warming, Climate changes, Ethics, Global South, Social justice},
abstract = {In this viewpoint article, our goal is to raise awareness and spark debate in the Information Systems (IS) community regarding a prominent concern that has important strategic and ethical implications: the environmental impact of the increasing use of generative artificial intelligence (GAI). We examine several specific issues, beginning with GAI’s heavy consumption of natural resources and electricity. We then move to assessing how the rich and the Global North gain via GAI, while the poor and the Global South must deal with its adverse effects. We then move to assessing GAI’s impact on underrepresented communities and countries in the Global South; while GAI contributes to global warming, this affects people unevenly, because it is mostly rich people and the Global North that make intensive use of these technologies. After suggesting that more local and global laws are needed to regulate the sustainable use of AI, we report on how organizations can perform AI strategizing, for instance to control emissions in smart cities and improve weather forecasting. We conclude with a research agenda that aims to encourage IS scholars to focus on the environmental impact of AI, its ethical implications for organizations, and how GAI can be used strategically to benefit all.}
}
@article{SARRAF2024114132,
title = {How do system and user characteristics, along with anthropomorphism, impact cognitive absorption of chatbots – Introducing SUCCAST through a mixed methods study},
journal = {Decision Support Systems},
volume = {178},
pages = {114132},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2023.114132},
url = {https://www.sciencedirect.com/science/article/pii/S0167923623002075},
author = {Shagun Sarraf and Arpan Kumar Kar and Marijn Janssen},
keywords = {Cognitive absorption, Chatbots, Generative artificial intelligence, Anthropomorphism, Qualitative comparative analysis, Artificial intelligence},
abstract = {Chatbots are radically redefining the customer service landscape. With the advent of AI-enabled chatbots, like ChatGPT, organizations are adopting chatbots to provide better customer services; however, the user experience has been given less attention. Building on IS success model and cognitive absorption theory, we posit that system and user characteristics enhance cognitive absorption amongst users, such that the relationship varies between anthropomorphic (e.g., human-like) and non-anthropomorphic chatbots. We undertook a cross-sectional comparative study, which was analyzed using PLS-SEM and fsQCA. Where PLS-SEM provided limited inferential insights about the differences between anthropomorphic and non-anthropomorphic chatbots, the FsQCA analysis resulted in three configurations of attributes for non-anthropomorphic and two configurations for anthropomorphic chatbots, which lead to higher cognitive absorption. The findings extend the existing literature, suggesting that anthropomorphic and non-anthropomorphic chatbots impact cognitive absorption through separate system and user characteristics configurations.}
}
@article{ALMATRAFI2025100404,
title = {Leveraging generative AI for course learning outcome categorization using Bloom's taxonomy},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100404},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100404},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2500044X},
author = {Omaima Almatrafi and Aditya Johri},
keywords = {Large language models (LLMs), Generative artificial intelligence, Learning outcomes, Cognitive level, Bloom's taxonomy, Classification},
abstract = {Learning outcomes are clear and concise statements that describe what students should be able to do or know at the end of a particular course. These statements are crucial in instructional planning, curriculum development, and assessment of student progress and learning. Although there is no universal guidance on how to develop learning outcomes, Bloom's taxonomy is one widely used framework that helps instructors develop outcomes that reflect different levels of thinking, from basic remembering to creative problem-solving. This study investigates the potential of generative AI, specifically GPT-4, in classifying course learning outcomes according to their respective cognitive levels within the revised Bloom's taxonomy. To assess the effectiveness of GenAI, we conducted a comparative study using a dataset of 1000 annotated learning outcomes. We tested multiple prompt engineering strategies, including zero-shot, few-shot, chain-of-thought, rhetorical situation, and multiple binary questions, leveraging GPT-4. Classification performance was evaluated using accuracy, Cohen's κ, and F1-score. The results indicate that the prompt incorporating rhetorical context and domain-specific knowledge achieved the highest classification performance, while the multiple binary question approach underperformed even compared to the zero-shot method. Furthermore, we compared the best-performing prompting strategy with a state-of-the-art classification model, BERT. Although the fine-tuned BERT model showed superior performance, prompt-based classification exhibited moderate to substantial agreement with expert annotations. Overall, this article demonstrates the potential of leveraging large language models to advance both theoretical understanding and practical application within the field of education and natural language processing.}
}
@article{HAYAWI2024101533,
title = {Generative AI and large language models: A new frontier in reverse vaccinology},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101533},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101533},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000893},
author = {Kadhim Hayawi and Sakib Shahriar and Hany Alashwal and Mohamed Adel Serhani},
keywords = {Reverse vaccinology, Large language models (LLMs), AI, Generative AI, Vaccine candidate identification, AI ethics, Vaccines},
abstract = {Reverse vaccinology is an emerging concept in the field of vaccine development as it facilitates the identification of potential vaccine candidates. Biomedical research has been revolutionized with the recent innovations in Generative Artificial Intelligence (AI) and Large Language Models (LLMs). The intersection of these two technologies is explored in this study. In this study, the impact of Generative AI and LLMs in the field of vaccinology is explored. Through a comprehensive analysis of existing research, prospective use cases, and an experimental case study, this research highlights that LLMs and Generative AI have the potential to enhance the efficiency and accuracy of vaccine candidate identification. This work also discusses the ethical and privacy challenges, such as data consent and potential biases, raised by such applications that require careful consideration. This study paves the way for experts, researchers, and policymakers to further investigate the role and impact of Generative AI and LLM in vaccinology and medicine.}
}
@article{REWTHAMRONGSRIS2025100848,
title = {Image-Based Diagnostic Performance of LLMs vs CNNs for Oral Lichen Planus: Example-Guided and Differential Diagnosis},
journal = {International Dental Journal},
volume = {75},
number = {4},
pages = {100848},
year = {2025},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2025.100848},
url = {https://www.sciencedirect.com/science/article/pii/S0020653925001376},
author = {Paak Rewthamrongsris and Jirayu Burapacheep and Ekarat Phattarataratip and Promphakkon Kulthanaamondhita and Antonin Tichy and Falk Schwendicke and Thanaphum Osathanon and Kraisorn Sappayatosok},
keywords = {Chatbot, Computer-assisted diagnosis, Differential diagnosis, Generative artificial intelligence, Large language model, Oral lichen planus},
abstract = {Introduction and aims
The overlapping characteristics of oral lichen planus (OLP), a chronic oral mucosal inflammatory condition, with those of other oral lesions, present diagnostic challenges. Large language models (LLMs) with integrated computer-vision capabilities and convolutional neural networks (CNNs) constitute an alternative diagnostic modality. We evaluated the ability of seven LLMs, including both proprietary and open-source models, to detect OLP from intraoral images and generate differential diagnoses.
Methods
Using a dataset with 1,142 clinical photographs of histopathologically confirmed OLP, non-OLP lesions, and normal mucosa. The LLMs were tested using three experimental designs: zero-shot recognition, example-guided recognition, and differential diagnosis. Performance was measured using accuracy, precision, recall, F1-score, and discounted cumulative gain (DCG). Furthermore, the performance of LLMs was compared with three previously published CNN-based models for OLP detection on a subset of 110 photographs, which were previously used to test the CNN models.
Results
Gemini 1.5 Pro and Flash demonstrated the highest accuracy (69.69%) in zero-shot recognition, whereas GPT-4o ranked first in the F1 score (76.10%). With example-guided prompts, which improved consistency and reduced refusal rates, Gemini 1.5 Flash achieved the highest accuracy (80.53%) and F1-score (84.54%); however, Claude 3.5 Sonnet achieved the highest DCG score of 0.63. Although the proprietary models generally excelled, the open-source Llama model demonstrated notable strengths in ranking relevant diagnoses despite moderate performance in detection tasks. All LLMs were outperformed by the CNN models.
Conclusion
The seven evaluated LLMs lack sufficient performance for clinical use. CNNs trained to detect OLP outperformed the LLMs tested in this study.}
}
@article{MENG2025933,
title = {“Talk to me, I’m secure”: investigating information disclosure to AI chatbots in the context of privacy calculus},
journal = {Online Information Review},
volume = {49},
number = {5},
pages = {933-954},
year = {2025},
issn = {1468-4527},
doi = {https://doi.org/10.1108/OIR-06-2024-0375},
url = {https://www.sciencedirect.com/science/article/pii/S1468452725000150},
author = {Xiaoxiao Meng and Jiaxin Liu},
keywords = {Privacy calculus, Human–computer interaction, Parasocial interaction, Privacy disclosure, AI chatbots},
abstract = {Purpose
This study aims to explain the privacy paradox, wherein individuals, despite privacy concerns, are willing to share personal information while using AI chatbots. Departing from previous research that primarily viewed AI chatbots from a non-anthropomorphic approach, this paper contends that AI chatbots are taking on an emotional component for humans. This study thus explores this topic by considering both rational and non-rational perspectives, thereby providing a more comprehensive understanding of user behavior in digital environments.
Design/methodology/approach
Employing a questionnaire survey (N = 480), this research focuses on young users who regularly engage with AI chatbots. Drawing upon the parasocial interaction theory and privacy calculus theory, the study elucidates the mechanisms governing users’ willingness to disclose information.
Findings
Findings show that cognitive, emotional and behavioral dimensions all positively influence perceived benefits of using ChatGPT, which in turn enhances privacy disclosure. While cognitive, emotional and behavioral dimensions negatively impact perceived risks, only the emotional and behavioral dimensions significantly affect perceived risk, which in turn negatively influences privacy disclosure. Notably, the cognitive dimension’s lack of significant mediating effect suggests that users’ awareness of privacy risks does not deter disclosure. Instead, emotional factors drive privacy decisions, with users more likely to disclose personal information based on positive experiences and engagement with ChatGPT. This confirms the existence of the privacy paradox.
Research limitations/implications
This study acknowledges several limitations. While the sample was adequately stratified, the focus was primarily on young users in China. Future research should explore broader demographic groups, including elderly users, to understand how different age groups engage with AI chatbots. Additionally, although the study was conducted within the Chinese context, the findings have broader applicability, highlighting the potential for cross-cultural comparisons. Differences in user attitudes toward AI chatbots may arise due to cultural variations, with East Asian cultures typically exhibiting a more positive attitude toward social AI systems compared to Western cultures. This cultural distinction—rooted in Eastern philosophies such as animism in Shintoism and Buddhism—suggests that East Asians are more likely to anthropomorphize technology, unlike their Western counterparts (Yam et al., 2023; Folk et al., 2023).
Practical implications
The findings of this study offer valuable insights for developers, policymakers and educators navigating the rapidly evolving landscape of intelligent technologies. First, regarding technology design, the study suggests that AI chatbot developers should not focus solely on functional aspects but also consider emotional and social dimensions in user interactions. By enhancing emotional connection and ensuring transparent privacy communication, developers can significantly improve user experiences (Meng and Dai, 2021). Second, there is a pressing need for comprehensive user education programs. As users tend to prioritize perceived benefits over risks, it is essential to raise awareness about privacy risks while also emphasizing the positive outcomes of responsible information sharing. This can help foster a more informed and balanced approach to user engagement (Vimalkumar et al., 2021). Third, cultural and ethical considerations must be incorporated into AI chatbot design. In collectivist societies like China, users may prioritize emotional satisfaction and societal harmony over privacy concerns (Trepte, 2017; Johnston, 2009). Developers and policymakers should account for these cultural factors when designing AI systems. Furthermore, AI systems should communicate privacy policies clearly to users, addressing potential vulnerabilities and ensuring that users are aware of the extent to which their data may be exposed (Wu et al., 2024). Lastly, as AI chatbots become deeply integrated into daily life, there is a growing need for societal discussions on privacy norms and trust in AI systems. This research prompts a reflection on the evolving relationship between technology and personal privacy, especially in societies where trust is shaped by cultural and emotional factors. Developing frameworks to ensure responsible AI practices while fostering user trust is crucial for the long-term societal integration of AI technologies (Nah et al., 2023).
Originality/value
The study’s findings not only draw deeper theoretical insights into the role of emotions in generative artificial intelligence (gAI) chatbot engagement, enriching the emotional research orientation and framework concerning chatbots, but they also contribute to the literature on human–computer interaction and technology acceptance within the framework of the privacy calculus theory, providing practical insights for developers, policymakers and educators navigating the evolving landscape of intelligent technologies.}
}
@article{BADINI2025100275,
title = {Enhancing mechanical and bioinspired materials through generative AI approaches},
journal = {Next Materials},
volume = {6},
pages = {100275},
year = {2025},
issn = {2949-8228},
doi = {https://doi.org/10.1016/j.nxmate.2024.100275},
url = {https://www.sciencedirect.com/science/article/pii/S2949822824001722},
author = {Silvia Badini and Stefano Regondi and Raffaele Pugliese},
keywords = {Mechanical materials, Bioinspired materials, Additive manufacturing, Generative AI, Human-machine interaction},
abstract = {The integration of generative artificial intelligence (AI) into the design and additive manufacturing processes of mechanical and bioinspired materials has emerged as a transformative approach in engineering and material science, allowing to explore relationships across different field (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-3D printing). In addition, generative AI techniques, including generative adversarial networks (GAN), genetic algorithms, and large language models (LLMs), offer efficient and tunable solutions for optimizing material properties, reducing production costs, and accelerating the development timelines. In the field of mechanical materials design, generative AI enables the rapid generation of novel structures with enhanced mechanical performance. Instead, bioinspired materials design benefits significantly from the synergy of generative AI with bioinspired concepts and additive manufacturing. By harnessing generative algorithms and topology optimization, researchers can explore complex biological phenomena and translate them into innovative engineering solutions. Lastly, the emergence of LLMs in additive manufacturing optimization demonstrates their potential to optimize printing parameters, debug errors, and enhance productivity. This review highlights the pivotal role of generative AI in advancing materials science and engineering, unlocking new possibilities for innovation, and accelerating the development of efficient material solutions. As generative AI continues to evolve, its integration promises to revolutionize engineering design and drive the field towards unprecedented levels of efficiency, thus turns information into knowledge.}
}
@article{PHAM2025117932,
title = {Segmental retaining wall displacement monitoring using RGB-D image and generative AI approach},
journal = {Measurement},
volume = {254},
pages = {117932},
year = {2025},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2025.117932},
url = {https://www.sciencedirect.com/science/article/pii/S0263224125012916},
author = {Minh-Vuong Pham and Yong-Soo Ha and Thanh-Nhan Nguyen and Yun-Tae Kim},
keywords = {Displacement monitoring, Retaining wall, RGB-D image, Depth estimation model, Generative AI},
abstract = {Using a red green blue (RGB) image obtained from a monocular camera allows measurement of in-plane displacements of segmental retaining walls (SRWs). However, it cannot measure out-of-plane displacements, which are movements perpendicular to the image plane. To address the limitation, this study presents a novel approach for SRW displacement monitoring by using RGB-depth (RGB-D) image. The proposed method used RGB images captured from a single camera and CNN-based depth estimation models to generate a depth map. The depth map was then used for point cloud reconstruction and displacement calculation. Additionally, a generative artificial intelligence (AI)-based enhancement module was implemented to enhance low-quality images captured in low-light or overexposed environments, leading to improved monitoring. The proposed approach was validated through laboratory experiments. The depth estimation models demonstrated high performance, achieving accuracies ranging from 0.896 to 0.957. The generative AI model effectively improved the accuracy of depth map prediction in low-light conditions. The calculated 3D displacement results derived from RGB-D images, with the depth component estimated by the MobileNet depth estimation model, demonstrated the highest accuracy, with errors ranging from 0.0 to 2.6 mm. The proposed method is a reliable, adaptable, and efficient solution for monitoring structural displacement, offering significant potential for real-world applications.}
}
@article{GAO2026112865,
title = {A cosmetic packaging design method based on online reviews},
journal = {Engineering Applications of Artificial Intelligence},
volume = {163},
pages = {112865},
year = {2026},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112865},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625028969},
author = {Zhan Gao and Zhenyu Li},
keywords = {Online reviews, Cosmetic packaging design, Latent dirichlet allocation topic model, Analytic hierarchy process, Technique for order preference by similarity to an ideal solution, Midjourney},
abstract = {To address the transformation of user experience and packaging iteration in cosmetics due to the diversification of usage scenarios and demands, this study capitalizes on the advancements in artificial intelligence across user analysis, data analysis, and generative design domains, and proposes a cosmetic packaging design approach centered around online reviews. In this study, 124,879 pieces of user review data were collected from JingDong (JD), a Chinese e-commerce platform, using Python programming technology. Five topics are clustered through the application of the Latent Dirichlet Allocation (LDA) topic model. By integrating the coding of Grounded Theory, 18 demand elements within six core categories are summarized. The Kano model and the Analytic Hierarchy Process (AHP) are employed to classify and rank these demands. Notably, aspects such as strong brand recognition (M1, 0.2182), strong brand value perception (M5, 0.1129), and visually appealing and refined aesthetics (A5, 0.0983) exhibit relatively high weights. Subsequently, six lipstick packaging design schemes are developed by combining traditional software with the MidJourney generative artificial intelligence tool. Through comprehensive evaluation using the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method, the optimal Scheme c is identified and further optimized. This study constructs a comprehensive design strategy with user online reviews at its core, encompassing data collection, analysis, scheme design, artificial intelligence (AI)-assisted design, and evaluation. It is recommended that the application of artificial intelligence (AI)-assisted design be significantly enhanced throughout the entire design process, enabling precise and rapid generation of design schemes, streamlining the process, and shortening the development cycle.}
}
@article{URIBE2024105275,
title = {Estimating the use of ChatGPT in dental research publications},
journal = {Journal of Dentistry},
volume = {149},
pages = {105275},
year = {2024},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2024.105275},
url = {https://www.sciencedirect.com/science/article/pii/S0300571224004445},
author = {Sergio E. Uribe and Ilze Maldupa},
keywords = {Large-language model, Artificial intelligence, Scientific communication, ChatGPT, Dental research},
abstract = {Introduction
Generative artificial intelligence (GenAI) Large-language models such as ChatGPT have become increasingly popular in various fields. However, the impact of ChatGPT on dental research writing has yet to be quantified. This study aimed to assess ChatGPT's usage in dental research writing and discuss potential advantages and challenges.
Methods
Using a bibliometric design, we performed a keyword analysis of specific 'signaling words' indicative of ChatGPT use in the titles/abstracts of 299,695 dental research abstracts indexed PubMed 2018–2024. Statistical comparisons using normalized ratios per 10,000 dental publications compared changes in word frequency before and after the ChatGPT release on November 30, 2022.
Results
Before ChatGPT's release, the frequency of abstracts with signaling words was 47.1 per 10,000 papers. After the release, this increased to 224.2 per 10,000 papers, an increase of 177.2 per 10,000 papers (p = 0.014, 95 % CI 53.5–300.7). The word 'delve' showed the most significant usage increase (increased ratio=17.0).
Conclusions
This study is among the first to systematically assess the use of GenAI, specifically ChatGPT, in dental research. We found evidence of the use and growth of ChatGPT in dental research publications. This trend indicates the widespread adoption of GenAI-assisted writing in scientific communication, consistent with other scientific fields. While GenAI can potentially increase productivity and inclusivity, it raises concerns such as bias, inaccuracy, and distortion of academic incentives. Therefore, our findings support the need for clear AI guidelines and standards for academic publishing to ensure responsible use and maintain scientific integrity.}
}
@incollection{GAUR2026243,
title = {Chapter 14 - Role of governability and generative AI for healthcare},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {243-260},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00004-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000047},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Ethical guidelines, Generative AI, Governability, Healthcare, Regulatory frameworks, Societal values, Stakeholder involvement},
abstract = {This chapter examines the critical role of governability in the context of generative artificial intelligence (AI), particularly within healthcare systems. Governability refers to the ability to regulate, manage, and ensure the ethical operation of AI technologies, which is increasingly essential as these technologies become integrated into healthcare practices. The introduction highlights the need for effective governance frameworks that align AI systems with societal values, ensuring they operate ethically and responsibly. The chapter provides an overview of existing regulations governing AI in healthcare, including global standards and country-specific guidelines. It discusses the unique challenges posed by generative AI technologies, such as accountability, transparency, and compliance, and presents case studies that illustrate various regulatory approaches, their successes, and areas needing improvement. Ensuring the ethical operation of AI systems is paramount. The chapter discusses ethical guidelines that govern AI in healthcare, emphasizing principles like fairness, transparency, and patient safety. It also explores how to balance the push for innovation with adherence to ethical standards, using case studies to illustrate ethical challenges faced in AI-driven healthcare and the governance strategies employed to address them. Effective governance strategies are critical for the successful management of AI in healthcare. Different governance models are explored, highlighting the importance of stakeholder involvement, including healthcare professionals, patients, and policymakers. The chapter examines ongoing monitoring and auditing strategies to ensure AI systems operate in alignment with ethical and regulatory standards. Moreover, aligning AI systems with societal values—such as equity, access, and patient autonomy—is discussed. Strategies for embedding these values into AI design and operation are explored, along with case studies showcasing successful alignment with societal goals. Looking to the future, the chapter discusses the potential evolution of governance standards for AI in healthcare and the role of emerging technologies, such as blockchain and AI, in enhancing governability and transparency. It concludes with recommendations for building a sustainable governance framework for generative AI in healthcare, addressing both challenges and opportunities.}
}
@article{ZHOU2025102508,
title = {Modern energy resilience studies with artificial intelligence for energy transitions},
journal = {Cell Reports Physical Science},
volume = {6},
number = {4},
pages = {102508},
year = {2025},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2025.102508},
url = {https://www.sciencedirect.com/science/article/pii/S2666386425001079},
author = {Yuekuan Zhou and Zhaohui Dan},
keywords = {climate change, energy resilience, carbon neutrality, sustainability development goals, machine learning, generative artificial intelligence, AI},
abstract = {Summary
Climate change and multifaceted energy crises necessitate resilient power systems for sustainable and smart energy transitions. However, correlations among energy efficiency, energy reliability, robustness, flexibility, and energy resilience remain unclear. This review employs bibliometric analysis to evaluate AI-driven solutions, particularly generative AI, in enhancing urban energy resilience. We quantify energy resilience metrics, as well as highlight the synergy among energy efficiency, energy reliability, robustness, flexibility, energy resilience with carbon neutrality, and multi-sector strategies across supply, demand, storage, and grid systems. The analysis demonstrates the capacity of AI to improve climate change adaptation during extreme events, illustrated as bio-inspired frameworks that emulate human self-regulation and self-healing. The integration of end-user participation and techno-economic-social benefits are emphasized. Big data technology facilitates information communications and inter-component interactions, while generative AI enables automatic city-scale information modeling and real-time decision-making. To conclude, we highlight challenges in smart energy transitions and suggest pathways to harmonize resilience with energy efficiency and reliability under climate challenges.}
}
@article{LOMURNO202552,
title = {Synthetic image learning: Preserving performance and preventing Membership Inference Attacks},
journal = {Pattern Recognition Letters},
volume = {190},
pages = {52-58},
year = {2025},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2025.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167865525000388},
author = {Eugenio Lomurno and Matteo Matteucci},
keywords = {Generative deep learning, Dataset generation, Classification Accuracy Score, Privacy, Membership Inference Attack, Generative Knowledge Distillation, Knowledge Recycling},
abstract = {Generative artificial intelligence has transformed the generation of synthetic data, providing innovative solutions to challenges like data scarcity and privacy, which are particularly critical in fields such as medicine. However, the effective use of this synthetic data to train high-performance models remains a significant challenge. This paper addresses this issue by introducing Knowledge Recycling (KR), a pipeline designed to optimise the generation and use of synthetic data for training downstream classifiers. At the heart of this pipeline is Generative Knowledge Distillation, the proposed technique that significantly improves the quality and usefulness of the information provided to classifiers through a synthetic dataset regeneration and soft labelling mechanism. The KR pipeline has been tested on a variety of datasets, with a focus on six highly heterogeneous medical image datasets, ranging from retinal images to organ scans. The results show a significant reduction in the performance gap between models trained on real and synthetic data, with models based on synthetic data outperforming those trained on real data in some cases. Furthermore, the resulting models show almost complete immunity to Membership Inference Attacks, manifesting privacy properties missing in models trained with conventional techniques.}
}
@article{HU2025103376,
title = {Syntactic paraphrase-based synthetic data generation for backdoor attacks against Chinese language models},
journal = {Information Fusion},
volume = {124},
pages = {103376},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103376},
url = {https://www.sciencedirect.com/science/article/pii/S156625352500449X},
author = {Man Hu and Yatao Yang and Deng Pan and Zhongliang Guo and Luwei Xiao and Deyu Lin and Shuai Zhao},
keywords = {Generative artificial intelligence, Large language models, Model security, Backdoor attacks, Synthetic data generation, Syntactic structure},
abstract = {Language Models (LMs) have shown significant advancements in various Natural Language Processing (NLP) tasks. However, recent studies indicate that LMs are particularly susceptible to malicious backdoor attacks, where attackers manipulate the models to exhibit specific behaviors when they encounter particular triggers. While existing research has focused on backdoor attacks against English LMs, Chinese LMs remain largely unexplored. Moreover, existing backdoor attacks against Chinese LMs exhibit limited stealthiness. In this paper, we investigate the high detectability of current backdoor attacks against Chinese LMs and propose a more stealthy backdoor attack method based on syntactic paraphrasing. Specifically, we leverage large language models (LLMs) to construct a syntactic paraphrasing mechanism that transforms benign inputs into poisoned samples with predefined syntactic structures. Subsequently, we exploit the syntactic structures of these poisoned samples as triggers to create more stealthy and robust backdoor attacks across various attack strategies. Extensive experiments conducted on three major NLP tasks with various Chinese PLMs and LLMs demonstrate that our method can achieve comparable attack performance (almost 100% success rate). Additionally, the poisoned samples generated by our method show lower perplexity and fewer grammatical errors compared to traditional character-level backdoor attacks. Furthermore, our method exhibits strong resistance against two state-of-the-art backdoor defense mechanisms.}
}
@article{FASANO20251,
title = {The dilemma of accuracy in bankruptcy prediction: a new approach using explainable AI techniques to predict corporate crises},
journal = {European Journal of Innovation Management},
volume = {28},
number = {11},
pages = {1-22},
year = {2025},
issn = {1460-1060},
doi = {https://doi.org/10.1108/EJIM-06-2024-0633},
url = {https://www.sciencedirect.com/science/article/pii/S1460106024000075},
author = {Francesco Fasano and Carlo Adornetto and Iliess Zahid and Maurizio {La Rocca} and Luigi Montaleone and Gianluigi Greco and Alfio Cariola},
keywords = {Bankruptcy prediction, Corporate failure, Generative Artificial Intelligence, Business crisis management, Digital transformation},
abstract = {Purpose
Our aim is to develop a highly precise corporate crisis prediction model that surpasses previous versions, rooted in the forefront of technological advancements.
Design/methodology/approach
Artificial Intelligence (AI) for corporate default prediction with a novel approach based on a mix of techniques, enabling it to achieve a higher accuracy. We investigated models with sequence lengths that were both fixed and variable, and we chose the best variable sequence length model.
Findings
Our findings demonstrate that the artificial techniques implemented lead to very high accuracy in predicting business crises compared to previous research efforts, even those utilising long-time sequences or a high volume of observations.
Research limitations/implications
We highlight the key variables with a higher predictive power that need monitoring to prevent business crises. We also aim to open a new avenue of research that, starting from the use of these techniques and our results, can implement models incorporating non-accounting variables to prevent business crises.
Practical implications
We provide a model/tool that assesses a possible business crisis in advance through a monitoring and alert system. Policymakers can use our research’s output as a tool to combine with current credit-scoring systems and to assess the effectiveness of the new corporate crisis reforms that are upcoming in many European countries. The results of our research can be useful also to banks, public entities, and consulting firms that interact with companies and are interested in the evaluation of a firm’s financial health and stability.
Originality/value
Our innovative work leverages cutting-edge methodologies such as deep Recurrent Neural Networks and explainable AI. This choice is driven by the rapid evolution of AI techniques in practical application.}
}
@article{LI2025100722,
title = {The interaction between emotion dynamics and opinion changes in the era of generative AI},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100722},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100722},
url = {https://www.sciencedirect.com/science/article/pii/S245195882500137X},
author = {Shangqian Li and Shaoyang Fan and Gianluca Demartini},
keywords = {Human computer interaction, Generative Artificial Intelligence, Emotion regulation, Online opinion modelling},
abstract = {Online emotion regulation interventions have experienced huge developments during the last decade due to the expansion of information communication technologies applications. Most existing emotion regulation interventions aim to provide long-term or on-site assistance to help users manage their sentiments to a desired psychological state. Recent advancements have significantly bolstered online emotion regulation interventions, such as AI-driven mindfulness apps that adapt to user feedback. Online-based emotion regulation applications are considered influential on users’ contextual and emotional decision-making processes. However, existing research offers limited observations on (i) how emotion regulation interventions affect people’s opinion changes and (ii) how generative AI could contribute to the development of automatic emotion regulation interventions. Hence, we experimented with 150 participants to close this research gap. We proposed two novel emotion regulation approaches to determine whether users’ opinions and emotional changes differ between ordinary-AI-based and generative-AI-based interventions on emotion regulation tasks. The result revealed that people’s feelings and decisions are highly correlated to their information consumption and perspectives. Furthermore, we found that intervention methods and users’ perceptions of the technology behind that intervention also played a vital role in their user experiences and decision-making processes. This research (i) shows that there exist interactions between emotions and opinion changes, (ii) opens new avenues for leveraging generative AI in emotion regulation applications, and (iii) underscores how divergent attitudes towards AI technology can lead to varied levels of success in the user experience.}
}
@article{GOLDIE2025,
title = {Practitioner Perspectives on the Uses of Generative AI Chatbots in Mental Health Care: Mixed Methods Study},
journal = {JMIR Human Factors},
volume = {12},
year = {2025},
issn = {2292-9495},
doi = {https://doi.org/10.2196/71065},
url = {https://www.sciencedirect.com/science/article/pii/S2292949525002056},
author = {Jessie Goldie and Simon Dennis and Lyndsey Hipgrave and Amanda Coleman},
keywords = {artificial intelligence, ChatGPT, mental health care, practitioner perspectives, mixed methods, digital health},
abstract = {Background
Generative artificial intelligence (AI) chatbots have the potential to improve mental health care for practitioners and clients. Evidence demonstrates that AI chatbots can assist with tasks such as documentation, research, counseling, and therapeutic exercises. However, research examining practitioners’ perspectives is limited.
Objective
This mixed-methods study investigates: (1) practitioners’ perspectives on different uses of generative AI chatbots; (2) their likelihood of recommending chatbots to clients; and (3) whether recommendation likelihood increases after viewing a demonstration.
Methods
Participants were 23 mental health practitioners, including 17 females and 6 males, with a mean age of 39.39 (SD 16.20) years. In 45-minute interviews, participants selected their 3 most helpful uses of chatbots from 11 options and rated their likelihood of recommending chatbots to clients on a Likert scale before and after an 11-minute chatbot demonstration.
Results
Binomial tests found that Generating case notes was selected at greater-than-chance levels ( 15/23, 65%; P=.001), while Support with session planning (P=.86) and Identifying and suggesting literature (P=.10) were not. Although 55% (12/23) were likely to recommend chatbots to clients, a binomial test found no significant difference from the 50% threshold (P=.74). A paired samples t test found that recommendation likelihood increased significantly (19/23, 83%; P=.002) from predemonstration to postdemonstration.
Conclusions
Findings suggest practitioners favor administrative uses of generative AI and are more likely to recommend chatbots to clients after exposure. This study highlights a need for practitioner education and guidelines to support safe and effective AI integration in mental health care.}
}
@article{HUANG2026102986,
title = {Human–GenAI collaboration across creative phases: Cognitive mechanisms shaping novelty and usefulness},
journal = {International Journal of Information Management},
volume = {86},
pages = {102986},
year = {2026},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102986},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225001185},
author = {Shiyingzi Huang and Lirong Long and Yanghao Zhu and Julie N.Y. Zhu},
keywords = {Generative AI, Creativity, Cognitive flexibility, Cognitive overload, Perceived GenAI intelligence, Creative process theory, Goal orientation theory},
abstract = {Generative artificial intelligence (GenAI) has demonstrated remarkable potential in creative domains; however, existing research has yet to fully explore how to optimize human–GenAI synergy or uncover the mechanisms underlying its impact on creativity. This study transcends the view of creativity as a singular process or monolithic outcome and examines how human–GenAI collaboration differentially influences the distinct creative phases of idea generation and idea elaboration. Drawing on creative process theory and goal orientation theory, we propose that human–GenAI collaboration activates phase-specific psychological mechanisms in pursuit of divergent creative goals. Using a multimethod approach, including a qualitative study (N = 20), two lab experiments (N1 = 42; N2 = 44), and an online behavioral experiment (N = 198), we find that human–GenAI collaboration in the idea generation phase (compared with the elaboration phase) enhances creative novelty by increasing cognitive flexibility, whereas human–GenAI collaboration in the idea elaboration phase (compared with the generation phase) improves creative usefulness by reducing cognitive overload. Furthermore, perceived GenAI intelligence moderates the indirect relationship between collaboration phases and usefulness through cognitive overload. By deconstructing the creative process, this research offers a nuanced understanding of the mechanisms and boundary conditions of human–GenAI collaboration, advancing theoretical conversations on AI-assisted creativity and providing actionable guidance for integrating GenAI into creative and organizational workflows.}
}
@article{BISWAS2025450,
title = {Applying the stimulus-organism-behavior-consequence framework to examine the relationship between intention, usage and recommendation of ChatGPT in higher education},
journal = {International Journal of Educational Management},
volume = {39},
number = {2},
pages = {450-468},
year = {2025},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-09-2023-0463},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X25000109},
author = {Mohammad Islam Biswas and Md. Shamim Talukder and Yasheng Chen},
keywords = {Artificial intelligence, Technology adoption, ChatGPT, SOBC framework, Likelihood of recommending, Higher education},
abstract = {Purpose
The adoption and usage of generative artificial intelligence tools like Chat Generative Pre-Trained Transformer (ChatGPT) in academia is the subject of increasing research interest. This study investigates the factors influencing the intention, usage and recommendation of ChatGPT among university students by employing the stimulus-organism-behavior-consequence (SOBC) framework.
Design/methodology/approach
The proposed research model was validated by employing the partial least squares structural equation modeling (PLS-SEM) approach using 249 university students.
Findings
The study revealed that intention to use and usage behavior of ChatGPT among university students are highly influenced by perceived usefulness, initial trust, personal innovativeness and availability of information and support. Similarly, the study found a sequence of significant positive relationships among intention to use, actual use and likelihood of recommending the technology to others. However, the results showed that the impact of perceived ease of use and social influence on behavioral intention was not found to be significant predictors of intention to use ChatGPT in academic settings.
Practical implications
The research findings offer a number of benefits for educational institutions and technology developers regarding students’ perceptions of ChatGPT and its academic applications. Eventually, the findings will encourage AI technology developers to enhance the quality and design of their solutions. Additionally, it helps educators in designing the AI governance framework to promote the ethical and transparent use of AI in academic environments.
Originality/value
This study contributes to the expanding body of technology adoption research and offers an integrated theoretical framework for comprehending the adoption and usage of ChatGPT in academic settings.}
}
@article{MODGIL2025103124,
title = {How could Generative AI support and add value to non-technology companies – A qualitative study},
journal = {Technovation},
volume = {139},
pages = {103124},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103124},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001743},
author = {Sachin Modgil and Shivam Gupta and Arpan Kumar Kar and Tuure Tuunanen},
keywords = {Qualitative study, Generative artificial intelligence, Business value, Business model, Technology appropriation},
abstract = {With the spread of generative AI, non-technology companies are also adopting it at a faster rate. Therefore, this study aims to study the appropriation of Generative AI to create value to non-technology businesses through a knowledge based view of the firm. To achieve this objective, we followed a semi-structured interview schedule, where 98 qualitative data points were collected and analysed. We follow open, axial and selective coding along with Gioia methodology for analysis. Findings indicate that companies employ Generative AI for risk management, where potential threats, impact of possible hazards and degree of uncertainty in the business environment are considered in decision-making. Generative AI also helps in knowledge integration, where assimilation, adaptation, application and implementation are achieved. Findings also suggest that an improved business outlook can be achieved regarding accurate demand forecasting, real-time insights, contextual understanding and alignment to the vision through Generative AI. It is also observed that companies are investing in Generative AI to achieve competitive advantage and greater significance. The contribution of this study lies in the development of four propositions and a framework for generative AI-driven value for non-technology companies. The framework also uncovers the internal flow among key elements from risk identification to integration to developing the outlook and driving utility.}
}
@article{HUNG2025100151,
title = {The efficacy of incorporating Artificial Intelligence (AI) chatbots in brief gratitude and self-affirmation interventions: Evidence from two exploratory experiments},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100151},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000350},
author = {Jing Wen Hung and Andree Hartanto and Adalia Y.H. Goh and Zoey K.Y. Eun and K.T.A. Sandeeshwara Kasturiratna and Zhi Xuan Lee and Nadyanna M. Majeed},
keywords = {Positive psychology intervention, Gratitude, Self-affirmation, Artificial intelligence, AI chatbots, Well-being},
abstract = {Numerous studies have demonstrated that positive psychology interventions, including brief interventions, can significantly improve well-being outcomes. These findings are particularly important given that many of these interventions are brief and self-administered, making them both accessible and scalable for large populations. However, the efficacy of positive psychology interventions is often constrained by small effect sizes. In light of advancements in generative Artificial Intelligence (AI), this study explored whether integrating AI chatbots into positive psychology interventions could enhance their efficacy compared to traditional self-administered approaches. Study 1 examined the efficacy of a gratitude intervention delivered through Snapchat's My AI, while Study 2 evaluated a self-affirmation intervention integrated with a customized ChatGPT. Both studies employed within-subject experimental designs. Contrary to our hypotheses, the integration of AI did not yield incremental improvements in gratitude outcomes (Study 1), or self-view outcomes (Study 2) compared to existing non-AI interventions. However, exploratory analyses revealed that the AI-integrated self-affirmation intervention significantly enhanced life satisfaction and medium-arousal positive affect, suggesting potential benefits for selected well-being outcomes. These findings indicate that while AI integration in brief, self-administered positive psychology interventions may enhance certain outcomes, its suitability varies across intervention types. Further research is needed to better understand the contexts in which AI can effectively augment positive psychology interventions.}
}
@article{ALANISRUIZ2025112856,
title = {A deep convolutional generative adversarial network (DCGAN) for the fast estimation of pollutant dispersion fields in indoor environments},
journal = {Building and Environment},
volume = {276},
pages = {112856},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112856},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325003385},
author = {Claudio {Alanis Ruiz} and Marcel Loomans and Twan {van Hooff}},
keywords = {Generative adversarial networks (GANs), Convolutional neural networks (CNNs), Generative artificial intelligence (GenAI), Pollutant dispersion, Indoor air quality, Computational fluid dynamics (CFD)},
abstract = {This paper presents a generative AI approach using a conditional deep convolutional generative adversarial network (cDCGAN) to rapidly predict pollutant concentration fields in indoor environments. The cDCGAN model is applied to a case study of a generic classroom with multiple heat and pollution sources and two distinct ventilation system configurations. It predicts pollutant dispersion at the breathing plane under simultaneous variations in ventilation rates and air supply temperatures. The model was trained and validated using high-quality computational fluid dynamics (CFD) simulation data. Results show that the cDCGAN can generate rapid predictions within seconds, providing reasonable accuracy in capturing the overall distribution and concentration levels of pollutants, with a mean absolute percentage error ranging from 13 % to 15 % when compared to CFD simulations. Despite some limitations in reproducing small-scale flow features, the model's ability to handle multiple system parameters and efficiently predict complex flow phenomena with limited training data highlights its value and potential. The methodology is adaptable to a range of indoor and outdoor environments and can be extended to estimate other flow variables and incorporate additional system parameters, making it a promising tool for applications requiring speed and efficiency when analyzing a large number of flow and dispersion scenarios.}
}
@article{BHADRA2025108002,
title = {Reimagining ethnopharmacology with generative AI: Towards inclusive, ethical, and data-driven traditional medicine},
journal = {Pharmacological Research},
volume = {221},
pages = {108002},
year = {2025},
issn = {1043-6618},
doi = {https://doi.org/10.1016/j.phrs.2025.108002},
url = {https://www.sciencedirect.com/science/article/pii/S104366182500427X},
author = {Santanu Bhadra and Charu Pundir and Maria Mukherjee and Amit Kar and Subhadip Banerjee and Rawiwan Charoensup and Thidarat Duangyod and Pulok K. Mukherjee},
keywords = {Generative AI, Ethnopharmacology, Traditional medicine, Drug discovery, Indigenous knowledge, Natural language processing, Data-driven innovation},
abstract = {Ethnopharmacology explores bioactive compounds rooted in traditional medical knowledge systems and holds immense promise for drug discovery, cultural preservation, and healthcare innovation. However, fragmented documentation, minimal digitization, and limited integration with biomedical frameworks remain major barriers. The advent of generative artificial intelligence (GenAI), including large language models (LLMs) and molecular generation algorithms, offers transformative solutions to these challenges. This narrative review critically examines the application of GenAI in ethnopharmacology and highlights its role in digitizing traditional knowledge, decoding polyherbal formulations, predicting herb-drug interactions, and accelerating phytopharmaceutical discovery. It synthesizes current literature on GenAI tools and methods relevant to ethnopharmacology, considering natural language processing, knowledge graph construction, molecular modeling, and multimodal data integration. A five-phase strategic framework is proposed for the ethical and effective implementation of GenAI. This review narrates real-world applications from Asian (Ayurvedic, Chinese, Japanese, Thai, Vietnamese), African, and Indigenous American medicines systems demonstrate adaptability across cultures. Stakeholder-specific benefits, spanning academia, healthcare, industry, and indigenous communities, are also discussed, along with methodological innovations and ethical considerations. GenAI offers a significant transition in ethnopharmacology by integrating traditional knowledge systems with advanced computational tools to develop inclusive data-driven innovation across global traditional medicine systems.}
}
@article{WANG2025112115,
title = {A multi-view new energy vehicle form generation design method combining Kansei imagery and deep learning},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112115},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112115},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625021232},
author = {Zihao Wang and Le Xi and Yifan Ding and Wenjie Fang and Kaiming Wang and Hongliang Zuo},
keywords = {Vehicle appearance design, Design decision evaluation, Residual networks, Kernels network, Multi-view fusion},
abstract = {In the competitive landscape of new energy vehicles, exterior design has become a crucial differentiator amid functional homogenization. User preferences are central to shaping vehicle appearance, yet most perceptual design methods rely on a single viewpoint, limiting insights into complex preference patterns. This study proposes a multi-perspective mapping approach that integrates Kansei engineering with deep learning. Firstly, user core imagery is collected and mined through big data. Secondly, Kernels Network (KNet) semantic segmentation model, Residual Networks (ResNet) tri-view (front/side/rear) score prediction model and fully connected network (FCN) feature fusion model are integrated to construct a multi-view feature mapping system. Finally, the optimal combination of morphological elements is explored based on the Elite Genetic Algorithm (EGA), and the scheme is validated through generative artificial intelligence (AI) workflow. The experimental results demonstrate that, employing “Cool” as a case study, the three-view scheme and the combination scheme devised by this research process exhibit substantial superiority over the majority of the samples. Under identical parameters, the scheme with decision constraints surpasses the randomly generated scheme in terms of perceptual scores and stability. The performance of the test set and the experimental results collectively substantiate the model’s validity. This workflow—covering preference extraction, morphological decomposition, AI-driven generation, and validation—provides a scalable framework for new energy vehicle exterior design. It also demonstrates novel applications of Kansei engineering in multi-view fusion and generative form design.}
}
@article{MUTIN2025,
title = {Extraction de données d’articles scientifiques pharmaceutiques par intelligence artificielle : évaluation de la conformité des réponses de ChatGPT 4.0 avec l’extraction humaine},
journal = {Le Pharmacien Clinicien},
year = {2025},
issn = {2772-9532},
doi = {https://doi.org/10.1016/j.phacli.2025.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S2772953225000863},
author = {Juliette Mutin and Marie-Lili Hafizin and Victor El-Jammal and Célia Morel and Lisa Leca and Maxime Bergeron and Jean-François Bussières},
keywords = {Agents conversationnels, Extraction données, Intelligence artificielle, Pharmacie, Conversational agents, Data extraction, Generative artificial intelligence, Pharmacy},
abstract = {Résumé
Introduction
L’intelligence artificielle (IA) est notamment utilisée pour automatiser l’extraction de données, avec l’aide d’agents conversationnels tels que ChatGPT. Il reste à évaluer si ces outils peuvent extraire des données d’articles scientifiques avec une précision comparable à celle des humains dans le domaine pharmaceutique. L’objectif est d’évaluer la conformité des données extraites par ChatGPT 4.0 en comparaison avec celles extraites par des étudiants en pharmacie, dans le cadre de la mise à jour de la plateforme impactpharmacie.org.
Matériel et méthodes
Cent articles pharmaceutiques ont été analysés. ChatGPT 4.0 a été programmé par un prompt et a été interrogé par 18 questions pour chaque article afin d’en extraire les données ciblées. Elles ont ensuite été comparées à celles préalablement validées et intégrées dans la plateforme par cinq étudiants en pharmacie. La conformité a été évaluée sur 23 critères incluant la description du type d’étude, les limites, l’intervention pharmaceutique et ce selon trois niveaux : conforme, partiellement conforme et non conforme. Le nombre et la nature des hallucinations ont également été relevés.
Résultats
La conformité des données extraites par ChatGPT comparées à celles des étudiants a atteint 77±19 % en moyenne. Cependant, des hallucinations d’IA ont été relevées dans 23 des 100 articles, et 30 % des paramètres (outcomes) (n=138/449) étaient absents de l’extraction. Une analyse complémentaire a été effectuée pour six revues systématiques et cinq méta-analyses.
Discussion
ChatGPT 4.0 est un outil prometteur pour extraire des données de la littérature scientifique pharmaceutique, mais une validation humaine reste nécessaire.
Summary
Introduction
Generative Artificial Intelligence (AI), particularly conversational agents like ChatGPT, can be used to automate data extraction. However, it remains to be determined if these tools can extract scientific data with accuracy comparable to humans, especially in the field of pharmacy. Objective was to assess the compliance rate of data extracted by ChatGPT 4.0 compared to Impact Pharmacie entries.
Materials and methods
This is a descriptive comparative study. A random selection of 100 articles entered on Impact Pharmacie in 2024 was identified. ChatGPT 4.0 was programmed with a prompt and queried with 18 questions per article to extract targeted data. The responses were compared to data previously entered into the Impact Pharmacie platform by pharmacy students following a standardized operating procedure. Compliance was assessed across 23 criteria (e.g., study type description, pharmaceutical intervention description, limitations) and categorized into three levels: compliant, partially compliant, and non-compliant. The number and nature of AI hallucinations were also recorded.
Results
The compliance rate of data extracted by ChatGPT compared to student-entered data averaged 77±19%. However, AI hallucinations were observed in 23 out of 100 articles, and 30% of parameters (n=138/449) were missing from the extraction.
Discussion
ChatGPT 4.0 is a promising tool to support data extraction from pharmaceutical scientific literature, but human validation remains essential to ensure the accuracy of the information.}
}
@article{MEJIASALGADO2025102509,
title = {Diagnostic accuracy in dry eye: Insights into clinical and artificial intelligence limitations: Limitations of diagnostic accuracy in dry eye},
journal = {Contact Lens and Anterior Eye},
pages = {102509},
year = {2025},
issn = {1367-0484},
doi = {https://doi.org/10.1016/j.clae.2025.102509},
url = {https://www.sciencedirect.com/science/article/pii/S1367048425001432},
author = {Germán Mejía-Salgado and William Rojas-Carabali and Carlos Cifuentes-González and María Andrea Bernal-Valencia and Paola Saboya-Galindo and Jaime Soto-Ariño and Valentina Dumar-Kerguelen and Guillermo Marroquín-Gómez and Martha Lucía Moreno-Pardo and Juliana Tirado-Ángel and Anat Galor and Alejandra de-la-Torre},
keywords = {Dry eye disease, Diagnosis, Large language models, Generative artificial intelligence},
abstract = {Purpose
To evaluate the agreement and performance of four large language models (LLMs)—ChatGPT-3.5, ChatGPT-4.0, Leny-ai, and MediSearch—in diagnosing and classifying Dry Eye Disease (DED), compared to clinician judgment and Dry Eye Workshop-II (DEWS-II) criteria.
Methods
A standardized prompt incorporating retrospective clinical and symptomatic data from patients with suspected DED referred to a dry eye clinic was developed. LLMs were evaluated for diagnosis (DED vs. no DED) and classification (aqueous-deficient, evaporative, mixed-component). Agreement was assessed using Cohen’s-kappa (Cκ) and Fleiss’-kappa (Fκ). Balanced accuracy, sensitivity, specificity, and F1 score were calculated.
Results
Among 338 patients (78.6 % female, mean age 53.2 years), clinicians diagnosed DED in 300, and DEWS-II criteria identified 234. LLMs showed high agreement with clinicians for DED diagnosis (93 %–99 %, Cκ: 0.81–0.86). Subtype agreement was lower (aqueous-deficient: 0 %–18 %, evaporative: 4 %–80 %, mixed-component: 22 %–92 %; Fκ: −0.20 to −0.10). Diagnostic balanced accuracy was 48 %–56 %, with high sensitivity (93 %–99 %) but low specificity (0 %–16 %). Subtype balanced accuracy and F1 score ranged from 33 %-81 % 0 %–71 %, respectively. Compared to DEWS-II, agreement for DED diagnosis remained high (96 %–99 %) but with weaker Cκ (0.52–0.58). Subtype agreement was again low (aqueous-deficient: 0 %–20 %, evaporative: 9 %–68 %, mixed-component: 16 %–75 %; Fκ: −0.09 to −0.02). Diagnostic balanced accuracy was 49 %–56 %, sensitivity 97 %–99 %, and specificity 5 %–16 %. Subtype balanced accuracy ranged from 43 % to 56 %, F1 score 0–68.
Conclusion
LLMs showed strong agreement and high sensitivity for DED diagnosis but limited specificity and poor subtype classification, mirroring clinical challenges and highlighting risks of overdiagnosis.}
}
@article{DAI2025100019,
title = {Why students use or not use generative AI: Student conceptions, concerns, and implications for engineering education},
journal = {Digital Engineering},
volume = {4},
pages = {100019},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100019},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000190},
author = {Yun Dai},
keywords = {Artificial intelligence, generative AI, engineering education, student concern, barrier, technology integration, higher education},
abstract = {Generative artificial intelligence (GenAI) technologies are believed to transform engineering education. However, it remains underexamined how engineering students choose to use GenAI or not, along with the reasons behind their choices. To fill this research gap, this study presents a natural experiment that examines student use or non-use of GenAI tools in engineering design tasks in an undergraduate course. In this experiment, the participants (n = 403) were provided with unconstrained access to a GPT 4.0-empowered chatbot and were allowed to use it for their design projects voluntarily. Overall, 59.80 % of the students reported substantial use of GenAI in their design projects, and 40.20 % showed limited or no use. Those adopters used GenAI to aid idea generation and brainstorming, mediate discussions with instructors/TA, overcome non-technical expertise gaps, and optimize their design solutions. Conversely, non-adopters attributed their reluctance and rejection to inherent limitations in GenAI outputs, misalignment between GenAI functionalities and project needs, a lack of adaptation and prompt skills, and unclear benefits of GenAI use for personal growth. This study challenges the popular assumption of naturally active GenAI adoption among university students. It identifies three major factors—task characteristics, decision-maker characteristics, and context characteristics—that shape students' adoption of and interaction with GenAI. The findings highlight the need of establishing a consensus across various stakeholders (i.e., students, instructors, curriculum developers, policymakers, and others), while calling for adaptation and evidence-based decision-making in integrating GenAI tools into engineering education.}
}
@article{TRIANTAFYLLOPOULOS2025101802,
title = {Vishing: Detecting social engineering in spoken communication — A first survey & urgent roadmap to address an emerging societal challenge},
journal = {Computer Speech & Language},
volume = {94},
pages = {101802},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2025.101802},
url = {https://www.sciencedirect.com/science/article/pii/S0885230825000270},
author = {Andreas Triantafyllopoulos and Anika A. Spiesberger and Iosif Tsangko and Xin Jing and Verena Distler and Felix Dietz and Florian Alt and Björn W. Schuller},
keywords = {Vishing, Social engineering, Human–computer interaction, Computational paralinguistics},
abstract = {Vishing – the use of voice calls for phishing – is a form of Social Engineering (SE) attacks. The latter have become a pervasive challenge in modern societies, with over 300,000 yearly victims in the US alone. An increasing number of those attacks is conducted via voice communication, be it through machine-generated ‘robocalls’ or human actors. The goals of ‘social engineers’ can be manifold, from outright fraud to more subtle forms of persuasion. Accordingly, social engineers adopt multi-faceted strategies for voice-based attacks, utilising a variety of ‘tricks’ to exert influence and achieve their goals. Importantly, while organisations have set in place a series of guardrails against other types of SE attacks, voice calls still remain ‘open ground’ for potential bad actors. In the present contribution, we provide an overview of the existing speech technology subfields that need to coalesce into a protective net against one of the major challenges to societies worldwide. Given the dearth of speech science and technology works targeting this issue, we have opted for a narrative review that bridges the gap between the existing psychological literature on the topic and research that has been pursued in parallel by the speech community on some of the constituent constructs. Our review reveals that very little literature exists on addressing this very important topic from a speech technology perspective, an omission further exacerbated by the lack of available data. Thus, our main goal is to highlight this gap and sketch out a roadmap to mitigate it, beginning with the psychological underpinnings of vishing, which primarily include deception and persuasion strategies, continuing with the speech-based approaches that can be used to detect those, as well as the generation and detection of AI-based vishing attempts, and close with a discussion of ethical and legal considerations.}
}
@incollection{SALDANHADAGAMA2024,
title = {Facility location problems in supply chain operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00050-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000500},
author = {Francisco Saldanha-da-Gama},
keywords = {Effectiveness, Efficiency, Facility location, Logistics, Optimization modeling, Risk, Supply chain operations, Time, Triple bottom line, Uncertainty},
abstract = {This chapter focuses on the role of facility location problems on planning and managing supply chain operations. Emphasis is put on strategic supply chain design. Different aspects are discussed, which include the multilayer, multicommodity, and multiobjective nature of the problems in the field. Time-dependent decisions and uncertainty in data are also aspects covered. The insights resulting from the discussion made are materialized in a general mathematical model that leverages the discrete capacitated facility location. This lays the ground for embedding logistics decisions like distribution, inventory, procurement, and production. Different mechanisms for hedging against uncertainty are then analyzed, which ultimately lead to show how a facility location model can be set at the core of supply chain risk analytics. Environmental and social concerns aligned with the triple bottom line concept are also covered. In particular, the role of facility location in reverse logistics and closed-loop supply chain design is analyzed. Different sectors are discussed, including agro-food, energy, commercial industry, healthcare, and humanitarian operations. Several modern trends are highlighted. These include blockchain technology, data-driven decision-making, and the role of Big Data and generative Artificial Intelligence.}
}
@article{DEJESUS2025111135,
title = {Enhanced LLM-supported instructions for medication use through retrieval-augmented generation},
journal = {Computers in Biology and Medicine},
volume = {198},
pages = {111135},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.111135},
url = {https://www.sciencedirect.com/science/article/pii/S001048252501488X},
author = {Davi dos Reis {de Jesus} and Antônio Pereira {de Souza Júnior} and Elisa Tuler {de Albergaria} and Adriana Silvina Pagano and Isaias Jose Ramos {de Oliveira} and Cristiane {dos Santos Dias} and Eura Martins Lage and Flavia Ribeiro {de Oliveira} and Juliana Almeida Oliveira and Igor {de Carvalho Gomes} and Leonardo Chaves Dutra {da Rocha} and Zilma Silveira Nogueira Reis},
keywords = {Generative artificial intelligence, Drug prescriptions, Health communication, Electronic prescribing, Medication safety},
abstract = {Prescription systems support medication treatment by standardizing content, enhancing legibility and promoting correct dispensation. Challenges remain to personalize use instructions with sufficient clarity to meet patients' needs. Large Language Models (LLMs) are promising to improve communication in healthcare. This study investigates LLM Retrieval-Augmented Generation (RAG) drawing on patient information leaflets (PIL). We used a database with 119 outpatient scenarios to prepare prescriptions as input to LLMs. We evaluated patient instructions generated by open-source Llama3, using a standard prompt - model1, enhanced prompts with structured guidance - model2, and RAG-enhanced prompts incorporating PIL information from the Brazilian Health Regulatory Agency - model3. Five physicians independently scored the model-generated instructions, assessing adequacy, clarity, personalization and quality compared to reference texts; they reported their confidence level to perform the evaluation. Cosine similarity was computed between model-generated and reference texts. RAG introduction significantly improved instructions adequacy: median (interquartile range) 93.0 (40.0) vs. 94 (53.3) vs 100 (15.0), p = 0.001, and clarity 90.0 (60.0) vs. 92 (55.0) vs 95.0 (24.0), p = 0.012, for model1, model2, and model3 respectively. Enhanced prompt plus RAG in PIL reduced critical errors such as incorrect and incomplete instructions and factual inaccuracies. Prompt engineering positively impacted output, precluding the generation of vague and unsolicited instructions. Little impact of hallucination was found. Our findings underscore the role of AI in promoting safer medication use by incorporating authoritative medication information while maintaining concise and patient-friendly language. Human validation of output ensures error-free and safe implementation.}
}
@article{KWOK20243254,
title = {Utilizing large language models in infectious disease transmission modelling for public health preparedness},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {3254-3257},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024002654},
author = {Kin On Kwok and Tom Huynh and Wan In Wei and Samuel Y.S. Wong and Steven Riley and Arthur Tang},
keywords = {Large language model, Generative artificial intelligence, Infectious diseases, Mathematical transmission modelling, Simulation and modelling},
abstract = {Introduction
OpenAI's ChatGPT, a Large Language Model (LLM), is a powerful tool across domains, designed for text and code generation, fostering collaboration, especially in public health. Investigating the role of this advanced LLM chatbot in assisting public health practitioners in shaping disease transmission models to inform infection control strategies, marks a new era in infectious disease epidemiology research. This study used a case study to illustrate how ChatGPT collaborates with a public health practitioner in co-designing a mathematical transmission model.
Methods
Using natural conversation, the practitioner initiated a dialogue involving an iterative process of code generation, refinement, and debugging with ChatGPT to develop a model to fit 10 days of prevalence data to estimate two key epidemiological parameters: i) basic reproductive number (Ro) and ii) final epidemic size. Verification and validation processes are conducted to ensure the accuracy and functionality of the final model.
Results
ChatGPT developed a validated transmission model which replicated the epidemic curve and gave estimates of Ro of 4.19 (95 % CI: 4.13- 4.26) and a final epidemic size of 98.3 % of the population within 60 days. It highlighted the advantages of using maximum likelihood estimation with Poisson distribution over least squares method.
Conclusion
Integration of LLM in medical research accelerates model development, reducing technical barriers for health practitioners, democratizing access to advanced modeling and potentially enhancing pandemic preparedness globally, particularly in resource-constrained populations.}
}
@incollection{NAYYAR2025161,
title = {Chapter 7 - Tools and platforms for prompt engineering},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {161-210},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000082},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {FlowGPT, GIMP, GPT-Neo, Jasper AI, Prompt engineering, PromptBase},
abstract = {Prompt engineering has surfaced as a crucial strategy in how we interact with language models while using generative artificial intelligence (AI) over the last years. This chapter aims to introduce the range of tools and platforms fielded for prompt engineering, offering an exhaustive survey of resources that can be leveraged in order to shape more sophisticated prompts on various applications. Starting with prompt engineering tools, we are going to analyze the software/platforms that have been built specifically for trying out prompt generation across many different types of AI models. The tools provide certain features, such as prompt refinement, integration with AT models, and evaluation of results, that can help a wide variety of users, from novices to experts, in designing prompts. The chapter also touches on online resources to create powerful prompts, providing details about sites where you can learn about creating prompts, download prompt examples, and interactively fine-tune input from the user to obtain the desired output from AI systems. Then we are presented with a big picture of online resources for image generation, which are web interfaces made to convert textual prompts into sample images through advanced generative models. The Online Resources for Video Generation section is most exciting in considering tools designed around prompts to make and edit video content — a far more dynamic world full of possibilities. This chapter also offers a comprehensive resource for those interested in working with generative AI to be able to tap into such power across domains.}
}
@article{ZHAO2025100497,
title = {Large-scale pretrained frame generative model enables real-time low-dose DSA imaging: An AI system development and multi-center validation study},
journal = {Med},
volume = {6},
number = {1},
pages = {100497},
year = {2025},
issn = {2666-6340},
doi = {https://doi.org/10.1016/j.medj.2024.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S2666634024003076},
author = {Huangxuan Zhao and Ziyang Xu and Lei Chen and Linxia Wu and Ziwei Cui and Jinqiang Ma and Tao Sun and Yu Lei and Nan Wang and Hongyao Hu and Yiqing Tan and Wei Lu and Wenzhong Yang and Kaibing Liao and Gaojun Teng and Xiaoyun Liang and Yi Li and Congcong Feng and Tong Nie and Xiaoyu Han and Dongqiao Xiang and Charles B.L.M. Majoie and Wim H. {van Zwam} and Aad {van der Lugt} and P. Matthijs {van der Sluijs} and Theo {van Walsum} and Yun Feng and Guoli Liu and Yan Huang and Wenyu Liu and Xuefeng Kan and Ruisheng Su and Weihua Zhang and Xinggang Wang and Chuansheng Zheng},
keywords = {generative artificial intelligence, GenAI, GenDSA, large-scale pretrained model, deep learning, multi-center clinical study},
abstract = {Summary
Background
Digital subtraction angiography (DSA) devices are commonly used in numerous interventional procedures across various parts of the body, necessitating multiple scans per procedure, which results in significant radiation exposure for both doctors and patients. Inspired by generative artificial intelligence techniques, this study proposes GenDSA, a large-scale pretrained multi-frame generative model-based real-time and low-dose DSA imaging system.
Methods
GenDSA was developed to generate 1-, 2-, and 3-frame sequences following each real frame. A large-scale dataset comprising ∼3 million DSA images from 27,117 patients across 10 hospitals was constructed to pretrain, fine-tune, and validate GenDSA. Two other datasets from 25 hospitals were used for evaluation. Objective evaluations included SSIM and PSNR. Five interventional radiologists independently assessed the quality of the generated frames using the Likert scale and visual Turing test. Scoring consistency among the radiologists was measured using the Kendall coefficient of concordance (W). The Fleiss’ kappa values were used for inter-rater agreement analysis for visual Turing tests.
Findings
Using only one-third of the clinical radiation dose, videos generated by GenDSA were perfectly consistent with real videos. Objective evaluations demonstrated that GenDSA’s performance (PSNR = 36.83, SSIM = 0.911, generation time = 0.07 s/frame) surpassed state-of-the-art algorithms. Subjective ratings and statistical results from five doctors indicated no significant difference between real and generated videos. Furthermore, the generated videos were comparable to real videos in overall quality (4.905 vs. 4.935) and lesion assessment (4.825 vs. 4.860).
Conclusions
With clear clinical and translational values, the developed GenDSA can significantly reduce radiation damage to both doctors and patients during DSA-guided procedures.
Funding
This study was supported by the National Key R&D Program and the National Natural Science Foundation of China.}
}
@article{LIAO2025120662,
title = {Intelligent zoning design of concrete-faced rockfill dams using image-parameter fusion enhanced generative adversarial networks},
journal = {Engineering Structures},
volume = {339},
pages = {120662},
year = {2025},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2025.120662},
url = {https://www.sciencedirect.com/science/article/pii/S0141029625010533},
author = {Wenjie Liao and Zongliang Zhang and Biao Liu and Xinzheng Lu and Difu Liu and Qiang Liu and Zhijie Duan and Chao Liu},
keywords = {Intelligent zoning design of rockfill dams, Image-parameter feature fusion, Generative adversarial network, Parametric-generated data augmentation, Image pixel vectorization},
abstract = {The design of concrete-face rockfill dams (CFRDs) is gradually evolving from digitization to intelligent design, primarily driven by advanced technologies such as generative artificial intelligence (AI). Generative AI offers powerful capabilities for extracting and mining data features and generating new design solutions efficiently through inference. These strengths provide critical technical support for intelligent CFRD design, facilitating the full utilization of design data, and significantly improving design efficiency and quality. However, CFRD design is a highly specialized and complex task, and conventional generative AI techniques often fail to produce professional-grade designs. In response to this challenge, this study explored generative intelligent design methods specifically for the critical task of CFRD profile design. An intelligent design method based on feature-fusion generative adversarial networks (GANs) for CFRD profile solutions is proposed. This approach enables the dense representation and augmentation of design data, GAN model training, and automated evaluation, thereby addressing the key challenge of fusing small-sample multimodal image-parameter data. The effectiveness of the intelligent design method for CFRD profiles was validated through algorithm analysis and case studies. The design efficiency was nearly 10 times higher than that of traditional engineer-driven designs, reducing the time required from 1–2 h to approximately 6 min. The proposed intelligent design approach has great potential and provides valuable insights for the further development of intelligent design of rockfill dams.}
}
@incollection{GAUR2026211,
title = {Chapter 12 - Lawfulness and generative AI},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {211-226},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00011-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000114},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Data privacy, Ethical principles, Generative AI, Healthcare law, Medical regulations, Patient rights, Transparency},
abstract = {This chapter explores the legal landscape surrounding generative artificial intelligence (AI) in healthcare, emphasizing the need for a comprehensive legal and ethical framework to govern its use. Generative AI, which encompasses technologies that can create content, analyze data, and support clinical decision-making, has numerous applications in healthcare, including diagnostics, treatment planning, and patient management. However, the integration of AI technologies raises significant legal and ethical considerations that must be navigated to ensure patient rights and safety. The chapter begins by defining generative AI and examining its applications within the medical field. It discusses existing medical regulations that govern practice, including licensing, malpractice laws, and clinical guidelines, while exploring how the adoption of AI is reshaping these frameworks. Through case studies, it highlights the legal challenges and compliance issues encountered in AI-driven medical practice, focusing on liability and regulatory adherence. Patient rights and data privacy are crucial themes, with a review of the legal frameworks protecting patient autonomy and confidentiality. Key data privacy laws, such as General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA), are discussed in relation to generative AI, along with best practices for compliance. Transparency and fairness in AI systems are emphasized, detailing the legal and ethical imperatives for clear decision-making processes and the avoidance of biases in AI applications. The chapter outlines key ethical principles governing the use of AI in healthcare, such as autonomy, beneficence, and justice, and the importance of integrating these principles into AI development. The chapter concludes with case studies demonstrating successful legal and ethical practices in AI healthcare solutions and discusses future directions for evolving legal standards and ethical frameworks. Recommendations for building a robust legal and ethical framework are provided, ensuring that generative AI contributes positively to healthcare while addressing the challenges it presents.}
}
@article{CHEN2026103765,
title = {MALM-CLIP: A generative multi-agent framework for multimodal fusion in few-shot industrial anomaly detection},
journal = {Information Fusion},
volume = {127},
pages = {103765},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103765},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008279},
author = {Hanzhi Chen and Jingbin Que and Kexin Zhu and Zhide Chen and Fei Zhu and Wencheng Yang and Xu Yang and Xuechao Yang},
keywords = {CLIP, Few-shot learning, Industrial anomaly detection, Multi-agent systems, GenAI},
abstract = {The Contrastive Language-Image Pre-training (CLIP) model has significantly improved few-shot industrial anomaly detection. However, existing approaches often rely on manually crafted visual description texts, which lack robustness and generalizability in real-world production settings. This limitation is evident as these methods struggle to adapt to new or evolving anomalies, where original prompts fail to generalize beyond their initial design. This paper proposes a novel method, Multi-agent Language Models with CLIP (MALM-CLIP), which integrates the generative capabilities of large language models (LLMs) with CLIP within a multi-agent framework. In this system, specialized agents handle different subtasks such as prompt generation and model evaluation, enabling automated and context-aware multimodal information fusion. By eliminating manual prompt engineering, MALM-CLIP enhances both the accuracy and efficiency of anomaly detection. Experimental results on standard datasets such as MVTec and VisA demonstrate that our approach outperforms existing methods in detecting image-level anomalies with minimal training data. This work highlights the potential of combining Generative Artificial Intelligence (GenAI) and multi-agent systems for robust few-shot industrial anomaly detection.}
}
@article{SANDRINI2023111317,
title = {Generative AI and deceptive news consumption},
journal = {Economics Letters},
volume = {232},
pages = {111317},
year = {2023},
issn = {0165-1765},
doi = {https://doi.org/10.1016/j.econlet.2023.111317},
url = {https://www.sciencedirect.com/science/article/pii/S0165176523003427},
author = {Luca Sandrini and Robert Somogyi},
keywords = {Generative AI, News media market, Online advertising, Clickbait, Fake news},
abstract = {In this paper, we analyze the effects of advancements in generative Artificial Intelligence (GenAI) on the news media market. We model a representative consumer who allocates their time between reading news and deceptive articles. We find that GenAI may induce consumers to inefficiently reallocate their time and increase the consumption of the lower value good, i.e. deceptive content (clickbait articles or fake news). Therefore, early-stage GenAI distorts the incentives of consumers and reduces their welfare. After GenAI technology reaches a certain threshold, however, consumers start benefiting from its advancements. Finally, we find that the negative effects of early-stage GenAI are exacerbated as they induce a lower level of investment in news production.}
}
@article{BUNDUCHI2025124095,
title = {A legitimacy-based explanation for user acceptance of controversial technologies: The case of Generative AI},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124095},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124095},
url = {https://www.sciencedirect.com/science/article/pii/S004016252500126X},
author = {Raluca Bunduchi and Dan-Andrei Sitar-Tăut and Daniel Mican},
keywords = {Technology acceptance, Legitimacy, Technology uncertainty, Technology variation},
abstract = {Controversial technologies are technologies where social concerns play a disproportionate role in shaping the public attitudes to their adoption. An example of such controversial technologies is Generative Artificial Intelligence (GenAI), whose rapid diffusion is fuelled by expectations for significant performance improvements, while also facing concerns at individual (trust in technology), technology (accuracy and quality), and institutional (cultural, ethical and regulatory) level. Individual and technology factors are well accounted for by rational choice-based models which underpin most technology acceptance research. Such models are less suited to explore the role of institutional factors in shaping technology acceptance. Drawing from legitimacy and technology lifecycle research, we develop a legitimacy-based model of GenAI adoption which accounts for the institutional context in which technology use happens, and for technology characteristics, namely its maturity, in shaping users' acceptance. Surveying 483 information systems students who are GenAI users, we find that users' perceptions of technology uncertainty and variation positively affect their technology legitimacy evaluations and that their pragmatic and cognitive legitimacy evaluations, but not moral, affect their intention to use. We answer recent calls to examine alternative theoretical predictors of technology acceptance, and to consider the role of context in examining the acceptance of controversial technologies.}
}
@article{WANG2025112481,
title = {A graph-enabled parametric modeling approach for façade layout generative design},
journal = {Journal of Building Engineering},
volume = {105},
pages = {112481},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112481},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225007181},
author = {Bolun Wang and Weisheng Lu and Yi Zhang},
keywords = {Graph, Generative design, Multi-objective optimization, Façade layout, Residential buildings},
abstract = {Façade layout is a crucial design element that has significantly benefited from the advancements in generative artificial intelligence. However, current generative methods such as procedural modeling and parametric modeling exhibit two primary limitations. Firstly, they rely on drawings or images instead of more flexible and structured data inputs. Secondly, they often neglect the spatial sequence of the façade in the optimization process. This paper introduces a graph-enabled parametric modeling approach (GEPMA) for façade layout generation. The approach utilizes graphs to represent structural data inputs and incorporates spatial sequence-aware optimization for the output. The process begins by decoding a hierarchical attributed graph (HAG) to extract essential façade information and define key modeling parameters. Facades are then generated and simulated based on two predefined objectives: energy use intensity (EUI) and spatial daylight autonomy (sDA). Subsequently, the façade variants are optimized under four different spatial sequences using a non-dominated sorting genetic algorithm II (NSGA-II). GEPMA was evaluated through a case study of a residential building in China. The optimal solutions improved sDA by an average of 7.71 % (up to 12.02 %) and reduced EUI by an average of 0.40 % (up to 0.62 %) compared to the baseline façade. This study contributes to the field of generative design by presenting a flexible and editable methodology and providing practical insights for façade design.}
}
@article{GRECO2026101014,
title = {Encapsulating textual contents into a MOC data structure for advanced applications},
journal = {Astronomy and Computing},
volume = {54},
pages = {101014},
year = {2026},
issn = {2213-1337},
doi = {https://doi.org/10.1016/j.ascom.2025.101014},
url = {https://www.sciencedirect.com/science/article/pii/S2213133725000873},
author = {Giuseppe Greco and Thomas Boch and Pierre Fernique and Manon Marchand and Mark Allen and Francois-Xavier Pineau and Matthieu Baumann and Marco Molinaro and Roberto {De Pietri} and Marica Branchesi and Steven Schramm and Gergely Dálya and Elahe Khalouei and Barbara Patricelli and Giulia Stratta},
keywords = {Virtual Observatory, Multi Order Coverage map, IVOA standards, Textual MOC, Semantic MOC},
abstract = {Context:
The Multi-Order Coverage map (MOC) is a widely adopted standard promoted by the International Virtual Observatory Alliance (IVOA) to support data sharing and interoperability within the Virtual Observatory (VO) ecosystem. This hierarchical data structure efficiently encodes and visualizes irregularly shaped regions of the sky, enabling applications such as cross-matching large astronomical catalogs, visualizing multi-wavelength and multi-messenger surveys, and facilitating collaborative research through seamless interoperability in big-data-driven exploration.
Aims:
This study aims to explore potential enhancements to the MOC data structure by encapsulating textual descriptions and semantic embeddings into sky regions. Specifically, we introduce “Textual MOCs”, in which textual content is encapsulated, and “Semantic MOCs” that transform textual content into semantic embeddings. These enhancements are designed to enable advanced operations such as similarity searches and complex queries and to integrate with generative artificial intelligence (GenAI) tools to improve context-aware interactions and response accuracy in astronomical data analysis, and support agent-based applications.
Method:
We experimented with Textual MOCs by annotating detailed descriptions directly into the MOC sky regions, enriching the maps with contextual information suitable for interactive learning tools. For Semantic MOCs, we converted the textual content into semantic embeddings, numerical representations capturing textual meanings in multidimensional spaces, and stored them in high-dimensional vector databases optimized for efficient retrieval.
Results:
The implementation of Textual MOCs enhances user engagement by providing meaningful descriptions within sky regions, facilitating the development of effective game-based learning. Semantic MOCs enable sophisticated query capabilities, such as similarity-based searches and context-aware data retrieval, enhancing astronomical data analyses. Integration with multimodal generative AI systems allows for more accurate and contextually relevant interactions supporting both spatial, semantic and visual operations for advancing astronomical data analysis capabilities. Through straightforward examples, we discuss the fundamentals of this new experimental implementation.}
}
@article{YANG2024100085,
title = {Understanding natural language: Potential application of large language models to ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100085},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100085},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000860},
author = {Zefeng Yang and Deming Wang and Fengqi Zhou and Diping Song and Yinhang Zhang and Jiaxuan Jiang and Kangjie Kong and Xiaoyi Liu and Yu Qiao and Robert T. Chang and Ying Han and Fei Li and Clement C. Tham and Xiulan Zhang},
keywords = {Large language model, Ophthalmology, Artificial intelligence, ChatGPT},
abstract = {Large language models (LLMs), a natural language processing technology based on deep learning, are currently in the spotlight. These models closely mimic natural language comprehension and generation. Their evolution has undergone several waves of innovation similar to convolutional neural networks. The transformer architecture advancement in generative artificial intelligence marks a monumental leap beyond early-stage pattern recognition via supervised learning. With the expansion of parameters and training data (terabytes), LLMs unveil remarkable human interactivity, encompassing capabilities such as memory retention and comprehension. These advances make LLMs particularly well-suited for roles in healthcare communication between medical practitioners and patients. In this comprehensive review, we discuss the trajectory of LLMs and their potential implications for clinicians and patients. For clinicians, LLMs can be used for automated medical documentation, and given better inputs and extensive validation, LLMs may be able to autonomously diagnose and treat in the future. For patient care, LLMs can be used for triage suggestions, summarization of medical documents, explanation of a patient’s condition, and customizing patient education materials tailored to their comprehension level. The limitations of LLMs and possible solutions for real-world use are also presented. Given the rapid advancements in this area, this review attempts to briefly cover many roles that LLMs may play in the ophthalmic space, with a focus on improving the quality of healthcare delivery.}
}
@article{CHERREZOJEDA2025101071,
title = {How accurate are ChatGPT-4 responses in chronic urticaria? A critical analysis with information quality metrics},
journal = {World Allergy Organization Journal},
volume = {18},
number = {7},
pages = {101071},
year = {2025},
issn = {1939-4551},
doi = {https://doi.org/10.1016/j.waojou.2025.101071},
url = {https://www.sciencedirect.com/science/article/pii/S1939455125000481},
author = {Ivan Cherrez-Ojeda and Marco Faytong-Haro and Patricio Alvarez-Muñoz and José Ignacio Larco and Erika {de Arruda Chaves} and Isabel Rojo and Carol Vivian Moncayo and German D. Ramon and Gabriela Rodas-Valero and Emek Kocatürk and Giselle S. Mosnaim and Karla Robles-Velasco},
keywords = {Artificial intelligence, Generative artificial intelligence, Chronic urticaria},
abstract = {Background
The increasing use of artificial intelligence (AI) in healthcare, especially in delivering medical information, prompts concerns over the reliability and accuracy of AI-generated responses. This study evaluates the quality, reliability, and readability of ChatGPT-4 responses for chronic urticaria (CU) care, considering the potential implications of inaccurate medical information.
Objective
The goal of the study was to assess the quality, reliability, and readability of ChatGPT-4 responses to inquiries on CU management in accordance with international guidelines, utilizing validated metrics to evaluate the effectiveness of ChatGPT-4 as a resource for medical information acquisition.
Methods
Twenty-four questions were derived from the EAACI/GA2LEN/EuroGuiDerm/APAAACI recommendations and utilized as prompts for ChatGPT-4 to obtain responses in individual chats for each question. The inquiries were categorized into 3 groups: A.) Classification and Diagnosis, B.) Assessment and Monitoring, and C.) Treatment and Management Recommendations. The responses were separately evaluated by allergy specialists utilizing the DISCERN instrument for quality assessment, Journal of the American Medical Association (JAMA) benchmark criteria for reliability evaluation, and Flesch scores for readability analysis. The scores were further examined by median calculations and Intraclass Correlation Coefficient assessments.
Results
Categories A and C exhibited insufficient reliability according to JAMA, with median scores of 1 and 0, respectively. Category B exhibited a low reliability score (median 2, interquartile range 2). The information quality from category C questions was satisfactory (median 51.5, IQR 12.5). All 3 groups exhibited confusing readability levels according to the Flesch assessment.
Limitations
The study's limitations encompass the emphasis on CU, possible bias in question selection, the use of particular instruments such as DISCERN, JAMA, and Flesch, as well as reliance on expert opinion for assessment.
Conclusion
ChatGPT-4 demonstrates potential for producing medical content; nonetheless, its reliability is shaky underscoring the necessity for caution and confirmation when employing AI-generated medical information, especially in the management of CU.}
}
@article{VAUGHN2024101487,
title = {Enhancing Healthcare Education: Leveraging ChatGPT for Innovative Simulation Scenarios},
journal = {Clinical Simulation in Nursing},
volume = {87},
pages = {101487},
year = {2024},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2023.101487},
url = {https://www.sciencedirect.com/science/article/pii/S1876139923001019},
author = {Jacqueline Vaughn and Shannon H. Ford and Melissa Scott and Carolyn Jones and Allison Lewinski},
keywords = {generative artificial intelligence, ChatGPT, simulation, Scenario Design},
abstract = {Background
Developing simulation scenarios for implementation in nursing programs is labor intensive and time consuming. The purpose of this study was to determine if ChatGPT could create accurate and realistic simulation scenarios efficiently to assist faculty in healthcare education.
Methods
ChatGPT was used to create five healthcare simulations. The scenarios were sent to 18 peer reviewers who evaluated them using a 25-question Likert scale survey, which also included opportunities to provide qualitative feedback.
Results
Data analysis revealed that scenarios varied in terms of realism regarding patient profile, history, present illness and the way the scenario unfolded. Also noted was that pertinent information was missing in all scenarios however, the information generated was accurate. Most of the reviewer comments were positive and many were surprised at the amount of overall information included in each scenario.
Conclusions
ChatGPT is a powerful AI tool that has the potential to help simulation educators develop simulation scenarios. However, at present, caution needs to be employed, considering its current limitations.}
}
@article{SACHER2024,
title = {Impact of a Health Coach–Led, Text-Based Digital Behavior Change Intervention on Weight Loss and Psychological Well-Being in Patients Receiving a Procedureless Intragastric Balloon Program: Prospective Single-Arm Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/54723},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24004207},
author = {Paul M Sacher and Emily Fulton and Victoria Rogers and Julia Wilson and Marco Gramatica and Jennifer E Dent and Edo O Aarts and David Eccleston and Jan Willem Greve and Inge Palm-Meinders and Ram Chuttani},
keywords = {intragastric balloon, obesity, behavior change, health coaching, digital health, weight management, well-being, mobile phone},
abstract = {Background
Digital health interventions show promise for weight management. However, few text-based behavior change interventions have been designed to support patients receiving intragastric balloons, and none have simultaneously evaluated weight loss, psychological well-being, and behavior change despite the crucial interplay of these factors in weight management.
Objective
This study aims to assess whether a health coach–led, asynchronous, text-based digital behavior change coaching intervention (DBCCI) delivered to participants receiving an intragastric balloon and its aftercare program was feasible and acceptable to participants and supported improved outcomes, including weight loss, psychological well-being, and lifestyle behavior change conducive to weight loss maintenance.
Methods
This 12-month, single-arm prospective study enrolled adults aged 21 to 65 years with BMI ≥27 kg/m2 receiving a procedureless intragastric balloon (PIGB) at 5 bariatric clinics in the United Kingdom and the Netherlands. Participants received the DBCCI and the clinic-led PIGB aftercare program (remotely delivered) for 6 months after PIGB placement and then no intervention for an additional 6 months. The DBCCI was an evidence-based, personalized intervention wherein health coaches supported participants via exchanged asynchronous in-app text-based messages. Over the 12-month study, we assessed percentage of total body weight loss and psychological well-being via self-administered validated questionnaires (Warwick-Edinburgh Mental Wellbeing Scale, Generalized Anxiety Disorder Scale, Impact of Weight on Quality of Life–Lite–Clinical Trials Version, Loss of Control Over Eating Scale–Brief, Weight Efficacy Lifestyle Questionnaire–Short Form, and Barriers to Being Active Quiz). Participant engagement with and acceptability of the intervention were assessed via self-reported surveys.
Results
Overall, 107 participants (n=96, 89.7% female; mean baseline BMI 35.4, SD 5.4 kg/m2) were included in the analysis. Mean total body weight loss was 13.5% (SEM 2.3%) at the end of the DBCCI and 11.22% (SEM 2.3%) at the 12-month follow-up (P<.001). Improvements were observed for all psychological well-being measures throughout the 12 months except for the Generalized Anxiety Disorder Scale (improvement at month 1) and Barriers to Being Active Quiz (improvements at months 3 and 6). Surveys showed high levels of engagement with and acceptability of the DBCCI.
Conclusions
This study provides evidence that the health coach–led, asynchronous, text-based DBCCI was engaging and acceptable to participants with overweight and obesity. The DBCCI, delivered alongside the PIGB and its aftercare program, supported improved weight loss outcomes and psychological well-being versus baseline and was associated with lifestyle behavior changes known to help achieve and maintain long-term weight loss and improved health outcomes. Follow-up findings suggest a potential need for longer-term, more intense coaching to focus on weight loss maintenance and support ongoing self-coaching. This could be achieved by leveraging generative artificial intelligence to provide ongoing automated behavior change coaching support to augment human-led care.
Trial Registration
ClinicalTrials.gov NCT05884606; https://clinicaltrials.gov/study/NCT05884606}
}
@article{DAS2025100213,
title = {Generative AI for drug discovery and protein design: the next frontier in AI-driven molecular science},
journal = {Medicine in Drug Discovery},
volume = {27},
pages = {100213},
year = {2025},
issn = {2590-0986},
doi = {https://doi.org/10.1016/j.medidd.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2590098625000107},
author = {Uddalak Das},
keywords = {Generative AI, Molecular design, Protein engineering, Diffusion models, Drug discovery},
abstract = {Generative artificial intelligence (AI) has emerged as a disruptive paradigm in molecular science, enabling algorithmic navigation and construction of chemical and proteomic spaces through data-driven modeling. This review systematically delineates the theoretical underpinnings, algorithmic architectures, and translational applications of deep generative models—including variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive transformers, and score-based denoising diffusion probabilistic models (DDPMs)—in the rational design of bioactive small molecules and functional proteins. We examine the role of latent space learning, probabilistic manifold exploration, and reinforcement learning in inverse molecular design, focusing on optimization of pharmacologically relevant objectives such as ADMET profiles, synthetic accessibility, and target affinity. Furthermore, we survey advancements in graph-based molecular generative frameworks, LLM-guided protein sequence modeling, and diffusion-based structural prediction pipelines (e.g., RFdiffusion, FrameDiff), which have demonstrated state-of-the-art performance in de novo protein engineering and conformational sampling. Generative AI is also catalyzing a paradigm shift in structure-based drug discovery via AI-augmented molecular docking (e.g., DiffDock), end-to-end binding affinity prediction, and quantum chemistry-informed neural potentials. We explore the convergence of generative models with Bayesian retrosynthesis planners, self-supervised pretraining on ultra-large chemical corpora, and multimodal integration of omics-derived features for precision therapeutics. Finally, we discuss translational milestones wherein AI-designed ligands and proteins have progressed to preclinical and clinical validation, and speculate on the synthesis of generative AI, closed-loop automation, and quantum computing in future autonomous molecular design ecosystems.}
}
@article{SAQIB20241430,
title = {Evaluation of AI content generation tools for verification of academic integrity in higher education},
journal = {Journal of Applied Research in Higher Education},
volume = {17},
number = {4},
pages = {1430-1440},
year = {2024},
issn = {2050-7003},
doi = {https://doi.org/10.1108/JARHE-10-2023-0470},
url = {https://www.sciencedirect.com/science/article/pii/S205070032400007X},
author = {Muhammad Bilal Saqib and Saba Zia},
keywords = {Chatbot, Generative AI, ChatGPT, LLM, AI content detectors, AI writing},
abstract = {Purpose
The notion of using a generative artificial intelligence (AI) engine for text composition has gained excessive popularity among students, educators and researchers, following the introduction of ChatGPT. However, this has added another dimension to the daunting task of verifying originality in academic writing. Consequently, the market for detecting artificially generated content has seen a mushroom growth of tools that claim to be more than 90% accurate in sensing artificially written content.
Design/methodology/approach
This research evaluates the capabilities of some highly mentioned AI detection tools to separate reality from their hyperbolic claims. For this purpose, eight AI engines have been tested on four different types of data, which cover the different ways of using ChatGPT. These types are Original, Paraphrased by AI, 100% AI generated and 100% AI generated with Contextual Information. The AI index recorded by these tools against the datasets was evaluated as an indicator of their performance.
Findings
The resulting figures of cumulative mean validate that these tools excel at identifying human generated content (1.71% AI content) and perform reasonably well in labelling AI generated content (76.85% AI content). However, they are perplexed by the scenarios where the content is either paraphrased by the AI (39.42% AI content) or generated by giving a precise context for the output (60.1% AI content).
Originality/value
This paper evaluates different services for the detection of AI-generated content to verify academic integrity in research work and higher education and provides new insights into their performance.}
}
@article{MASROURI2024102230,
title = {Generative AI model trained by molecular dynamics for rapid mechanical design of architected graphene},
journal = {Extreme Mechanics Letters},
volume = {72},
pages = {102230},
year = {2024},
issn = {2352-4316},
doi = {https://doi.org/10.1016/j.eml.2024.102230},
url = {https://www.sciencedirect.com/science/article/pii/S235243162400110X},
author = {Milad Masrouri and Kamalendu Paul and Zhao Qin},
keywords = {Architected graphene, Molecular dynamics, Stable Diffusion, Low Rank Adaptation, Von Mises stress field},
abstract = {Generative artificial intelligence (AI) is shown to be a useful tool to automatically learn from existing information and generate new information based on their connections, but its usage for quantitative mechanical research is less understood. Here, we focus on the structure-mechanics relationship of architected graphene as graphene with void defects of specific patterns. We use Molecular Dynamics (MD) to simulate uniaxial tension on architected graphene, extract the von Mises stress field in mechanical loading, and use the results to train a fine-tuned generative AI model through a Low-Rank Adaptation method. This model enables the freely designed architected graphene structures and predicts its associated stress field in uniaxial tension loading through simple descriptive language. We demonstrate that the fine-tuned model can be established with a few training images and can quantitatively predict the stress field for graphene with various defect geometries and distributions not included in the training set. We validate the accuracy of the stress field with MD simulations. Moreover, we illustrate that our generative AI model can predict the stress field from a schematic drawing of the architected graphene through image-to-image generation. These features underscore the promising future for employing advanced generative AI models in end-to-end advanced nanomaterial design and characterization, enabling the creation of functional, structural materials without using complex numerical modeling and data processing.}
}
@article{HAWASHIN2025100754,
title = {Using GenAI and blockchain for enhanced user experience in Metaverse-based therapy sessions},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100754},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100754},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001691},
author = {Diana Hawashin and Khaled Salah and Raja Jayaraman and Samer Ellaham and Ibrar Yaqoob},
keywords = {Therapy sessions, Metaverse, GenAI, LLM, Blockchain, Virtual healthcare},
abstract = {As awareness of mental health issues rises, the demand for accessible and effective therapy becomes more urgent. However, existing digital therapy platforms fall short of providing personalization and real-time interaction, often leading to generic and ineffective responses that fail to meet individual psychological needs. These platforms rely on costly therapists or inadequately trained assistants, which limits their effectiveness. Additionally, the centralized systems used to manage therapy sessions lack adequate traceability, trust, and security, which are critical for users’ confidence in the process. In this paper, we present a blockchain-based solution integrated with Generative Artificial Intelligence (GenAI) to deliver superior Metaverse-based therapy sessions that are decentralized, traceable, trustworthy, secure, and access-controlled. We fine-tune a Generative Pre-trained Transformer (GPT)-3.5 model to provide personalized and context-aware responses in real time, enhancing user experience and engagement. The proposed system achieves a ROUGE-1 score of 0.5147 and a ROUGE-L score of 0.4048, demonstrating its effectiveness in generating relevant responses. A cost analysis reveals that user access control operations incur the highest gas costs, while simpler operations remain cost-efficient. Compared to existing digital mental health platforms, our system offers superior access control, automation, security, and user interaction through the integration of blockchain, NFTs, and decentralized storage. These features, combined with GenAI for real-time interaction, have the potential to significantly improve user experience and engagement in Metaverse-based therapy sessions}
}
@article{KUMAR2025102993,
title = {Advances in DeepFake detection algorithms: Exploring fusion techniques in single and multi-modal approach},
journal = {Information Fusion},
volume = {118},
pages = {102993},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102993},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000661},
author = {Ashish Kumar and Divya Singh and Rachna Jain and Deepak Kumar Jain and Chenquan Gan and Xudong Zhao},
keywords = {DeepFake, Artificial intelligence, Generative adversarial network, Fusion algorithms, Transformer, Detection},
abstract = {In recent years, generative artificial intelligence has gained momentum and created extremely realistic synthetic multimedia content that can spread misinformation and mislead society. Deepfake detection is a technique consisting of frameworks, algorithms and approaches to predict manipulated contents namely, image, audio and video. To this end, we have analyzed and explored various deepfake detection frameworks by categorizing them as single-modal or multi-modal approaches. To provide better understanding and clarity, single-modal approaches are further categorized as conventional and advanced techniques. Conventional techniques extract complementary handcrafted features and classify them using machine-learning-based algorithms. On the other hand, advanced techniques adopt deep learning and hybrid algorithms to detect deepfakes. Multi-modal techniques utilize a mixture of two or more modalities for feature extraction and fuse them to obtain the final classification scores. These techniques are also categorized either as deep learning or hybrid techniques. The complementary features, multiple modalities, and deep learning models are fused adaptively using score-level or feature-level fusion. The advantages, features, practical applications, and limitations under each category are highlighted to address the challenges and determine future trends to counter deepfakes. In addition, recommendations are also elaborated to evaluate the potential of artificial intelligence in deepfake detection for providing a safer and more reliable digital world.}
}
@article{SABOUNI2025,
title = {From Hype to Implementation: Embedding GPT-4o in Medical Education},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/79309},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001357},
author = {Sumaia Sabouni and Mohammad-Adel Moufti and Mohamed Hassan Taha},
keywords = {multimodal generative pretraining transformers, GPT-4o, artificial intelligence, interactive learning, medical education},
abstract = {The release of GPT-4 Omni (GPT-4o), an advanced multimodal generative artificial intelligence (AI) model, generated substantial enthusiasm in the field of higher education. However, one year later, medical education continues to face significant challenges, demonstrating the need to move from initial experimentation with the integration of multimodal AIs in medical education toward meaningful integration. In this Viewpoint, we argue that GPT-4o’s true value lies not in novelty, but in its potential to enhance training in communication skills, clinical reasoning, and procedural skills by offering real-time simulations and adaptive learning experiences using text, audio, and visual inputs in a safe, immersive, and cost-effective environment. We explore how this innovation has made it possible to address key medical educational challenges by simulating realistic patient interactions, offering personalized feedback, and reducing educator workloads and costs, where traditional teaching methods struggle to replicate the complexity and dynamism of real-world clinical scenarios. However, we also address the critical challenges of this approach, including data accuracy, bias, and ethical decision-making. Rather than seeing GPT-4o as a replacement, we propose its use as a strategic supplement, scaffolded into curriculum frameworks and evaluated through ongoing research. As the focus shifts from AI novelty to sustainable implementation, we call on educators, policymakers, and curriculum designers to establish governance mechanisms, pilot evaluation strategies, and develop faculty training. The future of AI in medical education depends not on the next breakthrough, but on how we integrate today’s tools with intention and rigor.}
}
@article{RUIZ2025104293,
title = {Artificial intelligence-created personal statements compared with applicant-written personal statements: a survey of obstetric anesthesia fellowship program directors in the United States},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104293},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003054},
author = {A.M. Ruiz and M.B. Kraus and K.W. Arendt and D.R. Schroeder and E.E. Sharpe},
keywords = {Artificial intelligence, Generative AI, Medical education, Obstetric anesthesia, Personal statements, Fellowship},
abstract = {Background
A personal statement is a common requirement in medical residency and fellowship applications. Generative artificial intelligence may be used to create a personal statement for these applications.
Methods
Two personal statements were created using OpenAI’s Chat Generative Pre-trained Transformer (ChatGPT) and two applicant-written statements were collected. A survey was sent to obstetric anesthesia fellowship program directors in the United States to assess the perceived readability, authenticity, and originality of the four personal statements. In addition, the survey assessed perceptions of applicants who use artificial intelligence to write a personal statement, including their integrity, work ethic, reliability, intelligence, and English proficiency.
Results
Surveyed fellowship directors could not accurately discern whether statements were applicant-written or artificial intelligence-generated. The artificial intelligence-generated personal statements were rated as more readable and original than the applicant-written statements. Most program directors were moderately or extremely concerned about the applicant’s integrity, work ethic, and reliability if they suspected the applicant utilized ChatGPT.
Conclusions
Program directors could not accurately discern if the statements were written by a person or artificial intelligence and would have concerns about an applicant suspected of using artificial intelligence. Medical training programs may benefit from outlining their expectations regarding applicants’ use of artificial intelligence.}
}
@article{BELANCHE2025102954,
title = {Customer reactions to generative AI vs. real images in high-involvement and hedonic services},
journal = {International Journal of Information Management},
volume = {85},
pages = {102954},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102954},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000866},
author = {Daniel Belanche and Sergio Ibáñez-Sánchez and Pau Jordán and Sergio Matas},
keywords = {Generative artificial intelligence, AI-generated images, Hedonic services, Utilitarian services, Consumer involvement level, ChatGPT, Midjourney},
abstract = {Given the emerging opportunities of generative AI for business and marketing, many companies are wondering whether they should use images created through generative AI for commercial purposes. Prior research on hospitality communication has not solved this issue, as AI-generated images are occasionally promoted as effective marketing tools across various service contexts, while other scholars caution against their use due to the significant concerns they may trigger among consumers. Following a mixed-methods approach to find boundary conditions, our research reveals that consumers prefer hospitality services advertised with real images, rather than those featuring AI-generated images. Nevertheless, this effect is moderated by two key factors. In particular, the research reveals that the negative influence of using generative AI images on intentions to use and recommend the service are strengthened for hedonic rather than utilitarian services, and for highly rather than lowly involved customers. A qualitative study further explores the reasons behind this rejection, highlighting that customers perceive companies using AI-generated images as impersonal, less professional, lacking credibility, and potentially misleading, as they impede customers’ ability to envision the actual experience. Implications for management suggest that, while generative AI holds promise for enhancing communication, companies should use AI-generated images with caution. The discussion also proposes future research directions to explore the broader implications of AI use in marketing.}
}
@article{ZHOU2026104006,
title = {CADialogue: A multimodal LLM-powered conversational assistant for intuitive parametric CAD modeling},
journal = {Computer-Aided Design},
volume = {191},
pages = {104006},
year = {2026},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2025.104006},
url = {https://www.sciencedirect.com/science/article/pii/S0010448525001678},
author = {Jiwei Zhou and Jorge D. Camba and Pedro Company},
keywords = {Large Language Models (LLMs), Computer-Aided Design (CAD), Interactive design, Human-Computer Interaction (HCI), Parametric modeling, Programming-based CAD},
abstract = {Recent advances in generative Artificial Intelligence (AI)—particularly Large Language Models (LLMs)—offer a new paradigm for CAD interaction by enabling natural and intuitive input through texts, images, and context-aware selections. In this study, we present CADialogue, a multimodal LLM-powered conversational assistant to enable intuitive parametric CAD modeling through natural language, speech, image, and selection-based geometry interactions. Built on a general-purpose large language model, CADialogue translates user prompts into executable code to support geometry creation and context-aware editing. The system features a modular architecture that decouples prompt handling, refinement logic, and execution—allowing seamless model replacement as LLMs develop—and includes caching for rapid reuse of validated designs. We evaluate the system on 70 modeling and 10 editing tasks across varying difficulty levels, assessing performance in terms of accuracy, refinement behavior, and execution time. Results show an overall success rate of 95.71%, combining a 91.43% baseline under Text-Only input with additional recoveries enabled by Text + Image input, with robust recovery from failure via self-correction and human-in-the-loop refinement. Comparative analysis reveals that image input improves success in semantically complex prompts but introduces additional processing time. Furthermore, caching confirmed macros yields over 85.71% speedup in repeated executions. These findings highlight the potential of general-purpose LLMs for enabling accessible, iterative, and accurate CAD modeling workflows without domain-specific fine-tuning. The source code and dataset for CADialogue are available at https://github.com/Hiram31/CADialogue.}
}
@article{CHIU2024100197,
title = {Future research recommendations for transforming higher education with generative AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100197},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100197},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000760},
author = {Thomas K.F. Chiu},
keywords = {Generative artificial intelligence, ChatGPT, Learning outcomes, AI literacy, Assessment},
abstract = {Higher education is crucial for producing ethical citizens and professionals globally. The introduction of generative AI (GenAI), such as ChatGPT, has posed opportunities and challenges to the traditional model of education. However, the current conversations primarily focus on policy development and assessment, with limited research on the future of higher education. GenAI's impact on learning outcomes, pedagogy, and assessment is crucial for reforming and advancing the workforce. This qualitative study aims to investigate student perspectives on GenAI's impact on higher education. The study uses an initial conceptual framework driven by a systematic literature review to investigate the opportunities and challenges of AI in education. This framework serves as an initial data collection and analysis framework. A sample of 51 students from three research-intensive universities was selected for this study. Thematic analysis identified three themes and 10 subthemes. The findings suggest that future higher education should be transformed to train students to be future-ready for employment in a society powered by GenAI. They suggest new learning outcomes—skills in learning and teaching with GenAI, AI literacy—and emphasize the significance of interdisciplinarity and maker learning, with assessment focusing on in-class and hands-on activities. They recommend six future research directions – competence for future workforce and its self-assessment measures, AI literacy or competency measures, new literacies and their relationships, interdisciplinary teaching, Innovative pedagogies and their evaluation, new assessment and its acceptance.}
}
@article{RAY2024174,
title = {Large language models in laparoscopic surgery: A transformative opportunity},
journal = {Laparoscopic, Endoscopic and Robotic Surgery},
volume = {7},
number = {4},
pages = {174-180},
year = {2024},
issn = {2468-9009},
doi = {https://doi.org/10.1016/j.lers.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468900924000483},
author = {Partha Pratim Ray},
keywords = {Large language model, Artificial intelligence, Generative artificial intelligence, Laparoscopy, Surgery},
abstract = {This opinion paper explores the transformative potential of large language models (LLMs) in laparoscopic surgery and argues for their integration to enhance surgical education, decision support, reporting, and patient care. LLMs can revolutionize surgical education by providing personalized learning experiences and accelerating skill acquisition. Intelligent decision support systems powered by LLMs can assist surgeons in making complex decisions, optimizing surgical workflows, and improving patient outcomes. Moreover, LLMs can automate surgical reporting and generate personalized patient education materials, streamlining documentation and improving patient engagement. However, challenges such as data scarcity, surgical semantic capture, real-time inference, and integration with existing systems need to be addressed for successful LLM integration. The future of laparoscopic surgery lies in the seamless integration of LLMs, enabling autonomous robotic surgery, predictive surgical planning, intraoperative decision support, virtual surgical assistants, and continuous learning. By harnessing the power of LLMs, laparoscopic surgery can be transformed, empowering surgeons and ultimately benefiting patients.}
}
@article{ZHOU2025110090,
title = {Forward and inverse adversarial model applying to well-logging},
journal = {Engineering Applications of Artificial Intelligence},
volume = {144},
pages = {110090},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110090},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625000909},
author = {Jun Zhou and Juan Zhang and Rongbo Shao and Lizhi Xiao and Guangzhi Liao},
keywords = {Generative artificial intelligence, Well logging, Forward model, Inverse model, Machine learning},
abstract = {Geophysical logging is critical for reservoir characterization but is limited by the small sample problem in machine learning. To address this, we propose the Forward and Inverse Adversarial Model (FIAM), which borrows the training method from generative adversarial networks and applies to geophysical logging. The FIAM includes a forward model for generating synthetic logging data and an inverse model for predicting reservoir parameters. These models are trained using an adversarial process, enabling continuous improvement without large labeled datasets. In the case study with exploration logging data, the FIAM enhances reservoir parameter prediction effect and maps the relationship between logging curves and reservoir parameters by pure data-driven training. The inverse model is pre-trained by measured data and then guides the forward model to generate logging data based on virtual reservoir parameters. Both models are trained alternately until no further improvement is achieved. Experimental results on oilfield datasets show that the FIAM improves reservoir parameter predictions by more than 30% when facing the small sample problem. The FIAM demonstrates significant potential for improving reservoir parameters prediction with small sample dataset, advancing both artificial intelligence methodologies and practical engineering applications.}
}
@article{CAI2025103373,
title = {Differentially private synthetic data generation for robust information fusion},
journal = {Information Fusion},
volume = {124},
pages = {103373},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103373},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004464},
author = {Xiaohong Cai and Yi Sun and Zhaowen Lin and Ripeng Li and Tianwei Cai},
keywords = {Generative artificial intelligence, Fusion, Differential privacy, Fine-tuning},
abstract = {Synthetic data is crucial in information fusion in term of enhancing data representation and improving system robustness. Among all synthesis methods, deep generative models exhibit excellent performance. However, recent studies have shown that the generation process faces privacy challenges due to the memorization of training instances by generative models. To maximize the benefits of synthesis data while ensuring data security, we propose a novel framework for the generation and utilization of private synthetic data in information fusion processes. Furthermore, we present differential private adaptive fine-tuning (DP-AdaFit), a method for private parameter efficient fine-tuning that applies differential privacy only to the singular values of the incremental updates. In details, DP-AdaFit adaptively adjusts the rank of the low-rank weight increment matrices according to their importance score, and allows us to achieve an equivalent privacy policy by only injecting noise into gradient of the corresponding singular values. Such a novel approach essentially reduces their parameter budget but avoids too much noise introduced by the singular value decomposition. We decrease the cost on memory and computation nearly half of the SOTA, and achieve the FID of 19.2 on CIFAR10. Our results demonstrate that trading off weights contained in the differential privacy fine-tuning parameters can improve model performance, even achieving generation quality competitive with differential privacy full fine-tuning diffusion model. Our code is available at DP-AdaFit.}
}
@article{CELIKTEN20243351,
title = {HybridGAD: Identification of AI-Generated Radiology Abstracts Based on a Novel Hybrid Model with Attention Mechanism},
journal = {Computers, Materials and Continua},
volume = {80},
number = {2},
pages = {3351-3377},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.051574},
url = {https://www.sciencedirect.com/science/article/pii/S154622182400537X},
author = {Tuğba Çelikten and Aytuğ Onan},
keywords = {Generative artificial intelligence, AI-generated text detection, attention mechanism, hybrid model for text classification},
abstract = {The purpose of this study is to develop a reliable method for distinguishing between AI-generated, paraphrased, and human-written texts, which is crucial for maintaining the integrity of research and ensuring accurate information flow in critical fields such as healthcare. To achieve this, we propose HybridGAD, a novel hybrid model that combines Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM), and Bidirectional Gated Recurrent Unit (Bi-GRU) architectures with an attention mechanism. Our methodology involves training this hybrid model on a dataset of radiology abstracts, encompassing texts generated by AI, paraphrased by AI, and written by humans. The major findings of our analysis indicate that HybridGAD achieves a high accuracy of 98%, significantly outperforming existing state-of-the-art models. This high performance is attributed to the model’s ability to effectively capture the contextual nuances and structural differences between AI-generated and human-written texts. In conclusion, HybridGAD not only enhances the accuracy of text classification in the field of radiology but also paves the way for more advanced medical diagnostic processes by ensuring the authenticity of textual information. Future research will focus on integrating textual and visual data for comprehensive radiology assessments and improving model generalization with partially labeled data. This study underscores the potential of HybridGAD in transforming medical text classification and highlights its applicability in ensuring the integrity and reliability of research in healthcare and beyond.}
}
@article{RACHANAHARISH2025103366,
title = {Collaborative garment design through group chatting with generative industrial large models},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103366},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103366},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625002599},
author = {Arjun {Rachana Harish} and Zhaolin Yuan and Ming Li and Hongxia Yang and George Q. Huang},
keywords = {Collaborative Garment Design, Industrial Large Model, Generative Artificial Intelligence, Group Chat, Transformer},
abstract = {The collaborative garment designing lifecycle involves stages such as designing, styling, and patterning. Some of these stages can be partially or fully automated using industrial large models (LMs), such as generative and large language models. The key to quick and cost-effective order fulfillment is the orchestration of group interactions, or a group chat, between the stakeholders and LMs in garment design. However, certain unaddressed aspects, such as knowledge retention, generalization, and complexity of group interaction, are critical to realizing group chat for garment design. This study proposes a framework called ChatFashion for group chat in garment design. Transformer, a core construct of the proposed framework, orchestrates interaction among stakeholders and industrial LMs. It undergoes an evolution with the intelligence it picks up from its interaction with diverse stakeholders and industrial LMs, allowing it to act as a one-stop solution for multidisciplinary design needs. This study contributes to theory in the following aspects. First, it proposes transformers to eliminate concerns about knowledge retention by industrial LMs. Second, while other studies focus on the benefits of industrial LMs to simplify individual stages in garment design, this study introduces the design and demonstration of a ChatFashion framework for collaborative garment designing using industrial LMs. Finally, this study advances the literature on prompt engineering of industrial LMs by utilizing collaborative learning (or models learning from each other) to capture and orchestrate the group chat among stakeholders, signifying its practicality and value for research in garment design.}
}
@article{DENHOLM2025100842,
title = {Virtual Histological Staining as a Tool for Extending Renal Segmentation Across Stains},
journal = {Modern Pathology},
volume = {38},
number = {12},
pages = {100842},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2025.100842},
url = {https://www.sciencedirect.com/science/article/pii/S0893395225001395},
author = {James Denholm and Azam Hamidinekoo and Nikolay Burlutskiy and Laura C. Setyo and Irina Zhang and Fariba Yousefi and Jack Mortimer and Joana Palés Huix and Christopher Bagnall and Arthur Lewis and Heather E. Hulme and Robert Unwin and Simon T. Barry and Richard J.A. Goodwin and Ferdia A. Gallagher and Magnus Söderberg and Talha Qaiser},
keywords = {chronic kidney disease, computational pathology, generative artificial intelligence, National Unified Renal Translational Research Enterprise, renal pathology, virtual staining},
abstract = {In renal histopathology, the routine clinical use of several histological stains presents challenges for the direct application of stain-specific deep learning–based analysis tools to whole-slide images. We present an approach to the in silico histological staining of kidney tissue where samples stained with hematoxylin and eosin (H&E) are virtually restained with periodic acid-Schiff (PAS). Our approach is underpinned by cycle-consistent generative adversarial neural networks trained on the National Unified Renal Translational Research Enterprise data set—the first UK-wide Biobank for chronic kidney disease—which features diverse data from 16 nephrology centers. Our work is divided into the following 4 main components: (1) we developed a virtual staining model, which infers PAS staining from H&E; (2) 2 board-certified pathologists assessed the virtual staining by attempting to distinguish it from real examples; (3) we trained a glomerular segmentation model using 3 independent renal segmentation data sets (Kidney Precision Medicine Project, Human BioMolecular Atlas Program [Kidney], and data by Jayapandian et al); and (4) we demonstrated the utility of virtual staining by inferring PAS staining from previously unseen H&E test images and applying our PAS-specific glomerular segmentation model. Each pathologist was able to identify 52.5% and 75.8% of the virtually stained images, respectively, showing an overlap in the variability of the authentic and synthetic staining. We discussed the utility of virtual staining in digital pathology, the need for pathology-specific testing with respect to chronic damage, and minimal changes and steps for incorporating more stains. Furthermore, alongside this article, we included complete glomerular annotations for 20 Kidney Precision Medicine Project H&E-stained slides.}
}
@article{STEVENS2025100831,
title = {A Comparison of Artificial Intelligence Platforms in the Utility of Answering Frequently Asked Questions About Carpal Tunnel Syndrome: A Cross-Sectional Study},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100831},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100831},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001513},
author = {Calista Stevens and Mehreen Pasha and Dashun Liu and Andrew Block and Anthony Parrino and Craig Rodner},
keywords = {Carpal tunnel syndrome, Generative artificial intelligence, Hand, Orthopedic surgery},
abstract = {Purpose
The rise of artificial intelligence (AI) in health care comes with increasing concerns about the use and integrity of the information it generates. Chat Generative Pre-Trained Transformer (ChatGPT) 3.5, Google Gemini, and Bing Copilot are free AI chatbot platforms that may be used for answering medical questions and disseminating medical information. Given that carpal tunnel syndrome accounts for 90% of all neuropathies, it is important to understand the accuracy of the information patients may be receiving. The purpose of this study is to determine the use and accuracy of responses generated by ChatGPT, Google Gemini, and Bing Copilot in answering frequently asked questions about carpal tunnel syndrome.
Methods
Two independent authors scored responses using the DISCERN tool. DISCERN consists of 15 questions assessing health information on a five-point scale, with total scores ranging from 15 to 75 points. Then, a two-factor analysis of variance was conducted, with scorer and chatbot type as the factors.
Results
One-way analysis of variance revealed no significant difference in DISCERN scores among the three chatbots. The chatbots each scored in the “fair” range, with means of 45 for ChatGPT, 48 for Bing Copilot, and 46 for Google Gemini. The average Journal of the American Medical Association score for ChatGPT and Google Gemini surpassed that of Bing Copilot, with averages of 2.3, 2.3, and 1.8, respectively.
Conclusions
ChatGPT, Google Gemini, and Bing Copilot platforms generated relatively reliable answers for potential patient questions about carpal tunnel syndrome. However, users should continue to be aware of the shortcomings of the information provided, given the lack of citations, potential for misconstrued information, and perpetuated biases that inherently come with using such platforms. Future studies should explore the response quality for less common orthopedic pathologies and assess patient perceptions of response readability to determine the value of AI as a patient resource across the medical field.
Type of study/level of evidence
Cross-sectional study V}
}
@article{HU2025100979,
title = {Enhancing student engagement in online collaborative writing through a generative AI-based conversational agent},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100979},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2024.100979},
url = {https://www.sciencedirect.com/science/article/pii/S1096751624000411},
author = {Wanqing Hu and Jirong Tian and Yanyan Li},
keywords = {Student engagement, Online collaborative writing, Conversational agents, Generative artificial intelligence, Retrieval-augmented generation},
abstract = {Promoting student engagement in online collaborative writing (OCW) activities has been a critical concern for educators. Previous research has attempted to design conversational agents (CAs) utilizing retrieval-based models to engage students in collaborative learning. However, few studies have yet explored the design of CAs for OCW based on generative AI (GAI) models. Researchers are calling for investigations into how GAI technology can be better utilized to support learning. Addressing this gap, this study integrates advanced AI technologies (i.e. the retrieval-based model, GAI model, and retrieval-augmented generation) to develop a CA aimed at enhancing students' engagement in OCW activities. Furthermore, a quasi-experiment involving 78 undergraduate students was conducted to explore the effects of this CA on students' engagement (including behavioral, cognitive, and emotional engagement) and group writing performance. The results indicate that the CA did not significantly impact behavioral engagement, emotional engagement, or group writing performance. However, it was found to significantly enhance students' cognitive engagement, particularly by supporting students in sharing opinions, explaining concepts, and engaging in analysis. This research offers both theoretical and practical implications for better utilizing GAI technology to facilitate OCW activities.}
}
@article{ZENG2025120578,
title = {Data-driven structural generative design based on diffusion model for flexible support of optical mirror},
journal = {Engineering Structures},
volume = {338},
pages = {120578},
year = {2025},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2025.120578},
url = {https://www.sciencedirect.com/science/article/pii/S0141029625009691},
author = {Chaoqun Zeng and Jiaying Wang and Wei Wang and Kuo Hai and Shaoxing Ma and Lei Wei},
keywords = {Airborne optical system, Flexible support, Data-driven generative design, Diffusion model, Performance-guided sketch generation},
abstract = {Generative artificial intelligence has enabled new structural design methods, allowing for rapid generation of complex designs. High-end equipment in aerospace, electronics, information, and other fields operates under demanding conditions with stringent performance requirements, making the initial design phase challenging. An example is the design of mirror flexible supports, a critical component in the optical systems of unmanned aerial vehicles that determines their optical precision. Empirical design processes are increasingly inadequate for meeting high-performance and rapid designing for flexible supports under varying conditions. This study proposes a generative structural design approach based on diffusion model to establish the relationship between structural performance and existing sketches. A dataset of flexible support structures is prepared using a maze path-planning algorithm. The method can automatically generate initial feasible design solutions rapidly. A case study involving a 400 millimeter (mm) aperture reflector shows that the designed support achieves a surface shape accuracy of approximately 15 nanometer (nm) at room temperature and under 40 nm at −20 degrees Celsius (℃). Compared to conventional methods, the proposed approach significantly improves design quality and significantly shortens the design cycle. This work contributes to the application of diffusion models in structural designs.}
}
@article{SUN2025103037,
title = {Multi-objective math problem generation using large language model through an adaptive multi-level retrieval augmentation framework},
journal = {Information Fusion},
volume = {119},
pages = {103037},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103037},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525001101},
author = {Jianwen Sun and Wangzi Shi and Xiaoxuan Shen and Shengyingjie Liu and Luona Wei and Qian Wan},
keywords = {Math problem generation, Large language model, Retrieval-augmented generation, Educational application, Generative artificial intelligence},
abstract = {Math problems are an important knowledge carrier and evaluation means in personalized teaching. Their high cost of manual compilation promotes the research of math problem generation. Many previous studies have focused on the generation of math word problems, which are difficult to meet the real teaching needs due to the single task-objective orientation and small differences in generation results. By fusing external knowledge through retrieval-augmented generation (RAG), large language model (LLM) can generate a variety of math problems, but the generated results still have limitations such as poor knowledge consistency, uncontrollability, and high computational cost. In this paper, we propose the task of multi-objective math problem generation (MMPG). This task introduces the triple objectives of generation including “question type, knowledge point and difficulty” in respond to teaching needs in real scene. To the best of our knowledge, this is the first study considering multiple objectives on the process of math problem generation. Based on this, we further design an adaptive multi-level retrieval augmentation framework (AMRAF) for LLM to generate multi-objective math problems. This plug-and-play framework can effectively improve the generation performance without parameter tuning of the target model due to the fine-grained information retrieval and fusion. To verify the effectiveness of the proposed framework and provide a benchmark for subsequent research, we construct an MMPG dataset containing 9,000 samples. Experimental results demonstrate the superiority and effectiveness of our framework.}
}
@article{HUETTEMANN2025102901,
title = {Designing ontology-based search systems for research articles},
journal = {International Journal of Information Management},
volume = {83},
pages = {102901},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2025.102901},
url = {https://www.sciencedirect.com/science/article/pii/S0268401225000337},
author = {Sebastian Huettemann and Roland M. Mueller and Barbara Dinter},
keywords = {Search engines, Ontologies, Domain ontologies, Large language models, Knowledge extraction, Design science research, Literature review},
abstract = {The process of conducting scientific literature reviews is becoming increasingly complex and time-consuming due to the rapid expansion of available research. Popular academic search engines offer limited filtering capabilities and suffer from low precision. Machine learning-enhanced approaches tend to target rather specific areas, and novel approaches based on generative artificial intelligence suffer from hallucinations. Drawing on information foraging theory, this article presents a design science research project aimed at generating design knowledge for developing domain-specific search systems for research articles. Our contributions include: (1) integrating domain ontologies with large language models to design ontology-based search systems, (2) generating descriptive design knowledge by exploring the problem space, (3) generating prescriptive design knowledge for developing domain-specific search systems, and (4) presenting an ontology-based search engine prototype. Our results indicate that the proposed solution supports researchers in conducting literature reviews by increasing information gain while reducing interaction costs.}
}
@article{HERCKIS2025183,
title = {AI-enabled fraud detection, prevention, and perpetration in nursing credential evaluation: A scoping study},
journal = {Journal of Nursing Regulation},
volume = {16},
number = {3},
pages = {183-194},
year = {2025},
note = {Technology and the Nursing Needs of Tomorrow},
issn = {2155-8256},
doi = {https://doi.org/10.1016/j.jnr.2025.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S2155825625000973},
author = {Lauren Herckis and Emily Tse},
keywords = {Scoping review, Fraud, Credential evaluation, Artificial intelligence},
abstract = {Background
Credential fraud among healthcare professionals is a global, significant, and ever-evolving challenge. Technological innovations, such as digital imaging and generative artificial intelligence (AI) that make it easier to fabricate documents, have changed the credential evaluation and verification landscape. A global health worker shortage compounds the critical need to maintain integrity, reliability, and rigor in credential verification of healthcare professionals.
Purpose
To identify evidence-based best practices for combatting nursing credential fraud in the context of AI.
Methods
This research effort entailed a scoping review following Arskey and O'Malley's methodological framework to identify scholarly research related to AI and nursing credential fraud. After the scoping review, an environmental scan of grey literature and professional guidance was performed. Integrated analysis of the findings was used to develop themes and recommendations to guide future work.
Results
Four articles, all published between 2020 and 2025, were subjected to full-text review. Of these four articles, none directly addressed AI in perpetrating or combatting nursing credential fraud. The environmental scan revealed practices documented by professional associations and regulatory bodies as well as emerging trends. Five areas of future research are recommended based on these findings: (1) translate existing research, (2) collaborate in cross-functional teams; (3) engage in experimental software development; (4) generate evidence-based guidance; and (5) participate in ongoing evaluation processes.
Conclusions
This study found emerging practices but no empirical research or evidence-based guidance on the use of AI in combatting or perpetuating nursing credential fraud. Literature addressing employment fraud, AI and nursing regulation, and AI in credential evaluation reveal that nursing credential fraud leveraging AI tools requires urgent attention from regulators, credential evaluators, employers, and researchers.}
}
@incollection{GAUR2026227,
title = {Chapter 13 - Empathy and generative AI: Role and ethical challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {227-242},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000011},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Emotional intelligence, Empathy, Ethical challenges, Generative AI, Human-AI interactions, Transparency, User autonomy},
abstract = {This chapter delves into the concept of empathy in the context of generative artificial intelligence (AI), examining its significance in enhancing human-AI interactions while addressing the ethical challenges that arise. Empathy, defined as the ability to understand and share the feelings of another, is crucial for creating AI systems that foster meaningful and socially intelligent interactions. By embedding empathetic responses into AI design, developers can improve user experiences and engagement, making technology more relatable and effective. The chapter discusses various strategies for incorporating empathy into AI systems, such as leveraging natural language processing, affective computing, and emotional intelligence models. Through illustrative case studies, it highlights successful applications of empathetic AI, showcasing how they enhance user satisfaction. However, designing empathetic AI is fraught with challenges, including technical limitations and the complexity of accurately understanding emotional nuances. Ethical considerations surrounding empathetic AI are a major focus. The potential for emotional manipulation poses significant risks, necessitating discussions about authenticity and transparency. The chapter explores how empathetic interactions can respect user autonomy, ensuring that AI does not undermine decision-making abilities. Through case studies, the ethical dilemmas faced by emotional AI assistants and health-related AI systems are examined, illustrating the complexities of managing empathy in practice. Developing ethical guidelines for empathetic AI is essential, and the chapter advocates for the involvement of diverse stakeholders in the design process to address ethical concerns effectively. Looking to the future, the chapter discusses innovations in empathetic AI technologies and the need to anticipate emerging ethical challenges. It concludes with recommendations for building a robust framework that supports ethical empathy in AI, aiming to create systems that are both effective and aligned with ethical principles.}
}
@article{YIN2024,
title = {Consumer Attitudes Towards GenAI Advertisements:},
journal = {Journal of Cases on Information Technology},
volume = {26},
number = {1},
year = {2024},
issn = {1548-7717},
doi = {https://doi.org/10.4018/JCIT.356502},
url = {https://www.sciencedirect.com/science/article/pii/S1548771724000836},
author = {Mengjiao Yin and Biao Ma and Xianyu Pan},
keywords = {Advertisement, Consumer Attitude, Gen AI, IKEA Effect, In-group Bias, Perceived Authenticity, Social Identity Theory},
abstract = {ABSTRACT
This research focuses on the attitudes of potential consumers towards generative artificial intelligence (GenAI) advertisements, employing a multi-experimental approach based on engagement to shed light on how e-marketers should leverage novel technological tools in the age of human-AI co-creation to enhance brand favorability. The experimental findings indicate the continued adaptiveness of concepts such as in-group bias, IKEA effect, and social identity theory in the GenAI era, demonstrating that (a) consumers' awareness of AI authorship (b) their level of participation in the co-creative process and (c) their perceived authenticity, significantly influence their attitudes. This study expands the boundaries of theories previously confined to human populations and provides pioneering practical guidance for AI co-creation in the realm of electronic commerce.}
}
@article{LIU2025103797,
title = {Critical digital literacies, agentic practices, and AI-mediated informal digital learning of English},
journal = {System},
volume = {134},
pages = {103797},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103797},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002076},
author = {Guangxiang Leon Liu and Ju Seong Lee and Xian Zhao},
keywords = {Critical digital literacies, Generative AI, Agency, AI-mediated informal digital learning of English (AI-IDLE)},
abstract = {Building upon Darvin and Norton's (2015) model of investment, this paper presents a case study of eight Chinese university EFL learners who have developed creative and productive informal language learning experiences using generative artificial intelligence (AI) tools. It aims to examine how these students invest in critical digital literacies (CDL) that empower them to navigate invisible power relations of AI platforms and enact agentic language learning practices. Data was collected through an adapted questionnaire, semi-structured interviews, digital artifacts (e.g., screenshots of interactions with AI), and reflective journals. Using NVivo 12, an inductive thematic analysis approach (Braun & Clarke, 2021) was adopted to code data and generate the primary themes. The analysis revealed that participants' investment in CDL manifested through multiple interconnected dimensions. These participants invested in CDL by first establishing dispositional stances and mobilizing capital to demystify the black box of AI tools and developing critical awareness about power relations embedded in AI platforms. Participants also negotiated varying levels of agency in their AI-mediated informal digital learning of English (AI-IDLE), ranging from basic content consumption to sophisticated co-creative partnerships. By shedding light on the components of CDL that AI-IDLE learners need to develop, this paper provides implications for language educators and policymakers to design pedagogies of critical AI literacies and promote equitable and agentic AI-supported language learning practices outside of the classroom.}
}
@article{BALKI2023,
title = {Use and Acceptance of Digital Communication Technology by Older Adults for Social Connectedness During the COVID-19 Pandemic: Mixed Methods Study},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/41535},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123005861},
author = {Eric Balki and Carol Holland and Niall Hayes},
keywords = {aging in place, technology acceptance, technology adoption, information and communication technologies, qualitative research, COVID-19 pandemic, Facebook, Meta, WhatsApp, Zoom, generative artificial intelligence, AI},
abstract = {Background
Older adults are at higher risk for health issues, including mental health problems. This was especially apparent during the COVID-19 pandemic, where older adults were simultaneously more vulnerable to the disease and the mental health concerns created by social distancing. Subsequently, the use of digital communication technology (DCT) became a critical option for maintaining social connectedness in older adults. Prior to the pandemic, the low uptake and use of technology by older adults was an established problem, known as the digital divide. However, not much is known about how this may have changed as a result of the pandemic.
Objective
This study aims to explore how older adults maintained social connectedness through DCT during the pandemic and to understand factors influencing the use and acceptance of DCT.
Methods
A mixed methods explorative field study was set up, involving surveys and interviews of 25 community-dwelling older adults (65-88 years old) living in the United Kingdom. The surveys included the internet acceptance questionnaire (based on the Technology Acceptance Model [TAM]); COVID-19 dysfunctional anxiety was captured using the COVID-19 Anxiety Scale (CAS). Background information (demographics, use of technology) was gathered before conducting semistructured interviews. We hypothesized that CAS would affect constructs of TAM and that predictive constructs of TAM would have remained valid during the pandemic. We also posited that there would be unidentified themes outside TAM that impacted the acceptance and use of DCT. We used the quantitative data to guide the semistructured interviews, which were then analyzed through thematic analysis to identify additional themes.
Results
Correlational analysis showed that CAS influences all constructs of TAM. We also saw that the predictive constructs of TAM, especially the perceived ease of use (PEU) and perceived usefulness (PU), remained valid during the pandemic. Common acceptance-influencing themes were encountered in both quantitative and qualitative analyses, with 3 matching the known constructs of TAM (PU, PEU, and behavioral intention). We identified 2 additional themes affecting acceptance, namely influence of the pandemic (situational context) and privacy and security concerns. DCT use (especially email and videoconferencing use) increased during the pandemic, but the results related to social networking sites were mixed.
Conclusions
The COVID-19 pandemic impacted technology acceptance and use by older adults, encouraging their use of certain DCT apps (email and videoconferencing apps, such as WhatsApp). These apps helped insulate them from adverse effects (social isolation and loneliness). Other social networking apps, however, exerted a negative influence, increasing anxiety and a general feeling of negativity. Future studies should maximize older adult agency related to design, privacy, security, and user requirements for development. We also recommend that when studying DCT acceptance for older adults, our additional identified themes should be considered alongside the existing TAM constructs.}
}
@article{ALLI2024,
title = {The Potential of Artificial Intelligence Tools for Reducing Uncertainty in Medicine and Directions for Medical Education},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/51446},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224001314},
author = {Sauliha Rabia Alli and Soaad Qahhār Hossain and Sunit Das and Ross Upshur},
keywords = {artificial intelligence, machine learning, uncertainty, clinical decision-making, medical education, generative AI, generative artificial intelligence},
abstract = {In the field of medicine, uncertainty is inherent. Physicians are asked to make decisions on a daily basis without complete certainty, whether it is in understanding the patient’s problem, performing the physical examination, interpreting the findings of diagnostic tests, or proposing a management plan. The reasons for this uncertainty are widespread, including the lack of knowledge about the patient, individual physician limitations, and the limited predictive power of objective diagnostic tools. This uncertainty poses significant problems in providing competent patient care. Research efforts and teaching are attempts to reduce uncertainty that have now become inherent to medicine. Despite this, uncertainty is rampant. Artificial intelligence (AI) tools, which are being rapidly developed and integrated into practice, may change the way we navigate uncertainty. In their strongest forms, AI tools may have the ability to improve data collection on diseases, patient beliefs, values, and preferences, thereby allowing more time for physician-patient communication. By using methods not previously considered, these tools hold the potential to reduce the uncertainty in medicine, such as those arising due to the lack of clinical information and provider skill and bias. Despite this possibility, there has been considerable resistance to the implementation of AI tools in medical practice. In this viewpoint article, we discuss the impact of AI on medical uncertainty and discuss practical approaches to teaching the use of AI tools in medical schools and residency training programs, including AI ethics, real-world skills, and technological aptitude.}
}
@article{KUMAR2024100005,
title = {A market management approach to transformative business operations},
journal = {Marketing Strategy Journal},
volume = {1},
pages = {100005},
year = {2024},
issn = {2950-3086},
doi = {https://doi.org/10.1016/j.msj.2025.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2950308625000055},
author = {V. Kumar and Philip Kotler},
keywords = {New-age technologies, Market management approach, Transformative business operations, Research agenda, Artificial intelligence, Generative artificial intelligence, The metaverse, Cloud computing, IoT, Robotics, Drones, And blockchain},
abstract = {How are new-age technologies transforming business operations? Why does it matter? The article suggests that a market management approach is conducive to understanding how new-age technologies can transform business operations. In this regard, the article defines market management approach as a holistic framework for managing transformative business operations that emphasizes the integration of emerging technologies with an organization’s operational processes. In this regard, the concept of transformative business operations is introduced and defined as the transformation of organizational systems, resources, and processes using new-age technologies to improve business functions that can generate superior value offerings to all stakeholders. The proposed transformative business operations approach identifies three triggers—the tension of uncertainty, adaptive capabilities, and operational elasticity—that drive the unique and synergistic impacts of these technologies. These triggers result in transformative changes through (a) foundational shifts in organizations, (b) strategy design, execution, and optimization, (c) unified ecosystem creation, and (d) pioneering business operations solutions. The actual transformation is observed in hyper-automation, augmented decision-making, and decentralized supply chains. The article also highlights barriers to adopting these technologies - cultural and workforce adjustments, data security and privacy concerns, and interoperability issues -, which moderate their potential impact, and guide organizations navigating these challenges. Finally, it outlines a market management agenda for exploring the implications of these developments.}
}
@article{MUNIR2025102370,
title = {Taking the plunge together: A student-led faculty learning seminar series on artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {8},
pages = {102370},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102370},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000917},
author = {Faria Munir and Elma Abdulbaki and Zeba Saiyad and Heather Ipema},
keywords = {Artificial intelligence, Drug information, Higher education, Pharmacy, Faculty, Pharmacy students, Learning series},
abstract = {Objective
This pilot study explored the effectiveness of a student-led faculty development series by evaluating two key outcomes: the capacity of students to deliver meaningful professional development sessions to faculty and the impact of these sessions on faculty perceptions of generative artificial intelligence (AI).
Methods
In a flipped classroom model, two pharmacy students and 12 faculty members engaged in a semester-long learning series on AI. Each week, students presented on a selected topic followed by discussions that facilitated self-directed learning, including decision-making and project management. Faculty perceptions of AI were evaluated before and after the series using an anonymous survey tool (Technology Acceptance Model Edited to Assess ChatGPT Adoption, TAME-ChatGPT). Respondents created a self-chosen code to link their responses. Additionally, students completed a questionnaire to gauge their reflective thinking after the series.
Results
Faculty participation averaged 7 members per session. Twelve faculty completed the pre-survey, while 8 faculty completed the post-survey. Among those who had used ChatGPT (n = 4 pre [33 %], n = 2 post [25 %]), scores for usefulness increased, while concerns about risks decreased. In contrast, faculty who had not used ChatGPT (n = 8 pre [67 %], n = 6 post [75 %]) reported unchanged or improved scores for ease of use and reduced anxiety. Both students responded positively to the reflective thinking questionnaire.
Conclusion
This pilot study demonstrated that a student-led faculty learning series effectively fostered mutual collaborative learning, benefiting both faculty and students. Pharmacy students, often an underutilized resource, can play a valuable role in faculty development. Colleges of pharmacy may enhance faculty engagement by integrating student-led initiatives into their programs.}
}
@article{WORKUM2026155262,
title = {AI in critical care: A roadmap to the future},
journal = {Journal of Critical Care},
volume = {91},
pages = {155262},
year = {2026},
issn = {0883-9441},
doi = {https://doi.org/10.1016/j.jcrc.2025.155262},
url = {https://www.sciencedirect.com/science/article/pii/S0883944125002497},
author = {J.D. Workum and G. Meyfroidt and J. Bakker and C. Jung and J.M. Tobin and D. Gommers and P.W.G. Elbers and J.G. {van der Hoeven} and M.E. {Van Genderen}},
keywords = {Large language models, Generative artificial intelligence, AI readiness, Implementation},
abstract = {Artificial intelligence (AI) has the potential to revolutionize critical care medicine by enhancing patient care, improving resource allocation and reducing clinician workload. Despite this promise, many AI applications remain confined to scientific research rather than being integrated into everyday clinical practice. This manuscript aims to help intensivists prepare themselves and their intensive care units (ICUs) for AI implementation. It provides a comprehensive yet practical roadmap, detailing AI methods, applications, responsible AI principles, common roadblocks and implementation strategies. We propose a three-tiered risk-based approach to AI implementation, starting with low-risk low-complexity administrative AI, progressing to logistical AI, and finally integrating medical AI as clinical decision support systems. This ensures a gradual build-up of AI skills, technical AI readiness of the ICU, incremental value demonstration and alignment with evolving regulatory standards. For each AI project, responsible AI principles should be incorporated and adequately addressed throughout the entire AI lifecycle, from development to validation to implementation and scaling. Common roadblocks for AI implementation including technical issues (such as data quality and interoperability issues), organizational challenges (such as lack of a clear vision and strategy), and clinical concerns (such as limited AI literacy among staff), should be addressed proactively. By following this roadmap, ICUs can achieve sustainable AI integration, ultimately improving patient outcomes and clinician experience. The future of critical care lies in the responsible and strategic adoption of AI, with intensivists playing a central role in shaping its implementation.}
}
@article{ODU2025112353,
title = {Automatic instantiation of assurance cases from patterns using large language models},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112353},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112353},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000214},
author = {Oluwafemi Odu and Alvine B. Belle and Song Wang and Segla Kpodjedo and Timothy C. Lethbridge and Hadi Hemmati},
keywords = {Requirement engineering, Assurance cases, Assurance case patterns, Pattern formalization, Generative artificial intelligence, Large language models, GPT},
abstract = {An assurance case is a structured set of arguments supported by evidence, demonstrating that a system’s non-functional requirements (e.g., safety, security, reliability) have been correctly implemented. Assurance case patterns serve as templates derived from previous successful assurance cases, aimed at facilitating the creation of new assurance cases. Despite using these patterns to generate assurance cases, their instantiation remains a largely manual and error-prone process that heavily relies on domain expertise. Thus, exploring techniques to support their automatic instantiation becomes crucial. This study aims to investigate the potential of Large Language Models (LLMs) in automating the generation of assurance cases that comply with specific patterns. Specifically, we formalize assurance case patterns using predicate-based rules and then utilize LLMs, i.e., GPT-4o and GPT-4 Turbo, to automatically instantiate assurance cases from these formalized patterns. Our findings suggest that LLMs can generate assurance cases that comply with the given patterns. However, this study also highlights that LLMs may struggle with understanding some nuances related to pattern-specific relationships. While LLMs exhibit potential in the automatic generation of assurance cases, their capabilities still fall short compared to human experts. Therefore, a semi-automatic approach to instantiating assurance cases may be more practical at this time.}
}
@article{FLECKENSTEIN2024100209,
title = {Do teachers spot AI? Evaluating the detectability of AI-generated texts among student essays},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100209},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100209},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000109},
author = {Johanna Fleckenstein and Jennifer Meyer and Thorben Jansen and Stefan D. Keller and Olaf Köller and Jens Möller},
keywords = {Generative AI, Writing assessment, Teachers, Essay writing, ChatGPT},
abstract = {The potential application of generative artificial intelligence (AI) in schools and universities poses great challenges, especially for the assessment of students’ texts. Previous research has shown that people generally have difficulty distinguishing AI-generated from human-written texts; however, the ability of teachers to identify an AI-generated text among student essays has not yet been investigated. Here we show in two experimental studies that novice (N = 89) and experienced teachers (N = 200) could not identify texts generated by ChatGPT among student-written texts. However, there are some indications that more experienced teachers made more differentiated and more accurate judgments. Furthermore, both groups were overconfident in their judgments. Effects of real and assumed source on quality assessment were heterogeneous. Our findings demonstrate that with relatively little prompting, current AI can generate texts that are not detectable for teachers, which poses a challenge to schools and universities in grading student essays. Our study provides empirical evidence for the current debate regarding exam strategies in schools and universities in light of the latest technological developments.}
}
@article{LIAO2024105187,
title = {Generative AI design for building structures},
journal = {Automation in Construction},
volume = {157},
pages = {105187},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105187},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523004478},
author = {Wenjie Liao and Xinzheng Lu and Yifan Fei and Yi Gu and Yuli Huang},
keywords = {Building structural design, Data feature representation, Generative AI algorithm, Design evaluation, Intelligent optimization},
abstract = {Designing building structures presents various challenges, including inefficient design processes, limited data reuse, and the underutilization of previous design experience. Generative artificial intelligence (AI) has emerged as a powerful tool for learning and creatively using existing data to generate new design ideas. Learning from past experiences, this technique can analyze complex structural drawings, combine requirement texts, integrate mechanical and empirical knowledge, and create fresh designs. In this paper, a comprehensive review of recent research and applications of generative AI in building structural design is provided. The focus is on how data is represented, how intelligent generation algorithms are constructed, methods for evaluating designs, and the integration of generation and optimization. This review reveals the significant progress generative AI has made in building structural design, while also highlighting the key challenges and prospects. The goal is to provide a reference that can help guide the transition towards more intelligent design processes.}
}
@article{CHOWDHURY2025112827,
title = {R-VQA: A robust visual question answering model},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112827},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112827},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124014618},
author = {Souvik Chowdhury and Badal Soni},
keywords = {Visual question answering, Large language model, In-context learning, Computer vision, Natural language processing, Generative artificial intelligence},
abstract = {Visual Question Answering (VQA) involves generating answers to questions about visual content, such as images. VQA models process an image and a question to produce an answer. One major challenge in this domain is robustness, as current VQA models often operate within a fixed answer space and struggle with issues related to language prior (favoring frequent answers) and compositional reasoning (difficulty with complex object relationships). While existing research addresses these challenges separately, no work has tackled both language prior and compositional reasoning simultaneously. This paper presents three key contributions: the development of a dataset specifically designed to address language prior and compositional reasoning issues, the creation of a unified model capable of addressing both problems in a single inference, and the ability to generate answers beyond a predefined answer space. Our proposed model, R-VQA, demonstrates superior performance compared to state-of-the-art (SOTA) models across various VQA datasets.}
}
@article{AGARWAL2025100214,
title = {Beyond boundaries: Charting the frontier of healthcare with big data and ai advancements in pharmacovigilance},
journal = {Health Sciences Review},
volume = {14},
pages = {100214},
year = {2025},
issn = {2772-6320},
doi = {https://doi.org/10.1016/j.hsr.2025.100214},
url = {https://www.sciencedirect.com/science/article/pii/S2772632025000066},
author = {Arohi Agarwal and Gagan Singh and Samyak Jain and Piyush Mittal},
keywords = {Big data, Big data analytics, Genomics, Structured data, Unstructured data, Semi-structured data, Descriptive analytics, Exploratory or discovery analytics, Predictive analytics, Pharmacovigilance (Pv), Artificial intelligence (AI), Generative adversarial networks, Variational autoencoders, Transformer-based models},
abstract = {The healthcare sector is intricate, generating vast amounts of data from various sources at an accelerated pace. The contemporary trend of Big Data Analytics is pivotal, impacting not only the pharmaceutical industry but also transforming healthcare, contributing to personalized treatment, aiding in preventive healthcare, managing electronic health records, facilitating adverse drug reporting, and incorporating consumer reviews. This article provides an overview of the inevitable influence of big data and the utilization of artificial intelligence in revolutionizing both healthcare and the pharmaceutical sector. It delves into the notable benefits and challenges encountered in advancing data analytics of the early 21st century.In many countries, Post-marketing surveillance of drug safety relinquishes on a systematic analysis of spontaneous using Generative artificial intelligence (AI) to overcome gaps in the present PV ecosystem is critical to maintaining an uninterrupted record of security and effectiveness within healthcare analytics, data mining techniques, predictive analytics, and the emergence of scientific fields like bioinformatics and health informatics are empowered by Big Data. Nevertheless, the integration of AI in healthcare, especially in pharmacovigilance, aligns with the evolving landscape of electronic health information technology. In conclusion, review highlights the transformative impact of Big Data and AI in healthcare, emphasizing their applications in pharmacovigilance and pharmacoepidemiology. The continuous evolution of these technologies holds promise for improving patient safety, personalized medicine, and overall healthcare outcomes.}
}
@article{XIAO2024114691,
title = {Exploring automated energy optimization with unstructured building data: A multi-agent based framework leveraging large language models},
journal = {Energy and Buildings},
volume = {322},
pages = {114691},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114691},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824008077},
author = {Tong Xiao and Peng Xu},
keywords = {Automated energy optimization, Unstructured data, Generative Artificial Intelligence, Energy audit, Energy efficiency diagnosis},
abstract = {The building sector is a significant energy consumer, making building energy optimization crucial for reducing energy demand. Automating energy optimization tasks eases the workload on engineers and hastens energy savings. More than 85% of building data is unstructured and diverse, concealing energy insights that demand laborious extraction. We propose an LLM-based multi-agent framework to explore automated tasks using these data. The framework includes three stages: building information processing, performance diagnosis, and retrofit recommendation, where LLMs injected with domain expertise act as agents for the roles of planner, researcher and advisor. We develop knowledge databases with retriever tools to inject knowledge and validate through experiments. In case studies, our framework delivered reliable results with only $5.15, effectively handling diverse inputs and tasks across cases. This demonstrates its potential to significantly reduce repetitive human labor and costs. We also discuss the potential of LLM-based multi-agent systems as trustworthy, generalized automated task solvers.}
}
@article{GUPTA2024103997,
title = {Exploring the generative AI adoption in service industry: A mixed-method analysis},
journal = {Journal of Retailing and Consumer Services},
volume = {81},
pages = {103997},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103997},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924002935},
author = {Rohit Gupta and Bhawana Rathore},
keywords = {Generative AI, Service industry, Text mining, Topic modelling, FDM, Fuzzy AHP, Fuzzy DEMATEL},
abstract = {In the last few years, many service organisations have been exploring the use of Generative Artificial Intelligence (GAI) tools for their businesses and upgrading their existing processes. These tools have the potential and capability to transform the business world in various aspects. However, serval service organisations are facing many challenges while adopting the GAI tools in their organisations. In a similar context, this study explores the adoption of GAI barriers through two studies by a mixed-method approach. The first study is based on YouTube datasets of selected videos where GAI adoption challenges, problems, and barriers were discussed. Further, these YouTube datasets were analysed through text mining and empirical modelling techniques. In the second study, an extensive literature review was done and critical barriers to GAI adoption were identified based on the extensive literature review. Further, these barriers were analysed through three theoretical lenses and a hybrid fuzzy multicriteria decision-making approach. In addition, the results from the first study were further matched and verified with our second study. This establishes the relevance of adopting a mixed-method approach. Our major findings are: (i) trust, anticipation, and surprise emerged as the strongest emotions of the viewers who posted their comments on the YouTube videos; (ii) Five major barriers are revealed through topic analysis of YouTube transcripts and these are ethical, technological, regulations & policies, cost, and human resources; (iii) Six major barriers are identified through second study are privacy & security, return on investment, running cost, misuse, over-reliance, and Lack of digital infrastructure.}
}
@article{DALVIESFAHANI2025124291,
title = {Stimulus-organism-response framework of decision-makers intention to adopt generative AI to replace entry-level jobs: The moderating impact of personality traits},
journal = {Technological Forecasting and Social Change},
volume = {219},
pages = {124291},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124291},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003221},
author = {Mohammad Dalvi-Esfahani and Hajar Barati-Ahmadabadi and T. Ramayah and Jason J. Turner and Noorminshah {A. Iahad} and Nasrin Azar},
keywords = {Generative AI, Entry-level jobs, Stimulus-Organism-Response (S-O-R), Theory of Effective Use (TEU)},
abstract = {This study was motivated by the limited research on the adoption of Generative Artificial Intelligence (GenAI) in the workplace. Based on the Stimulus-Organism-Response (S-O-R) framework, we developed a model to assess the factors influencing decision-makers' intention to adopt GenAI as a substitute for entry-level jobs in financial institutions. To test the hypotheses, we collected survey data from 335 respondents in Malaysian financial institutions and analyzed it using partial least squares structural equation modeling. The findings indicate that trust in GenAI significantly affects decision-makers' intention to adopt it as an alternative solution to human positions. Trust, in turn, was found to be positively influenced by constructs from the Theory of Effective Use (transparent interaction, informed action, and representational fidelity) as well as AI literacy, which reflects users' ability to evaluate and interact with AI. The results also show that personality traits, particularly conscientiousness, moderate the relationship between trust and adoption intention, highlighting the importance of individual differences in GenAI usage. Collectively, our findings extend the S-O-R framework by revealing how both cognitive and affective factors shape GenAI adoption behavior. The study also offers practical implications for GenAI stakeholders, especially about the vital role of trust-building strategies in fostering AI adoption.}
}
@article{AHLGREN2025107832,
title = {Assisting early-stage software startups with LLMs: Effective prompt engineering and system instruction design},
journal = {Information and Software Technology},
volume = {187},
pages = {107832},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107832},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001715},
author = {Thea Lovise Ahlgren and Helene Fønstelien Sunde and Kai-Kristian Kemell and Anh Nguyen-Duc},
keywords = {Generative Artificial Intelligence, GenAI, ChatGPT, StartupGPT, Software engineering, Software startup, Software development, Design Science Research},
abstract = {Context:
Early-stage software startups, despite their strong innovative potential, experience high failure rates due to factors such as inexperience, limited resources, and market uncertainty. Generative AI technologies, particularly Large Language Models (LLMs), offer promising support opportunities; however, effective strategies for their integration into startup practices remain underexplored.
Objective:
This study investigates how prompt engineering and system instruction design can enhance the utility of LLMs in addressing the specific needs and challenges faced by early-stage software startups.
Methods:
A Design Science Research (DSR) methodology was adopted, structured into three iterative cycles. In the first cycle, use cases for LLM adoption within the startup context were identified. The second cycle experimented with various prompt patterns to optimize LLM responses for the defined use cases. The third cycle developed “StartupGPT”, an LLM-based assistant tailored for startups, exploring system instruction designs. The solution was evaluated with 25 startup practitioners through a combination of qualitative feedback and quantitative metrics.
Results:
The findings show that tailored prompt patterns and system instructions significantly enhance user perceptions of LLM support in real-world startup scenarios. StartupGPT received strong evaluation scores across key dimensions: satisfaction (93.33%), effectiveness (80%), efficiency (80%), and reliability (86.67%). Nonetheless, areas for improvement were identified, particularly in context retention, personalization of suggestions, communication tone, and sourcing external references.
Conclusion:
This study empirically validates the applicability of LLMs in early-stage software startups. It offers actionable guidelines for prompt and system instruction design and contributes both theoretical insights and a practical artifact — StartupGPT — that supports startup operations without necessitating costly LLM retraining.}
}
@article{YAN2025620,
title = {Real-time detection of road surface friction coefficient: A new framework integrating diffusion model and Transformer in Transformer algorithms},
journal = {Alexandria Engineering Journal},
volume = {113},
pages = {620-632},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824014170},
author = {Zhangcun Yan and Lishengsa Yue and Wang Luo and Jian Sun},
keywords = {Road engineering, Road surface friction coefficient detection, Image classification, Data augmentation, Diffusion model, Transform in transform},
abstract = {The real-time road surface friction coefficient (RSFC) is a critical parameter for evaluating skid resistance and making safe driving decisions in driver assistance systems and autonomous vehicles, especially under adverse weather conditions. RSFC estimation depends on the interaction between the road surface and tires. However, accurate estimation is challenging due to varying road environments and sensor errors that can cause significant distortions. To obtain high-accuracy RSFC, this study proposes a novel real-time RSFC detection method that integrates a diffusion model with the Transformer-in-Transformer(TNT) model to detect RSFC from vehicle video pictures. The method consists of three steps. First, we created labeled friction coefficient image datasets representing asphalt concrete surfaces under four moisture conditions. Second, we used a diffusion model to enhance the dataset, increasing sample diversity. Finally, we trained a TNT model on the extended dataset to recognize friction coefficients. The approach was tested across various datasets and compared to four state-of-the-art (SOTA) methods. The results show that the proposed method significantly improves accuracy, achieving a 22.89% increase compared to the unenhanced dataset and a 5.59% improvement over SOTA methods. The primary contribution of this study is the integration of generative artificial intelligence and computer vision algorithms to enhance RSFC recognition accuracy. Furthermore, the recognition method meets the real-time performance requirements, processing frames in just two milliseconds. This method can be an effective tool for perceiving road surface environmental parameters and holds significant value in improving driving safety under adverse weather conditions.}
}
@article{CANOORTIZ2024102745,
title = {Enhancing pavement crack segmentation via semantic diffusion synthesis model for strategic road assessment},
journal = {Results in Engineering},
volume = {23},
pages = {102745},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102745},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024010004},
author = {Saúl Cano-Ortiz and Eugenio Sainz-Ortiz and Lara {Lloret Iglesias} and Pablo {Martínez Ruiz del Árbol} and Daniel Castro-Fresno},
keywords = {Pavement crack segmentation, Generative artificial intelligence, Semantic diffusion synthesis, Road maintenance, Deep learning},
abstract = {Computer-aided deep learning has significantly advanced road crack segmentation. However, supervised models face challenges due to limited annotated images. There is also a lack of emphasis on deriving pavement condition indices from predicted masks. This article introduces a novel semantic diffusion synthesis model that creates synthetic crack images from segmentation masks. The model is optimized in terms of architectural complexity, noise schedules, and condition scaling. The optimal architecture outperforms state-of-the-art semantic synthesis models across multiple benchmark datasets, demonstrating superior image quality assessment metrics. The synthetic frames augment these datasets, resulting in segmentation models with significantly improved efficiency. This approach enhances results without extensive data collection or annotation, addressing a key challenge in engineering. Finally, a refined pavement condition index has been developed for automated end-to-end defect detection systems, promoting more effective maintenance planning.}
}
@article{GANGA2024127932,
title = {Object detection and crowd analysis using deep learning techniques: Comprehensive review and future directions},
journal = {Neurocomputing},
volume = {597},
pages = {127932},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127932},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224007033},
author = {B. Ganga and Lata B.T. and Venugopal K.R.},
keywords = {Deep learning, Generative Artificial Intelligence (GAI), Generative Adversarial Network (GAN), Object detection, Object localization, Convolutional Neural Network (CNN)},
abstract = {Object detection using deep learning has attracted considerable interest from researchers because of its competency in performing state-of-the-art tasks, including detection, observation, and action recognition. Deep Learning (DL)-based object detection models extract features directly from data, which is more efficient and effective than traditional methods requiring handcrafted features. Further, DL also effectively tackles spatiotemporal challenges by leveraging techniques; hence, researchers can develop better object detection models and implement more efficient strategies for object recognition. Moreover, optimizing these models improves performance and recognizes objects within videos or images. This survey comprises of an overview of related review papers and DL-based Object Detection (OD) algorithms. Object detection algorithms are presented as two classifications, namely Two-stage and One-stage methods, with Convolutional Neural Network (CNN) as the backbone. OD’s applications are examined here, and crowd analysis has been extensively studied and researched for potential applications. Most of the papers in object detection rely on Convolutional Neural Networks (CNNs) (28%), whereas crowd analysis papers are distributed as follows: 24% in counting, 25% in categorizing, and 25% in analyzing individual behaviors, and 27% in others. In recent years, deep learning has significantly advanced object detection capabilities to provide effective solutions for various applications, including crowd analysis.}
}
@article{ZHENG2024100271,
title = {The effects of chatbot use on foreign language reading anxiety and reading performance among Chinese secondary school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100271},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100271},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000742},
author = {Shuyan Zheng},
keywords = {Chatot-assisted language learning (BALL), Foreign language reading anxiety (FLRA), Foreign language reading performance (FLRP), Chinese L1 secondary school students, Generative artificial intelligence (GenAI)},
abstract = {The present study investigates the effectiveness of a GenAI-based chatbot, “Reading Bot,” in reducing foreign language reading anxiety (FLRA) and improving foreign language reading performance (FLRP) among Chinese secondary school students learning English as a foreign language (EFL). To do so, a mixed-methods quasi-experimental pre-test/post-test design with qualitative interviews was employed. After ensuring homogeneity between the two groups, one class was designated as the experimental group (n = 42), utilizing a chatbot as a treatment, while the other class served as the comparison group (n = 42), receiving traditional teacher support. Both groups participated in five 45-min reading practice sessions. The results indicated that the chatbot intervention significantly reduced the participants' FLRA within the experimental group when comparing pre- and post-test scores. However, no significant differences were found between the two groups after the treatment, either in FLRA or FLRP. The qualitative analysis of semi-structured interviews suggested that the chatbot provided technological, pedagogical, linguistic, and affective affordances to assist reading. Nevertheless, the analysis also revealed some potential drawbacks and challenges to a GenAI-enhanced approach to reading instruction that may have influenced FLRA and FLRP. The theoretical and pedagogical implications of these findings are discussed, along with potential directions for future research.}
}
@article{BAYRAM2025107850,
title = {Nutritional analysis of AI-generated diet plans based on popular online diet trends},
journal = {Journal of Food Composition and Analysis},
volume = {145},
pages = {107850},
year = {2025},
issn = {0889-1575},
doi = {https://doi.org/10.1016/j.jfca.2025.107850},
url = {https://www.sciencedirect.com/science/article/pii/S0889157525006659},
author = {Hatice Merve Bayram and Sedat Arslan},
keywords = {Artificial intelligence, Diet analysis, Popular diets, The Mediterranean diet, Raw diet, Vegetarian diet, Low sodium diet, High protein diet},
abstract = {This study aimed to evaluate the nutritional composition and consistency of 1500 kcal daily diet plans generated by four generative Artificial Intelligence (AI) tools (ChatGPT-4, ChatGPT-4o, Mistral, and Claude) based on five popular diet types identified via Google Trends (keto, paleo, Mediterranean, intermittent fasting, and raw). Each AI model was prompted with standardized requests, and the resulting menus were analyzed using Nutrition Information System (BeBIS) (version 9.0) to determine energy, macronutrient, and micronutrient content. Nutrient composition differences across AI tools were statistically assessed using SPSS 24.0 (ANOVA, p < 0.05). Results showed significant variations between AI outputs, with energy values ranging from 1357 kcal to 2273 kcal and protein intake varying by up to 65 g across models. Notable inconsistencies were also found in micronutrients such as calcium, iron, and vitamin D. AI models often failed to meet targeted caloric levels and showed inconsistent adherence to diet-specific nutrient profiles. These discrepancies suggest limitations not only in the AI tools’ capabilities but also in their interpretation of user prompts. The findings highlight the need for improved prompt design, database integration, and AI training for safe and reliable use in personalized nutrition.}
}
@article{MAKSOUD2025101699,
title = {Applications of large language models and generative AI in transportation: A systematic review and bibliometric analysis},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {34},
pages = {101699},
year = {2025},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2025.101699},
url = {https://www.sciencedirect.com/science/article/pii/S2590198225003781},
author = {Nadia Maksoud and Hamad AlJassmi and Luqman Ali and Abdul Rahman Masoud},
keywords = {Large Language Models (LLMs), Intelligent Transportation Systems (ITS), Generative Artificial Intelligence (GenAI), Bibliometric analysis, AI in Transportation},
abstract = {The integration of Large Language Models (LLMs) and Generative AI (GenAI) in transportation has gained significant attention, particularly in applications related to traffic safety, intelligent transportation systems, and autonomous driving. This paper provides a bibliometric analysis and systematic review of the current literature on LLM-based applications in transportation, analyzing 65 relevant studies published between 2023 and 2024 from Scopus and Web of Science. The review categorizes existing applications into three primary thematic areas: Traffic (28 studies), Autonomous Driving (23), and Safety (15). The findings highlight the transformative role of LLMs in traffic prediction, crash analysis, and risk perception, demonstrating their ability to process large-scale, multimodal datasets with improved efficiency and adaptability. Additionally, this study explores challenges such as computational demands, data limitations, model scalability, and cybersecurity concerns, providing insights into emerging solutions for real-time traffic management, accident prevention, and human-AI interaction in autonomous systems. The review concludes by identifying key research gaps and future directions, emphasizing the need for lightweight AI models, enhanced multimodal integration, and privacy-preserving frameworks to advance LLM applications in smart and sustainable transportation systems.}
}
@article{GOH2025113968,
title = {Extracting knowledge from limited data: An updated review of data-driven and model-driven few-shot learning for agriculture},
journal = {Applied Soft Computing},
volume = {185},
pages = {113968},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113968},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625012815},
author = {Kam Meng Goh and Usman Ullah Sheikh and Jun Kit Chaw and Weng Kin Lai and Weng Chun Tan and Santhi Krishnamoorthy},
keywords = {Agriculture, Disease, Few-Shot learning, Transfer learning},
abstract = {Deep learning has demonstrated considerable success in agricultural applications. However, its conventional implementations heavily depend on large-scale labelled datasets—a requirement that is often impractical in agriculture due to data scarcity, high annotation costs, or environmental variability. While insufficient training data can significantly limit the performance of standard deep learning models, Few-Shot Learning (FSL) has emerged as a transformative paradigm, enabling robust model training with minimal labelled samples by utilising limited data for training instead. Despite its potential, a critical review assessing how FSL addresses expert system challenges in agriculture remains notably absent. This paper attempts to fill this void by presenting an updated comprehensive review of FSL's applications in agriculture. We categorise FSL methodologies into two primary approaches: data processing-driven and model learning-driven. Data processing–driven approaches address data scarcity by enriching representational diversity through synthetic samples generated with models such as generative adversarial networks, or by transferring knowledge from related domains to improve generalisation. In contrast, model learning–driven strategies confront the same challenge through specialised architectures and optimisation techniques that enable effective generalisation from limited samples. Within this taxonomy, data processing–driven paradigms include transfer learning and generative artificial intelligence, while model learning–driven paradigms cover metric learning methods such as Siamese or prototypical networks, together with model-based and optimisation approaches designed for efficient generalisation. Our analysis pinpoints cutting-edge technologies within each sector, shedding light on overlooked areas and opportunities where FSL can harness limited data to yield promising outcomes when used to solve problems in agriculture.}
}
@article{SINGH2024103021,
title = {Applications of generative AI and future organizational performance: The mediating role of explorative and exploitative innovation and the moderating role of ethical dilemmas and environmental dynamism},
journal = {Technovation},
volume = {133},
pages = {103021},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224000713},
author = {Kuldeep Singh and Sheshadri Chatterjee and Marcello Mariani},
keywords = {Generative AI, Organization future performance, Exploratory and exploitative innovation, Environmental dynamism, Ethics},
abstract = {Generative Artificial Intelligence (GenAI) is one of the popular AI technologies which can produce multiple kinds of contents including music, text, image, as well as synthetic data. As GenAI technology can produce various forms of contents, organizations must face ethical dilemmas as to where this technology is likely to be used. Organizations do not want to compromise their ethical standards and compliance policies. Against this backdrop, the aim of this study is to examine if GenAI technology could improve the future performance of the organizations. This study deployed ethical dilemmas and environmental dynamism as two moderators acting on different linkages between adoption of GenAI and organizational future performance. With the help of literature review and theories, a theoretical model has been developed conceptually which was validated using PLS-SEM technique with the feedback of 326 responses from different types of organizations. This study found that the adoption of GenAI could improve exploratory and exploitative innovation under the moderating effects of environmental dynamism and ethical dilemmas. Moreover, it highlighted that the application of GenAI could improve organizational performance.}
}