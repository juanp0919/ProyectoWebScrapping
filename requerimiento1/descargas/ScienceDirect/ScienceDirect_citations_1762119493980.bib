@article{CHIOSA2024114802,
title = {A portable application framework for energy management and information systems (EMIS) solutions using Brick semantic schema},
journal = {Energy and Buildings},
volume = {323},
pages = {114802},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114802},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824009186},
author = {Roberto Chiosa and Marco Savino Piscitelli and Marco Pritoni and Alfonso Capozzoli},
keywords = {Energy management and information systems, Portable application, Brick metadata schema, Anomaly detection, Machine learning},
abstract = {This paper introduces a portable framework for developing, scaling and maintaining energy management and information systems (EMIS) applications using an ontology-based approach. Key contributions include an interoperable layer based on Brick schema, the formalization of application constraints pertaining metadata and data requirements, and a field demonstration. The framework allows for querying metadata models, fetching data, preprocessing, and analyzing data, thereby offering a modular and flexible workflow for application development. Its effectiveness is demonstrated through a case study involving the development and implementation of a data-driven anomaly detection tool for the photovoltaic systems installed at the Politecnico di Torino, Italy. During eight months of testing, the framework was used to tackle practical challenges including: (i) developing a machine learning-based anomaly detection pipeline, (ii) replacing data-driven models during operation, (iii) optimizing model deployment and retraining, (iv) handling critical changes in variable naming conventions and sensor availability (v) extending the pipeline from one system to additional ones.}
}
@article{MENG2025104166,
title = {Personal information organization literacy in the academic context: Scale development, performance assessment, and influence exploration},
journal = {Information Processing & Management},
volume = {62},
number = {5},
pages = {104166},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104166},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325001074},
author = {Gaohui Meng and Chang Liu},
keywords = {Personal information management, Information literacy, Scale development and validation, Learning performance, Academic procrastination},
abstract = {Personal information management literacy (PIML) is a literacy that has been increasingly valued and highlighted in the emerging knowledge society, yet the related research is insufficient. This study focuses on personal information organization literacy (PIOL) as an essential component of PIML, examining its measurement, assessment, and influence in the academic context. We conducted two linked studies to address the research questions. In Study 1, we developed a scale to measure PIOL in the academic context through three phases: generating a sample of items, exploring the factorial structure, and examining the reliability and validity. In Study 2, based on the developed scale, we assessed the performance of college students in PIOL and explored the influence of PIOL on their learning performance. The results indicate that PIOL in the academic context is a five-dimensional construct. There is a gap between college students’ real performance and the ideal level of PIOL in the academic context, and their PIOL performance differ significantly, allowing them to be categorized into four groups. Moreover, it is verified that college students’ PIOL has a beneficial effect on their learning performance, including mitigating procrastination, alleviating passive procrastination, and elevating academic grades. This study takes a pioneering step in measuring PIOL and discovering its effect, with the potential to inspire educators to incorporate more PIOL elements into information literacy standards and to define PIOL education.}
}
@article{HARMS2024114364,
title = {Dark clouds on the horizon: Dark personality traits and the frontiers of the entrepreneurial economy},
journal = {Journal of Business Research},
volume = {171},
pages = {114364},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114364},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323007233},
author = {P.D. Harms and Joshua V. White and Tyler N.A. Fezzey},
keywords = {Dark personality, Gig economy, Remote work, Dark triad, Entrepreneurship, Self-employment},
abstract = {Recent developments in technology and shifting societal patterns threaten to upend norms surrounding the world of work. The present paper introduces the idea of an emerging entrepreneurial economy and describes how it is reshaping our understanding of work, provides a framework for understanding whether and why individuals with dark personality traits may be attracted to careers in this new occupational frontier. Specifically, we will discuss how dark traits shape interest in remote work, the gig economy, social media and podcasting careers, and occupations related to cryptocurrencies, blockchain technologies, and crowdfunding. We also note how technologies enhanced by artificial intelligence (AI) might contribute to uncertainty concerning how individuals with dark traits may function in these vocational contexts. We finish by making arguments for how future research can be improved in order to attain a more comprehensive understanding of dark personality in the entrepreneurial economy.}
}
@article{KEMBRO2025163,
title = {Why review papers get rejected: common pitfalls and how to avoid them},
journal = {International Journal of Physical Distribution & Logistics Management},
volume = {55},
number = {11},
pages = {163-192},
year = {2025},
issn = {0960-0035},
doi = {https://doi.org/10.1108/IJPDLM-03-2025-0125},
url = {https://www.sciencedirect.com/science/article/pii/S0960003525000017},
author = {Joakim Hans Kembro and Sven Kunisch and Christian F. Durach},
keywords = {Literature review, Systematic literature review, Structured literature review, Review research, Research methods, Academic writing, Publishing},
abstract = {Purpose
In this paper, we discuss common pitfalls in producing review articles for publication in academic journals, offering guidance to minimize rejection rates. We highlight the dual core features of systematicity (i.e. rigor and transparency) and generativity (i.e. advancing knowledge) in review papers. Thereby, we aim to help researchers deal with the abundance of guidelines and create publishable literature reviews that meaningfully contribute to their fields. Additionally, we discuss the prospects and perils of incorporating advanced technologies, such as artificial intelligence (AI), in review research.
Design/methodology/approach
Drawing from an analysis of editorial guidelines, desk-rejection decisions and reviewer feedback, as well as our experience as authors, reviewers and editors, we identify six common pitfalls of literature reviews. For each pitfall, we discuss typical manifestations and mitigation strategies. We also incorporate illustrative examples of literature reviews that have successfully navigated these pitfalls.
Findings
We identify and discuss six common pitfalls: (1) lack of compelling motivation, (2) weak conceptual foundation, (3) poor research design, (4) flawed research method, (5) insufficient knowledge contributions and (6) poor paper crafting – which undermine systematicity and generativity. For each of the pitfalls, we put forward mitigation strategies, which collectively help improve systematicity and generativity. Additionally, we anticipate and discuss two (emerging) pitfalls related to AI and digital technologies in review research: irresponsible and ineffective use of AI. Again, we propose mitigation strategies.
Originality/value
We offer a structured framework to help researchers overcome common challenges in literature reviews and reduce the likelihood of rejection by leading academic journals.}
}
@article{MUNUZURI202264,
title = {Unified representation of Life's basic properties by a 3-species Stochastic Cubic Autocatalytic Reaction-Diffusion system of equations},
journal = {Physics of Life Reviews},
volume = {41},
pages = {64-83},
year = {2022},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2022.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1571064522000185},
author = {Alberto P. Muñuzuri and Juan Pérez-Mercader},
keywords = {Living systems, Turing instability, Top-down approach, Bottom-up approach, Non-linear reaction-diffusion equations, Properties of life},
abstract = {Today we can use physics to describe in great detail many of the phenomena intervening in the process of life. But no analogous unified description exists for the phenomenon of life itself. In spite of their complexity, all living creatures are out of equilibrium chemical systems sharing four fundamental properties: they (1) handle information, (2) metabolize, (3) self-reproduce and (4) evolve. This small number of features, which in terran life are implemented with biochemistry, point to an underlying simplicity that can be taken as a guide to motivate and implement a theoretical physics style unified description of life using tools from the non-equilibrium physical-chemistry of extended systems. Representing a system with general rules is a well stablished approach to model building and unification in physics, and we do this here to provide an abstract mathematical description of life. We start by reviewing the work of previous authors showing how the properties in the above list can be individually represented with stochastic reaction-diffusion kinetics using polynomial reaction terms. These include “switches” and computation, the kinetic representation of autocatalysis, Turing instability and adaptation in the presence of both deterministic and stochastic environments. Thinking of these properties as existing on a space-time lattice each of whose nodes are subject to a common mass-action kinetics compatible with the above, leads to a very rich dynamical system which, just as natural life, unifies the above properties and can therefore be interpreted as a high level or “outside-in” theoretical physics representation of life. Taking advantage of currently available advanced computational techniques and hardware, we compute the phase plane for this dynamical system both in the deterministic and stochastic cases. We do simulations and show numerically how the system works. We review how to extract useful information that can be mapped into emergent physical phenomena and attributes of importance in life such as the presence of a “membrane” or the time evolution of an individual system's negentropy or mass. Once these are available, we illustrate how to perform some basic phenomenology based on the model's numerical predictions. Applying the above to the idealization of the general Cell Division Cycle (CDC) given almost 25 years ago by Hunt and Murray, we show from the numerical simulations how this system executes a form of the idealized CDC. We also briefly discuss various simulations that show how other properties of living systems such as migration towards more favorable regions or the emergence of effective Lotka-Volterra populations are accounted for by this general and unified view from the “top” of the physics of life. The paper ends with some discussion, conclusions, and comments on some selected directions for future research. The mathematical techniques and powerful simulation tools we use are all well established and presented in a “didactical” style. We include a very rich but concise SI where the numerical details are thoroughly discussed in a way that anyone interested in studying or extending the results would be able to do so.}
}
@article{LV2025113417,
title = {MDF-FND: A dynamic fusion model for multimodal fake news detection},
journal = {Knowledge-Based Systems},
volume = {317},
pages = {113417},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113417},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125004642},
author = {Hongzhen Lv and Wenzhong Yang and Yabo Yin and Fuyuan Wei and Jiaren Peng and Haokun Geng},
keywords = {Fake news detection, Dynamic fusion, Dempster–Shafer evidence theory, Information fusion},
abstract = {Fake news detection has received increasing attention from researchers in recent years, especially in the area of multimodal fake news detection involving both text and images. However, many previous studies have simply fed the semantic features of both text and image modalities into a binary classifier after applying basic concatenation or attention mechanisms, where these features often contain a significant amount of inherent noise. This, in turn, leads to both intra- and inter-modal uncertainty. In addition, while methods based on simple concatenation of the two modalities have achieved notable results, they often ignore the drawback of applying fixed weights across modalities, which causes some high-impact features to be ignored. To address these issues, we propose a novel semantic-level multimodal dynamic fusion framework for fake news detection (MDF-FND). To the best of our knowledge, this is the first attempt to develop a dynamic fusion framework for semantic-level multimodal fake news detection. Specifically, our model consists of two main components: (1) the Uncertainty Estimation Module (UEM), which is an uncertainty modeling module that uses a multi-head attention mechanism to model intra-modal uncertainty, and (2) the Dynamic Fusion Network, which is based on Dempster–Shafer evidence theory (DFN) and is designed to dynamically integrate the weights of both text and image modalities. To further enhance the dynamic fusion framework, a graph attention network is employed for inter-modal uncertainty modeling before DFN. Extensive experiments have demonstrated the effectiveness of our model across three datasets, with a performance improvement of up to 4% on the Twitter dataset, achieving state-of-the-art performance. We also conducted a systematic ablation study to gain insights into our motivation and architectural design. Our model is publicly available at https://github.com/CoisiniStar/MDF-FND.}
}
@article{FAMTA202530,
title = {Despicable role of epithelial–mesenchymal transition in breast cancer metastasis: Exhibiting de novo restorative regimens},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {1},
pages = {30-47},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000016},
author = {Paras Famta and Saurabh Shah and Biswajit Dey and Kondasingh Charan Kumar and Deepkumar Bagasariya and Ganesh Vambhurkar and Giriraj Pandey and Anamika Sharma and Dadi A. Srinivasarao and Rahul Kumar and Santosh Kumar Guru and Rajeev Singh Raghuvanshi and Saurabh Srivastava},
keywords = {Breast cancer, Epithelial-to-mesenchymal transition, Metastases, Cancer stem cells, Epigenetics},
abstract = {Breast cancer (BC) is the most prevalent cancer in women globally. Anti-cancer advancements have enabled the killing of BC cells through various therapies; however, cancer relapse is still a major limitation and decreases patient survival and quality of life. Epithelial-to-mesenchymal transition (EMT) is responsible for tumor relapse in several cancers. This highly regulated event causes phenotypic, genetic, and epigenetic changes in the tumor microenvironment (TME). This review summarizes the recent advancements regarding EMT using de-differentiation and partial EMT theories. We extensively review the mechanistic pathways, TME components, and various anti-cancer adjuvant and neo-adjuvant therapies responsible for triggering EMT in BC tumors. Information regarding essential clinical studies and trials is also discussed. Furthermore, we also highlight the recent strategies targeting various EMT pathways. This review provides a holistic picture of BC biology, molecular pathways, and recent advances in therapeutic strategies.}
}
@article{MAJRASHI2024,
title = {Determinants of Public Sector Managers’ Intentions to Adopt AI in the Workplace},
journal = {International Journal of Public Administration in the Digital Age},
volume = {11},
number = {1},
year = {2024},
issn = {2334-4520},
doi = {https://doi.org/10.4018/IJPADA.342849},
url = {https://www.sciencedirect.com/science/article/pii/S2334452024000018},
author = {Khalid Majrashi},
keywords = {AI Adoption, AI Ethics, Artificial Intelligence, Attitudes, Behavioral Intentions, Managers, Public Sector, Technology Acceptance Model, Trust in AI, Workplace},
abstract = {ABSTRACT
This study investigated the determinants of public sector managers' intentions to adopt artificial intelligence (AI) systems within their organizations. An extended technology acceptance model (TAM) was developed, incorporating additional constructs including fairness, humanity, reliability, safety, transparency, accountability, privacy, security, trust, social norms, tolerance, impact, and isomorphic pressure. A survey was conducted among 330 public sector managers, and the data were analyzed using linear regression tests to evaluate the model. The results showed significant positive influences of both perceived usefulness and perceived impact on managers' attitudes and behavioral intentions toward AI adoption. Isomorphic pressure was also a significant determinant of managers' behavioral intentions toward adopting AI systems. Our findings also indicated that perceptions related to AI ethical principles, such as transparency, privacy, and security, influenced managers' trust in AI systems.}
}
@article{KANG2023100824,
title = {Learner innovativeness, course interaction, and the use of a new educational technology system after the COVID-19 pandemic},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100824},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100824},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000629},
author = {Dongsuk Kang and Min Jae Park},
keywords = {Learner innovativeness, Learning interaction, Blended learning, Educational management, Educational innovation},
abstract = {Due to the global COVID-19 pandemic and social distancing policies, higher education has adopted a new online learning system (e.g., viewing recorded lectures at one's own pace or participating in online streaming courses) as a necessary education service. Although many universities have switched to face-to-face courses in light of the reduced spread of the coronavirus, the new system could be a meaningful complement to the traditional learning method. This study focuses on identifying factors that influence students' utilization of new lecture systems in universities. This research investigated undergraduates majoring in management and other fields in South Korea through structural questionnaires. It analyzes the data using the partial least squares methodology of structural equation analysis. The results show that learners' innovativeness could increase their willingness to use the system, and the learning interaction in a course could improve students' learning satisfaction. Furthermore, the innovativeness could lead to a positive relationship between learning satisfaction, intention to use, and the system's potential impact. These findings suggest that instructors and universities need to offer new opportunities to promote students' willingness and motivation, as well as their preparation for online courses and learning interactions.}
}
@article{YIN2025105434,
title = {The association between groups' interactions with the Visual-GenAI learning analytics feedback and student engagement in CSCL},
journal = {Computers & Education},
volume = {239},
pages = {105434},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105434},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002027},
author = {Xinghan Yin and Junmin Ye and Shuang Yu and Honghui Li and Qingtang Liu and Gang Zhao},
keywords = {Cooperative/collaborative learning, Distance education and online learning, Data science applications in education, Evaluation methodologies},
abstract = {Promoting student engagement has long been a vital subject in the research of Computer-Supported Collaborative Learning (CSCL). Previous research has indicated the potential of AI-based visual learning analytics feedback and generative AI (GenAI) feedback in this context. However, there is currently a lack of definitive research on the combined impact of these two types of intelligent feedback in CSCL. Additionally, limited attention has been paid to how groups utilize these tools in CSCL practice and the differences that may exist. In this study, we developed an Visual-GenAI learning analytics feedback tool that integrates AI-based visual learning analytics feedback and GenAI-based feedback. We then evaluated the differences in groups' interactions with this Visual-GenAI learning analytics feedback and its association with student engagement and academic performance. The study employed a mixed-methods approach, combining quantitative analysis of feedback interaction log data, content analysis of group discussion data, and qualitative analysis of students' perceptions of different feedback tools through surveys. Our results show that groups exhibit four distinct levels of feedback interaction behavior patterns with the Visual-GenAI learning analytics feedback. These four patterns exhibit significant differences in behavioral engagement, emotional engagement, cognitive engagement, and academic performance. This study's significance lies in its potential contribution to future research on examining group behavior and optimizing learning using AI-based visual learning analytics feedback and GenAI-based feedback.}
}
@article{GAO2025102907,
title = {Time-frequency dependence and dynamic linkages between digital economy and education markets},
journal = {Technology in Society},
volume = {82},
pages = {102907},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102907},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25000971},
author = {Wang Gao},
keywords = {Digital economy, Education, Time-frequency},
abstract = {This study utilizes a comprehensive analytical framework, incorporating both time and frequency domain methodologies, to investigate the complex interdependencies between the digital economy and the education market. The evaluation encompasses several critical dimensions, including return, volatility, and liquidity interconnectedness. The principal findings of this research are as follows: (1) There is a substantial co-dependence observed between the digital economy and the education sector, with a particular focus on components such as mobile internet, artificial intelligence, and big data—elements that exhibit the most pronounced linkages to educational infrastructures. Frequency domain analysis indicates that return spillover effects are potent in the short term, whereas spillovers related to volatility become increasingly significant in the long term. (2) The analysis reveals cloud computing and big data as the principal sources of spillover effects, while artificial intelligence, mobile internet, virtual reality, and online education serve as critical intermediaries. Importantly, vocational and K-12 education emerge as the primary beneficiaries of these spillover phenomena. (3) The interrelationships between the digital economy and educational markets exhibit time-varying characteristics, particularly marked by heightened fluctuations during pivotal events such as the COVID-19 pandemic and the implementation of the "Double Reduction" policy. Additionally, a notable strengthening of these trends has been observed after 2022. (4) The study demonstrates that assets associated with cloud computing, 5G technology, big data, artificial intelligence, and online education possess robust hedging effectiveness. The findings of this research aspire to inform educational policymakers regarding optimal resource allocation strategies, facilitate the seamless integration of digital technologies within educational frameworks, and provide strategic insights for asset investors seeking to navigate cross-market investments while enhancing risk management practices.}
}
@article{MENG202532,
title = {“Design nature”: A color interpretation of Bauhaus school building in Dessau and its conceptual origins},
journal = {Frontiers of Architectural Research},
volume = {14},
number = {1},
pages = {32-61},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2024.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S2095263524001043},
author = {Yuan Meng and Wei Liu},
keywords = {Dessau Bauhaus, Walter Gropius, Architectural space color design, Educational philosophy, Origin tracing research},
abstract = {In modernist architecture, color serves as a crucial tool in shaping spatial experiences. However, due to historical reasons, the color design of early modernist architecture has not been fully explored. The paper focuses on the iconic modernist work, the Bauhaus school building in Dessau. Through historical investigation and theoretical research, it elucidates the evolution of color cognition from the perspectives of color theory development, architectural color characteristics, and the interaction between visual perception and color. On this basis, it explores the color theory origins of the Bauhaus and Gropius, dissecting the conceptual framework and methods behind the color design of the Bauhaus school building in Dessau. Additionally, this article analyzes the spatial characteristics of architectural color from an experiential standpoint. The paper argues that Gropius conveyed his concept of “natural perspective” through color design, emphasizing the eternal value of natural internal logic. The Bauhaus redefined the role of color in architectural expression, based on natural laws, and deduced a scientifically designed method related to perception, promoting a shift in color design from subjective to objective and injecting deeper connotations into architectural color.}
}
@article{BRICE2024101159,
title = {Selected bibliography of recent scholarship in second language writing},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101159},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101159},
url = {https://www.sciencedirect.com/science/article/pii/S1060374324000663},
author = {Colleen Brice and Carolina Pelaez-Morales}
}
@article{UZOCHUKWU2023101820,
title = {Optimizing feed utilization and reducing deterioration of African catfish feed with sodium propionate supplementation},
journal = {Aquaculture Reports},
volume = {33},
pages = {101820},
year = {2023},
issn = {2352-5134},
doi = {https://doi.org/10.1016/j.aqrep.2023.101820},
url = {https://www.sciencedirect.com/science/article/pii/S2352513423003599},
author = {Ifeanyi Emmanuel Uzochukwu and Patrick Emeka Aba and Nelson Ike Ossai and Hillary Chukwuemeka Ugwuoke and Krisztián Nyeste and Ndubuisi Samuel Machebe},
keywords = {Sodium propionate, African catfish, Growth performance, Feed quality, Feed deterioration, Aquaculture production},
abstract = {A 56-day, two-phased experiment was conducted to investigate the effect of sodium propionate (NaP) on the growth performance of African catfish and the feed quality. One hundred juveniles with an average body weight of 50.47 g ( ± 4.60) were procured and used for the study’s first phase. Fish were randomly assigned to five groups (A, control group), B, C, D, and E) and replicated four times with five fish each. Respective groups were fed diets containing NaP at 0, 1.67, 3.33, 5.00, and 6.67 g kg−1 feed, respectively. For the second trial, the individual diets were analyzed for quality characteristics on 0-, 28- and 56-days of storage, using a mixed-model analysis of variance. Results showed significant differences in most growth performance parameters among groups except for the final body length and condition factor. Group C had lower final body weight (FW), weight gain (WG), average feed intake (AFI), specific growth rate (SGR), and higher feed conversion ratio (FCR) than the control. However, these parameters did not differ in Group D, which also showed lower AFI compared to the control. Increasing NaP decreased the sensory attribute scores of the feed and its crude protein (CP), ether, and ash levels while increasing moldiness, crude fiber, nitrogen-free extract, and thiobarbituric acid reactive substances (TBARs). NaP inclusion in feed resulted in a dose-dependent reduction in the feed deterioration, as seen in the lowered aggregate changes in sensory attributes, CP, moisture, and ash levels, with Group D having an optimal effect. The TBARs level (rancidity) decreased in Group B but increased in Group E during the study. The study concludes that there was a loss of fish feed quality with increasing storage time and that NaP particularly at 5.0 g kg−1 feed optimally improves feed utilization and effectively lowers feed deterioration for 56 days. Therefore, the use of NaP is recommended for improved aquaculture production.}
}
@article{ZHANG2025108457,
title = {Flow in ChatGPT-based logic learning and its influences on logic and self-efficacy in English argumentative writing},
journal = {Computers in Human Behavior},
volume = {162},
pages = {108457},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108457},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400325X},
author = {Ruofei Zhang and Di Zou and Gary Cheng and Haoran Xie},
keywords = {AI in education, ChatGPT-based learning, Engagement, Flow experience, Learning affection and cognition, Logic learning},
abstract = {Flow is a state of full engagement in an activity. Learning environments featured by Skill-challenge balance, Clear goal, Feedback, and Playability — collectively known as flow antecedents – can induce flow experiences and improve learning outcomes. ChatGPT-based environment seems to encourage a flow in learners: By customising tasks to match students' abilities, aligning materials with clear objectives, providing instant feedback, and ensuring ease of use, ChatGPT can help learners enter a flow state, which, in turn, leads to improved learning. However, there hasn't been much research on flow in ChatGPT-based learning. To bridge the gap, we developed a ChatGPT-based environment for developing logic in English argumentative writing. We studied 40 Chinese university English-as-a-foreign-language (EFL) students in the learning using questionnaires, eye-tracking data, knowledge tests, essay writing tasks, and semi-structured interviews to understand how they experienced flow and how it affected their learning. Our findings showed that the ChatGPT-based environment strongly supports flow antecedents. Skill-challenge balance and Playability were particularly influential for inducing flow experiences. Students who experienced a deeper flow showed better understanding of argumentative writing logic, although their writing self-efficacy became lower. Drawing from the findings, our study highlights how AI like ChatGPT can influence experiences and outcomes of logic learning and language learning, which may be applicable across various domains and disciplines.}
}
@incollection{DAVILADELGADO2025463,
title = {Chapter 23 - Demystifying machine learning for predictive analytics in construction},
editor = {Ehsan Noroozinejad Farsangi and Mohammad Noori and T.Y Yang and Vasilis Sarhosis and Seyedali Mirjalili and Mirosław J. Skibniewski},
booktitle = {Digital Transformation in the Construction Industry},
publisher = {Woodhead Publishing},
pages = {463-486},
year = {2025},
series = {Woodhead Publishing Series in Civil and Structural Engineering},
isbn = {978-0-443-29861-5},
doi = {https://doi.org/10.1016/B978-0-443-29861-5.00023-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443298615000238},
author = {Juan Manuel {Davila Delgado}},
keywords = {Machine learning, artificial intelligence, computer vision, construction, AEI.},
abstract = {This is a horizontal analysis on the state of research of machine learning (ML) for construction applications. The objective is to identify relevant topics in the research area and clarify the actual capabilities and limitations of ML approaches for construction. A literature review and thematic analyses were conducted to identify significant topics as well as an analysis of the most cited papers and use cases. A discussion of relevant applications and challenges is presented as well. The key findings are (1) there has been a massive increase on research efforts in the area; however, research is still behind in the use of state-of-the-art models, such as large language models, transformers, and reinforcement learning. Most importantly, it is usually limited to the use of relatively small datasets. (2) There are still significant challenges regarding the creation of sufficiently large datasets, but there are effective manners to address those challenges including the creation of synthetic data. This study provides construction practitioners and researchers with an overview of the key aspects of research on ML in construction that will help improve the understanding in this research area.}
}
@article{LI2025106509,
title = {Movement behavior of rock strata in multi-level sublevel filling mining and forecasting of differential surface subsidence},
journal = {Results in Engineering},
volume = {27},
pages = {106509},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.106509},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025025782},
author = {Fei Li and Yihui Feng and Haitao Ma and Yongming Yin and Xinai Lu and Chaoyu Zan},
keywords = {Mining rock mechanics, Filling mining method, Strata control, Stress arch, Multi-level backfill mining},
abstract = {To address issues such as ground pressure manifestation, rock beam fracture, and overburden displacement caused by multi-level sublevel filling mining of gently inclined medium-thick ore bodies, this study adopts the Fankou Lead-Zinc Mine as the engineering background. Through a combination of numerical simulation and theoretical analysis, it systematically reveals the movement behavior and the mechanism of surface subsidence of the overburden under the disturbance of multi-level sublevel filling mining. Mechanical models of the stress “pressure relief arch” and “bearing arch” are established, along with a mechanical model of the filling body and roof under combined disturbance effects. The results indicate that multi-level sublevel filling mining induces nonlinear superposition effects in the stress unloading-loading cycles. The disturbance of adjacent stopes induces an alternating development pattern of “pressure relief arch” and “bearing arch”. The activation of potential slip surfaces under combined disturbance is a key controlling factor contributing to asymmetric surface settlement. The disturbance zone can be divided into three types: a direct disturbance zone influencing the settlement magnitude of the overburden; a compound disturbance zone that alters the transmission pattern of mining-induced stress and the height of the stress arch; and a potential slip zone prone to shear and tensile failure. The stope layout pattern significantly influences the transmission pattern of mining-induced stress and the disturbance range. Under the intermittent mining mode, the overburden experiences uneven deformation within a height range of less than 150 m, whereas under the continuous filling-mining mode, uneven deformation extends to a height of up to 220 m.}
}
@article{ZHANG2024104911,
title = {Strategies and conditions for crafting managerial responses to online reviews},
journal = {Tourism Management},
volume = {103},
pages = {104911},
year = {2024},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.104911},
url = {https://www.sciencedirect.com/science/article/pii/S026151772400030X},
author = {Xin Zhang and Lei La and GuoQiong Ivanka Huang and Haoxiang Xie},
keywords = {Managerial response, Customer reviews, Helpfulness votes, Uncertainty reduction theory, Rapport management model},
abstract = {The present study investigates how managerial responses to online reviews can help managers maintain relationships with past and future customers, exploring the question through the lens of the uncertainty reduction theory and the rapport management model. The present work crawled 446,663 customer reviews and 96,633 tour managerial responses on Ctrip.com using Python. Through randomly selecting 1000 responses, Study 1 manually identified nine managerial response strategies to customer online reviews. The Bidirectional Encoder Representations from Transformers (BERT) model was then adopted to automatically label the strategies used in all of the managerial responses. Employing negative binomial regression models, Study 2 then examined the interactions between attributes of customer reviews and managerial responses as a method for estimating helpfulness votes. The results indicate that excessively lengthy, highly templated, and unfocused managerial responses to customer reviews can dampen the relationship between customers’ information processing and their perception of the helpfulness of online reviews.}
}
@article{HUSSAIN2024344,
title = {Temperature, topography, woody vegetation cover and anthropogenic disturbance shape the orchids distribution in the western Himalaya},
journal = {South African Journal of Botany},
volume = {166},
pages = {344-359},
year = {2024},
issn = {0254-6299},
doi = {https://doi.org/10.1016/j.sajb.2024.01.042},
url = {https://www.sciencedirect.com/science/article/pii/S0254629924000541},
author = {Karamit Hussain and Muhammad Ejaz-Ul-Islam Dar and Arshad Mahmood Khan and Taskeen Iqbal and Ansar Mehmood and Tariq Habib and Ihab Mohamed Moussa and Ryan Casini and Hosam O. Elansary},
keywords = {Climate variability, Orchids microhabitats, Community ecology, Species interactions, Diversity and distribution},
abstract = {Orchid species require unique microhabitat conditions and are globally distributed from the tropics to alpine regions. These plant species are important both ecologically and economically but are facing multiple threats, especially habitat destruction, climate change, and overexploitation. Therefore, documenting species richness, diversity, distribution, and important driving factors is crucial for biodiversity conservation. The orchid species distribution patterns and order of importance of the main driving environmental factors in the western Himalayas of Azad Jammu and Kashmir remain unclear. The main aims of this study were to explore the richness and distribution of orchids and neighboring vascular flora and to identify the principal driving environmental factors, as no study has yet targeted these plant species specifically in the study area. Field data collection surveys were conducted from August 2018 to July 2021 using the vegetation sampling method. The presence of ≥ two individuals belonging to any orchid species in a 20 × 20 m² land area criterion was used to select the study sites along the elevation gradient for data collection. Multivariate statistical tools, such as hierarchical classification and ordination, were used to analyze the data. A total of 32 orchid species belonging to 18 different Orchidaceae genera were recorded at the 57 study sites. Only one individual each of Herminium monorchis, Habenaria furcifera, and Malaxis muscifera was collected, depicting these orchids as extremely rare in the study area. A total of 324 vascular plant species (including orchids and their neighboring plant species in the studied plots) were classified into seven significantly (p < 0.05) different plant associations, each with a unique species composition. The results of canonical correspondence analysis showed that temperature variability was the most influential among the 28 environmental factors considered. Different microhabitats with an elevation range of ≥1500–3500 m a.s.l. in the central part of the study area are moister and richer in organic matter and support high orchid diversity. It was observed that a higher density of co-existing tree and shrub species and a higher geographic slope were supporting the growth and survival of orchid species as well. Conversely, higher deforestation activities and potassium levels in the soil were observed as negatively influencing factors. The influence of non-native plant species on orchid species distribution was not significant, indicating that the local orchid species were not remarkably affected when growing in microhabitats with optimal conditions. This study concluded that the central part of the study area is richer in orchid abundance and diversity and needs effective conservation and management planning.}
}
@article{HUYNH2025114159,
title = {Joint state-parameter estimation for the reduced fracture model via the united filter},
journal = {Journal of Computational Physics},
volume = {538},
pages = {114159},
year = {2025},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2025.114159},
url = {https://www.sciencedirect.com/science/article/pii/S0021999125004425},
author = {Phuoc Toan Huynh and Thi-Thao-Phuong Hoang and Guannan Zhang and Feng Bao},
keywords = {Reduced fracture model, Data assimilation, Joint state-parameter estimation, Ensemble score filter, Bayesian inference},
abstract = {In this paper, we introduce an effective United Filter method for jointly estimating the solution state and physical parameters in flow and transport problems within fractured porous media. Fluid flow and transport in fractured porous media are critical in subsurface hydrology, geophysics, and reservoir geomechanics. Reduced fracture models, which represent fractures as lower-dimensional interfaces, enable efficient multi-scale simulations. However, reduced fracture models also face accuracy challenges due to modeling errors and uncertainties in physical parameters such as permeability and fracture geometry. To address these challenges, we propose a United Filter method, which integrates the Ensemble Score Filter (EnSF) for state estimation with the Direct Filter for parameter estimation. EnSF, based on a score-based diffusion model framework, produces ensemble representations of the state distribution without deep learning. Meanwhile, the Direct Filter, a recursive Bayesian inference method, estimates parameters directly from state observations. The United Filter combines these methods iteratively: EnSF estimates are used to refine parameter values, which are then fed back to improve state estimation. Numerical experiments demonstrate that the United Filter method surpasses the state-of-the-art Augmented Ensemble Kalman Filter, delivering more accurate state and parameter estimation for reduced fracture models. This framework also provides a robust and efficient solution for PDE-constrained inverse problems with uncertainties and sparse observations.}
}
@article{MARKOVITCH2024103847,
title = {Consumer reactions to chatbot versus human service: An investigation in the role of outcome valence and perceived empathy},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103847},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103847},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924001437},
author = {Dmitri G. Markovitch and Rusty A. Stough and Dongling Huang},
keywords = {Chatbot, Empathy, Chatbot appearance, Anthropomorphic, Humanoid, Attribution theory},
abstract = {Service outcome valence is a prominent contextual factor that has been under-researched in studies of consumer response to automated service-givers. We investigate whether consumers respond differently to chatbot and human customer service when faced with positive versus negative service outcomes. We also explore the role of perceived empathy as a potential mediator in the focal relationship. 714 individuals participated in three studies based on the vignette method. Study participants reported significantly lower satisfaction, repatronage intentions, recommendation acceptance, and recommending the provider to others following interactions with a chatbot compared with a human agent in both positive and negative service outcome conditions. The effect was fully mediated by the service-giver's perceived empathy. Increasing a chatbot's perceived empathy via more empathetic communication (but not human-like appearance) improved consumer evaluations of chatbot service relative to a less empathetic chatbot configuration and matched evaluations of the human agent. A fourth study involved a quasi-experiment in which 100 individuals interacted with ChatGPT to obtain medical advice. This study corroborated our conclusions about the impact of perceived empathy on consumers' service experience and provider ratings.}
}
@article{BAO2023,
title = {A Preliminary Study on Graduate Student Instructors’ Exploration, Perception, and Use of ChatGPT},
journal = {International Journal of Computer-Assisted Language Learning and Teaching},
volume = {13},
number = {1},
year = {2023},
issn = {2155-7098},
doi = {https://doi.org/10.4018/IJCALLT.332873},
url = {https://www.sciencedirect.com/science/article/pii/S2155709823000099},
author = {Yingling Bao and Belle Li},
keywords = {ChatGPT, Exploration, Foreign Language, Novice Instructors, Perception, TPACK},
abstract = {ABSTRACT
Research on teachers’ technological pedagogical content knowledge (TPACK) has been burgeoning recently. Yet, little is known about how teachers integrate AI tools such as ChatGPT in language teaching. This preliminary qualitative study investigates the exploration and incorporation of ChatGPT in language teaching by graduate student instructors (GSIs). By analyzing data from questionnaires, focus group interviews, screenshots of interactions with ChatGPT, and participants' lesson plans, this study shows how instructors develop their knowledge about ChatGPT and mobilize content and pedagogy knowledge to enact technology integration. Findings reveal that GSIs adopted various strategies when exploring the affordances of ChatGPT. Furthermore, while GSIs form positive perceptions of ChatGPT affordances, negative perceptions pertain to its limited capacity to process the Chinese language. Lastly, GSIs drew on various aspects of TPACK to design lessons, among which content knowledge and its interplay with technology seem to be prominent.}
}
@article{WANG2025108658,
title = {Recent advances in engineering microbial lipases for industrial applications},
journal = {Biotechnology Advances},
volume = {83},
pages = {108658},
year = {2025},
issn = {0734-9750},
doi = {https://doi.org/10.1016/j.biotechadv.2025.108658},
url = {https://www.sciencedirect.com/science/article/pii/S0734975025001442},
author = {Geng Wang and Asma Abdella and Mohamadali Fakhari and Jie Dong and Kevin K. Yang and Shang-Tian Yang},
keywords = {Lipase, Enzyme, Genetic engineering, Immobilization, Protein engineering},
abstract = {Lipases, a green biocatalyst found in animals, plants, and microorganisms, are widely used in the agricultural, biofuel, cosmetics, chemical, food, pharmaceutical, and textile industries due to their versatility, exceptional specificity, and ease of production and use. However, the presence of multiple isoforms of microbial lipases often limits their applications and requires costly purification. There are also growing demands for improved lipase stability, activity, and specificity in industrial applications. One emerging research direction in this field is integrating synthetic biology and engineering tools to design novel lipases for diverse industrial applications. Recent progress in protein engineering, immobilization technologies, and artificial intelligence (AI) tools have significantly improved lipase catalytic performance. This paper provides a comprehensive review of the classification, general characteristics, industrial production and applications of lipases and recent advances in engineering lipases and lipase-producing microbial cells to develop novel lipase-based bioprocesses and bioproducts.}
}
@article{SONTADRACZKOWSKA2025321,
title = {Co-creating innovations with users: A systematic literature review and future research agenda for project management},
journal = {European Management Journal},
volume = {43},
number = {2},
pages = {321-339},
year = {2025},
issn = {0263-2373},
doi = {https://doi.org/10.1016/j.emj.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0263237324000902},
author = {Ewa Sońta-Drączkowska and Marzenna Cichosz and Patrycja Klimas and Tomasz Pilewicz},
keywords = {NPD, User-driven innovation, User engagement, Co-innovation, PM, Domain-based review, Meta-systematic review},
abstract = {This study aimed to systematically review the extensive literature on user innovation co-creation and connect the findings to the project management domain. It focused specifically on new product development, offering a domain-based systematic review of methods, tools, and user types involved in the co-creation process. Analyzing a total of 266 articles, the authors synthesize the types of users and methods discussed in the domain of user innovation, aligning them across the new product development cycle and specific phases of co-innovation. Additionally, the authors formulate research questions and propositions that may inspire the project management domain. This study provides insights into innovation-oriented, exploratory project management and enhances the configuration approach to project management. From a practical perspective, it provides a comprehensive overview of methods that can enrich a managerial toolkit for leading innovative projects.}
}
@article{ROSCOE2023103059,
title = {Automated strategy feedback can improve the readability of physicians’ electronic communications to simulated patients},
journal = {International Journal of Human-Computer Studies},
volume = {176},
pages = {103059},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2023.103059},
url = {https://www.sciencedirect.com/science/article/pii/S107158192300068X},
author = {Rod D. Roscoe and Renu Balyan and Danielle S. McNamara and Michelle Banawan and Dean Schillinger},
keywords = {Automated feedback, Natural language processing, Patient-physician communication, Readability, Electronic health records, Health literacy},
abstract = {Modern communication between health care professionals and patients increasingly relies upon secure messages (SMs) exchanged through an electronic patient portal. Despite the convenience of secure messaging, challenges include gaps between physician and patient expertise along with the asynchronous nature of such communication. Importantly, less readable SMs from physicians (e.g., too complicated) may result in patient confusion, non-adherence, and ultimately poorer health outcomes. The current simulation trial synthesizes work on patient-physician electronic communication, message readability assessments, and feedback to explore the potential for automated strategy feedback to improve the readability of physicians’ SMs to patients. Within a simulated secure messaging portal featuring multiple simulated patient scenarios, computational algorithms assessed the complexity of SMs written by 67 participating physicians to patients. The messaging portal provided strategy feedback for how physician responses might be improved (e.g., adding details and information to reduce complexity). Analyses of changes in SM complexity revealed that automated strategy feedback indeed helped physicians compose and refine more readable messages. Although the effects for any individual SM were slight, the cumulative effects within and across patient scenarios showed trends of decreasing complexity. Physicians appeared to learn how to craft more readable SMs via interactions with the feedback system. Implications for secure messaging systems and physician training are discussed, along with considerations for further investigation of broader physician populations and effects on patient experience.}
}
@article{WANG2024102809,
title = {Exploring product rendering generation design catering to multi-emotional needs through the Superiority Chart-Entropy Weight method and Stable Diffusion model},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102809},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102809},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004579},
author = {Zeng Wang and Hui-ru Pan and Jiang-shan Li and Shi-fan Niu},
keywords = {Superiority Chart-Entropy Weight method, Stable Diffusion model, Product rendering, Multi-emotional needs, Tunable weight allocation mechanism, Data driven},
abstract = {The experience economy has shifted user demands towards emotionalization, emphasizing multi-emotional considerations as pivotal in design. This study addresses challenges in accurately determining emotional needs and the inadequacy of current intelligent design approaches. It proposes a method for designing multi-emotional product renderings by integrating the Superiority Chart-Entropy Weight method with the Stable Diffusion model within a big data framework. Initially, online user comments, hand-drawn sketches, and renderings of target products are collected. The Superiority Chart-Entropy Weight is then adopted to establish weights for multi-emotional needs, creating an allocation mechanism of these weights. Incorporating these multi-emotional weights, a Stable Diffusion model embedded with LoRa is trained to generate diverse rendering schemes. Finally, the Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) method is employed to select the optimal rendering scheme for 3D display. An experimental case study focusing on new energy vehicle renderings demonstrates the efficiency of this approach in precisely meeting users’ multi-emotional needs, thereby enhancing design efficiency and quality. Comparative experiments indicate that the method proposed in this study offers advantages in creating multi-emotional renderings. This study innovatively introduces a finer-grained multi-emotional needs confirmation method for users, overcoming the ambiguity and uncertainty of traditional recognition approaches, and develops a Stable Diffusion generation method tailored for product renderings, providing practical value in streamlining the conventional product design representation cycle and enhancing design efficiency, quality and user satisfaction.}
}
@article{LIU2024103191,
title = {Does modality matter? A meta-analysis of the effect of video input in L2 listening assessment},
journal = {System},
volume = {120},
pages = {103191},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2023.103191},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X23002130},
author = {Tingting Liu and Vahid Aryadoust},
keywords = {Audio-based listening assessment, Meta-Analysis, Meta-regression, Target language use (TLU) domain, Video-based listening assessment, Visual cues},
abstract = {Over the past two decades, there has been a growing research interest in examining the effects of video-based second language (L2) listening tests. However, these studies have shown inconsistency in their findings, prompting the need for a comprehensive analysis. This study aims to address this issue by conducting a meta-analysis to synthesize the quantitative research in this field. Our primary objective is to determine the pooled effect of video-based L2 listening assessment on test-takers’ listening comprehension and identify moderators that could potentially influence this effect. These potential moderators encompassed participants' characteristics, research method, video input features, and outcome measures. Through an extensive search process, we identified a total of 28 primary studies (years 1984–2022) that contributed data from 43 independent samples. We found that video input had a small overall positive effect on test-takers’ performance (g = 0.297). Additionally, we observed patterns in the effect of video input across different levels of moderators such as test-takers’ language proficiency, research design, reporting of reliability, speaker presentation, video length, question accessibility, note-taking availability, and item format. We discuss the implications of these findings and conclude with the limitations and several perspectives for future research.}
}
@article{DONG2024116666,
title = {Ship pipe route design based on NSGA-III and multi-population parallel evolution},
journal = {Ocean Engineering},
volume = {293},
pages = {116666},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.116666},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824000039},
author = {Zong-ran Dong and Wan-wan Luo},
keywords = {Ship pipe route design, Multi-objective optimization, NSGA-III, Heuristic pathfinding, OpenMP, Parallel evolution},
abstract = {Ship pipe route design (SPRD) aims to generate pipe layouts while considering various objectives and constraints in a confined 3D space, leading to extremely high complexity. To solve the problem of SPRD, traditional methods often adopt weighted summation of sub-objectives, introduce penalty functions to convert it to a single-objective optimization problem. However, these methods tend to yield a single optimal pipe route design pattern, and some existing multi-objective pipe routing algorithms do not have high search performance or sufficient treatment of constraints. Based on the grid-space decomposition model, this paper establishes a multi-objective pipe routing optimization model with several sub-objectives including path length, bends number, path energy, number of air-pockets, and number of violated bending distance, which also considers pipe routing for different diameters and interface direction requirements. A ship pipe route design framework based on the NSGA-III (Non-dominated Sorting Genetic algorithm III) is proposed, and its embedded pathfinding algorithm can explore pipe route using heuristic information and failure retry strategy, which greatly reduces the algorithm complexity compared to the classical algorithms such as A* and LEE and also facilitates parallel implementation. By employing OpenMP technology to achieve parallel evolution of multiple populations, more Pareto optimal solutions can be obtained in approximately the same timeframe as single population evolution. Finally, through comparative experiments using simulated cases, the feasibility and advancement of the proposed method are verified.}
}
@article{MELO2025322,
title = {An overview of randomized phase III clinical trials of cancer nanomedicines},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {4},
pages = {322-336},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000867},
author = {Micael N. Melo and Ricardo G. Amaral and Lucas R. {Melo de Andrade} and Patricia Severino and Cristina Blanco-Llamero and Luciana N. Andrade and Eliana B. Souto},
keywords = {Antineoplastic drugs, Chemotherapy, Nanomedicine, Drug delivery systems, Personalized medicine, Clinical trials},
abstract = {Background
Cancer therapy has undergone significant advances in recent decades attributed to personalized medicine and targeted drug delivery. Among the promising approaches, the use of nano-based delivery systems has become a relevant approach capable of improving treatment by releasing antineoplastic drugs at the target site, improving therapeutic efficacy, minimizing cytotoxicity in healthy tissues, and ultimately, reducing the intensity of adverse effects of chemotherapy. This study prospectively evaluated the impact of formulating anti-neoplastic drugs as nanomedicines on clinical response, overall survival, safety, and quality of life of cancer patients, based on the outcomes of randomized clinical trials.
Methods
A literature review was carried out by systematically searching the PubMed/MEDical Literature Analysis and Retrieval System Online (MEDLINE), Excerpta Medica Database (EMBASE), and Latin American and Caribbean Health Sciences Literature (LILACS) databases for phase III clinical trials, comparing nanomedicines with conventional therapies for the treatment of various cancer types.
Results
The nanomedicines analyzed were those that are approved and used in Brazil, considering the country's emerging market for advanced cancer treatments. From a total of 303 articles found, 26 articles were selected for systematic review. Studies showed that PEGylated l-asparaginase achieved a similar therapeutic effect to that of l-asparaginase, with fewer applications due to its longer half-life. Paclitaxel bound to albumin improved therapeutic efficacy as well as reduced infusion time and solvent-related toxicity of the conventional paclitaxel formulation. PEGylated liposomal doxorubicin showed better pharmacokinetics, reduced cardiotoxicity, and improved quality of life in cancer patients compared to that of free doxorubicin.
Conclusions
This study reinforces the scientific evidence of the added value of nanomedicines to improve therapeutic efficacy and reduce toxicity in patients under chemotherapy.}
}
@article{BIE2025101002,
title = {Can news predict firm bankruptcy?},
journal = {Journal of Financial Markets},
pages = {101002},
year = {2025},
issn = {1386-4181},
doi = {https://doi.org/10.1016/j.finmar.2025.101002},
url = {https://www.sciencedirect.com/science/article/pii/S1386418125000424},
author = {Siyu Bie and Guanhao Feng and Naixin Guo and Jingyu He},
keywords = {Bankruptcy prediction, ChatGPT, Generative AI, News data, Sentiment},
abstract = {We examine whether real-time business news predicts firm bankruptcy. Using full-text daily articles from the Dow Jones Newswires database, we generate firm-level predictors with ChatGPT and benchmark against FinBERT and dictionary-based models. ChatGPT-based variables outperform alternatives, with sentiment scores showing predictive power across horizons. Full-text news significantly enhance predictive accuracy over headlines. News-based measures add explanatory power beyond financial variables. Finally, we show that news captures timely information on macroeconomic conditions relevant to bankruptcy prediction, such as VIX, real GDP growth, and recession probability.}
}
@article{HARWOOD2024104013,
title = {“Anything you can do, I can do”: Examining the use of ChatGPT in situational judgement tests for professional program admission},
journal = {Journal of Vocational Behavior},
volume = {154},
pages = {104013},
year = {2024},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2024.104013},
url = {https://www.sciencedirect.com/science/article/pii/S000187912400054X},
author = {Harley Harwood and Nicolas Roulin and Muhammad Zafar Iqbal},
keywords = {Generative AI, ChatGPT, Situational judgement tests, Faking},
abstract = {We explored the transformative impact of ChatGPT on applicants' responses and performance in situational judgement tests (SJTs), as well as the role played by faking-prevention mechanisms, in two complementary studies. Study 1 examined how the availability of ChatGPT influenced response content and performance of real applicants (N = 107,805), who completed an SJT for admission before vs. after the release of the technology. We found only small differences in content (e.g., slightly less “authentic” words used) and performance (slight score improvements when controlling for response length, no differences otherwise). In Study 2, we used an experimental approach with (N = 138) Prolific participants completing a mock SJT, while being instructed to use ChatGPT when responding (vs. use online resources or no resources). We found only slightly higher SJT scores for the ChatGPT users, but no difference in response content. Additionally, GPTZero (i.e., a popular AI detection tool) struggled to detect ChatGPT content, and generated many false positives, in both studies. This research advances our understanding of how the release and popularization of ChatGPT can influence applicant behaviors. Given the “arms race” nature of applicant selection, they also highlight the importance of designing assessments to prevent or limit faking. Yet, the ever-evolving nature of AI calls for continuous research on the topic.}
}
@article{2023A5,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {36},
number = {7},
pages = {A5-A13},
year = {2023},
note = {34th ASE Annual Scientific Sessions},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(23)00276-6},
url = {https://www.sciencedirect.com/science/article/pii/S0894731723002766}
}
@article{HIGGINS2025103630,
title = {Evaluating empathic responses to bimodal realism in emotionally expressive virtual humans: An eye-tracking and facial electromyography study},
journal = {International Journal of Human-Computer Studies},
volume = {205},
pages = {103630},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103630},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925001879},
author = {Darragh Higgins and Benjamin R. Cowan and Rachel McDonnell},
keywords = {Virtual humans, Emotion perception, Empathy, Realism},
abstract = {With the expanding range of uses for advancements in animation and voice synthesis, more opportunities arise for interactions with animated virtual humans. Such interactions may be influenced by improved portrayals of character features such as emotion and realism. The present study aimed to examine how variations in animated facial detail and vocal prosody shape user perception of emotion in virtual characters. This impact was assessed via facial electromyography and eye-tracking measures, as well as self-reports of state empathy and character appeal. Results indicate that participants were influenced by emotional valence in terms of zygomaticus major and corrugator supercilii muscle activation. Survey data appear to show greater empathy for conditions of increased facial detail and more human-like vocal prosody. Moreover, eye tracking results suggest a preference for eye contact regardless of detail or prosody, with participants fixating more on facial areas of interest overall for the positively valenced conditions. Finally, there is evidence that trait empathy and mismatches between higher facial detail and lower vocal human-likeness may influence zygomaticus major activity in response to positively valenced stimuli. These results are discussed in the context of virtual character design, contemporary understandings of empathy and the phenomenon of the Uncanny Valley.}
}
@article{LI2025175,
title = {Generative AI-powered planning: A hybrid graph-diffusion approach for demand-driven flexible manufacturing systems},
journal = {Journal of Manufacturing Systems},
volume = {83},
pages = {175-195},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525002109},
author = {Chen Li and Qing Chang},
keywords = {Flexible smart manufacturing systems (FSMS), Generative AI, Diffusion model, Graph neural network (GNN), Manufacturing system planning, Robot assignment},
abstract = {Flexible Smart Manufacturing Systems (FSMS) are critical to achieving mass customization and operational agility under Industry 4.0. However, planning effective FSMS configurations remains challenging due to fluctuating market demands, heterogeneous system components, complex interdependencies, and the need to optimize resource utilization. Conventional planning methods often require predefined line configurations and lack adaptability, scalability, and awareness of dynamic system properties. This paper presents a novel Hybrid Graph-Diffusion Based Planning Framework that integrates generative AI with system-theoretic modeling to autonomously generate optimal FSMS configurations based on different market demands. Specifically, we introduce a system model-embedded Heterogeneous Graph (HG) to represent the structure and properties of an FSMS and infuse it within a system property-tailored diffusion model to generate reconfigurable plan configurations. The final system property-guided refinement guarantees that the final plan configuration is optimal in both demand satisfaction and resource use. Furthermore, our ablation studies validate that our framework significantly outperforms conventional approaches in both demand satisfaction and resource efficiency. Furthermore, our ablation studies validate the effectiveness of the system property guidance and HG-based representation in enhancing planning feasibility, robustness, and adaptability.}
}
@article{2024A11,
title = {Guide for Authors},
journal = {Journal of the American Society of Echocardiography},
volume = {37},
number = {1},
pages = {A11-A19},
year = {2024},
issn = {0894-7317},
doi = {https://doi.org/10.1016/S0894-7317(23)00603-X},
url = {https://www.sciencedirect.com/science/article/pii/S089473172300603X}
}
@article{RENAUD2024103877,
title = {VISTA: An inclusive insider threat taxonomy, with mitigation strategies},
journal = {Information & Management},
volume = {61},
number = {1},
pages = {103877},
year = {2024},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2023.103877},
url = {https://www.sciencedirect.com/science/article/pii/S0378720623001258},
author = {Karen Renaud and Merrill Warkentin and Ganna Pogrebna and Karl {van der Schyff}},
keywords = {Insider threats, Taxonomy, Mitigations, Cybersecurity},
abstract = {Insiders have the potential to do a great deal of damage, given their legitimate access to organisational assets and the trust they enjoy. Organisations can only mitigate insider threats if they understand what the different kinds of insider threats are, and what tailored measures can be used to mitigate the threat posed by each of them. Here, we derive VISTA (inclusiVe InSider Threat tAxonomy) based on an extensive literature review and a survey with C-suite executives to ensure that the VISTA taxonomy is not only scientifically grounded, but also meets the needs of organisations and their executives. To this end, we map each VISTA category of insider threat to tailored mitigations that can be deployed to reduce the threat.}
}
@article{DAI2023108129,
title = {ITF-WPI: Image and text based cross-modal feature fusion model for wolfberry pest recognition},
journal = {Computers and Electronics in Agriculture},
volume = {212},
pages = {108129},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.108129},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923005173},
author = {Guowei Dai and Jingchao Fan and Christine Dewi},
keywords = {Cross-modal fusion, Contextual transformer, Pyramid squeeze attention mechanism, Convolutional neural network and bi-directional long short-term memory, Pest recognition},
abstract = {As one of the necessary cash crops in China and many other countries, wolfberry is parasitized by multiple pests, and its yield is highly susceptible to being affected. On the other hand, agricultural pest backgrounds are complex. When identifying them, single-modal models cannot utilize diverse data types across modalities, resulting in low identification accuracy and data utilization. Traditional unimodal identification models can no longer meet the needs of multimodal data development in agriculture. To overcome these challenges, the ITF-WPI cross-modal feature fusion model is proposed, which consists of CoTN and ODLS for parallel processing of images and text, respectively. We incorporate the Transformer structure (CoT), which focuses on contextual feature extraction, into CoTN to make full use of the rich static and dynamic linear fusion contexts between adjacent keys and improve the 4-stage network of CoTN using Pyramid Squeezed Attention (PSA) to improve the extraction of multi-scale feature structure information and effectively promote the interaction of in-depth features with multi-scale spatial information. The ODLS network constructed by introducing 1D convolutional and bidirectional LSTM stacking has been shown to have more robust text feature acquisition than other advanced convolutional neural network-long short-term memory (CNN-LSTM) models from experimental results, with a 30% reduction in MACCs compared to the optimal model. The results showed that ITF-WPI performed well in accuracy, F1 score, model size, and MACCs with 97.98%, 93.19%, 52.20 MB, and 7.828 G compared to the classical state-of-the-art (SOTA) model, lightweight SOTA model and advanced Transformer neural network synthesis, respectively. The model has critical practical applications for promoting the development of cross-modal models in agriculture and research on wolfberry pest control and improving wolfberry yields. The code and dataset for this study will be posted on GitHub (https://github.com/wemindful/Cross-modal-pest-Identifying) as soon as the study is released, and new data will be updated in the future.}
}
@article{ARDIMENTO2025112569,
title = {A novel LLM-based classifier for predicting bug-fixing time in Bug Tracking Systems},
journal = {Journal of Systems and Software},
volume = {230},
pages = {112569},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112569},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002389},
author = {Pasquale Ardimento and Michele Capuzzimati and Gabriella Casalino and Daniele Schicchi and Davide Taibi},
keywords = {Bug fixing time, Software maintenance and evolution, Large language models, Zero-shot learning},
abstract = {Predicting whether a newly submitted bug will be resolved quickly or slowly is a crucial aspect of the bug triage process, as it enables project managers to estimate software maintenance efforts and manage development workflows more effectively. This paper proposes a deep learning approach for classifying bug reports into two categories—FAST or SLOW—based on their expected fixing time. The method leverages a feature set composed of the bug description and reporter comments and adopts a transfer learning strategy using pre-trained Large Language Models (LLMs). The problem is framed as a supervised text classification task, where LLMs exploit their ability to learn rich contextual representations of language. We introduce a novel classification workflow that guides the LLM through a structured prompt, combining two design patterns: the persona pattern to contextualize the task and the input semantic pattern to organize textual information. The workflow relies on zero-shot learning to assess whether the intrinsic knowledge embedded in the LLMs is sufficient for this prediction task. We conducted a comprehensive evaluation of three state-of-the-art LLMs across multiple real-world datasets sourced from Bugzilla, encompassing a diverse range of software projects. The experimental results demonstrate that the proposed method is effective in accurately identifying fast-resolving bugs. Among the evaluated models, LLaMA3-8B consistently delivered superior performance. Additionally, the absence of statistically significant performance variations across datasets highlights the generalizability of the approach. Notably, the LLMs maintained strong performance even on small and imbalanced datasets, underscoring their robustness and practical applicability in real-world, data-scarce scenarios.}
}
@article{KENNEDY2025106116,
title = {Asia-Pacific Developments},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106116},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106116},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000111},
author = {Gabriela Kennedy and Joanna Wong and Justin Lai and James North and Philip Catania and Michael do Rozario and Jack Matthews and Arun Babu and Gayathri Poti and Ishita Vats and Kiyoko Nakaoka and Lam Chung Nian and Emma Choe},
abstract = {This column provides a country by country analysis of the latest legal developments, cases and issues relevant to the IT, media and telecommunications' industries in key jurisdictions across the Asia Pacific region. The articles appearing in this column are intended to serve as ‘alerts’ and are not submitted as detailed analyses of cases or legal developments.}
}
@article{LEE2024102520,
title = {Data Collection, data mining and transfer of learning based on customer temperament-centered complaint handling system and one-of-a-kind complaint handling dataset},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102520},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102520},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400168X},
author = {Ching-Hung Lee and Xuejiao Zhao},
keywords = {Customer Complaint Handling System, Customer Temperament, Data Mining, Correspondence Analysis, Interactive marketing},
abstract = {One of the most significant sources of information from customers is customer complaints. Successful and effective complaint management can end complaint crises and ensure client loyalty, which is a sign of great service performance. In this paper, we proposed a novel customer temperament-centered and e-CCH system-based data collection and data mining method titled “3D” model for customer complaint data analysis. Three phases are (1) Development and launch of e-Customer Complaint Handling system, (2) Data collection and transfer of learning by e-Customer Complaint Handling system, and (3) Data mining by e-Customer Complaint Handling system. An advanced electronic Customer Complaint Handling System called the e-CCH system was then developed and launched. This system adapts the seasonal associations model based on Hippocrates's customer temperament theory to the whole stages of customer complaint reporting and handling. With this system, we conducted a dataset collection work from restaurant chains of two brands over four years. As a result, we collect thousands of real-world temperament-centred customer complaint cases by four years to form the one-of-a-kind CCH dataset. This one-of-a-kind CCH dataset was open-sourced with detailed customer complaint attributes and heuristic decision-making for valuable industrial handling manner. After further analysis of this dataset, we found that customers with different temperament types tend to have different types of complaints. In addition, adapting the temperament theory to the e-CCH system can classify customer types better and provide personalized solutions. To our best knowledge, this rich and the one-of-a-kind CCH dataset reported in this paper is the first comprehensive study of customer complaint handling in an industrial service management context. Meanwhile, data mining with cross analysis and correspondence analysis and an ChatGPT experiment for transfer of learning based on this yearly and one-of-a-kind industrial customer complaint dataset was analyzed and discussed. In addition, how this dataset may contribute to more realistic complaint-handling theoretic studies for better service failure recovery and interactive marketing is discussed in-depth.}
}
@article{SHEN2025118374,
title = {Advanced deep learning algorithms in food quality and authenticity},
journal = {TrAC Trends in Analytical Chemistry},
volume = {191},
pages = {118374},
year = {2025},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2025.118374},
url = {https://www.sciencedirect.com/science/article/pii/S0165993625002420},
author = {Che Shen and Qi Jin and Ganghua Zhou and Ran Wang and Zhenwei Wang and Di Liu and Kezhou Cai and Baocai Xu},
keywords = {Advanced deep learning, Algorithms, Food authentication, Food quality, Artificial intelligence, Food safety},
abstract = {Ensuring food quality and authenticity is critical to the food industry and consumers. With the advancements in Industry 4.0 and Artificial Intelligence (AI) technologies, deep learning (DL) offers unparalleled opportunities to extract information and make decisions on complex or large datasets. However, conventional convolutional neural networks (CNN) and recurrent neural networks (RNN) have limitations. The development of advanced DL algorithms can accommodate the growing demand for complex tasks and herald revolutionary breakthroughs in the field of food quality and authenticity identification, which will continue to be driven by the ongoing development of advanced DL. This review provides a comprehensive overview of various advanced DL algorithms for food quality identification and food authenticity analysis, including advanced variants of CNN, lightweight DL, sequential neural networks, graph neural networks (GNN), deep generative models (DGM), and target detection algorithms. It also surveys recent applications of advanced DL algorithms for Food quality inspection and authenticity analysis. This review discusses the challenges associated with advanced DL and the future trends, offering new insights into the development of advanced DL algorithms in food quality and authenticity. Challenges such as overfitting, scalability, interpretability, accessibility, data privacy, algorithmic bias, and the creation of large databases must be addressed in the application of advanced DL algorithms to drive their further iterations.}
}
@article{KARAKOLTZIDIS2025100012,
title = {AI-driven parametrization of Michaelis–Menten maximal velocity: Advancing in silico new approach methodologies (NAMs)},
journal = {NAM Journal},
volume = {1},
pages = {100012},
year = {2025},
issn = {3050-6204},
doi = {https://doi.org/10.1016/j.namjnl.2025.100012},
url = {https://www.sciencedirect.com/science/article/pii/S3050620425000077},
author = {Achilleas Karakoltzidis and Spyros P. Karakitsios and Dimosthenis Α. Sarigiannis},
keywords = {Deep learning, , Maximal velocity, Enzyme structure, QSPR, NAMs},
abstract = {The development of mechanistic systems biology models necessitates the utilization of numerous kinetic parameters once the enzymatic mode of action has been identified. Simultaneously, wet lab experimentation is associated with particularly high costs, does not adhere to principles of reducing the number of animal tests, and is a time-consuming procedure. Alternatively, an artificial intelligence-based method is proposed that utilizes enzyme amino acid structures as input data. This method combines NLP techniques with molecular fingerprints of the catalysed reaction to determine Michaelis–Menten maximal velocities (Vmax). The molecular fingerprints employed include RCDK standard fingerprints (1024 bits), MACCS keys (166 bits), PubChem fingerprints (881 bits), and E-States fingerprints (79 bits). These were integrated to produce reaction fingerprints. The data entries were sourced from SABIO RK, providing a concrete framework to support training procedures. After the data preprocessing stage, the dataset was randomly split into the training set (70 %), validation set (10 %), and test set (20 %) ensuring unique amino acid sequences for each subset. The data points with structures similar to the ones used to train the model as well as uncommon reactions were employed to further test the model. The developed models were optimized during the training procedure to predict Vmax values efficiently and reliably. Utilizing a fully connected neural network, these models can be applied to all organisms. Amino acid proportions of enzymes were also tested resulting in an unreliable predictor for the Vmax value. During testing, the model demonstrated better performance on known structures compared to unseen data. In the given use case, the model trained solely on enzyme representations achieved an R-squared of 0.45 on unseen data and 0.70 on known structures. When enzyme representations were integrated with RCDK fingerprints, the model achieved an R-squared of 0.46 on unseen data and 0.62 on known structures.}
}
@article{MANCHEL2024111322,
title = {From sampling to simulating: Single-cell multiomics in systems pathophysiological modeling},
journal = {iScience},
volume = {27},
number = {12},
pages = {111322},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.111322},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224025471},
author = {Alexandra Manchel and Michelle Gee and Rajanikanth Vadigepalli},
keywords = {Systems biology, Data processing in systems biology, In silico biology, Biological constraints, Omics},
abstract = {Summary
As single-cell omics data sampling and acquisition methods have accumulated at an unprecedented rate, various data analysis pipelines have been developed for the inference of cell types, cell states and their distribution, state transitions, state trajectories, and state interactions. This presents a new opportunity in which single-cell omics data can be utilized to generate high-resolution, high-fidelity computational models. In this review, we discuss how single-cell omics data can be used to build computational models to simulate biological systems at various scales. We propose that single-cell data can be integrated with physiological information to generate organ-specific models, which can then be assembled to generate multi-organ systems pathophysiological models. Finally, we discuss how generic multi-organ models can be brought to the patient-specific level thus permitting their use in the clinical setting.}
}
@article{CANANAU2025104816,
title = {Critical thinking in preparation for student teachers’ professional practice: A case study of critical thinking conceptions in policy documents framing teaching placement at a Swedish university},
journal = {Teaching and Teacher Education},
volume = {153},
pages = {104816},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104816},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24003494},
author = {Iulian Cananau and Silvia Edling and Björn Haglund},
keywords = {Critical thinking, Teacher education, Placement, Teacher profession, Concept, Policy documents},
abstract = {This paper explores the conceptions of critical thinking in national and local policy documents for teaching placement, using the case of teacher education programs at a Swedish university. The concept under scrutiny is based on three contemporary theoretical models of critical thinking in education: critical thinking movement, critical pedagogy, and “criticality” movement. In Sweden, the teacher profession is framed with a broader socio-ethical scope than the focus on individual cognitive skills of the critical thinking movement. Critical reflection and self-reflection, two conceptions identified with the criticality ideal of education for critical being, prevail in the analyzed documents.}
}
@article{CANIGLIA2025107605,
title = {FOBICS: Assessing project security level through a metrics framework that evaluates DevSecOps performance},
journal = {Information and Software Technology},
volume = {178},
pages = {107605},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107605},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924002106},
author = {Alessandro Caniglia and Vincenzo Dentamaro and Stefano Galantucci and Donato Impedovo},
keywords = {DevSecOps, Metrics framework, Project security, Software engineering, Evaluating security, DevOps, Security assessment, Software metrics, Secure software development, Business metrics},
abstract = {Context:
In today’s software development landscape, the DevSecOps approach has gained traction due to its focus on the software development process and bolstering security measures in projects, a task in light of the ever-evolving cybersecurity threats.
Objective:
This study aims to address the lack of metrics for quantitatively assessing its efficacy from both security and business logic perspectives.
Methods:
To tackle this issue, the research introduces the Framework of Business Index Concerning Security (FOBICS), a set of metrics designed to enable transparent evaluations of project security. FOBICS considers various perspectives relevant to DevSecOps practices. It includes factors such as project duration and financial outcomes, making it appealing for implementation in business settings.
Results:
The effectiveness of FOBICS is validated theoretically and empirically via its application in two real-world projects: the results from these implementations show a correlation between FOBICS metrics and the security strategies employed as the development methodologies adopted by diverse teams throughout the projects.
Conclusion:
Hence, FOBICS emerges as a tool for assessing and continuously monitoring project security, offering insights into areas of strength and areas that may require enhancement. FOBICS is shown to be effective in assessing the level of DevSecOps implementation. The ease of calculating FOBICS metrics makes them easily interpretable and continuously verifiable. Moreover, FOBICS summarizes most of the other quantitative and qualitative metrics in the literature.}
}
@article{SUH2024,
title = {Toward Tailoring Just-in-Time Adaptive Intervention Systems for Workplace Stress Reduction: Exploratory Analysis of Intervention Implementation},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/48974},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000982},
author = {Jina Suh and Esther Howe and Robert Lewis and Javier Hernandez and Koustuv Saha and Tim Althoff and Mary Czerwinski},
keywords = {workplace stress, just-in-time, just-in-time adaptive intervention, JITAI, engagement, microintervention, stress reduction, psychotherapy},
abstract = {Background
Integrating stress-reduction interventions into the workplace may improve the health and well-being of employees, and there is an opportunity to leverage ubiquitous everyday work technologies to understand dynamic work contexts and facilitate stress reduction wherever work happens. Sensing-powered just-in-time adaptive intervention (JITAI) systems have the potential to adapt and deliver tailored interventions, but such adaptation requires a comprehensive analysis of contextual and individual-level variables that may influence intervention outcomes and be leveraged to drive the system’s decision-making.
Objective
This study aims to identify key tailoring variables that influence momentary engagement in digital stress reduction microinterventions to inform the design of similar JITAI systems.
Methods
To inform the design of such dynamic adaptation, we analyzed data from the implementation and deployment of a system that incorporates passively sensed data across everyday work devices to send just-in-time stress reduction microinterventions in the workplace to 43 participants during a 4-week deployment. We evaluated 27 trait-based factors (ie, individual characteristics), state-based factors (ie, workplace contextual and behavioral signals and momentary stress), and intervention-related factors (ie, location and function) across 1585 system-initiated interventions. We built logistical regression models to identify the factors contributing to momentary engagement, the choice of interventions, the engagement given an intervention choice, the user rating of interventions engaged, and the stress reduction from the engagement.
Results
We found that women (odds ratio [OR] 0.41, 95% CI 0.21-0.77; P=.03), those with higher neuroticism (OR 0.57, 95% CI 0.39-0.81; P=.01), those with higher cognitive reappraisal skills (OR 0.69, 95% CI 0.52-0.91; P=.04), and those that chose calm interventions (OR 0.43, 95% CI 0.23-0.78; P=.03) were significantly less likely to experience stress reduction, while those with higher agreeableness (OR 1.73, 95% CI 1.10-2.76; P=.06) and those that chose prompt-based (OR 6.65, 95% CI 1.53-36.45; P=.06) or video-based (OR 5.62, 95% CI 1.12-34.10; P=.12) interventions were substantially more likely to experience stress reduction. We also found that work-related contextual signals such as higher meeting counts (OR 0.62, 95% CI 0.49-0.78; P<.001) and higher engagement skewness (OR 0.64, 95% CI 0.51-0.79; P<.001) were associated with a lower likelihood of engagement, indicating that state-based contextual factors such as being in a meeting or the time of the day may matter more for engagement than efficacy. In addition, a just-in-time intervention that was explicitly rescheduled to a later time was more likely to be engaged with (OR 1.77, 95% CI 1.32-2.38; P<.001).
Conclusions
JITAI systems have the potential to integrate timely support into the workplace. On the basis of our findings, we recommend that individual, contextual, and content-based factors be incorporated into the system for tailoring as well as for monitoring ineffective engagements across subgroups and contexts.}
}
@article{KANG2025111189,
title = {A trust and bundling-based task allocation scheme to enhance completion rate and data quality for mobile crowdsensing},
journal = {Computer Networks},
volume = {262},
pages = {111189},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111189},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625001574},
author = {Yunchuan Kang and Houbing Herbert Song and Tian Wang and Shaobo Zhang and Mianxiong Dong and Anfeng Liu},
keywords = {Mobile crowdsensing, Task bundling, Task assignment scheme, Truth discovery, Multi-objective optimization},
abstract = {In Mobile CrowdSensing (MCS), task bundling has shown promise in improving task completion rate by pairing unpopular tasks with popular ones. However, existing methods often assume truthful data from workers, an assumption misaligned with real-world MCS scenarios. Workers tend to submit low-quality or false data to maximize their rewards, particularly given the Information Elicitation Without Verification (IEWV) problem, which hinders the detection of dishonest behavior. To address this, we propose a Trust and Bundling-based Task Allocation (TBTA) scheme to enhance task completion rates and data quality at a low cost. The TBTA scheme includes three main strategies: (1) a trusted worker identification algorithm that evaluates workers' trust degrees by considering the IEWV challenge, allowing for the selection of reliable workers and thus ensuring higher data quality; (2) a task bundling method using the Non-dominated Sorting Genetic Algorithm II to bundle unpopular tasks with popular ones strategically, maximizing platform utility and completion rates; and (3) an optimal allocation algorithm that assigns trusted workers to tasks best suited to their capabilities, thus improving data reliability and minimizing costs. Experimental results demonstrate that compared to the state-of-the-art methods, the TBTA scheme achieves a 15.54 % improvement in task completion rate, and a 1.83 % reduction in worker travel distance.}
}
@article{WANG2024,
title = {Applications and Concerns of ChatGPT and Other Conversational Large Language Models in Health Care: Systematic Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/22769},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400757X},
author = {Leyao Wang and Zhiyu Wan and Congning Ni and Qingyuan Song and Yang Li and Ellen Clayton and Bradley Malin and Zhijun Yin},
keywords = {large language model, ChatGPT, artificial intelligence, natural language processing, health care, summarization, medical knowledge inquiry, reliability, bias, privacy},
abstract = {Background
The launch of ChatGPT (OpenAI) in November 2022 attracted public attention and academic interest to large language models (LLMs), facilitating the emergence of many other innovative LLMs. These LLMs have been applied in various fields, including health care. Numerous studies have since been conducted regarding how to use state-of-the-art LLMs in health-related scenarios.
Objective
This review aims to summarize applications of and concerns regarding conversational LLMs in health care and provide an agenda for future research in this field.
Methods
We used PubMed, ACM, and the IEEE digital libraries as primary sources for this review. We followed the guidance of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) to screen and select peer-reviewed research articles that (1) were related to health care applications and conversational LLMs and (2) were published before September 1, 2023, the date when we started paper collection. We investigated these papers and classified them according to their applications and concerns.
Results
Our search initially identified 820 papers according to targeted keywords, out of which 65 (7.9%) papers met our criteria and were included in the review. The most popular conversational LLM was ChatGPT (60/65, 92% of papers), followed by Bard (Google LLC; 1/65, 2% of papers), LLaMA (Meta; 1/65, 2% of papers), and other LLMs (6/65, 9% papers). These papers were classified into four categories of applications: (1) summarization, (2) medical knowledge inquiry, (3) prediction (eg, diagnosis, treatment recommendation, and drug synergy), and (4) administration (eg, documentation and information collection), and four categories of concerns: (1) reliability (eg, training data quality, accuracy, interpretability, and consistency in responses), (2) bias, (3) privacy, and (4) public acceptability. There were 49 (75%) papers using LLMs for either summarization or medical knowledge inquiry, or both, and there are 58 (89%) papers expressing concerns about either reliability or bias, or both. We found that conversational LLMs exhibited promising results in summarization and providing general medical knowledge to patients with a relatively high accuracy. However, conversational LLMs such as ChatGPT are not always able to provide reliable answers to complex health-related tasks (eg, diagnosis) that require specialized domain expertise. While bias or privacy issues are often noted as concerns, no experiments in our reviewed papers thoughtfully examined how conversational LLMs lead to these issues in health care research.
Conclusions
Future studies should focus on improving the reliability of LLM applications in complex health-related tasks, as well as investigating the mechanisms of how LLM applications bring bias and privacy issues. Considering the vast accessibility of LLMs, legal, social, and technical efforts are all needed to address concerns about LLMs to promote, improve, and regularize the application of LLMs in health care.}
}
@article{SAXENA2025532,
title = {COMPARATIVE ANALYSIS OF LARGE LANGUAGE MODELS FOR THE APPLICATION OF SCIENTIFIC ARTICLE SUMMARIZATION},
journal = {Procedia Computer Science},
volume = {259},
pages = {532-542},
year = {2025},
note = {Sixth International Conference on Futuristic Trends in Networks and Computing Technologies (FTNCT06), held in Uttarakhand, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925010993},
author = {Rishabh Saxena and Shubhangi Singh and Preeti Dubey},
keywords = {LLMs, LLaMa-3, GPT-3, Mixtral, Gemma, ROUGE, BLEU, BERT, Automatic text summarization},
abstract = {Automatic text summarization has become an essential tool for academics to stay up to date with the newest advancements due to the high rise of scientific publications. Abstractive text summarisation tasks can be done using LLMs. However current summarization methods often struggle to capture the nuanced and technical details present in research papers and there are prevalent research gaps in the realm of abstractive summarisation using generative AI. This study aims to analyse the efficiency of LLM models – GPT-3.5, LLaMa 3, Mixtral 8x7b and Gemma-2, in condensing detailed scientific literature into manageable summaries, and their further evaluation based on ROUGE, BERT and BLEU scores. The results show that GPT-3.5 and LLaMa 3 generate more coherent and contextually accurate summaries with a BERT score of 0.21 and 0.19 respectively, even though Mixtral 8x7B performs exceptionally well in quantitative measurements. Despite its coherence, Gemma-2 receives poorer performance in both qualitative and quantitative assessments. These findings bring out the value of integrating quantitative and qualitative evaluations to gain a thorough understanding of summarization.}
}
@article{ZHANG2024106553,
title = {Pre-gating and contextual attention gate — A new fusion method for multi-modal data tasks},
journal = {Neural Networks},
volume = {179},
pages = {106553},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106553},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024004775},
author = {Duoyi Zhang and Richi Nayak and Md Abul Bashar},
keywords = {Multi-modal data learning, Cross-attention module, Neural networks},
abstract = {Multi-modal representation learning has received significant attention across diverse research domains due to its ability to model a scenario comprehensively. Learning the cross-modal interactions is essential to combining multi-modal data into a joint representation. However, conventional cross-attention mechanisms can produce noisy and non-meaningful values in the absence of useful cross-modal interactions among input features, thereby introducing uncertainty into the feature representation. These factors have the potential to degrade the performance of downstream tasks. This paper introduces a novel Pre-gating and Contextual Attention Gate (PCAG) module for multi-modal learning comprising two gating mechanisms that operate at distinct information processing levels within the deep learning model. The first gate filters out interactions that lack informativeness for the downstream task, while the second gate reduces the uncertainty introduced by the cross-attention module. Experimental results on eight multi-modal classification tasks spanning various domains show that the multi-modal fusion model with PCAG outperforms state-of-the-art multi-modal fusion models. Additionally, we elucidate how PCAG effectively processes cross-modality interactions}
}
@article{MUSARAT2024102057,
title = {Automated monitoring innovations for efficient and safe construction practices},
journal = {Results in Engineering},
volume = {22},
pages = {102057},
year = {2024},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2024.102057},
url = {https://www.sciencedirect.com/science/article/pii/S2590123024003116},
author = {Muhammad Ali Musarat and Abdul Mateen Khan and Wesam Salah Alaloul and Noah Blas and Saba Ayub},
keywords = {Construction monitoring, Traditional, Automation, Photogrammetry, Sensors, BIM},
abstract = {As construction projects increase in complexity, there are growing challenges with conventional monitoring methods in terms of efficiency, safety, and competitiveness. Traditional supervision techniques are labour-intensive, intermittent, and prone to errors. Hence, this study statistically evaluates the potential advantages of photogrammetry, sensors, and algorithms to enable continuous automated monitoring. The results of this survey were analysed to compare manual and automated monitoring systems. The outcome shows that the Malaysian construction industry is aware of Automated Monitoring Innovations for Efficient and Safe Construction Practices. The top ranked factor was Photogrammetry which had a relative importance index (RII) of 0.821 for straightforward site monitoring and 0.812 for accelerated 3D BIM modelling. The RII for sensors to track labourers, apparatus, and progress in real time was 0.82, while the RII for hazard anticipation was 0.796. Automation achieved a reduction in fatigue by 0.784, labour intensity by 0.792, and time demands by 0.768, as measured by the RII. A conceptual framework was developed that incorporates measurable improvements in schedules, safety, and quality control. Automated solutions, as opposed to human examinations which are prone to error, provided exhaustive geographical data and ongoing surveillance notwithstanding obstacles pertaining to cost, cybersecurity, privacy, and integration. Construction monitoring must incorporate new technology, strategic change management, data investments, and supporting regulations to increase profitability, safety, and efficiency as competition and complexity increase.}
}
@article{MOBARAK2023100523,
title = {Scope of machine learning in materials research—A review},
journal = {Applied Surface Science Advances},
volume = {18},
pages = {100523},
year = {2023},
issn = {2666-5239},
doi = {https://doi.org/10.1016/j.apsadv.2023.100523},
url = {https://www.sciencedirect.com/science/article/pii/S2666523923001575},
author = {Md Hosne Mobarak and Mariam Akter Mimona and Md. Aminul Islam and Nayem Hossain and Fatema Tuz Zohura and Ibnul Imtiaz and Md Israfil Hossain Rimon},
keywords = {Machine learning, Materials research, Machine learning methods, Material synthesis, Image processing},
abstract = {This comprehensive review investigates the multifaceted applications of machine learning in materials research across six key dimensions, redefining the field's boundaries. It explains various knowledge acquisition mechanisms starting with supervised, unsupervised, reinforcement, and deep learning techniques. These techniques are transformative tools for transforming unactionable data into insightful actions. Moving on to the materials synthesis, the review emphasizes the profound influence of machine learning, as demonstrated by predictive models that speed up material selection, structure-property relationships that reveal crucial connections, and data-driven discovery that fosters innovation. Machine learning reshapes our comprehension and manipulation of materials by accelerating discovery and enabling tailored design through property prediction models and structure-property relationships. Machine learning extends its influence to image processing, improving object detection, classification, and segmentation precision and enabling methods like image generation, revolutionizing the potential of image processing in materials research. The most recent developments show how machine learning can have a transformative impact at the atomic level by enabling precise property prediction and intricate data extraction, representing significant advancements in material understanding and innovation. The review highlights how machine learning has the potential to revolutionize materials research by accelerating discovery, improving performance, and stimulating innovation. It does so while acknowledging obstacles like poor data quality and complicated algorithms. Machine learning offers a wide range of exciting prospects for scientific investigation and technological advancement, positioning it as a powerful force for influencing the future of materials research.}
}
@article{KHATUA2024100812,
title = {FedGen: Federated learning-based green edge computing for optimal route selection using genetic algorithm in Internet of Vehicular Things},
journal = {Vehicular Communications},
volume = {49},
pages = {100812},
year = {2024},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2024.100812},
url = {https://www.sciencedirect.com/science/article/pii/S2214209624000871},
author = {Sushovan Khatua and Anwesha Mukherjee and Debashis De},
keywords = {Internet of Vehicular Things, Federated learning, Vehicular networks, Optimal route, Time consumption, Power consumption},
abstract = {Time-efficient route planning is a significant research area of Internet of Vehicular Things. Optimal route selection is important to reach the destination in minimal time. Further, energy efficiency is vital for route planning in a sustainable environment. To address these issues, this paper proposes a federated learning and genetic algorithm-based green edge computing framework for optimal route planning in Internet of Vehicular Things. The vehicles are connected to the road side unit. The road side unit processes the image and video of the road, and predicts the number of vehicles on the road. For video processing Region-based Convolutional Neural Network is used. The road side units send the result and the local model parameters to the regional server. The regional server determines the optimal route using modified genetic algorithm, and sends it to the vehicles and the cloud. Also, the regional server updates its model and sends the updated model parameters to the road side units. The road side units update their local models accordingly. The regional server also sends the model parameters to the cloud, and the cloud updates the global model. The cloud sends the updated model parameters to the regional servers. The regional servers update their models accordingly. The results present that above 90% accuracy is achieved by the proposed model. The results also present that using modified GA the proposed approach reduces time and power consumption to find the optimal route by ∼62% and ∼66% than the cloud-only model.}
}
@incollection{FREITASDEARAUJOFILHO2025111,
title = {Chapter 5 - Safeguarding IoT networks with generative adversarial networks},
editor = {Dinh Thai Hoang and Nguyen Quang Hieu and Diep N. Nguyen and Ekram Hossain},
booktitle = {Advanced Machine Learning for Cyber-Attack Detection in IoT Networks},
publisher = {Academic Press},
pages = {111-142},
year = {2025},
isbn = {978-0-443-29032-9},
doi = {https://doi.org/10.1016/B978-0-44-329032-9.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290329000105},
author = {Paulo {Freitas de Araujo-Filho} and Georges Kaddoum and Divanilson R. Campelo and Cleber Zanchettin},
keywords = {Generative adversarial networks, Cybersecurity, Internet of things},
abstract = {Although generative adversarial networks (GANs) were initially developed to generate images, they have proven to be extremely useful in various other domains, including IoT security. By simultaneously training two competing neural networks, namely the generator and the discriminator, GANs successfully estimate generative models by capturing data distributions. Additionally, they provide a discriminative model that estimates the probability of a sample being real rather than produced by the generator. These capabilities are particularly valuable in the unsupervised detection of attacks, where labeled attack data is not available. Hence, GANs have an important role in securing IoT devices. Furthermore, GANs have shown promising results in other IoT security tasks, such as defending against adversarial attacks and evaluating authentication systems. In this chapter, we present different formulations and variations of GANs, discuss their applications in IoT security, showcase state-of-the-art GAN-based security solutions, and explore the challenges and future research opportunities in the field of IoT security.}
}
@article{ZHAO2024109964,
title = {Domain generalization for cross-domain fault diagnosis: An application-oriented perspective and a benchmark study},
journal = {Reliability Engineering & System Safety},
volume = {245},
pages = {109964},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2024.109964},
url = {https://www.sciencedirect.com/science/article/pii/S0951832024000395},
author = {Chao Zhao and Enrico Zio and Weiming Shen},
keywords = {Fault diagnosis, Domain shift, Domain generalization, Deep learning},
abstract = {Most data-driven methods for fault diagnostics rely on the assumption of independently and identically distributed data of training and testing. However, domain shift between the phases of training and testing is common in practice. Recently, domain generalization-based fault diagnosis (DGFD) has gained widespread attention for learning fault diagnosis knowledge from multiple source domains and applying it to unseen target domains. This paper summarizes the developments in DGFD from an application-oriented perspective. Firstly, basic definitions of DGFD and its variant applications are formulated. Then, motivations, goals, challenges and state-of-the-art solutions for different applications are discussed. The limitations of existing technologies are highlighted. A comprehensive benchmark study is carried out on eight open-source and two self-collected datasets to provide an understanding of the existing methods and a unified framework for researchers. Finally, several future directions are given. Our code is available at https://github.com/CHAOZHAO-1/DG-PHM.}
}
@incollection{OZCAN2025111,
title = {Chapter 5 - Dynamic relationalities across (stacked) strata},
editor = {Kerimcan Ozcan and Venkat Ramaswamy},
booktitle = {Dynamic Relationality Theory of Creative Transformation},
publisher = {Elsevier},
pages = {111-136},
year = {2025},
isbn = {978-0-443-30159-9},
doi = {https://doi.org/10.1016/B978-0-443-30159-9.00005-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443301599000050},
author = {Kerimcan Ozcan and Venkat Ramaswamy},
keywords = {Becoming, Experiencial computing, Machinic generalized intelligence, Natural transformation, Reterritorialization, Technological singularity, Transcendence},
abstract = {In this chapter, explores the synergy between human intelligence (HI) and artificial intelligence (AI), emphasizing the transformative power of AI in digital ecosystems. It articulates the shift toward Machinic Generalized Intelligence (MGI), highlighting AI's role in creating immersive, personalized experiences. Through the lens of Dynamic Relationality Theory (DRT), it delves into “becoming” via lines of flight, marking departures from established structures toward new formations, with AI fostering technological singularity and healthcare evolution. It examines reterritorialization, where foundational cognitive processes evolve into complex systems, and the enrichment of the Experience-verse, blending organic and artificial elements for enhanced digital ecosystems. The chapter concludes by addressing identity and structure transformations within digital realms, underpinning the fluidity and continuous change integral to DRT's framework. This comprehensive analysis underscores the interdependent evolution of HI and AI, reinforcing their collective impact on advancing digital ecosystems.}
}
@article{ZHANG2025226,
title = {Targeting cuproptosis for cancer therapy: Focus on the anti-tumor immune system},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {3},
pages = {226-243},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000569},
author = {Xuan Zhang and Xiaohong Han},
keywords = {Cuproptosis, Copper homeostasis, Immunotherapy, Drug synergism},
abstract = {Copper (Cu) is an indispensable micronutrient that maintains signaling pathways and biological homeostasis in almost all cell types; however, its excess affects the tricarboxylic acid cycle, causes the accumulation of fatty acylated proteins, destabilization of iron–sulfur cluster proteins, and increases the levels of intracellular reactive oxygen species, leading to proteotoxic stress and cell death. Cuproptosis, a form of Cu-dependent cell death, differs from other types of regulated cell death (RCD) and was first reported in Science in 2022. Recently, the RCD pathways have been targeted in cancer therapy. However, the escape of apoptosis in tumor cells causes resistance to treatment and tumor recurrence. Therefore, there is an urgent need to study the alternative mechanisms of cancer cell mortality. Compared to normal patients, a significant increase in serum Cu ion levels has been observed in patients with tumors. Moreover, tumor cell proliferation, angiogenesis, and metastasis are associated with cuproptosis. Thus, exploring cancer signaling pathways related to cuproptosis will provide a new perspective for the development of anti-cancer drugs. Importantly, cuproptosis is closely associated with the modulation of anti-tumor immunity. The expression of cuproptosis-related genes (CRGs) is significantly correlated with immune cell infiltration and the immune checkpoint programmed cell death protein 1 (PD-1)/programmed death-ligand 1 (PD-L1). Based on these findings, a series of cuproptosis-related drugs have been used in tumor-targeted combination therapy or as immune synergists. Therefore, elucidating the role of cuproptosis per cancer stage and in the tumor immune microenvironment (TIME) is helpful in clarifying the potential value of Cu in the treatment of specific cancers. In this review, we summarize specific cancer signaling pathways related to cuproptosis and cancer treatment based on the regulation of Cu concentration. The combination of these two approaches may help researchers develop more therapies targeting cuproptosis-related pathways. Importantly, we focused on the effect of cuproptosis on the TIME and systematically discussed the role of CRGs in tumor immunity considering CRG-related anti-tumor immune signaling pathways, tumor prognosis scoring system, anti-tumor immunotherapy, and biological experiments and bioinformatics prediction models, to provide new ideas for the development of anticancer therapy targeting cuproptosis-related pathways.}
}
@article{MIRONE2024108754,
title = {Combined rate-temperature effects in postnecking plasticity of A2-70 stainless steel},
journal = {International Journal of Mechanical Sciences},
volume = {262},
pages = {108754},
year = {2024},
issn = {0020-7403},
doi = {https://doi.org/10.1016/j.ijmecsci.2023.108754},
url = {https://www.sciencedirect.com/science/article/pii/S0020740323006562},
author = {Giuseppe Mirone and Raffaele Barbagallo and Luca Corallo},
keywords = {Thermal softening, Strain rate effect, Flow stress, Hopkinson bar, Necking},
abstract = {In this paper, a comprehensive study that integrates theoretical, experimental and FE analyses, elucidates the combined effect of strain, strain rate, and temperature on the mechanical response of A2-70 stainless steel. A wide series of tensile experiments on cylindrical specimens is presented, including low to high temperatures and quasi-static to dynamic rates. Opportune combinations of temperatures and strain rates are imposed in order to possibly separate and identify their respective effects on the flow curve of the material. The adopted experimental procedures based on neck-related measurements revealed the onset of secondary phenomena affecting dynamic tensile tests. Classical material models were found not suitable to correctly predict the complex elastoplastic deformation of this material. Thus, a new general material model is presented and used to account for the complex interplay between strain, temperature, and rate-dependent effects. Finite element simulations are conducted using both the proposed constitutive model and another classical model of dynamic hardening, to investigate and compare their predictive capability over the entire experimental campaign.}
}
@article{AGUSTI2024117377,
title = {Christensenella minuta mitigates behavioral and cardiometabolic hallmarks of social defeat stress},
journal = {Biomedicine & Pharmacotherapy},
volume = {180},
pages = {117377},
year = {2024},
issn = {0753-3322},
doi = {https://doi.org/10.1016/j.biopha.2024.117377},
url = {https://www.sciencedirect.com/science/article/pii/S0753332224012629},
author = {A. Agusti and GV. Molina-Mendoza and M. Tamayo and V. Rossini and MC. Cenit and C. Frances-Cuesta and V. Tolosa-Enguis and EM. {Gómez Del Pulgar} and A. Flor-Duro and Y. Sanz},
keywords = {Microbiota, Gut-brain axis, Behavior, Dopamine, Social defeat, Depression},
abstract = {Psychological stress during early development and adolescence may increase the risk of psychiatric and cardiometabolic comorbidities in adulthood. The gut microbiota has been associated with mental health problems such as depression and anxiety and with cardiometabolic disease, but the potential role of the gut microbiota in their comorbidity is not well understood. We investigated the effects and mode of action of the intestinal bacterium Christensenella minuta DSM 32891 on stress-induced mental health and cardiometabolic disturbances in a mouse model of social defeat stress. We demonstrate that administered C. minuta alleviates chronic stress-induced depressive, anxiogenic and antisocial behavior. These effects are attributed to the bacterium’s ability to modulate the hypothalamic-pituitary-adrenal axis, which mediates the stress response. This included the oversecretion of corticosterone and the overexpression of its receptors, as well as the metabolism of dopamine (DA) and the expression of its receptors (D1, D2L and D2S). Additionally, C. minuta administration reduced chronically induced inflammation in plasma, spleen and some brain areas, which likely contribute to the recovery of physical and behavioral function. Furthermore, C. minuta administration prevented chronic stress-induced cardiovascular damage by regulating key enzymes mediating liver fibrosis and oxidative stress. Finally, C. minuta increased the abundance of bacteria associated with mental health. Overall, our study highlights the potential of microbiota-directed interventions to alleviate both the physical and mental effects of chronic stress.}
}
@article{EMSSAAD2025100221,
title = {Leveraging multilingual RAG for breast cancer RCPs: AI-driven speech transcription and compliance in Darija-French clinical discussions},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {8},
pages = {100221},
year = {2025},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2025.100221},
url = {https://www.sciencedirect.com/science/article/pii/S2666990025000461},
author = {Ilyass Emssaad and Fatima-Ezzahraa Ben-Bouazza and Idriss Tafala and Manal Chakour El Mezali and Bassma Jioudi},
keywords = {Multilingual AI, Retrieval-augmented generation, Clinical decision support, Automatic speech recognition},
abstract = {The integration of artificial intelligence (AI) into clinical decision-making has introduced new opportunities for automating and enhancing medical documentation, particularly in oncology, where multidisciplinary meetings are central to treatment planning. However, existing speech-to-text and retrieval-augmented generation (RAG) systems are not equipped to operate effectively in multilingual, dialect-rich environments such as those in North African hospitals where Moroccan Darija, Arabic, and French are frequently interwoven. These linguistic complexities, combined with the high-stakes nature of clinical dialogue, challenge transcription accuracy, contextual information retrieval, and regulatory compliance. This study presents a multilingual RAG system tailored to clinical meetings, integrating a fine-tuned Whisper ASR model with a sentence-level semantic retrieval pipeline and a compliance-aware generation framework. Evaluated on real-world clinical queries, the system demonstrates improved transcription quality and retrieval precision over standard pipelines, while enforcing factual grounding and safety through multi-stage output validation. These results highlight the potential of multilingual, speech-driven AI to support decision-making and compliance in linguistically diverse healthcare environments, offering a deployable foundation for clinical NLP in underserved regions.}
}
@incollection{STANCIU2025443,
title = {Chapter 28 - Artificial intelligence for cancer care 4.0/5.0},
editor = {Tuan Anh Nguyen},
booktitle = {IoT-WSN-DT Based Medical Systems and Nanotechnology for Smart Cancer Care},
publisher = {Academic Press},
pages = {443-460},
year = {2025},
isbn = {978-0-443-33984-4},
doi = {https://doi.org/10.1016/B978-0-443-33984-4.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339844000079},
author = {Alexandru Stanciu and Elena Paraschiv},
keywords = {Artificial intelligence, Digital twins, Explainable AI, Generative AI, Machine learning, Oncology},
abstract = {The integration of artificial intelligence (AI) in healthcare has revolutionized cancer care, enabling earlier detection, more accurate prognoses, and tailored treatment strategies. This chapter explores the transition from Healthcare 4.0 to Healthcare 5.0, highlighting the shift from a technology-centric approach to one that is deeply personalized and patient-centered. In Healthcare 5.0, we envision the focus will be on leveraging AI to empower patients and create a truly patient-centric experience. This includes using predictive modeling to anticipate treatment outcomes, employing explainable AI (XAI) to ensure transparency and trust, and utilizing cutting-edge technologies such as generative AI and digital twins to simulate patient-specific disease progressions and treatment responses. The chapter delves into the foundational machine-learning techniques used in cancer diagnosis, such as supervised learning, unsupervised learning, deep learning, and reinforcement learning. It then explores more advanced AI technologies, including generative AI, XAI, and digital twins, and discusses their applications in cancer care. Additionally, the chapter emphasizes the importance of data curation and augmentation in ensuring the availability of high-quality, diverse datasets for AI systems. It also examines computational pathology, which combines traditional pathology with AI to analyze pathology data in unprecedented ways. This chapter provides a comprehensive overview of the current and future applications of AI in cancer care, highlighting its potential to transform the way cancer is diagnosed and treated.}
}
@article{ALADINI2025100566,
title = {Self-directed writing development across computer/AI-based tasks: Unraveling the traces on L2 writing outcomes, growth mindfulness, and grammatical knowledge},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100566},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100566},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001994},
author = {Alaa Aladini and Sayed M. Ismail and Mohamad {Ahmad Saleem Khasawneh} and Goodarz Shakibaei},
keywords = {AI-based tasks, Grammatical knowledge, Growth mindfulness, L2 writing outcomes, Self-directed writing},
abstract = {As technology continues to reshape the educational landscape, understanding how autonomous engagement with AI-driven platforms influences second language (L2) acquisition is increasingly important. This study examined the impact of self-directed writing development through computer- and AI-based tasks on L2 writing outcomes, growth mindfulness, and grammatical knowledge. The research was conducted in three private English institutes in Ahvaz, Iran, involving 561 intermediate-level EFL learners that were selected using a convenience sampling method. Using a quasi-experimental design, participants were divided into two groups: an experimental group (EG) of 276 students, which engaged in self-directed AI-based writing tasks, and a control group (CG) of 285 students, which followed traditional writing instruction. Quantitative data were gathered through pre- and post-tests measuring writing proficiency, growth mindfulness, and grammatical accuracy. Additionally, qualitative data were collected through interviews and questionnaires administered to the EG to assess their attitudes toward AI-based learning. The results indicated that the EG significantly outperformed the CG in writing outcomes and grammatical accuracy. Moreover, the EG demonstrated greater growth in mindfulness, with participants showing increased awareness of their writing processes and enhanced self-regulation strategies. Interviews and questionnaires revealed that participants in the EG held positive attitudes toward AI-based tasks, emphasizing increased engagement, autonomy, enjoyment, motivation, personalized learning, critical thinking, self-efficacy, time management, and collaboration in their English learning development. These findings underscore the potential of AI-based tasks in fostering both linguistic competence and metacognitive skills in L2 learners. The study provides valuable insights into the role of AI technologies in promoting independent learning and calls for further exploration of AI-based interventions in writing education.}
}
@article{BERKOWITZ2024102890,
title = {Filling successive technologically-induced governance gaps: Meta-organizations as regulatory innovation intermediaries},
journal = {Technovation},
volume = {129},
pages = {102890},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2023.102890},
url = {https://www.sciencedirect.com/science/article/pii/S0166497223002018},
author = {Heloise Berkowitz and Antoine Souchaud},
keywords = {Meta-Organization, Technologically-induced governance gap, Sectoral governance, Regulation, Innovation intermediaries, Digital innovation, Organizationality, Meta-organizational filiation},
abstract = {Successive digital innovations create technologically-induced governance gaps that make public regulation quickly obsolete and that might be filled by sectoral governance. The literature has shown that most sectoral governance happens at the level of meta-organizations, organizations whose members are themselves organizations, although we lack a temporal understanding of this phenomenon. Further, while regulation is generally understood as a salient function of innovation intermediaries, the literature on innovation intermediaries has focused mostly on other functions such as idea sourcing, knowledge sharing, or capacity building. We know relatively little about regulatory innovation intermediaries, especially how they might evolve in response to the emergence of technologically-induced governance gaps. In this paper, we conduct an in-depth case study of the evolutions of the FinTech sector in France over almost 30 years, using more than 3000 min of interviews, 4500 pages of archives, and non-participant observations. We study three successive (non)digital financial innovations: business angels, crowdfunding platforms for SMEs, and blockchain technologies. We develop a meta-organizational analysis to investigate meta-organizations as regulatory innovation intermediaries. We describe the evolutions and interrelations of new technologies and meta-organizations, and unpack mechanisms of meta-organizational capacity building for multiple contributors, effects of innovation on organizationality and trajectories of meta-organizational filiation.}
}
@article{ACERORUGE2025102434,
title = {Inteligencia artificial para el abordaje integral de las enfermedades huérfanas/raras: revisión sistemática exploratoria},
journal = {Medicina de Familia. SEMERGEN},
volume = {51},
number = {5},
pages = {102434},
year = {2025},
issn = {1138-3593},
doi = {https://doi.org/10.1016/j.semerg.2024.102434},
url = {https://www.sciencedirect.com/science/article/pii/S1138359324002442},
author = {L.M. {Acero Ruge} and D.A. {Vásquez Lesmes} and E.H. {Hernández Rincón} and L.P. {Avella Pérez}},
keywords = {Enfermedad huérfana, Enfermedad rara, Inteligencia artificial, Aprendizaje profundo, Aprendizaje automático, Diagnóstico por ordenador, Diagnóstico por imagen, Redes neuronales de la computación, Orphan diseases, Rare diseases, Artificial intelligence, Deep learning, Machine learning, Diagnosis, Computer assisted, Diagnostic imaging, Neuronal networks computer},
abstract = {Resumen
Introducción
Las enfermedades huérfanas (EH) son raras, pero colectivamente comunes, presentan desafíos como diagnósticos tardíos, progresión de la enfermedad y escasa oferta terapéutica. Recientemente, la inteligencia artificial (IA) ha ganado interés en la investigación de estas enfermedades.
Objetivo
Sintetizar la evidencia disponible sobre el uso de la IA en el abordaje integral de las enfermedades huérfanas.
Métodos
Se realizó una revisión sistemática exploratoria tipo «Scoping Review» en PubMed, Bireme, Scopus entre 2019 al 2024.
Resultados
Se identificaron 56 artículos con un 21,4% de estudios experimentales; 28 documentos no especifican una EH, 8 documentos tenían como grupo más estudiado enfermedades genéticas; el 53,57% se enfocaban en diagnóstico y se encuentran 36 algoritmos diferentes.
Conclusiones
La información encontrada muestra el desarrollo de algoritmos de IA en diferentes escenarios clínicos, los resultados confirman los potenciales beneficios en tiempo de diagnósticos, opciones terapéuticas y mayor sensibilización de los profesionales de la salud.
Introduction
Orphan diseases (OD) are rare but collectively common, presenting challenges such as late diagnoses, disease progression, and limited therapeutic options. Recently, artificial intelligence (AI) has gained interest in the research of these diseases.
Objective
To synthesize the available evidence on the use of AI in the comprehensive approach to orphan diseases.
Methods
An exploratory systematic review of the Scoping Review type was conducted in PubMed, Bireme, and Scopus from 2019 to 2024.
Results
fifty-six articles were identified, with 21.4% being experimental studies; 28 documents did not specify an OD, 8 documents focused primarily on genetic diseases; 53.57% focused on diagnosis, and 36 different algorithms were identified.
Conclusions
The information found shows the development of AI algorithms in different clinical settings, confirming the potential benefits in diagnosis times, therapeutic options, and greater awareness among health professionals.}
}
@incollection{EGHBAL202591,
title = {Chapter Five - Modernizing distribution networks for an electrified future: case study of Queensland, Australia},
editor = {Fereidoon Sioshansi},
booktitle = {Electrification and the Future of Decentralized Electricity Supply},
publisher = {Elsevier},
pages = {91-120},
year = {2025},
isbn = {978-0-443-34268-4},
doi = {https://doi.org/10.1016/B978-0-443-34268-4.00015-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443342684000159},
author = {Daniel Eghbal and Glenn Springall},
keywords = {Distributed Energy Resources (DER), distribution system operator (DSO), dynamic connections, grid modernization, Queensland, rooftop solar},
abstract = {This chapter summarizes key strategies that enabled Energex and Ergon Energy Network to achieve one of the highest per-capita uptakes of rooftop solar globally. The chapter outlines key foundational distribution system operator capabilities such as dynamic connections, distributed energy resource orchestration, and optimal operation of local renewable energy zones. The chapter concludes with recommendations for modernizing distribution networks, drawing on the case study of Queensland that collectively pave the way for a resilient, efficient, and customer-centric energy system.}
}
@article{TESSELAAR2025106325,
title = {Psychiatric comorbidity in substance use disorders, a systematic review of neuro-imaging findings},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {177},
pages = {106325},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106325},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425003264},
author = {Debbie R.M. Tesselaar and Arnt F.A. Schellekens and Judith R. Homberg and Jan Booij and Cyprien Guerrin},
keywords = {SUD, Addiction, Psychopathology, Comorbidity, Co-occurring psychiatric disorders, Neuro-imaging},
abstract = {Substance use disorder (SUD) have negative consequences for affected individuals and society. Current treatments are moderately effective, partly due to the large heterogeneity in SUDs, including co-occurring psychopathology. A better understanding of the mechanisms underlying these frequently co-occurring psychiatric conditions is required to develop individualized treatments to increase treatment success rates. We systematically reviewed case-control studies investigating neurobiological differences measured using neuroimaging between participants with SUD only and participants with SUD and co-occurring psychiatric disorders. We searched articles in four databases. Inclusion criteria further existed of an ICD and/or DSM diagnoses based on interview assessment or Fagerström test for Nicotine Dependence scores ≥ 5. We hypothesised that co-occurring psychopathology could (1) amplify the neurobiological effects of SUD, (2) attenuate it, (3) have unique neurobiological effects, or (4) have no additional neurobiological effects. From 10,076 unique records screened, we included a total of 26 articles investigating the effect of personality disorder cluster B and/or C (6), depression (4), PTSD (4), ADHD (4), schizophrenia (8), bipolar disorder (1) or anxiety disorders (1) on SUD. We found amplifying effects of co-occurring schizophrenia and personality disorder, unique effects of schizophrenia, ADHD and personality disorder, and attenuating or no effect of depression on SUD. Findings on PTSD were contradictory. In conclusion, different co-occurring psychiatric disorder have distinct effects on the neurobiology of SUD.}
}
@article{KHALIL2025115456,
title = {Unlocking the AI-Productivity paradox in HR: Qualitative insights across organizational levels},
journal = {Journal of Business Research},
volume = {199},
pages = {115456},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115456},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325002796},
author = {Ashraf Khalil and Reeti Agarwal and Muhammad Zafar Yaqub and Armando Papa},
keywords = {Artificial Intelligence, Productivity Paradox, Productivity, General Purpose Technology},
abstract = {Artificial Intelligence (AI) is widely expected to boost productivity and economic growth. As with other technological innovations, a productivity paradox emerges, stating that productivity falls upon its introduction. Therefore, while organizations consistently augment their investments in AI, they might fall short of significant productivity improvements. This study delves into this productivity paradox using a longitudinal qualitative research design with two waves of data collection. We explored four critical themes: AI’s evolving role in organizations, its tangible effects on HR productivity, the underlying reasons behind the productivity paradox, and its multifaceted impact on the employee, team, and organizational levels. Our findings reveal compelling insights into why increased AI investments may not always translate into immediate productivity gains. In addition to providing a framework outlining the relationship between AI and the productivity paradox in HR operations, the findings offer insightful information that can be extremely helpful to industry practitioners.}
}
@article{VINOI2025106,
title = {Charting the course for adaptive selling: A systematic review and meta-analysis},
journal = {Industrial Marketing Management},
volume = {130},
pages = {106-127},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2025.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019850125001324},
author = {Nivin Vinoi and Amit Shankar and Priyavrat Sanyal},
keywords = {Adaptive selling, Systematic literature review, Lexicometric analysis, TCCM framework, Meta-analysis},
abstract = {This study aims to comprehensively analyze the current body of literature on adaptive selling behavior. Accordingly, it employs a hybrid review methodology that integrates systematic literature review, lexicometric analysis, and meta-analysis. This multifaceted approach facilitates both thematic and theoretical syntheses while revealing empirical inconsistencies through quantitative validation. The study further advances the field by developing a conceptual framework based on the antecedents–decisions–outcomes model and proposing a future research agenda based on theory-context-characteristics-method framework, encompassing emerging phenomena, such as technology-driven adaptive selling, gamification, and corporate social responsibility alignment. This novel triangulation of methods and the resulting integrated framework offer rich insights, charting a future roadmap for adaptive selling research.}
}
@article{SCHIFANO2025107591,
title = {High throughput edit distance computation on FPGA-based accelerators using HLS},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107591},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107591},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005557},
author = {Sebastiano Fabio Schifano and Marco Reggiani and Enrico Calore and Rino Micheloni and Alessia Marelli and Cristian Zambelli},
keywords = {DNA-based storage, Bioinformatics, Edit distance, HLS programming, FPGA, Performance analysis},
abstract = {Edit distance is a computational grand challenge problem to quantify the minimum number of editing operations required to modify one string of characters to the other, finding many applications of natural language processing. In recent years, relevant and increasing interest has also emerged from deoxyribonucleic acid (DNA) applications, like Next Generation Sequencing and DNA storage technologies. Both applications share two crucial features: i) the information is coded into the four bases of DNA and ii) the level of operational noise is still high causing errors in the data, requiring inclusion in the workflow of the computation of algorithms such as the edit distance for finding similarities between sequences. To boost this computation many solutions are available in the literature. Among them, the FPGAs are largely used since the data domain of those applications is strings of 4 characters represented as two-bit values, inconveniently fitting the basic data types of ordinary CPUs and GPUs, with additional benefits of providing a high level of parallelism and low processing latency. This contribution presents a computing- and energy-efficient design implementing the edit distance algorithm combining metaprogramming and High-Level Synthesis. We also assess the performance of our design targeting recent FPGA-based accelerators. Our solution uses nearly 90% of FPGA basic-block hardware resources achieving about 90% of computing efficiency delivering a maximum throughput of 16.8 TCUPS and an energy efficiency of 46 Mpair/Joule, enabling the use of FPGAs as a new class of accelerators for High Performance Computing in DNA applications.}
}
@article{FANG2025105264,
title = {Understanding the gender divide in digital literacy in four European countries: A comprehensive decomposition analysis using unconditional quantile regression},
journal = {Computers & Education},
volume = {229},
pages = {105264},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105264},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000326},
author = {Guangbao Fang and Jiaxin Wang and Philip Wing Keung Chan and Penelope Kalogeropoulos},
keywords = {Gender divide, Computer and information literacy, Computational thinking, Oaxaca-Blinder decomposition, Unconditional quantile regression decomposition},
abstract = {Digital literacy is crucial for adolescents’ future, yet significant gender divides persist, particularly in Computer and Information Literacy (CIL) and Computational Thinking (CT). This study examines the gender divide in CIL and CT among adolescents in four European countries, highlighting the gender-based disparities in digital literacy development. Based on ICILS 2018 data, this research identifies factors contributing to gender divides in CIL and CT using regression and decomposition methods. Findings indicate that females outperform males in CIL, while males excel in CT. Gender divides decrease as the percentiles of students’ proficiency levels increase. The explained portion of the gender divide in CIL and CT is consistently smaller than the unexplained portion across countries, suggesting that gender divide or unobserved factors may drive these divides. A comparison of OLS regression results with decomposition approaches indicates that the factors influencing digital literacy development differ from those contributing to the gender divide. Variation in the factors contributing to gender divides is greater across countries than within countries for both CIL and CT. These findings highlight the need to consider national digital environments and socio-cultural contexts in addressing gender divides in digital literacy. This study offers insights for policymakers and educators to address the gender divide in digital literacy.}
}
@article{CUI2025,
title = {The Impact of AI Writing Assistants on Academic Writing Performance:},
journal = {International Journal of Distance Education Technologies},
volume = {23},
number = {1},
year = {2025},
issn = {1539-3100},
doi = {https://doi.org/10.4018/IJDET.391326},
url = {https://www.sciencedirect.com/science/article/pii/S1539310025000213},
author = {Yulu Cui and Weimiao He and Xingke Du and Manlin Zeng and Dongping Liu},
keywords = {AI in Education, AI Writing Assistants, Chatbots, Academic Writing, Writing Performance, Subjectivity},
abstract = {ABSTRACT
With the rapid rise of generative AI, writing tools are increasingly integrated into higher education, reshaping human-AI interaction and raising concerns about students' critical thinking, autonomy, and engagement. This study examined AI-assisted writing through the lens of subjectivity—students' autonomy, motivation, and self-regulation. Using a within-subjects pre-post design with 44 undergraduates, results showed that AI significantly improved writing quality, especially in linguistic precision, critical recognition, and structure and logic, while overall subjectivity remained stable. Cluster analysis revealed four usage patterns, with high-subjectivity students maintaining cognitive control and outperforming passive users. AI readiness was positively related to all subjectivity dimensions and indirectly enhanced performance via motivational and autonomy pathways. Rather than a neutral tool, AI emerges as a catalyst of educational transformation, reconfiguring student agency and compelling educators to rethink how equity and subjectivity can be preserved in AI-rich environments.}
}
@article{KSHETRI2024101931,
title = {Metaverse for advancing government: Prospects, challenges and a research agenda},
journal = {Government Information Quarterly},
volume = {41},
number = {2},
pages = {101931},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101931},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X24000236},
author = {Nir Kshetri and Yogesh K. Dwivedi and Marijn Janssen},
keywords = {Augmented reality, Digital avatars, Electronic government, Digital government, Metaverse, Cityverse, Virtual reality},
abstract = {A number of government agencies have started deploying the Metaverse to connect better with their constituents. The Metaverse provides a rich interaction environment and has the potential to engage with, especially, the younger generation. However, the Metaverse's potential impact on the government sector has been given limited attention. This discussion paper aims to fill this void by reviewing the state of the art, analyzing possible roles of the Metaverse for governments and providing research directions. We found six facilitators and nine barriers and risks. The Metaverse offers much more than a virtual presence or copy of the physical world; significant transformations are needed in government to reap the benefits. Given the evolution of the Metaverse, government presence also needs to evolve, and different governments make different decisions about their Metaverse presence. We recommend more research into the nature, use, applications, transformations, and implications of the Metaverse on government functioning.}
}
@article{NGUYEN2024112059,
title = {GPTSniffer: A CodeBERT-based classifier to detect source code written by ChatGPT},
journal = {Journal of Systems and Software},
volume = {214},
pages = {112059},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001043},
author = {Phuong T. Nguyen and Juri {Di Rocco} and Claudio {Di Sipio} and Riccardo Rubei and Davide {Di Ruscio} and Massimiliano {Di Penta}},
keywords = {ChatGPT, Code classification, CodeBERT, Pre-trained Models},
abstract = {Since its launch in November 2022, ChatGPT has gained popularity among users, especially programmers who use it to solve development issues. However, while offering a practical solution to programming problems, ChatGPT should be used primarily as a supporting tool (e.g., in software education) rather than as a replacement for humans. Thus, detecting automatically generated source code by ChatGPT is necessary, and tools for identifying AI-generated content need to be adapted to work effectively with code. This paper presents GPTSniffer– a novel approach to the detection of source code written by AI – built on top of CodeBERT. We conducted an empirical study to investigate the feasibility of automated identification of AI-generated code, and the factors that influence this ability. The results show that GPTSniffer can accurately classify whether code is human-written or AI-generated, outperforming two baselines, GPTZero and OpenAI Text Classifier. Also, the study shows how similar training data or a classification context with paired snippets helps boost the prediction. We conclude that GPTSniffer can be leveraged in different contexts, e.g., in software engineering education, where teachers use the tool to detect cheating and plagiarism, or in development, where AI-generated code may require peculiar quality assurance activities.}
}
@article{JIANG2024105113,
title = {They believe students can fly: A scoping review on the utilization of drones in educational settings},
journal = {Computers & Education},
volume = {220},
pages = {105113},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105113},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524001271},
author = {Michael Yi-Chao Jiang and Morris Siu-Yung Jong and Ching Sing Chai and Biyun Huang and Gaowei Chen and Chung-Kwan Lo and Frankie Kwan-Kit Wong},
keywords = {Drones, Unmanned aerial vehicles (UAVs), Scoping review, SAMR, Technology integration},
abstract = {In the past decade, drones have become another cutting-edge technology for educators, especially those in STEM-related domains. Accordingly, there is a significant need to thoroughly examine how drones are integrated into current pedagogical practices. This study scopes the domain of drone-based learning based on a collection of forty-eight articles identified via systematic searches across the Web of Science (WoS) databases. The analytical framework for coding is underpinned by the Substitution-Augmentation-Modification-Redefinition (SAMR) model. The review explored trends, domains and pedagogical activities, research approaches, learners and learning objectives, variables and aspects of interest, and most importantly, the integration levels of drones into current pedagogical practices. The findings highlight that drones are predominantly utilized in short-term, intermittent, and collaborative learning activities, particularly within STEM-related fields. Notably, the analysis reveals a prevalent use of drones to transform learning, mainly at the Modification and Redefinition levels of the SAMR framework. Regarding drone types, off-the-shelf drones are primarily used for applying-oriented learning and are evenly distributed across the Augmentation, Modification, and Redefinition levels. Conversely, custom-built drones are typically utilized for creating-oriented tasks and are most often associated with the highest SAMR level, i.e., Redefinition. Building upon these findings, the present work underscores the importance of addressing the novelty effect associated with drone-based learning, exploring strategies for sustaining student engagement over time, and investigating the cognitive benefits of intermittent drone use in educational settings. The collaborative nature of drone-based activities is also emphasized, calling for more process-oriented research to understand how drones influence collaborative learning.}
}
@article{CHAN2025112330,
title = {Effectiveness of symmetric metamorphic relations on validating the stability of code generation LLM},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112330},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112330},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003741},
author = {Pak Yuen Patrick Chan and Jacky Keung and Zhen Yang},
keywords = {Metamorphic testing, Metamorphic relation, True satisfaction, Large language model, Code generation},
abstract = {Pre-trained large language models (LLMs) are increasingly used in software development for code generation, with a preference for private LLMs over public ones to avoid the risk of exposing corporate secrets. Validating the stability of these LLMs’ outputs is crucial, and our study proposes using symmetric Metamorphic Relations (MRs) from Metamorphic Testing (MT) for this purpose. Our study involved an empirical experiment with ten LLMs (eight private and two public) and two publicly available datasets. We defined seven symmetric MRs to generate “Follow-up” datasets from “Source” datasets for testing. Our evaluation aimed to detect violations (inconsistent predictions) between “Source” and “Follow-up” datasets and assess the effectiveness of MRs in identifying correct and incorrect non-violated predictions from ground truths. Results showed that one public and four private LLMs did not violate “Case transformation of prompts” MR. Furthermore, effectiveness and performance results indicated that proposed MRs are effective tools for explaining the instability of LLM's outputs by “Case transformation of prompts”, “Duplication of prompts”, and “Paraphrasing of prompts”. The study underscored the importance of enhancing LLMs’ semantic understanding of prompts for better stability and highlighted potential future research directions, including exploring different MRs, enhancing semantic understanding, and applying symmetry to prompt engineering.}
}
@article{WANG2023109593,
title = {Verifying empirical predictive modeling of societal vulnerability to hazardous events: A Monte Carlo experimental approach},
journal = {Reliability Engineering & System Safety},
volume = {240},
pages = {109593},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109593},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023005070},
author = {Yi Victor Wang and Seung Hee Kim and Menas C. Kafatos},
keywords = {Hazard loss, Machine learning, Simulation, Social vulnerability, Societal system},
abstract = {With the emergence of large amounts of historical records on adverse impacts of hazardous events, empirical predictive modeling has been revived as a foundational paradigm for quantifying disaster vulnerability of societal systems. This paradigm models societal vulnerability to hazardous events as a vulnerability curve indicating an expected loss rate of a societal system with respect to a possible spectrum of intensity measure (IM) of an event. Although the empirical predictive models (EPMs) of societal vulnerability are calibrated on historical data, they should not be experimentally tested with data derived from field experiments on any societal system. Alternatively, in this paper, we propose a Monte Carlo simulation-based approach to experimentally test EPMs of societal vulnerability. Our study applied an eigenvalue-based method to generate data on societal experiences of IM and pre-event vulnerability indicators. True models were designed to simulate event loss data. Supervised machine learning (ML) models were then trained on simulated data and were found to provide similar predictive performances as the true models. Our results suggested that the calibrated ML-EPMs could effectively quantify societal vulnerability given a normally experienced IM. To extrapolate a vulnerability curve for large IMs, however, simple models should be preferred.}
}
@article{QAISAR2026113860,
title = {Exploring large language models for indoor occupancy measurement in smart office buildings},
journal = {Building and Environment},
volume = {287},
pages = {113860},
year = {2026},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113860},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325013307},
author = {Irfan Qaisar and Kailai Sun and Qianchuan Zhao},
keywords = {Energy saving, Occupancy detection and estimation, Artificial intelligence, Large language model, Office buildings},
abstract = {Accurately measuring building occupancy is essential for optimizing Heating, Ventilation, and Air Conditioning control and enhancing energy efficiency in smart buildings. However, existing machine learning models often struggle to generalize across diverse occupancy patterns with limited data. Recent advances in large language models present new opportunities by leveraging contextual reasoning and few-shot learning to enhance performance in smart building systems. This study proposes an LLM-based framework for real-time indoor occupancy measurement, incorporating few-shot learning, chain-of-thought reasoning, and in-context learning techniques. This study explores how LLMs can enable accurate and data-efficient occupancy measurement for indoor occupant-centric control and energy optimization. We evaluate LLMs’ performance against traditional models across two case studies: binary occupancy detection and multi-level occupancy estimation. Experiments are conducted using two real-world datasets collected from office buildings in China and Singapore. Results indicate that LLMs consistently outperform traditional models across various time intervals and training/testing configurations. Under a 4-day training/1-day testing setup, DeepSeek-R1 achieves 95.92% accuracy and a 96.1% F1-score, while Gemini-Pro attains 94.14% accuracy in multi-level estimation with only 1 day of training. An occupant-centric control (OCC) simulation and ablation study were implemented in EnergyPlus with real data to improve energy efficiency and comfort. These findings highlight the adaptability and robustness of LLMs, positioning them as promising tools for real-time occupancy measurement in smart office environments. Code and implementation details are available at: https://github.com/kailaisun/LLM-occupancy.}
}
@article{LI2025100894,
title = {A concise review of intelligent game agent},
journal = {Entertainment Computing},
volume = {52},
pages = {100894},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100894},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002623},
author = {Hui Li and Xinyi Pang and Bixia Sun and Kexin Liu},
keywords = {Intelligent agent, Artificial intelligence, Monte Carlo tree, Reinforcement learning, Large language models},
abstract = {Intelligent game agents are crafted using AI technologies to mimic player behavior and make decisions autonomously. Over the past decades, the scope of intelligent agents has broadened from chess to encompass content generation, player modeling, and result prediction, reflecting the field’s evolving and multifaceted nature. In this paper, we conduct a systematic review of recent literature on intelligent methods and applications of game agents, along with general game agent frameworks. Our findings suggest that creating general intelligent agents remains a significant challenge, yet it is worthwhile to explore methods that better integrate the strengths of different techniques to build more robust and adaptable intelligent game agents.}
}
@article{DENG2025127500,
title = {Research on intelligent prediction method of supersonic flow field in scramjet based on deep learning: A review},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127500},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127500},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425011224},
author = {Xue Deng and Ye Tian and Erda Chen and Maotao Yang and Hua Zhang and Jialing Le},
keywords = {Deep learning, Flow field prediction, Model lightweight, Physical constraints, Scramjet},
abstract = {Direct numerical simulation (DNS) serves as a crucial method for optimizing and validating scramjets, significantly advancing their design process. Nonetheless, solving the Navier-Stokes equations numerically entails substantial computational expenses, particularly for large-scale projects characterized by intricate hysteresis and high-precision thermochemical reactions. In recent years, numerous studies have demonstrated the rationality and efficacy of deep learning in reconstructing the evolutionary characteristics of flow fields. To reduce neural network models’ dependence on high-fidelity data and prevent the generation of non-physical solutions, neural networks incorporating physical information constraints offer a novel learning paradigm. This approach encodes prior knowledge and physical interpretability, which traditional neural networks lack. Based on this, this study investigates, analyzes, and summarizes traditional prediction methods for supersonic combustion flow, data-driven intelligent solution algorithms for supersonic flow fields, lightweight neural network models, and intelligent prediction algorithms for flow fields using physical information neural networks.}
}
@article{ZHU2025103412,
title = {Fostering children's dispositional autonomy and AI understanding through co-designing AI systems: A learning science perspective},
journal = {International Journal of Human-Computer Studies},
volume = {196},
pages = {103412},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103412},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001952},
author = {Yumeng Zhu and Samantha-Kaye Johnston and Caifeng Zhu and Yan Li},
keywords = {AI education, Co-design, Learning science, K-12, Child-centered AI, Design methods, Autonomy},
abstract = {Co-designing AI systems with children to foster their autonomy has gained traction in the child-computer interaction community. However, the prerequisites for co-designing with a focus on children's dispositional autonomy, their intentional inclination to determine their own actions, and their understanding of AI, have not been thoroughly examined. This study contributes to child-centered co-design research methodologies from the perspective of learning science, aiming to enhance children's dispositional autonomy and AI understanding through co-design activities. A 14-week curriculum based on the Learning by Design (LBD) framework was developed, incorporating activities that require co-designing AI systems with students. 116 middle school students, organized into 24 groups, engaged with the curriculum. Through the analysis of pre-and post-questionnaires, storytelling drawings, and co-design worksheets, we assessed how the LBD curriculum influenced students’ dispositional autonomy and how students’ understandings (perceptions and demands) of AI systems changed during this process. Our findings indicate that the LBD curriculum significantly impacted students’ dispositional autonomy in two of the three dimensions that were assessed (authorship/congruence and interest-taking), and students transitioned from passive users to active engagers of AI. Based on students’ designs, we further propose designing AI systems with children-in-the-loop approaches. We provide a conceptual framework for categorizing the types of digital nudges provided by AI systems. This framework aims to foster children's dispositional autonomy and enhance their understanding of AI by facilitating self-regulation in their interactions with these systems.}
}
@article{BOUCHER2024104041,
title = {Smart PSS modelling language for value offer prototyping: A design case study in the field of heating appliance offers},
journal = {Computers in Industry},
volume = {155},
pages = {104041},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104041},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001914},
author = {Xavier Boucher and Camilo Murillo Coba and Damien Lamy},
keywords = {Smart PSS, Design prototypes, Value offer design, Conceptual models},
abstract = {The recent convergence between two industrial transitions towards digitalization on the one side and servitization on the other side led to the new business strategies of digital servitization and smart PSS delivery. While inheriting from the previous scientific literature on PSS, because of the multiple impacts of digitalization in the overall system, the processes of ensuring the design and engineering of smart PSS solutions poses new challenges. This research addresses the specific needs to develop conceptual prototypes of smart PSS value offers, at early stages of the design process. The paper presents the development and experimentation of a modelling language and its associated modelling toolkit (sPS²Modeller). The application case study addresses the design of a smart PSS in the field of heating appliances, developed in collaboration with the company elm.leblanc, Bosch Group – France.}
}
@article{ERRAZURIZ2025101057,
title = {Prevalence of anxiety disorders in Latin America: a systematic review and meta-analysis},
journal = {The Lancet Regional Health - Americas},
volume = {45},
pages = {101057},
year = {2025},
issn = {2667-193X},
doi = {https://doi.org/10.1016/j.lana.2025.101057},
url = {https://www.sciencedirect.com/science/article/pii/S2667193X25000675},
author = {Antonia Errazuriz and Dalia Avello-Vega and Alvaro Passi-Solar and Rafael Torres and Felix Bacigalupo and Nicolas A. Crossley and Eduardo A. Undurraga and Peter B. Jones},
keywords = {Anxiety disorders, Prevalence, Latin America, Systematic review, Meta-analysis, Global mental health},
abstract = {Summary
Background
The prevalence of anxiety disorders among the adult population in Latin America (LATAM) and its association with development indicators is insufficiently characterised. We estimated pooled regional, country, and sex-specific prevalence rates of anxiety disorders in LATAM based on International Classification of Diseases (ICD) or Diagnostic and Statistical Manual of Mental Disorders (DSM) criteria. Additionally, we examined the association between its prevalence and four country-level development indicators: Human Development Index (HDI), income inequality (Gini coefficient), Gender Inequality Index (GII), and Intentional Homicide Rate (IHR).
Methods
We conducted a systematic review and meta-analysis of population-based studies on the prevalence of ICD/DSM anxiety disorders in LATAM from 1990 to 2024, irrespective of language. We searched PubMed, PsycINFO, Cochrane Library, SciELO, LILACS, and grey literature. Study quality was assessed using JBI's critical appraisal tools. Pooled estimates were generated using random-effects meta-analysis, and heterogeneity was evaluated using the I-squared (I2) statistic. Meta-regression analyses were performed to examine the ecological association between anxiety disorders prevalence and four development indicators. The study was registered with PROSPERO (CRD42020190238).
Findings
Using data from 36 studies in LATAM, we calculated the lifetime, 12-month, and current prevalence of ICD/DSM anxiety disorders at 14.55% (95% Confidence Interval 12.32%–17.11%; I2 = 97.9%); 6.61% (5.20–8.37; I2 = 98.1%), and 3.27% (2.34–4.56; I2 = 97.5%), respectively. Heterogeneity was high across prevalence periods, sexes, and countries (all I2 ≥ 91.4%), warranting caution in interpreting pooled estimates. Elevated 12-month and current prevalence rates of anxiety disorders were associated with higher Gini coefficients (p ≤ 0.0013). Additionally, higher current prevalence was associated with lower HDI (p = 0.0103) and higher GII (p = 0.0023), while elevated 12-month prevalence was associated with higher IHR (p = 0.011).
Interpretation
This study shows that approximately one in seven people in LATAM experience anxiety disorders at some point in their lives. These findings highlight the need to strengthen mental health systems in the region, and evidence the association between prevalence of anxiety disorders and development indicators. Our results can serve as a baseline for tracking anxiety disorders and for informed decision-making at the national and regional levels. The substantial heterogeneity between studies and the underrepresentation of some countries underscore the imperative for enhancing regional mental health capacities.
Funding
Pfizer Independent Medical Education Grant (69879319).}
}
@article{GWAGWA2024101078,
title = {How could the United Nations Global Digital Compact prevent cultural imposition and hermeneutical injustice?},
journal = {Patterns},
volume = {5},
number = {11},
pages = {101078},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101078},
url = {https://www.sciencedirect.com/science/article/pii/S266638992400237X},
author = {Arthur Gwagwa and Warmhold Jan Thomas Mollema},
keywords = {AI governance, AI regulation, Global Digital Compact, United Nations, cultural imposition, hermeneutical injustice, domination, artificial intelligence, AI ethics, AI colonialism},
abstract = {Summary
As the geopolitical superpowers race to regulate the digital realm, their divergent rights-centered, market-driven, and social-control-based approaches require a global compact on digital regulation. If diverse regulatory jurisdictions remain, forms of domination entailed by cultural imposition and hermeneutical injustice related to AI legislation and AI systems will follow. We argue for consensual regulation on shared substantive issues, accompanied by proper standardization and coordination. Failure to attain consensus will fragment global digital regulation, enable regulatory capture by authoritarian powers or bad corporate actors, and deepen the historical geopolitical power asymmetries between the global South and the global North. To prevent an unjust regulatory landscape where the global South’s cultural and hermeneutic resources are absent, two principles for the Global Digital Compact to counter these prospective harms are proposed and discussed: (1) “recognitive consensus on key substantive benefits and harms” and (2) “procedural consensus on global coordination and essential standards.”}
}
@article{JACOB2025,
title = {AI for IMPACTS Framework for Evaluating the Long-Term Real-World Impacts of AI-Powered Clinician Tools: Systematic Review and Narrative Synthesis},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67485},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125001797},
author = {Christine Jacob and Noé Brasier and Emanuele Laurenzi and Sabina Heuss and Stavroula-Georgia Mougiakakou and Arzu Cöltekin and Marc K Peter},
keywords = {eHealth, assessment, adoption, implementation, artificial intelligence, clinician, efficiency, health technology assessment, clinical practice},
abstract = {Background
Artificial intelligence (AI) has the potential to revolutionize health care by enhancing both clinical outcomes and operational efficiency. However, its clinical adoption has been slower than anticipated, largely due to the absence of comprehensive evaluation frameworks. Existing frameworks remain insufficient and tend to emphasize technical metrics such as accuracy and validation, while overlooking critical real-world factors such as clinical impact, integration, and economic sustainability. This narrow focus prevents AI tools from being effectively implemented, limiting their broader impact and long-term viability in clinical practice.
Objective
This study aimed to create a framework for assessing AI in health care, extending beyond technical metrics to incorporate social and organizational dimensions. The framework was developed by systematically reviewing, analyzing, and synthesizing the evaluation criteria necessary for successful implementation, focusing on the long-term real-world impact of AI in clinical practice.
Methods
A search was performed in July 2024 across the PubMed, Cochrane, Scopus, and IEEE Xplore databases to identify relevant studies published in English between January 2019 and mid-July 2024, yielding 3528 results, among which 44 studies met the inclusion criteria. The systematic review followed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) guidelines and the Cochrane Handbook for Systematic Reviews. Data were analyzed using NVivo through thematic analysis and narrative synthesis to identify key emergent themes in the studies.
Results
By synthesizing the included studies, we developed a framework that goes beyond the traditional focus on technical metrics or study-level methodologies. It integrates clinical context and real-world implementation factors, offering a more comprehensive approach to evaluating AI tools. With our focus on assessing the long-term real-world impact of AI technologies in health care, we named the framework AI for IMPACTS. The criteria are organized into seven key clusters, each corresponding to a letter in the acronym: (1) I—integration, interoperability, and workflow; (2) M—monitoring, governance, and accountability; (3) P—performance and quality metrics; (4) A—acceptability, trust, and training; (5) C—cost and economic evaluation; (6) T—technological safety and transparency; and (7) S—scalability and impact. These are further broken down into 28 specific subcriteria.
Conclusions
The AI for IMPACTS framework offers a holistic approach to evaluate the long-term real-world impact of AI tools in the heterogeneous and challenging health care context and lays the groundwork for further validation through expert consensus and testing of the framework in real-world health care settings. It is important to emphasize that multidisciplinary expertise is essential for assessment, yet many assessors lack the necessary training. In addition, traditional evaluation methods struggle to keep pace with AI’s rapid development. To ensure successful AI integration, flexible, fast-tracked assessment processes and proper assessor training are needed to maintain rigorous standards while adapting to AI’s dynamic evolution.
Trial Registration
reviewregistry1859; https://tinyurl.com/ysn2d7sh}
}
@article{YAO2024e33531,
title = {The evolution of the ambidextrous innovation synergy strategy of new entrants from the perspective of key core technology monopoly},
journal = {Heliyon},
volume = {10},
number = {13},
pages = {e33531},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e33531},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024095628},
author = {Shuang Yao and Leke Wu and Donghua Yu},
keywords = {Key core technology, New entrants, Ambidextrous innovation synergy, Original innovation search, Network embedding},
abstract = {Ambidextrous innovation synergy is an effective way for new entrants and R&D entities to break the blockade of key core technologies. This paper constructs a tripartite evolutionary game model of new entrants, the R&D entity, and monopoly enterprises under the monopoly situation of key core technologies, discusses the dynamic equilibrium process of how new entrants cooperate with the R&D entity to carry out the ambidextrous innovation synergy strategy, and extends the model to the policy subsidy situations of different development stages of key core technology. The results show that the monopoly of key core technologies enhances the original innovation search ability of new entrants and promotes the evolution of enterprise imitation innovation to the exploratory innovation strategy. In the basic research stage of key core technology, the exploratory innovation strategy of new entrants is more sensitive to the cost of network embedding and the original innovation knowledge search. New entrants prefer the imitation innovation strategy, and policy subsidies have no significant effect on exploratory innovation. In the promotion stage of the key core technology market, fiscal and tax subsidies can more easily promote the evolution of new entrants from the imitative innovation strategy to the exploratory innovation strategy than R&D subsidies, and network embeddedness can induce enterprises to carry out exploratory innovation only when a certain threshold is reached. In addition, this paper discusses the influence mechanism of monopoly enterprises' suppression intensities and key core technology breakthrough probabilities on the evolution equilibrium of new entrants' ambidextrous innovation synergy strategies.}
}
@article{HASAN2025,
title = {Mushrooms as Potent Autophagy Modulators in Cancer Therapy: Current Evidence and Therapeutic Prospects},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000916},
author = {Md.Mahmudul Hasan and Eva Azme and Rashedul Alam and Md.Jahirul Islam Mamun and Md.Tanvir Chowdhury and Md.Hossain Rasel and Md.Safayat Hossen Momen and Neamul Hoque and Md.Ekramul Haque Ekram and Nazmul Hasan Eshaque and Shakil Ahmed and Md.Tashrif Rahman Tipu and Sanjida Shahid Juthi and Mohammad Fazlul Kabir and Ahsan Ullah and Md.Liakot Ali and S.M.Moazzem Hossen and Hea-Jong Chung},
keywords = {Mushroom, autophagy, cancer, traditional medicine, functional food, Endoplasmic reticulum stress},
abstract = {Mushrooms, recognized for their culinary and medicinal applications, are emerging as potential sources of autophagy modulators in cancer treatment. Autophagy is cellular degradation triggered by organelle damage, protein aggregation, metabolic disturbances, or nutrient scarcity. It contributes to the suppression of early tumor development and the promotion of cancer cell survival at advanced stages. This review systematically assesses the current evidence on the anticancer potential of mushrooms and their bioactive compounds, focusing on their ability to modulate autophagy. The review lists over 18 mushroom species (e.g., Ganoderma lucidum, Cordyceps, Phellinus) and 28 bioactive compounds (such as Ganoderic acid DM, Cordycepin, Hispidin) that affect autophagy, demonstrating efficacy against 15 cancer types, including colorectal, lung, breast, and liver cancers. Essential compounds modulate autophagy through phosphoinositide 3-kinase (PI3K)/protein kinase B (Akt)/mechanistic target of rapamycin (mTOR), AMP-activated protein kinase (AMPK), and Beclin-1 pathways, resulting in notable anticancer effects. G. lucidum extracts quantitatively reduced colorectal tumor growth by up to 60% in vivo. Additionally, Cordycepin induced autophagic cell death in lung cancer cells, with IC50 values as low as 25 μmol/L.The findings highlight the potential of mushrooms as low-toxicity adjuvants to conventional therapies, providing advantages such as immune modulation and antioxidant activity. Mushrooms and their bioactive components present promising avenues for cancer therapy through the modulation of autophagy. The context-dependent effects of autophagy, along with the limited clinical evidence, present considerable challenges. Future clinical trials must focus on developing standardized extracts and personalized approaches to effectively translate this potential into clinical practice.}
}
@article{SPRUTE2025101609,
title = {Land use and land cover classification on high-resolution UAV images for heavy rainfall hazard maps using deep neural networks},
journal = {Remote Sensing Applications: Society and Environment},
volume = {38},
pages = {101609},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101609},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525001624},
author = {Dennis Sprute and Hanne Hendrickx and Pedro Zamboni and Muhtasimul Islam Rushdi and Florian Brodrecht and Anette Eltner and Holger Flatt},
keywords = {Land use/cover classification, UAV, RGB images, Heavy rainfall hazard maps, Semantic segmentation, Deep neural networks},
abstract = {The increasing frequency and intensity of extreme weather events due to climate change highlight the need for accurate hazard mapping for heavy rainfall. Land use and land cover (LULC) maps, along with digital elevation models (DEMs) and meteorological data, are essential to construct these hazard maps. For this purpose, LULC maps must be of high resolution to capture small hydrodynamically relevant structures and up-to-date to reflect constant changes driven by human activities. Uncrewed aerial vehicles (UAVs) are ideal for acquiring these high-resolution images because of their cost effectiveness, flexibility, and detail. However, no publicly available datasets and approaches currently provide urban LULC maps at this level of detail (<5 cm) while considering classes relevant for constructing heavy rainfall hazard maps. Therefore, this article presents a novel approach for LULC classification using high-resolution UAV imagery to enhance the generation of heavy rainfall hazard maps. We develop a comprehensive processing pipeline that includes UAV data collection, orthophoto creation, and LULC classification using advanced deep learning architectures. Our method tackles challenges such as differing between 22 LULC classes with objects of varying sizes and managing imbalanced datasets. Additionally, we create a high-resolution UAV image dataset with more than 12K annotated images. A comprehensive evaluation of 29 deep learning architectures reveals that CFNet with an EfficientNetB4 backbone achieves the best performance, with an accuracy of 0.911 and a Mean Intersection over Union (IoU) of 0.738. The results demonstrate that our approach effectively classifies hydrodynamically relevant structures, such as different roof types, street materials, and drainage facilities. This work establishes a solid foundation for future research and practical applications in the automated generation of accurate heavy rainfall hazard maps, ultimately aiming to improve risk management strategies in the context of climate change.}
}
@article{WU2025105119,
title = {How well can ChatGPT forecast tourism demand?},
journal = {Tourism Management},
volume = {108},
pages = {105119},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105119},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724002383},
author = {Doris Chenguang Wu and Wenjia Li and Ji Wu and Mingming Hu and Shujie Shen},
keywords = {tourism demand forecasting, ChatGPT, Zero-shot, Chain-of-Thought, artificial intelligence},
abstract = {ChatGPT has demonstrated remarkable capabilities across various natural language processing (NLP) tasks. However, its potential for forecasting tourism demand from temporal data, specifically historical tourism arrivals data, remains an unexplored frontier. This research presents the first attempt to conduct an extensive Zero-shot and Chain-of-Thought analysis of ChatGPT's capabilities in tourism demand forecasting, under various temporal scenarios. Based on the Macau inbound tourism arrivals dataset, our empirical findings indicate that the predictive capability of ChatGPT-4 is noteworthy compared to the three benchmark time series models (Naïve, Exponential Smoothing, SARIMA) and the three benchmark machine learning models (Random Forest, Multi-Layer Perceptron, Long Short-Term Memory), especially when the forecast horizon is relatively short. Furthermore, compared to Zero-shot prompts, engaging in continuous dialogue can enhance the forecast accuracy of ChatGPT-4. This performance of ChatGPT highlights its potential for quantitative data prediction as a new user-friendly and cost-effective management tool.}
}
@article{ALMOGREN2024e31887,
title = {Exploring factors influencing the acceptance of ChatGPT in higher education: A smart education perspective},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31887},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31887},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079180},
author = {Abeer S. Almogren and Waleed Mugahed Al-Rahmi and Nisar Ahmed Dahri},
keywords = {Smart education, ChatGPT, Higher education, Acceptance factors, Technology adoption},
abstract = {AI-powered chatbots hold great promise for enhancing learning experiences and outcomes in today's rapidly evolving education system. However, despite the increasing demand for such technologies, there remains a significant research gap regarding the factors influencing users' acceptance and adoption of AI-powered chatbots in educational contexts. This study aims to address this gap by investigating the factors that shape users' attitudes, intentions, and behaviors towards adopting ChatGPT for smart education systems. This research employed a quantitative research approach, data were collected from 458 of participants through a structured questionnaire designed to measure various constructs related to technology acceptance, including perceived ease of use, perceived usefulness, feedback quality, assessment quality, subject norms, attitude towards use, and behavioral intention to use ChatGPT. Structural model analysis (SEM) Statistical techniques were then utilized to examine the relationships between these constructs. The findings of the study revealed that Perceived ease of use and perceived usefulness emerged as significant predictors of users' attitudes towards ChatGPT for smart education. Additionally, feedback quality, assessment quality, and subject norms were found to positively influence users' behavioral intentions to use ChatGPT for smart educational purposes. Moreover, users' attitudes towards use and behavioral intentions were significantly proved for the actual adoption of ChatGPT. However, a few hypotheses, such as the relationship between trust in ChatGPT and perceived usefulness, were not supported by the data. This study contributes to the existing body information systems applications for the determining factor of technology acceptance in smart education context.}
}
@article{ELJAOUHARI2025123658,
title = {Turning trash into treasure: Exploring the potential of AI in municipal waste management - An in-depth review and future prospects},
journal = {Journal of Environmental Management},
volume = {373},
pages = {123658},
year = {2025},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2024.123658},
url = {https://www.sciencedirect.com/science/article/pii/S0301479724036442},
author = {Asmae {El jaouhari} and Ashutosh Samadhiya and Anil Kumar and Eyob Mulat-weldemeskel and Sunil Luthra and Rajesh Kumar},
keywords = {Artificial intelligence, Conceptual framework, Municipal waste, Optimization, Performance metrics, Systematic literature review},
abstract = {Rapid urbanization, economic expansion, and population growth have increased waste generation in many nations worldwide. Research on municipal waste management (MWM) is moving towards new frontiers in efficiency and applicability due to the growing amount of data being collected in these systems and the convergence of various technological applications; artificial intelligence (AI) techniques present novel and creative alternatives for MWM. Even though much research has been conducted in this field, relatively few review studies assess how advancements in AI techniques can contribute to the sustainable advancement of MWM systems. Furthermore, there are discrepancies and a dearth of knowledge regarding the operation of AI-based techniques in MWM. To close this gap, this study conducts a thorough review of the relevant literature with an application of preferred reporting items for systematic reviews and meta-analyses-based methods, examining 229 peer-reviewed publications to explore the role of AI in different MWM areas, such as waste characteristics forecasting, waste bin level monitoring, process parameter prediction, vehicle routing, and MWM planning. The main AI techniques and models used in MWM optimization, as well as the application areas and stated performance metrics, are all thoroughly analyzed in this review. A conceptual framework is proposed to guide research and practice to take a holistic approach to MWM, along with areas of future study that need to be explored. Researchers, policymakers, municipalities, governments, and other waste management organizations will benefit from this study to minimize costs, maximize efficiency, eliminate the need for manual labor, and change the approach to MWM.}
}
@article{BAABDULLAH2024122951,
title = {Generative conversational AI agent for managerial practices: The role of IQ dimensions, novelty seeking and ethical concerns},
journal = {Technological Forecasting and Social Change},
volume = {198},
pages = {122951},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122951},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523006364},
author = {Abdullah M. Baabdullah},
keywords = {Generative conversational AI agent, Information quality, Novelty seeking, Ethical concerns, Decision-making efficiency, Innovation performance},
abstract = {This study aims to identify and empirically examine the influence of the main factors related to the content quality of generative conversational AI agents on decision-making efficiency. Additionally, this study explores the ramifications of decision-making efficiency facilitated by generative conversational AI agents in organisational innovation performance. This study proposes a model based on the information quality model as well as other factors, such as novelty seeking and ethical concerns. Data from this study was collected using online questionnaires from a purposive sample size of 228 employees in business organisations. Based on Structural Equation Modelling (SEM) analyses using AMOS, the results support the significant impact of information quality (intrinsic information quality, contextual information quality, representational information quality, and accessibility of information quality) on decision-making efficiency. The results also support the significant impact of novelty seeking and ethical concerns on decision-making efficiency. Decision-making efficiency was also found to have a significant positive impact on innovation performance. This empirical study makes a considerable contribution as it is among the first to expand the current understanding of the effective use of generative conversational AI agents in managerial practices (i.e. decision-making and innovation).}
}
@article{JENKINSON2024114908,
title = {Pizza3: A general simulation framework to simulate food-mechanical and food-deconstruction problems},
journal = {Food Research International},
volume = {194},
pages = {114908},
year = {2024},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2024.114908},
url = {https://www.sciencedirect.com/science/article/pii/S0963996924009785},
author = {William Jenkinson and Brian Guthrie and Denis Flick and Olivier Vitrac},
keywords = {Food Micromechanics, Hybrid numerical simulation, Smoothed Particle Hydrodynamics, Molecular Dynamics-like simulation, LAMMPS, Oral processing, Texture Perception, Mesoscopic modeling, Soft matter, Granular flow},
abstract = {Current mesh-based simulation approaches face significant challenges in continuously modeling the mechanical behaviors of foods through processing, storage, deconstruction, and digestion. This is primarily due to the limitations of continuum mechanics in dealing with systems characterized by free boundaries, substantial deformations, mechanical failures, and non–homogenized mechanical properties. The dynamic nature of food microstructure and the transformation of the food bolus, in relation to its composition, present formidable obstacles in computer-aided food design. In response, the Pizza3 project adopts an innovative methodology, utilizing an explicit microstructural representation to construct and subsequently deconstruct food products in a modular, Lego-like fashion. Central to this simulation approach are “food atoms”, conceptualized from the principles of smoothed particle hydrodynamics. These units are significantly larger than actual atoms but are finely scaled to represent both solid and liquid states of food faithfully. In solid phases, food atoms interact via pairwise forces akin to bond-peridynamic methods, thus extending the capabilities of continuum mechanics to encompass large deformations and fracturing phenomena. For liquids, the model employs artificial conservative and dissipative forces, enabling the simulation of a variety of phenomena within the framework of partial compressibility. The interaction dynamics between rigid and soft objects and fluids are accurately captured through Hertzian contact mechanics, offering a versatile parameterization applicable to impermeable (but possibly penetrable) surfaces and enforcing no-slip conditions. The efficacy of this framework is showcased through the successful modeling of three time-dependent 3D scenarios, each rigorously validated against established analytical and experimental models. Advancing beyond these initial applications, the framework is further extended to more intricate cases inadequately addressed in current literature. This extension sheds light on the underlying mechanisms of in-mouth texture perception, offering new insights and tools for food engineering and design.}
}
@article{SILVA2024107698,
title = {Mapping the landscape of energy markets research: A bibliometric analysis and predictive assessment using machine learning},
journal = {Energy Economics},
volume = {136},
pages = {107698},
year = {2024},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2024.107698},
url = {https://www.sciencedirect.com/science/article/pii/S0140988324004067},
author = {Thiago Christiano Silva and Tercio Braz and Benjamin Miranda Tabak},
keywords = {Clean energy, Bibliometrics, Machine learning, Volatility spillover, Energy markets, Crude-oil},
abstract = {This study examines the evolving dynamics of research on the energy market that focuses on understanding its interactions and interdependencies with other markets. Using published articles from 2002 to 2022 indexed by the Web of Science, we employ bibliometric methods, complex network measurements, and machine learning algorithms to analyze trends and predict academic success or interest. Our bibliometric analysis highlights the growing emphasis on new topics, such as clean energy, over traditional energy topics like crude oil and volatility spillovers. In a horse-race setup, we use supervised regression techniques to predict the paper’s academic success, measured in terms of the average number of citations over the years. We use meta-information from the paper, including keywords, as predictive attributes. The Random Forest achieves the best out-of-sample performance. We complement this analysis by using Shapley Additive Explanations to assess the contribution of each attribute to the overall prediction, thus allowing model interpretability. We find non-linear relationships between some numeric attributes, such as the number of keywords in the paper, and the target variable, highlighting the flexibility of non-linear methods compared to linear ones. Our findings offer valuable insights into emerging research trends and provide educators, policymakers, and finance professionals with critical information to navigate the evolving landscape of energy market research.}
}
@article{LIPNICKAS2025101017,
title = {Adaptive online course design: Analysis of changes in student behaviour throughout the degree lifecycle},
journal = {The Internet and Higher Education},
volume = {66},
pages = {101017},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101017},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000260},
author = {Gediminas Lipnickas and Joanne Harris and Bora Qesja and Svetlana {De Vos}},
keywords = {Learning analytics, Learning design, Engagement patterns, Academic performance, Online learning environments, Course design},
abstract = {With the growth of the online higher education sector, educational institutions are increasingly creating asynchronous online courses resembling Massive Open Online Courses (MOOCs), characterised by reduced interpersonal interactions. While these courses offer higher flexibility for students, much remains unknown about how the design of these courses impacts student behaviour and performance. This study combines learning analytics and learning design (via Open University Learning Design Initiative (OULDI) taxonomy) to examine effective online course design elements in a 100 % online environment. Effectiveness is evaluated based on the impact of design elements on student engagement and performance. Student engagement patterns throughout the degree are also explored. Results show that while assimilative activities are those most frequently undertaken by students, they rank as fourth in impact on performance. Experiential, interactive/adaptive, and productive activities, though more impactful, are less common and constitute only a fraction of online course design activities. Students were also more likely to engage with videos as opposed to readings, indicating a preference for this type of content in the online learning environment. Furthermore, an inverse correlation was found between students attempting a range of activities, and the need to communicate with staff (i.e., asking for clarification/guidance). Results also identified six types of student engagement patterns, revealing a transition over time towards an assessment focus, where students self-optimise and prioritise assessment completion (over other content/activities). In an online environment, where introducing sequential/scaffolding activities may prove difficult, findings indicate that activities should be clearly linked to assessments to cater for student engagement patterns.}
}
@article{HUANG2026105315,
title = {Responsible AI and human collaboration in tourism management: Ethical considerations and identity disclosure},
journal = {Tourism Management},
volume = {113},
pages = {105315},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105315},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001852},
author = {GuoQiong Ivanka Huang and Chen Jason Zhang and Wanyi Christina {Zhou Torres} and Xiling Xiong and Huahang Li},
keywords = {Artificial intelligence, Human intelligence, Managerial responses, The Turing Test, Moral responsibility},
abstract = {Artificial Intelligence has evolved from mimicking to enhancing or even surpassing human capabilities in specialized domains. Building on Turing's test and the theory of moral responsibility, this research delves into the ethical and perceptual dimensions of AI-generated content in tourism management through three studies. Study 1 (N=1400) assesses tourists' ability to distinguish AI-generated from human managerial responses and examines their perceptions of responsibility. Study 2 (N=700) develops and validates a multidimensional scale to measure Responsible AI within the tourism industry. Study 3 (N=600) uses a scenario-based experiment to evaluate how collaborative AI-human responses, compared to AI-only or human-only responses, influence tourists' attributions of responsibility and satisfaction, especially when the origin of the response is transparently disclosed. This research advances frameworks for responsible AI in tourism management and emphasizes ethical openness to align technological advances with societal well-being.}
}
@article{WANG2024105965,
title = {Do not go gentle into that good night: The European Union's and China's different approaches to the extraterritorial application of artificial intelligence laws and regulations},
journal = {Computer Law & Security Review},
volume = {53},
pages = {105965},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105965},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000323},
author = {Yan Wang},
keywords = {Artificial intelligence, Extraterritorial effects, Global governance},
abstract = {The extraterritorial application of artificial intelligence (AI) laws and regulations is a form of global AI governance. The EU and China serve as two different examples of how to achieve the extraterritorial applicability of AI laws and regulations. The former shows an explicit territorial extension with more trigger factors, whereas the latter shows vertical regulation with a narrower territorial scope. Both countries’ legislative motivations differ but also have some commonalities. One of the primary goals of extraterritorial application of domestic laws is to protect citizens within their territory. The digital economy's characteristics make it necessary for AI laws to have extraterritorial effects. Without international conventions or treaties, there is a legal vacuum in AI regulation. Additionally, the extraterritorial application of AI laws and regulations helps a state become a global standard-setter and gain an international sphere of influence. However, the extraterritorial application of AI laws and regulations sometimes functions as a form of legal imperialism. This exacerbates the injustice between great powers and weak countries in AI competition. To justify the legitimacy of the extraterritorial application of AI laws and regulations, it is beneficial to adopt the ‘inner morality of extraterritoriality’, a theoretical framework proposed by Professor Dan Svantesson. In fact, extraterritorial applicability depends on the market size and attractiveness. For other countries, whether their AI laws and regulations are endowed with extraterritorial effects is their prerogative. However, they should consider their soft power before implementing legislation.}
}
@article{SUNMOLA2024813,
title = {Artificial Intelligence Opportunities for Resilient Supply Chains},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {19},
pages = {813-818},
year = {2024},
note = {18th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.09.195},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324016148},
author = {Funlade Sunmola and George Baryannis},
keywords = {supply chain resilience, artificial intelligence, explainability, industry 5.0},
abstract = {The need for supply chains to be resilient is increasingly being recognised, following recent disruptions caused by global socioeconomic crises. Supply chain resilience allows for sustainable growth and development through adaptive capabilities, principally including the ability to effectively respond to disruptions to maintain consistent operations. This paper explores the opportunities presented by Artificial Intelligence (AI) in enhancing supply chain resilience. We first conceptualise resilience through a 4-C model: context, capabilities, choices, and contingencies. We then explore a range of AI approaches and develop a research roadmap that attempts to map particular technologies holding potential to the 4-C model.}
}
@article{GUO2025104804,
title = {The impact of parental involvement, social support, and peer relationships on L2 learning motivation: A mixed-methods study of Chinese university EFL students},
journal = {Acta Psychologica},
volume = {254},
pages = {104804},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.104804},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825001179},
author = {Zikai Guo and Chen Chen and Ruifang Guo},
keywords = {Parental involvement, Social support, Peer relationships, L2 learning motivation, EFL, Mixed-methods approach, Chinese university students},
abstract = {This mixed-methods study investigated the impact of parental involvement, social support, and peer relationships on L2 learning motivation among Chinese university students learning English as a foreign language (EFL). Quantitative data from 326 students and qualitative data from semi-structured interviews with 20 students were analyzed. Hierarchical regression analyses revealed that parental involvement significantly predicted all three components of L2 motivation: ideal L2 self, ought-to L2 self, and L2 learning experience. Peer relationships also positively predicted ideal L2 self and L2 learning experience. While social support was not a significant predictor in the quantitative analyses, the analysis of the qualitative data revealed its nuanced role, with students emphasizing the importance of diverse sources of support, including peers, teachers, mentors, and online communities, in fostering a sense of belonging and enhancing motivation. The study highlights the complex interplay of familial and social influences on L2 motivation, offering valuable insights for educators and parents in supporting EFL learners.}
}
@article{GUEVARA2025101090,
title = {Trends and perspectives on bacterial nanocellulose: A comprehensive analysis from the three helixes of innovation},
journal = {Materials Today Sustainability},
volume = {30},
pages = {101090},
year = {2025},
issn = {2589-2347},
doi = {https://doi.org/10.1016/j.mtsust.2025.101090},
url = {https://www.sciencedirect.com/science/article/pii/S2589234725000193},
author = {Kleber Mora Guevara and Gustavo Martínez-Valenzuela and Viviana Sánchez-Vásquez and Keyla Guerrero-Ruiz and Manuel Fiallos-Cárdenas},
keywords = {Bacterial cellulose, Sustainability, Biorefinery, Bioprocesses, Waste biomass, Bibliometry},
abstract = {Bacterial nanocellulose (BNC) stands out as a nanocrystalline material with a wide range of unique properties, including high mechanical strength, biodegradability, biocompatibility, and transparency. This versatility has attracted great interest in various fields, from biomedicine and materials engineering to the food industry and environmental technology. The present study focused on assessing the impact of BNC's scientific production within the framework of the three helixes of innovation and identifying trends in research and technological development. To this end, a comprehensive bibliometric analysis of 4814 peer-reviewed articles published between 2013 and 2023 was conducted, using the SCOPUS database and analyzing the information through Rstudio's Bibliometrix package. The results revealed an approximate annual growth of 15.67% in BNC's scientific output, with an average of 33.56 citations per paper. China was positioned as a leader in this output, backed by strong government commitment and considerable funding for sustainability-focused research. It is notable that BNC studies contribute mainly to the Sustainable Development Goals (SDGs), with SDGs 3, 6, 7, 9, 12, and 17 standing out. Despite the current trend towards process optimization and exploration of BNC-producing microorganisms, a lack of research in life cycle analysis and techno-economic analysis was identified. It is suggested that the implementation of biorefinery approaches, the utilization of residual biomass, and the evaluation of energy efficiency and exergy analysis could potentially significantly improve the process of obtaining BNC, providing a more sustainable and efficient approach to its production with multiple applications in various industrial sectors.}
}
@article{HOSSEINI2024142594,
title = {Mutual impacts of changing climate and flexible pavement performance considering resilience and sustainable aspects},
journal = {Journal of Cleaner Production},
volume = {460},
pages = {142594},
year = {2024},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.142594},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624020420},
author = {Fatemeh Hosseini and Mahdi Nasimifar and Nadarajah Sivaneswaran and Amir Golalipour},
keywords = {Changing climate, Pavement performance, Life-cycle assessment, Sustainability, Resilience},
abstract = {Roads play a vital role in transportation systems, and their construction and maintenance expenses are high. Those reasons make crucial the examination of factors that accelerate road deterioration and those factors' negative impacts on societies. Climatic-related elements, especially temperature and precipitation, significantly affect the quality and lifespans of roads. The Intergovernmental Panel on Climate Change has reported that increasing greenhouse gas (GHG) emissions is causing changes in climate and that the rate of change has accelerated during the past several decades. To assess the impacts of changing climatic parameters on flexible-pavement performance, this study used 32 climate models to evaluate the performance of interstate, primary, and secondary roads across 11 diverse locations with varying traffic and climatic conditions. The study's findings reveal that changing climate exacerbates pavement distresses, leading to reduced pavement lifespans and increased numbers of reconstruction projects, which in turn raise demands for materials and equipment and contribute to higher GHG emissions. The effects of changing climate and changing climate's associated economic and environmental costs make the application of various engineering solutions to enhance pavement resilience essential, as described in this paper, in the absence of comprehensive emissions reduction strategies.}
}