@article{CHIARELLO2024103002,
title = {Future applications of generative large language models: A data-driven case study on ChatGPT},
journal = {Technovation},
volume = {133},
pages = {103002},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103002},
url = {https://www.sciencedirect.com/science/article/pii/S016649722400052X},
author = {Filippo Chiarello and Vito Giordano and Irene Spada and Simone Barandoni and Gualtiero Fantoni},
keywords = {Generative artificial intelligence, Generative large language models, ChatGPT, Social media analysis, Technology adoption, Emerging technologies},
abstract = {This study delves into the evolving role of generative Large Language Models (LLMs). We develop a data-driven approach to collect and analyse tasks that users are asking to generative LLMs. Thanks to the focus on tasks this paper contributes to give a quantitative and granular understanding of the potential influence of LLMs in different business areas. Utilizing a dataset comprising over 3.8 million tweets, we identify and cluster 31,747 unique tasks, with a specific case study on ChatGPT. To reach this goal, the proposed method combines two Natural Language Processing (NLP) Techniques, Named Entity Recognition (NER) and BERTopic. The combination makes it possible to collect granular tasks of LLMs (NER) and clusters them in business areas (BERTopic). Our findings reveal a wide spectrum of applications, from programming assistance to creative content generation, highlighting LLM's versatility. The analysis highlighted six emerging areas of application for ChatGPT: human resources, programming, social media, office automation, search engines, education. The study also examines the implications of these findings for innovation management, proposing a research agenda to explore the intersection of the identified areas, with four stages of the innovation process: idea generation, screening/idea selection, development, and diffusion/sales/marketing.}
}
@article{LEISER2025,
title = {Large Language Model Architectures in Health Care: Scoping Review of Research Perspectives},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70315},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500843X},
author = {Florian Leiser and Richard Guse and Ali Sunyaev},
keywords = {large language models, scoping review, ChatGPT, generative artificial intelligence, digital health, medical informatics},
abstract = {Background
Large language models (LLMs) can support health care professionals in their daily work, for example, when writing and filing reports or communicating diagnoses. With the rise of LLMs, current research investigates how LLMs could be applied in medical practice and their benefits for physicians in clinical workflows. However, most studies neglect the importance of selecting suitable LLM architectures.
Objective
In this literature review, we aim to provide insights on the different LLM model architecture families (ie, Bidirectional Encoder Representations from Transformers [BERT]–based or generative pretrained transformer [GPT]–based models) used in previous research. We report on the suitability and benefits of different LLM model architecture families for various research foci.
Methods
To this end, we conduct a scoping review to identify which LLMs are used in health care. Our search included manuscripts from PubMed, arXiv, and medRxiv. We used open and selective coding to assess the 114 identified manuscripts regarding 11 dimensions related to usage and technical facets and the research focus of the manuscripts.
Results
We identified 4 research foci that emerged previously in manuscripts, with LLM performance being the main focus. We found that GPT-based models are used for communicative purposes such as examination preparation or patient interaction. In contrast, BERT-based models are used for medical tasks such as knowledge discovery and model improvements.
Conclusions
Our study suggests that GPT-based models are better suited for communicative purposes such as report generation or patient interaction. BERT-based models seem to be better suited for innovative applications such as classification or knowledge discovery. This could be due to the architectural differences where GPT processes language unidirectionally and BERT bidirectionally, allowing more in-depth understanding of the text. In addition, BERT-based models seem to allow more straightforward extensions of their models for domain-specific tasks that generally lead to better results. In summary, health care professionals should consider the benefits and differences of the LLM architecture families when selecting a suitable model for their intended purpose.}
}
@incollection{2026v,
title = {Contents},
editor = {Alex Khang},
booktitle = {Revolutionizing Digital Healthcare Through Artificial Intelligence and Automation},
publisher = {Academic Press},
pages = {v-xii},
year = {2026},
isbn = {978-0-443-36434-1},
doi = {https://doi.org/10.1016/B978-0-443-36434-1.00304-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443364341003049}
}
@article{DENG2025103275,
title = {ChatGPT is a comprehensive education tool for patients with patellar tendinopathy, but it currently lacks accuracy and readability},
journal = {Musculoskeletal Science and Practice},
volume = {76},
pages = {103275},
year = {2025},
issn = {2468-7812},
doi = {https://doi.org/10.1016/j.msksp.2025.103275},
url = {https://www.sciencedirect.com/science/article/pii/S2468781225000232},
author = {Jie Deng and Lun Li and Jelle J. Oosterhof and Peter Malliaras and Karin Grävare Silbernagel and Stephan J. Breda and Denise Eygendaal and Edwin HG. Oei and Robert-Jan {de Vos}},
keywords = {Self-management, Communication, Large language models, Patient education},
abstract = {Background
Generative artificial intelligence tools, such as ChatGPT, are becoming increasingly integrated into daily life, and patients might turn to this tool to seek medical information.
Objective
To evaluate the performance of ChatGPT-4 in responding to patient-centered queries for patellar tendinopathy (PT).
Methods
Forty-eight patient-centered queries were collected from online sources, PT patients, and experts and were then submitted to ChatGPT-4. Three board-certified experts independently assessed the accuracy and comprehensiveness of the responses. Readability was measured using the Flesch-Kincaid Grade Level (FKGL: higher scores indicate a higher grade reading level). The Patient Education Materials Assessment Tool (PEMAT) evaluated understandability, and actionability (0–100%, higher scores indicate information with clearer messages and more identifiable actions). Semantic Textual Similarity (STS score, 0–1; higher scores indicate higher similarity) assessed variation in the meaning of texts over two months (including ChatGPT-4o) and for different terminologies related to PT.
Results
Sixteen (33%) of the 48 responses were rated accurate, while 36 (75%) were rated comprehensive. Only 17% of treatment-related questions received accurate responses. Most responses were written at a college reading level (median and interquartile range [IQR] of FKGL score: 15.4 [14.4–16.6]). The median of PEMAT for understandability was 83% (IQR: 70%–92%), and for actionability, it was 60% (IQR: 40%–60%). The medians of STS scores in the meaning of texts over two months and across terminologies were all ≥ 0.9.
Conclusions
ChatGPT-4 provided generally comprehensive information in response to patient-centered queries but lacked accuracy and was difficult to read for individuals below a college reading level.}
}
@article{ASAD2024507,
title = {Impact of ChatGPT and generative AI on lifelong learning and upskilling learners in higher education: unveiling the challenges and opportunities globally},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {5},
pages = {507-523},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-06-2024-0103},
url = {https://www.sciencedirect.com/science/article/pii/S205648802400009X},
author = {Muhammad Mujtaba Asad and Aqsa Ajaz},
keywords = {ChatGPT, Generative AI, Lifelong learning, Competency-based personalized learning},
abstract = {Purpose
A gripping keyword emerged in the dynamic world of 2022: GPT or the advent of Generative Artificial Intelligence (GAI), at its forefront, embodied by the mysterious ChatGPT. This technological marvel had been silently lurking in the background for just over five years. However, all of a sudden, it emerged onto the scene, capturing the public’s attention and quickly becoming one of the most widely adopted inventions in history. Therefore, this narrative review is conducted in order to explore the impact of generative AI and ChatGPT on lifelong learning and upskilling of students in higher education and address opportunities and challenges proposed by Artificial Intelligence from a global perspective.
Design/methodology/approach
This review has been conducted using a narrative literature review approach. For in-depth identification of research gaps, 105 relevant articles were included from scholarly databases such as Scopus, Web of Science, ERIC and Google Scholar. Seven major themes emerged from the literature to answer the targeted research questions that describe the use of AI, the impact of generative AI and ChatGPT on students, the challenges and opportunities of using AI in education and mitigating strategies to cope with the challenges associated with the integration of ChatGPT and generative AI in education.
Findings
The review of the literature presents that generative AI and ChatGPT have gained a lot of recognition among students and have revolutionized educational settings. The findings suggest that there are some contexts in which adult education research and teaching can benefit from the use of chatbots and generative AI technologies like ChatGPT. The literature does, however, also highlight the necessity of carefully considering the benefits and drawbacks of these technologies in order to prevent restricting or distorting the educational process or endangering academic integrity. In addition, the literature raises ethical questions about data security, privacy and cheating by students or researchers. To these, we add our own ethical concerns about intellectual property, such as the fact that, once we enter ideas or research results into a generative chatbot, we no longer have control over how it is used.
Practical implications
This review is helpful for educators and policymakers to design the curriculum and policies that encourage students to use generative AI ethically while taking academic integrity into account. Also, this review article identifies the major gaps that are associated with the impact of AI and ChatGPT on the lifelong learning skills of students.
Originality/value
This review of the literature is unique because it explains the challenges and opportunities of using generative AI and ChatGPT, also defining its impact on lifelong learning and upskilling of students.}
}
@article{CARMALI2025103227,
title = {Magnetic sentinel node biopsy with Sienna+®/SentiMag® in penile squamous cell carcinoma: Case report},
journal = {Urology Case Reports},
volume = {63},
pages = {103227},
year = {2025},
issn = {2214-4420},
doi = {https://doi.org/10.1016/j.eucr.2025.103227},
url = {https://www.sciencedirect.com/science/article/pii/S2214442025002980},
author = {Diogo Carmali and Eduardo Felício and Sónia Afonso Ramos and António Pinheiro and Alberto Silva and Sara Duarte and Guilherme Bernardo and Filipe Gaboleiro and André Pita and Fernando Ferrito},
keywords = {Penile cancer, Sentinel lymph node biopsy, SentiMag, Sienna+, Magnetic tracer},
abstract = {Penile squamous cell carcinoma (SCC) is a rare malignancy where accurate nodal staging is essential for prognosis and management. Dynamic sentinel lymph node biopsy with radiotracers is the standard approach but requires nuclear medicine facilities and exposes patients to radiation. We report a 62-year-old man with penile SCC who underwent glansectomy with sentinel lymph node biopsy using Sienna+®/SentiMag® and methylene blue. Two sentinel nodes were identified, one exclusively by Sienna+®/SentiMag®. Both were negative for metastasis. This case supports the feasibility of magnetic tracers as a radiation-free alternative in penile cancer staging.}
}
@article{TAO2025112683,
title = {An outline of Prognostics and health management Large Model: Concepts, Paradigms, and challenges},
journal = {Mechanical Systems and Signal Processing},
volume = {232},
pages = {112683},
year = {2025},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2025.112683},
url = {https://www.sciencedirect.com/science/article/pii/S088832702500384X},
author = {Laifa Tao and Shangyu Li and Haifei Liu and Qixuan Huang and Liang Ma and Guoao Ning and Yiling Chen and Yunlong Wu and Bin Li and Weiwei Zhang and Zhengduo Zhao and Wenchao Zhan and Wenyan Cao and Chao Wang and Hongmei Liu and Jian Ma and Mingliang Suo and Yujie Cheng and Yu Ding and Dengwei Song and Chen Lu},
keywords = {Large model (LM), Large language model (LLM), Prognosis and health management (PHM), Fault diagnosis, Prediction, State assessment},
abstract = {Prognosis and Health Management (PHM), critical for preventing unexpected failures and ensuring task completion of complex systems, is widely adopted in the fields of aviation, aerospace, manufacturing, rail transportation, energy, etc. However, PHM’s developments and applications have been seriously constrained by bottlenecks like generalization, interpretation and verification abilities. Large Model (LM), a typical and powerful representation of generative artificial intelligence (AI), heralds a technological revolution with the potential to fundamentally reshape traditional technological fields. Its strong generalization and reasoning capabilities present opportunities to address those PHM’s bottlenecks existing. To this end, by systematically analyzing the current challenges and bottlenecks in PHM, as well as the advantages of Large Model, we propose a novel concept and corresponding three typical paradigms of PHM Large Model (PHM-LM) by the combination of the Large Model with PHM. Additionally, couples of feasible technical approaches for PHM-LM within the framework of the three paradigms are provided to address core issues confronting PHM and to bolster PHM’s core capabilities. Moreover, a series of technical challenges throughout the entire construction and application process of PHM-LM have been deeply discussed for further research recommendation. The comprehensive effort herein offers a comprehensive PHM-LM technical framework, and provides avenues for new methodologies, new technologies, new tools, new platforms and applications of PHM, which also potentially innovates design mode, research & development mode, verification and application mode of PHM, i.e., from traditional customization to generalization, from discriminative approaches to generative methods, and from idealized conditions to practical applications.}
}
@article{JIANG2025134548,
title = {Prompt engineering to inform large language model in automated building energy modeling},
journal = {Energy},
volume = {316},
pages = {134548},
year = {2025},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2025.134548},
url = {https://www.sciencedirect.com/science/article/pii/S0360544225001902},
author = {Gang Jiang and Zhihao Ma and Liang Zhang and Jianli Chen},
keywords = {Prompt engineering, Large language model, Building energy models, Automated building energy modeling, In-context learning, Generative artificial intelligence},
abstract = {Application of large language models (LLMs) to facilitate auto-building energy modeling (ABEM) is complex and resource-intensive. This paper presents practical guidelines for ABEM using prompt engineering with LLMs. Unlike training LLMs for ABEM with fine-tuning (involving model weight adjustment), prompt engineering is to provide specific prompts along with modeling descriptions and demonstrations, informing LLMs to automatically generate building energy models (BEMs) through natural language expression, and enabling users to perform ABEM without specialized building knowledge or software proficiency. In this study, the capabilities of prompt engineering for ABEM using LLMs are investigated. To achieve this, six types of prompts are designed, encompassing two exploratory tasks and one real-world task with a total of 648 case studies. The results from the case studies suggest that prompt engineering is feasible to automatically obtain the desired BEMs using one-shot learning (one demonstration), few-shot learning (few-demonstration), and chain-of-thought strategies (i.e., task explanation and division). Finally, the modeling comparison between the tested lightweighted LLMs with GPT-4o suggests that compact LLMs with an appropriate context window are suitable to be deployed for various building applications. The source codes for prompt engineering are available on GitHub (https://github.com/Gangjiang1/Prompting-for-Auto-building-Modeling.git).}
}
@article{CAI2023141,
title = {Performance of Generative Large Language Models on Ophthalmology Board–Style Questions},
journal = {American Journal of Ophthalmology},
volume = {254},
pages = {141-149},
year = {2023},
issn = {0002-9394},
doi = {https://doi.org/10.1016/j.ajo.2023.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0002939423002301},
author = {Louis Z. Cai and Abdulla Shaheen and Andrew Jin and Riya Fukui and Jonathan S. Yi and Nicolas Yannuzzi and Chrisfouad Alabiad},
abstract = {PURPOSE
To investigate the ability of generative artificial intelligence models to answer ophthalmology board–style questions.
DESIGN
Experimental study.
METHODS
This study evaluated 3 large language models (LLMs) with chat interfaces, Bing Chat (Microsoft) and ChatGPT 3.5 and 4.0 (OpenAI), using 250 questions from the Basic Science and Clinical Science Self-Assessment Program. Although ChatGPT is trained on information last updated in 2021, Bing Chat incorporates a more recently indexed internet search to generate its answers. Performance was compared with human respondents. Questions were categorized by complexity and patient care phase, and instances of information fabrication or nonlogical reasoning were documented.
MAIN OUTCOME MEASURES
Primary outcome was response accuracy. Secondary outcomes were performance in question subcategories and hallucination frequency.
RESULTS
Human respondents had an average accuracy of 72.2%. ChatGPT-3.5 scored the lowest (58.8%), whereas ChatGPT-4.0 (71.6%) and Bing Chat (71.2%) performed comparably. ChatGPT-4.0 excelled in workup-type questions (odds ratio [OR], 3.89, 95% CI, 1.19-14.73, P = .03) compared with diagnostic questions, but struggled with image interpretation (OR, 0.14, 95% CI, 0.05-0.33, P < .01) when compared with single-step reasoning questions. Against single-step questions, Bing Chat also faced difficulties with image interpretation (OR, 0.18, 95% CI, 0.08-0.44, P < .01) and multi-step reasoning (OR, 0.30, 95% CI, 0.11-0.84, P = .02). ChatGPT-3.5 had the highest rate of hallucinations and nonlogical reasoning (42.4%), followed by ChatGPT-4.0 (18.0%) and Bing Chat (25.6%).
CONCLUSIONS
LLMs (particularly ChatGPT-4.0 and Bing Chat) can perform similarly with human respondents answering questions from the Basic Science and Clinical Science Self-Assessment Program. The frequency of hallucinations and nonlogical reasoning suggests room for improvement in the performance of conversational agents in the medical domain.}
}
@article{JIANG2024105286,
title = {Automated site planning using CAIN-GAN model},
journal = {Automation in Construction},
volume = {159},
pages = {105286},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105286},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524000220},
author = {Feifeng Jiang and Jun Ma and Christopher John Webster and Wei Wang and Jack C.P. Cheng},
keywords = {Automated site planning, Generative design, Generative adversarial networks (GAN), Attention mechanism, Generative artificial intelligence (generative AI), Planning guidance},
abstract = {Automated site planning, powered by deep generative methods, excels in creating solutions responsive to exiting city structures but often overlooks user-specific design scenarios, leading to less performative solutions across varied urban contexts. Overcoming this challenge requires integrating domain knowledge and nuances of the built environment to enhance context-awareness in automated site planning. This study therefore proposes the context-aware site planning generative adversarial networks (CAIN-GAN) framework. In the case study of New York City (NYC), CAIN-GAN demonstrates its capability to not only synthesize visually realistic and semantically reasonable design solutions, but also evaluate their performance in urban sustainability for informed decision-making. This context-aware, learning-based, data-driven, and user-guided generation process signifies a pivotal advancement in more performative and tailored design solutions. Future studies will focus on refining the CAIN-GAN framework to accommodate diverse user-centric design needs and enhance human-machine interaction in urban development.}
}
@article{KESSEL2024111971,
title = {Promoting open science in test-driven software experiments},
journal = {Journal of Systems and Software},
volume = {212},
pages = {111971},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.111971},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224000141},
author = {Marcus Kessel and Colin Atkinson},
keywords = {Software, Engineering, Empirical, Experimentation, Observation, Behavior, Reproducibility, Replication, Data structures, Open science, Large language models, Machine learning, Generative artificial intelligence, Benchmark, Language-to-code, HumanEval, Automation, Measurement},
abstract = {A core principle of open science is the clear, concise and accessible publication of empirical data, including “raw” observational data as well as processed results. However, in empirical software engineering there are no established standards (de jure or de facto) for representing and “opening” observations collected in test-driven software experiments — that is, experiments involving the execution of software subjects in controlled scenarios. Execution data is therefore usually represented in ad hoc ways, often making it abstruse and difficult to access without significant manual effort. In this paper we present new data structures designed to address this problem by clearly defining, correlating and representing the stimuli and responses used to execute software subjects in test-driven experiments. To demonstrate their utility, we show how they can be used to promote the repetition, replication and reproduction of experimental evaluations of AI-based code completion tools. We also show how the proposed data structures facilitate the incremental expansion of execution data sets, and thus promote their repurposing for new experiments addressing new research questions.}
}
@article{AHMED2026103527,
title = {From data to diagnosis: AI-driven multi-modal fusion and generative AI-enhanced GAN-based MRI for brain tumour detection},
journal = {Information Fusion},
volume = {126},
pages = {103527},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103527},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525005998},
author = {Imran Ahmed and Misbah Ahmad and Abdellah Chehri and Gwanggil Jeon},
keywords = {Brain tumour, Generative artificial intelligence, Generative Adversarial Networks (GANs), Self-supervised learning (SSL), Synthetic medical images},
abstract = {Brain tumour is one of the most significant challenges in medical imaging, where early and accurate detection is crucial for improving patient outcomes. However, the lack of labelled Magnetic Resonance Imaging (MRI) data severely limits the development of reliable diagnostic methods, resulting in issues such as class imbalance and reduced accuracy. This study addresses these challenges by leveraging Self-Supervised Learning (SSL) and Generative Adversarial Networks (GANs) to generate synthetic MRI images. We present a dual-enhancement pipeline with domain-specific innovations, combining contrastive SSL pretraining with GAN-augmented data to improve brain tumour classification. Our GAN architecture features medical-specific normalization layers, tumour-focused conditioning, and loss stabilization techniques to enhance the quality of synthesis. The SSL component employs domain-adapted, tumour-preserving augmentations and tailored pretext tasks (e.g., spatial context prediction) to ensure semantically meaningful representations. Experimental results demonstrate the effectiveness of the proposed approach, showing an improvement in diagnostic precision. Additionally, the Fréchet Inception Distance (FID) score indicates that the synthetic images exhibit a high degree of similarity to real MRI scans. These findings highlight the transformative potential of SSL techniques in mitigating the limitations associated with the lack of labelled medical data. Furthermore, the integration of Generative AI (GenAI) within multi-source (rather than multimodal) data fusion frameworks represents a significant advancement in medical imaging. By synthesizing and harmonizing diverse data sources, GenAI enhances information aggregation, which is particularly valuable in healthcare applications. Case studies and practical implementations demonstrate how GenAI-powered fusion methods enhance diagnostic accuracy; support improved patient monitoring, facilitate timely interventions, and enable more effective clinical decision-making. To support clinical integration, we incorporate explainable AI (XAI) methods to ensure transparency and interpretability, enabling rapid and informed decision-making in brain tumour detection. This research positions SSL and GenAI not merely as engineering tools but as essential enablers of data-efficient and precision-driven healthcare.}
}
@incollection{GONZALEZANTA2026346,
title = {Digitalization},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {346-352},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00069-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013000694},
author = {Baltasar González-Anta},
keywords = {AIlization, AI-lization, AIzation, Artificial intelligence (AI), Automation, Digital competences, Digital transformation, Digitalization, Digitalized competences, Digitization, Fourth industrial revolution., Knowledge economy, Remote work, Robotization, Telework},
abstract = {Digitalization is transforming society and organizations in the knowledge economy. This chapter provides a comprehensive overview of digitalization and related concepts in Business Management. We first define key terms such as digitalization, digitization, digital transformation, and mention specific contexts in which digitalization can be implemented. We then adopt a sociotechnical approach to analyze opportunities and challenges of digitalization, considering organizational adaptability and work competences as central elements. In particular, we highlight the growing relevance of digital and digitalized competences to leverage technology while mitigating potential negative outcomes. Looking ahead, we reflect on the impact of Generative AI and the “AI-lization”, and how this can augment yet also potentially displace human capabilities. We conclude by summarizing key insights and identifying areas for future research on sustainable digitalization that promotes synergistic human-technology collaboration. The chapter offers an integrative analysis of technological and social factors to advance the understanding of digitalization in contemporary business.}
}
@article{ESCOLAGASCON2025106430,
title = {Beyond the brain: a computational MRI-derived neurophysiological framework for robotic conscious capacity},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {179},
pages = {106430},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2025.106430},
url = {https://www.sciencedirect.com/science/article/pii/S0149763425004312},
author = {Álex Escolà-Gascón and Kenneth Drinkwater and Andrew Denovan and Neil Dagnall and Julián Benito-León},
keywords = {Attribution Consciousness Index, Disorders of consciousness, Generative artificial intelligence, Anesthesia monitoring, Robotic consciousness},
abstract = {Explaining when neural activity supports conscious processing remains an unresolved question in neuroscience. Current frameworks describe correlates of consciousness but rarely provide thresholds to predict its emergence or recovery. We introduce the Attribution Consciousness Index (ACI), a metric that estimates the generative potential of consciousness by balancing measures of dynamic information (Φ) and complexity (κ) expressed as a normalized odds ratio. Using the empirically validated Connectome-76 within The Virtual Brain, we ran 500 resting-state simulations, selecting lowest-entropy regions to capture informative subnetworks. The ACI followed a log-normal distribution and highlighted hubs—cingulate cortex, dorsomedial prefrontal cortex, hippocampus, and amygdala—implicated in conscious processing. To test generality, we extended the framework to an artificial neural architecture with hierarchical modules, nonlinear Hebbian plasticity, and controlled entropy. Across 1921 executions, the ACI conformed to log-normal laws, enabling robust thresholding. Kernel ridge regression showed predictive validity: AI-derived ACI patterns explained 38.4 % of variance in human ACI distributions, revealing transferable principles between biological and artificial circuits. This extension indicates that ACI can guide artificial-consciousness models implementable in robotics, providing measurable criteria for when robotic systems might sustain conscious-like states. Two contributions are novel. First, ACI thresholds provide interpretable decision points: values above 10 correspond to probabilities greater than 90 % for conscious emergence. Second, the framework offers translational applications—from prognosis in disorders of consciousness, anesthesia monitoring, and neurorehabilitation to evaluating neuroprosthetics, generative AI, and robotics with conscious capacities. While ACI does not measure subjective experience, it predicts when neural or artificial conditions are poised to sustain it.}
}
@article{CHAN2024101395,
title = {Will generative AI replace teachers in higher education? A study of teacher and student perceptions},
journal = {Studies in Educational Evaluation},
volume = {83},
pages = {101395},
year = {2024},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2024.101395},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X24000749},
author = {Cecilia Ka Yuk Chan and Louisa H.Y. Tsi},
keywords = {ChatGPT, Generative AI, AI Literacy, Social-emotional competencies, Holistic competencies},
abstract = {This paper evaluates the potential of generative artificial intelligence (AI) in higher education, specifically its capacity to replace or assist human teachers. By reviewing relevant literature and analysing survey data from students and teachers, this mixed-methods study provides a comprehensive perspective on the future role of educators in the face of advancing generative AI technologies. An online survey was conducted to explore the perceptions of 399 university students and 184 teachers across different disciplines in eight higher education institutions in Hong Kong concerning the use of generative AI technologies. Findings suggest that although some believed generative AI may eventually replace teachers, the majority of participants argued that human teachers possess unique qualities, including critical thinking and emotions, which make them irreplaceable. Similarly, findings also emphasized the importance of social-emotional competencies developed through human interactions, something which generative AI technologies cannot currently replicate. Crucially, this study further found that students value and respect their human teachers, even as generative AI becomes more prevalent. As such, the authors propose that teachers can seek to effectively integrate generative AI to enhance teaching and learning without viewing it as their replacement. To do so, they must understand how generative AI can work well with teachers and students, avoid potential pitfalls, develop AI literacy, and address practical issues including ethics and privacy. Recommendations are offered on how universities, teachers, and students can adopt generative AI technologies in an approach that balances the strengths of human educators with generative AI technologies. As the future of education lies in the synergy between human teachers and generative AI, teachers, students, and universities should all understand and refine their unique qualities in order to effectively navigate the integration of generative AI, ensuring well-rounded and impactful learning experiences.}
}
@article{ARSLAN2025174,
title = {Evaluating LLM-based generative AI tools in emergency triage: A comparative study of ChatGPT Plus, Copilot Pro, and triage nurses},
journal = {The American Journal of Emergency Medicine},
volume = {89},
pages = {174-181},
year = {2025},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2024.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S0735675724007071},
author = {B. Arslan and C. Nuhoglu and M.O. Satici and E. Altinbilek},
keywords = {ChatGPT, Copilot, Triage, Emergency medicine, Emergency severity index, Large language models, Generative artificial intelligence},
abstract = {Background
The number of emergency department (ED) visits has been on steady increase globally. Artificial Intelligence (AI) technologies, including Large Language Model (LLMs)-based generative AI models, have shown promise in improving triage accuracy. This study evaluates the performance of ChatGPT and Copilot in triage at a high-volume urban hospital, hypothesizing that these tools can match trained physicians' accuracy and reduce human bias amidst ED crowding challenges.
Methods
This single-center, prospective observational study was conducted in an urban ED over one week. Adult patients were enrolled through random 24-h intervals. Exclusions included minors, trauma cases, and incomplete data. Triage nurses assessed patients while an emergency medicine (EM) physician documented clinical vignettes and assigned emergency severity index (ESI) levels. These vignettes were then introduced to ChatGPT and Copilot for comparison with the triage nurse's decision.
Results
The overall triage accuracy was 65.2 % for nurses, 66.5 % for ChatGPT, and 61.8 % for Copilot, with no significant difference (p = 0.000). Moderate agreement was observed between the EM physician and ChatGPT, triage nurses, and Copilot (Cohen's Kappa = 0.537, 0.477, and 0.472, respectively). In recognizing high-acuity patients, ChatGPT and Copilot outperformed triage nurses (87.8 % and 85.7 % versus 32.7 %, respectively). Compared to ChatGPT and Copilot, nurses significantly under-triaged patients (p < 0.05). The analysis of predictive performance for ChatGPT, Copilot, and triage nurses demonstrated varying discrimination abilities across ESI levels, all of which were statistically significant (p < 0.05). ChatGPT and Copilot exhibited consistent accuracy across age, gender, and admission time, whereas triage nurses were more likely to mistriage patients under 45 years old.
Conclusion
ChatGPT and Copilot outperform traditional nurse triage in identifying high-acuity patients, but real-time ED capacity data is crucial to prevent overcrowding and ensure high-quality of emergency care.}
}
@article{SHIN2025111393,
title = {Subthalamic nucleus or globus pallidus internus deep brain stimulation for the treatment of parkinson’s disease: An artificial intelligence approach},
journal = {Journal of Clinical Neuroscience},
volume = {138},
pages = {111393},
year = {2025},
issn = {0967-5868},
doi = {https://doi.org/10.1016/j.jocn.2025.111393},
url = {https://www.sciencedirect.com/science/article/pii/S0967586825003662},
author = {David Shin and Timothy Tang and Joel Carson and Rekha Isaac and Chandler Dinh and Daniel Im and Andrew Fay and Asael Isaac and Stephen Cho and Zachary Brandt and Kai Nguyen and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Samantha Spellicy and Miguel Angel Lopez-Gonzalez and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Deep brain stimulation, Neurosurgery, Parkinson’s disease},
abstract = {Background
Generative artificial intelligence (AI) in deep brain stimulation (DBS) is currently unvalidated in its content. This study sought to analyze AI responses to questions and recommendations from the 2018 Congress of Neurological Surgeons (CNS) guidelines on subthalamic nucleus and globus pallidus internus DBS for the treatment of patients with Parkinson’s Disease.
Methods
Seven questions were generated from CNS guidelines and asked to ChatGPT 4o, Perplexity, Copilot, and Gemini. Answers were “concordant” if they highlighted all points provided by the CNS guidelines; otherwise, answers were considered “non-concordant” and sub-categorized as either “insufficient” or “overconclusive.” AI responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, Simple Measure of Gobbledygook (SMOG) Index, and Flesch Reading Ease tests.
Results
ChatGPT 4o showcased 42.9% concordance, with non-concordant responses classified as 14.3% insufficient and 42.8% over-conclusive. Perplexity displayed a 28.6% concordance rate, with 14.3% insufficient and 57.1% over-conclusive responses. Copilot showed 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. Gemini demonstrated 28.6% concordance, with 28.6% insufficient and 42.8% over-conclusive responses. The Flesch-Kincaid Grade Level scores ranged from 14.44 (Gemini) to 18.94 (Copilot), Gunning Fog Index scores varied between 17.9 (Gemini) and 22.06 (Copilot), SMOG Index scores ranged from 16.54 (Gemini) to 19.67 (Copilot), and all Flesch Reading Ease scores were low, with Gemini showing the highest score of 30.91.
Conclusion
ChatGPT 4o displayed the most concordance, Perplexity displayed the highest over-conclusive rate, and Copilot and Gemini showcased the most insufficient answers. All responses showcased complex readability. Despite the possible benefits of future developments and innovation in AI capabilities, AI requires further improvement before independent clinical usage in DBS.}
}
@article{LI2026103665,
title = {SearchExpert: A GenAI-driven framework for reasoning-intensive multimedia information fusion through fine-tuning and reinforcement learning},
journal = {Information Fusion},
volume = {126},
pages = {103665},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103665},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525007377},
author = {Jinzheng Li and Yiqing Shen and Wei Zhou and Hui Chen},
keywords = {Large language models, Complex reasoning, Multimodal search, Reinforcement learning, DAG planning, Vision-language models},
abstract = {The rapid advancement of Generative Artificial Intelligence (GenAI) has opened new frontiers in multimodal information fusion, yet current large language model (LLM)-driven search agents remain limited in their ability to handle reasoning-intensive queries and integrate multimedia data effectively. In this paper, we propose SearchExpert, a GenAI-enhanced framework that augments LLMs with powerful multimedia search and reasoning capabilities via a novel two-stage training paradigm. First, we introduce an efficient natural language representation for directed acyclic graph (DAG)-based search plans to reduce token overhead and support structured reasoning. We then propose Supervised Fine-Tuning for Searching (SFTS), enabled by an automated data construction pipeline that adapts LLMs to generate token-efficient, structured search plans from complex queries. Second, to further enhance reasoning ability, we introduce Reinforcement Learning from Search Feedback (RLSF), which uses reward signals based on semantic alignment and intrinsic quality assessments of retrieved results to optimize LLM behavior. To address the limitations of unimodal input and output, we integrate a multimedia understanding and generation module based on vision-language models and image synthesis tools (e.g., BLIP-2, and DALLE-3), enabling the GenAI-based fusion of text and visual data. We also establish SearchExpertBench-25, a benchmark comprising 200 multimedia-rich, reasoning-intensive queries spanning financial and global news domains, accompanied by a rigorous human evaluation framework. Experimental results demonstrate that SearchExpert surpasses state-of-the-art baselines such as FinSearch and Perplexity Pro, achieving up to 71.5% accuracy on complex benchmark tasks while reducing token consumption by over 40%. Human evaluations further highlight improvements in completeness, analytical integrity, and multimodal fluency. This work presents a scalable and generalizable GenAI framework for information fusion, with implications for real-time decision-making in complex, multi-source environments. The code is available at https://anonymous.4open.science/r/SearchExpert-2343/.}
}
@article{MGADZAH2025,
title = {Enhancing Diagnostic Accuracy of Ophthalmological Conditions With Complex Prompts in GPT-4: Comparative Analysis of Global and Low- and Middle-Income Country (LMIC)–Specific Pathologies},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/64986},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25004445},
author = {Shona Alex Tapiwa M'gadzah and Andrew O'Malley},
keywords = {artificial intelligence, AI, ophthalmology, clinical diagnostics, medical technology, data project, complex prompt, diagnostic accuracy, ophthalmological conditions, ophthalmological disorder, eyes, blindness, low- and middle-income countries, LMIC, low-income or middle-income economies, health care, LLMs, NLP, machine learning, statistical analysis, GPT-4},
abstract = {Background
The global incidence of blindness has continued to increase, despite the enactment of a Global Eye Health Action Plan by the World Health Assembly. This can be attributed, in part, to an aging population, but also to the limited diagnostic resources within low- and middle-income countries (LMICs). The advent of generative artificial intelligence (AI) within health care could pose a novel solution to combating the prevalence of blindness globally.
Objective
The objectives of this study are to quantify the effect the addition of a complex prompt has on the diagnostic accuracy of a commercially available LLM, and to assess whether such LLMs are better or worse at diagnosing conditions that are more prevalent in LMICs.
Methods
Ten clinical vignettes representing globally and LMIC-prevalent ophthalmological conditions were presented to GPT-4‐0125-preview using simple and complex prompts. Diagnostic performance metrics, including sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were calculated. Statistical comparison between prompts was conducted using a chi-square test of independence.
Results
The complex prompt achieved a higher diagnostic accuracy (90.1%) compared to the simple prompt (60.4%), with a statistically significant difference (χ2=428.86; P<.001). Sensitivity, specificity, PPV, and NPV were consistently improved for most conditions with the complex prompt. The simple prompt struggled with LMIC-prevalent conditions, diagnosing only 1 of 5 accurately, while the complex prompt successfully diagnosed 4 of 5.
Conclusions
The study established that overall, the inclusion of a complex prompt positively affected the diagnostic accuracy of GPT-4‐0125-preview, particularly for LMIC-prevalent conditions. This highlights the potential for LLMs, when appropriately tailored, to support clinicians in diverse health care settings. Future research should explore the generalizability of these findings across other models and specialties.}
}
@article{CRAWFORD2024504,
title = {Digital Ink and Surgical Dreams: Perceptions of Artificial Intelligence–Generated Essays in Residency Applications},
journal = {Journal of Surgical Research},
volume = {301},
pages = {504-511},
year = {2024},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S002248042400355X},
author = {Loralai M. Crawford and Peter Hendzlik and Justine Lam and Lisa M. Cannon and Yanjie Qi and Lauren DeCaporale-Ryan and Nicole A. Wilson},
keywords = {Ethics, Generative artificial intelligence, Large language model, Surgical education},
abstract = {Introduction
Large language models like Chat Generative Pre-Trained Transformer (ChatGPT) are increasingly used in academic writing. Faculty may consider use of artificial intelligence (AI)–generated responses a form of cheating. We sought to determine whether general surgery residency faculty could detect AI versus human-written responses to a text prompt; hypothesizing that faculty would not be able to reliably differentiate AI versus human-written responses.
Methods
Ten essays were generated using a text prompt, “Tell us in 1-2 paragraphs why you are considering the University of Rochester for General Surgery residency” (Current trainees: n = 5, ChatGPT: n = 5). Ten blinded faculty reviewers rated essays (ten-point Likert scale) on the following criteria: desire to interview, relevance to the general surgery residency, overall impression, and AI- or human-generated; with scores and identification error rates compared between the groups.
Results
There were no differences between groups for %total points (ChatGPT 66.0 ± 13.5%, human 70.0 ± 23.0%, P = 0.508) or identification error rates (ChatGPT 40.0 ± 35.0%, human 20.0 ± 30.0%, P = 0.175). Except for one, all essays were identified incorrectly by at least two reviewers. Essays identified as human-generated received higher overall impression scores (area under the curve: 0.82 ± 0.04, P < 0.01).
Conclusions
Whether use of AI tools for academic purposes should constitute academic dishonesty is controversial. We demonstrate that human and AI-generated essays are similar in quality, but there is bias against presumed AI-generated essays. Faculty are not able to reliably differentiate human from AI-generated essays, thus bias may be misdirected. AI-tools are becoming ubiquitous and their use is not easily detected. Faculty must expect these tools to play increasing roles in medical education.}
}
@article{DONG2025110789,
title = {Can GPT-4 provide human-level emotion support? Insights from machine learning-based evaluation framework},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110789},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110789},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525011400},
author = {Wanghao Dong and Weijun Wang and Xinheng Han and Junhao Huang and Lie Li and Yinghui Huang},
keywords = {Emotional support, GPT-4, Prompt engineering, Explainable machine learning, Large language models},
abstract = {The global shortage of mental health services has sparked considerable interest in leveraging generative artificial intelligence (AI) to address psychological health challenges. This study systematically evaluates the emotional support capabilities of GPT-4 and explores ways to enhance its performance through targeted prompt engineering. Initially, natural language processing and explainable machine learning were employed to develop a predictive model for evaluating the empathy of GPT-4’s responses. Feature sensitivity analysis identified key linguistic features that significantly influence empathy performance. These insights were then integrated with empathy component theory and helping skills theory to design prompt engineering to enhance GPT-4’s emotional support capabilities. Evaluation results show that while unprompted GPT-4 demonstrates substantial empathy in addressing help-seekers’ needs, it still lags behind human counselors. However, when guided by targeted prompts, GPT-4’s emotional support capabilities improve markedly compared to its zero-prompt version. Notably, in handling emotional issues such as anger, fear, and disgust, prompted GPT-4 performs at a level comparable to human counselors. In summary, this study provides initial evidence of GPT-4’s potential in emotional support and introduces an evaluation framework (initial-Evaluation, Enhancement, and re-Evaluation; EEE) that can be used to assess and optimize LLMs' abilities in mental health applications, offering insights into their role in supporting human mental health services.}
}
@article{PAN2026105474,
title = {Self-regulation plus individual interests? A design-based study on the development of a GenAI-empowered platform for self-directed out-of-class reading},
journal = {Computers & Education},
volume = {241},
pages = {105474},
year = {2026},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105474},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002428},
author = {Mengru Pan and Chun Lai and Kai Guo and Jing Huang},
keywords = {Self-directed learning, Self-regulated learning, Out-of-class reading, Design-based research, Artificial intelligence},
abstract = {Self-directed out-of-class reading contributes to language and general learning, yet many learners struggle with it and need support. Generative Artificial Intelligence (GenAI) holds the potential to provide personalized support that can facilitate self-directed out-of-class reading. This study adopted a design-based research (DBR) methodology to unravel the effective design of GenAI-empowered self-directed out-of-class reading by comparing different ways of integrating a ChatGPT chatbot into an online reading platform in supporting the provision of reading texts and delivering self-regulated learning (SRL) support. The DBR study included three cycles: a conventional approach in Cycle 0 (i.e., a preset pool of reading materials plus human-delivered SRL training), a chatbot-empowered personalized SRL platform in Cycle 1 (i.e., GenAI-recommended reading materials and chatbot-supported personalized SRL training), and a chatbot-empowered interest-based reading with personalized SRL platform in Cycle 2 (i.e., GenAI-recommended interest-based reading materials and chatbot-supported personalized SRL training). This DBR study lasted three semesters, involving one hundred and sixteen English as a foreign language (EFL) students from three classes at a university in China. Qualitative data from open-ended surveys and interviews after each cycle were used to refine the platform design in the subsequent cycle. Quantitative data, including pre- and post-surveys on self-regulated reading strategy use and self-directed reading, along with log data, were analyzed to compare the effects of the platform design on students' self-regulated strategy use and self-directed reading across three cycles. The results indicated that the chatbot-empowered interest-based reading with personalized SRL training showed the greatest potential in enhancing students’ self-regulated reading strategy use and self-directed reading. This study contributes to the existing literature by elucidating the design principles that enhance self-directed out-of-class reading.}
}
@article{CHEN2025112891,
title = {Can large language models replace human experts? Effectiveness and limitations in building energy retrofit challenges assessment},
journal = {Building and Environment},
volume = {276},
pages = {112891},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112891},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325003737},
author = {Linyan Chen and Amos Darko and Fan Zhang and Albert P.C. Chan and Qiang Yang},
keywords = {Large language model, Building energy retrofit, Challenges assessment, Prompt engineering, Generative artificial intelligence},
abstract = {Retrofitting existing buildings is essential to improve energy efficiency and achieve carbon neutrality in the fight against global climate change. Large language models (LLMs) have recently attracted significant attention for their ability to process data efficiently. While LLMs have emerged as useful tools for various tasks, their potential to replace human experts in assessing building energy retrofit challenges remains unexplored. This research explores the potential of replacing human experts with LLMs by evaluating four mainstream LLM chatbots and comparing their performance against a human expert benchmark through semantic similarity and text correlation metrics. It answers the research question: can LLMs replace human experts in assessing the challenges to building energy retrofits? Prompt engineering techniques, including zero-shot and chain-of-thought (CoT) prompting, were employed to guide LLM responses. Results show that LLMs perform well in identifying challenges but are less reliable in ranking them. CoT prompting improves challenge ranking accuracy but does not enhance challenge identification. Incorporating domain-specific knowledge in prompts significantly enhances LLM performance, whereas prompts designed to simulate experts have notable limitations in improving LLM performance. Furthermore, there are no significant performance differences among LLMs, including their advanced versions. While LLMs can streamline the initial identification of building energy retrofit challenges, they cannot fully replace expert judgment in ranking challenges due to their lack of tacit knowledge. This research provides valuable insight into the capabilities and limitations of LLMs in the challenge assessment, offering practical guidance for industry practitioners seeking to integrate LLMs into their building energy efficiency practices.}
}
@article{AYOUB2024186,
title = {Inherent Bias in Large Language Models: A Random Sampling Analysis},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {2},
number = {2},
pages = {186-191},
year = {2024},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2024.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949761224000208},
author = {Noel F. Ayoub and Karthik Balakrishnan and Marc S. Ayoub and Thomas F. Barrett and Abel P. David and Stacey T. Gray},
abstract = {There are mounting concerns regarding inherent bias, safety, and tendency toward misinformation of large language models (LLMs), which could have significant implications in health care. This study sought to determine whether generative artificial intelligence (AI)-based simulations of physicians making life-and-death decisions in a resource-scarce environment would demonstrate bias. Thirteen questions were developed that simulated physicians treating patients in resource-limited environments. Through a random sampling of simulated physicians using OpenAI’s generative pretrained transformer (GPT-4), physicians were tasked with choosing only 1 patient to save owing to limited resources. This simulation was repeated 1000 times per question, representing 1000 unique physicians and patients each. Patients and physicians spanned a variety of demographic characteristics. All patients had similar a priori likelihood of surviving the acute illness. Overall, simulated physicians consistently demonstrated racial, gender, age, political affiliation, and sexual orientation bias in clinical decision-making. Across all demographic characteristics, physicians most frequently favored patients with similar demographic characteristics as themselves, with most pairwise comparisons showing statistical significance (P<.05). Nondescript physicians favored White, male, and young demographic characteristics. The male doctor gravitated toward the male, White, and young, whereas the female doctor typically preferred female, young, and White patients. In addition to saving patients with their own political affiliation, Democratic physicians favored Black and female patients, whereas Republicans preferred White and male demographic characteristics. Heterosexual and gay/lesbian physicians frequently saved patients of similar sexual orientation. Overall, publicly available chatbot LLMs demonstrate significant biases, which may negatively impact patient outcomes if used to support clinical care decisions without appropriate precautions.}
}
@article{JIANG2025105365,
title = {A hybrid framework for regional land valuation using generative intelligence and AutoML techniques},
journal = {Landscape and Urban Planning},
volume = {259},
pages = {105365},
year = {2025},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2025.105365},
url = {https://www.sciencedirect.com/science/article/pii/S0169204625000726},
author = {Feifeng Jiang and Jun Ma},
keywords = {Regional land value, Land price, Deep learning, Generative artificial intelligence (generative AI), Sustainable urban development},
abstract = {Land value is a crucial indicator of economic dynamics and regional development, providing essential information for urban planning and policy development. However, most existing studies estimate a singular land value over large areas, lacking the fine-grained details for urban management. This study therefore develops a RAHGV (relative-to-absolute hybrid generative valuation) framework for regional land valuation, which combines a hybrid learning strategy with deep generative modeling to produce high-resolution, spatially continuous land value distribution across extensive urban areas. In a case study of New York City (NYC), the RAHGV model outperforms typical one-step models by differentiating between local land variations and broader regional tendencies. Its bi-attention bottleneck significantly improves model performance, reducing MAE (Mean Absolute Error) by 45.75% and MSE (Mean Squared Error) by 69.86% compared to conventional deep generative methods. Local physical infrastructure and mixed land-use patterns primarily influence micro-scale land values, while community amenities and economic vibrancy drive macro-scale values. The findings highlight the potential of the RAHGV framework as a powerful tool for promoting sustainable urban development by delivering high-resolution, data-driven insights that support informed decision-making in rapidly evolving urban environments.}
}
@article{MATHIS2024108356,
title = {Inductive thematic analysis of healthcare qualitative interviews using open-source large language models: How does it compare to traditional methods?},
journal = {Computer Methods and Programs in Biomedicine},
volume = {255},
pages = {108356},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108356},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003493},
author = {Walter S Mathis and Sophia Zhao and Nicholas Pratt and Jeremy Weleff and Stefano {De Paoli}},
keywords = {Artificial intelligence, Large language models, Qualitative methods, Thematic analysis, Mental health},
abstract = {Background
Large language models (LLMs) are generative artificial intelligence that have ignited much interest and discussion about their utility in clinical and research settings. Despite this interest there is sparse analysis of their use in qualitative thematic analysis comparing their current ability to that of human coding and analysis. In addition, there has been no published analysis of their use in real-world, protected health information.
Objective
Here we fill that gap in the literature by comparing an LLM to standard human thematic analysis in real-world, semi-structured interviews of both patients and clinicians within a psychiatric setting.
Methods
Using a 70 billion parameter open-source LLM running on local hardware and advanced prompt engineering techniques, we produced themes that summarized a full corpus of interviews in minutes. Subsequently we used three different evaluation methods for quantifying similarity between themes produced by the LLM and those produced by humans.
Results
These revealed similarities ranging from moderate to substantial (Jaccard similarity coefficients 0.44–0.69), which are promising preliminary results.
Conclusion
Our study demonstrates that open-source LLMs can effectively generate robust themes from qualitative data, achieving substantial similarity to human-generated themes. The validation of LLMs in thematic analysis, coupled with evaluation methodologies, highlights their potential to enhance and democratize qualitative research across diverse fields.}
}
@article{GERMANMORALES2025103247,
title = {Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations},
journal = {Information Fusion},
volume = {123},
pages = {103247},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103247},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525003203},
author = {M. Germán-Morales and A.J. Rivera-Rivas and M.J. {del Jesus Díaz} and C.J. Carmona},
keywords = {Time series forecasting, Transfer Learning, Foundational Models, Large Language Models, Low-rank Adaptations},
abstract = {Foundational Models are an emerging widely used technique of Generative Artificial Intelligence. These models are distinguished by their scalability and the ease with which they can be adapted through the exploitation of Transfer Learning. The availability of high computational power and large datasets have supported their development, achieving a high generalization capacity due to the enormous and heterogeneous amounts of data used in their initial training. These characteristics contribute to a solid base that can be adapted or adjusted to a wide range of tasks, increasing their applicability. This study proposes the methodology LLIAM, a straightforward adaptation of a kind of Foundational Models, Large Language Models, for the Time Series Forecasting task. An adequate time-series prompting schema and Low-Rank Adaptations are used to enhance the knowledge of the model with diverse time series datasets, known as the fine-tuning phase. A study divided in two stages has been performed for evaluating the effectiveness of the proposed methodology. Initially, a comparison was made between the performance of LLIAM and different state-of-the-art Deep Learning algorithms, including Recurrent Neural Networks and Temporal Convolutional Networks, as well as a LLM-based method, TimeLLM. Following this, a zero-shot study is presented in order to evaluate the generalization capacity of the proposed methodology with time series datasets from unknown domains not considered in the model training. The outcomes of this investigation demonstrate the efficacy of LLIAM, highlighting that this straightforward and general approach can attain competent results without the necessity for applying complex modifications. This work also encourages the use of available resources (such as these pre-trained models) and efficient fine-tuning techniques to avoid unnecessary and costly training, narrowing the gap between the goals of traditional Artificial Intelligence and Green Artificial Intelligence.}
}
@article{DENG2025110123,
title = {Weed image augmentation by ControlNet-added stable diffusion for multi-class weed detection},
journal = {Computers and Electronics in Agriculture},
volume = {232},
pages = {110123},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110123},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925002297},
author = {Boyang Deng and Yuzhen Lu},
keywords = {Deep Learning, Generative Modeling, Stable Diffusion, Precision Agriculture, Weed Detection},
abstract = {Robust weed recognition for vision-guided weeding relies on curating large-scale, diverse field datasets, which however are practically difficult to come by. Text-to-image generative artificial intelligence opens new avenues for synthesizing perceptually realistic images beneficial for wide-ranging computer vision tasks in precision agriculture. This study investigates the efficacy of state-of-the-art diffusion models as an image augmentation technique for synthesizing multi-class weed images towards enhanced weed detection performance. A three-season 10-weed-class dataset was created as a testbed for image generation and weed detection tasks. The ControlNet-added stable diffusion models were trained to generate weed images with broad intra-class variations of targeted weed species and diverse backgrounds to adapt to changing field conditions. The quality of generated images was assessed using metrics including the Fréchet Inception Distance (FID) and Inception Score (IS), resulting in an average FID of 0.98 and IS of 3.63. The generated weed images were selected to supplement real-world images for weed detection by YOLOv8-large. Combining the manually selected, generated images with real images yielded an overall mAP@50:95 of 88.3 % and mAP@50 of 95.0 %, representing performance gains of 1.4 % and 0.8 %, respectively, compared to the baseline model trained using only real images. It also performed competitively or comparably with modeling by combining real images with the images generated by external, traditional data augmentation techniques. The proposed automated post-generation image filtering approach still needs improvements to select high-quality images for enhanced weed detection. Both the weed dataset11https://doi.org/10.5281/zenodo.14861516 and software programs22https://github.com/vicdxxx/ControlNet-involved-Weed-Detection developed in this study have been made publicly available. Considerable research is needed to exploit more controllable diffusion models for generating high-fidelity, diverse weed images to substantially enhance weed detection in changing field conditions.}
}
@article{LI2025110672,
title = {SafetyGPT: An autonomous agent of electrical safety risks for monitoring workers’ unsafe behaviors},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {168},
pages = {110672},
year = {2025},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2025.110672},
url = {https://www.sciencedirect.com/science/article/pii/S0142061525002236},
author = {Wei Li and Fuqi Ma and Zhiyuan Zuo and Rong Jia and Bo Wang and Abdullah M Alharbi},
keywords = {Generative artificial intelligence, Risk identification, Electric power production, Multi-modal large language model, Unsafe behaviors},
abstract = {Workers’ unsafe behavior is one of the major causes of accidents in electric power production. Intelligent monitoring of workers’ unsafe behaviors can effectively prevent the expansion of safety risks, thereby blocking the development process of risks to accidents. Electric power production processes are diverse in nature and require the frequent switching of operating scenarios. This makes it difficult to identify what is “unsafe” since worker behaviors within the given electrical context also exhibit variability and diversity. Existing methods have insufficient generalization and adaptability, which makes them inadequate for the case of electric power production. Therefore, this paper proposes Safety Generative Pre-trained Transformers (SafetyGPT), an autonomous agent of safety risk based on a multi-modal large language model, which incorporates a human–machine collaborative monitoring mode for unsafe behaviors of workers. SafetyGPT loads the electric power production video, and the backend supervisors set instructions for SafetyGPT based on task requirements. The model encodes visual and textual features into corresponding tokens, realizes multi-modal feature alignment and fusion through the cross-attention mechanism, and then generates targeted responses through the large language model. Next, the proposed method is applied to real production site data to confirm the effectiveness and superiority through comparison with other methods designed to identify unsafe behaviors. Experimental results show that the accuracy of the proposed method for the identification of unsafe behaviors in complex environments is 96.5%, and that it can generate reasonable recommended plan based on the identification results, assist backend supervisors in making decisions, and effectively improve the safety level of power production.}
}
@article{SELVARAJ2026109362,
title = {Automating the Observer OPTION-5 measure of shared decision making: Assessing validity by comparing large language models to human ratings},
journal = {Patient Education and Counseling},
volume = {142},
pages = {109362},
year = {2026},
issn = {0738-3991},
doi = {https://doi.org/10.1016/j.pec.2025.109362},
url = {https://www.sciencedirect.com/science/article/pii/S0738399125007293},
author = {Sai P. Selvaraj and Renata W. Yen and Rachel Forcino and Glyn Elwyn},
keywords = {Generative AI, LLM, GPT, Option talk, Shared decision-making},
abstract = {Objectives
Observer-based measures of shared decision rely on human raters, it is resource-intensive, limiting routine assessment and improvement. Generative artificial intelligence could increase the speed and accuracy of observer-based evaluation while reducing the burden. This study aimed to assess the performance of large language models (LLMs) from Gemini, GPT, and LLaMA family of models in evaluating the extent of shared decision-making between clinicians and women considering surgery for early-stage breast cancer.
Methods
LLM-generated scores were compared with those of trained human raters from a randomized controlled trial using the 5-item Observer OPTION-5 measure. We analyzed 287 anonymized transcripts of breast cancer consultations. A series of prompts were tested across models, assessing correlations with human scores. We also evaluated the ability of LLMs to distinguish high versus low encounters and the impact of inter-rater agreement on performance.11Codes available here
Results
The scores for Observer OPTION-5 items generated by the GPT-4o and Gemini-1.5-Pro-002 correlated with human ratings (Pearson r ≈ 0.6, p-value<0.01), representing ≈ 75–80 % of the correlation observed between human raters themselves (r = 0.77). Providing detailed descriptions and examples improved the models’ performance. The results also confirm that the models could distinguish high- from low-scoring encounters, with an independent-samples t-test showing a large and significant separation between the two groups (t > 10, p < 0.01).
Conclusions
Based on the breast cancer surgery dataset we explored, LLMs can evaluate aspects of clinician-patient dialog using existing measures, providing the basis for the development and fine-tuning of prompts. Future work should focus on generalizability, larger datasets, and improving model performance.
Practice implications
The prospect of being able to automate the assessment of shared decision-making opens the door to rapid feedback as a means for reflective practice improvement.}
}
@article{HIRAHARA2025109849,
title = {D4: Text-guided diffusion model-based domain adaptive data augmentation for vineyard shoot detection},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109849},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109849},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924012407},
author = {Kentaro Hirahara and Chikahito Nakane and Hajime Ebisawa and Tsuyoshi Kuroda and Yohei Iwaki and Tomoyoshi Utsumi and Yuichiro Nomura and Makoto Koike and Hiroshi Mineno},
keywords = {Agriculture, Generative data augmentation, Domain adaptation, Image-based phenotyping, Image generation},
abstract = {In agricultural practices, plant phenotyping using object detection models is gaining attention, plant phenotyping is a technology that accurately measures the quality and condition of cultivated crops from images, contributing to the improvement of crop yield and quality, as well as reducing environmental impact. However, collecting the training data necessary to create generic and high-precision models is extremely challenging due difficulties associated with annotations and the diversity of domains. Such difficulties arise from the unique shapes and backgrounds of plants, as well as the significant changes in appearance due to environmental conditions and growth stages. Furthermore, it is difficult to transfer training data across different crops, and although machine learning models effective for specific environments, conditions, and crops have been developed, they cannot be widely applied in real-world conditions. Therefore, in this study, we propose a generative artificial intelligence data augmentation method (D4) and investigated its application towards a shoot detection task in a vineyard. D4 uses a pre-trained text-guided diffusion model based on a large number of original images culled from video data collected by unmanned ground vehicles or other means, and a small number of annotated datasets. The proposed method generates new annotated images with background information adapted to the target domain while retaining annotation information necessary for object detection. In addition, D4 overcomes the lack of training data in agriculture, including the difficulty of annotation and diversity of domains. We confirmed that this generative data augmentation method improved the mean average precision by up to 28.65% for the BBox detection task and the average precision by up to 13.73% for the keypoint detection task for vineyard shoot detection. D4 generative data augmentation is expected to simultaneously solve the cost and domain diversity issues of training data generation for agricultural applications and improve the generalization performance of detection models.}
}
@article{ZHANG20243166,
title = {SeisResoDiff: Seismic resolution enhancement based on a diffusion model},
journal = {Petroleum Science},
volume = {21},
number = {5},
pages = {3166-3188},
year = {2024},
issn = {1995-8226},
doi = {https://doi.org/10.1016/j.petsci.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1995822624001869},
author = {Hao-Ran Zhang and Yang Liu and Yu-Hang Sun and Gui Chen},
keywords = {Seismic resolution enhancement, Diffusion model, High resolution, Reservoir characterization, Deep learning, Seismic data processing},
abstract = {High resolution of post-stack seismic data assists in better interpretation of subsurface structures as well as high accuracy of impedance inversion. Therefore, geophysicists consistently strive to acquire higher resolution seismic images in petroleum exploration. Although there have been successful applications of conventional signal processing and machine learning for post-stack seismic resolution enhancement, there is limited reference to the seismic applications of the recent emergence and rapid development of generative artificial intelligence. Hence, we propose to apply diffusion models, among the most popular generative models, to enhance seismic resolution. Specifically, we apply the classic diffusion model—denoising diffusion probabilistic model (DDPM), conditioned on the seismic data in low resolution, to reconstruct corresponding high-resolution images. Herein the entire scheme is referred to as SeisResoDiff. To provide a comprehensive and clear understanding of SeisResoDiff, we introduce the basic theories of diffusion models and detail the optimization objective's derivation with the aid of diagrams and algorithms. For implementation, we first propose a practical workflow to acquire abundant training data based on the generated pseudo-wells. Subsequently, we apply the trained model to both synthetic and field datasets, evaluating the results in three aspects: the appearance of seismic sections and slices in the time domain, frequency spectra, and comparisons with the synthetic data using real well-logging data at the well locations. The results demonstrate not only effective seismic resolution enhancement, but also additional denoising by the diffusion model. Experimental comparisons indicate that training the model on noisy data, which are more realistic, outperforms training on clean data. The proposed scheme demonstrates superiority over some conventional methods in high-resolution reconstruction and denoising ability, yielding more competitive results compared to our previous research.}
}
@article{BRAGA2025128034,
title = {Towards a methodology for ethical artificial intelligence system development: A necessary trustworthiness taxonomy},
journal = {Expert Systems with Applications},
volume = {286},
pages = {128034},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128034},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425016550},
author = {Carlos Mario Braga and Manuel A. Serrano and Eduardo Fernández-Medina},
keywords = {Artificial Intelligence, Methodology, Trustworthy, Ethics, Generative AI, Taxonomy, Sociotechnical system},
abstract = {Recently, generative artificial intelligence (GenAI) has arisen and been rapidly adopted; due to its emergent abilities, there is a significantly increased need for risk management in the implementation of such systems. At the same time, many proposals for translating ethics into AI, as well as the first agreements by regulators governing the use of artificial intelligence (AI), have surfaced. This underscores the need for Trustworthy AI, which implies reliability, compliance, and ethics. However, there is still a lack of unified criteria, and more critically, a lack of systematic methodologies for operationalizing trustworthiness within AI development processes. Trustworthiness is crucial, as it ensures that the system performs consistently under expected conditions while adhering to moral and legal standards. The problem of ensuring trustworthiness must be addressed as a preliminary step in creating a methodology for building AI systems with these desirable features. Based on a systematic literature review (SLR), we analyze the ethical, legal, and technological challenges that AI projects face, identifying key considerations and gaps in current approaches. This article presents a detailed and structured sociotechnical taxonomy related to the concept of Trustworthy AI, grounded in the analysis of all relevant texts on the topic, and designed to enable the systematic integration of ethical, legal, and technological principles into AI development processes. The taxonomy establishes a sociotechnical foundation that reflects the interconnected nature of technological, ethical, and legal considerations, and serves as the conceptual basis for CRISP-TAI, a proposed specialized development lifecycle currently under validation, aimed at systematically operationalizing trustworthiness principles across all phases of AI system engineering.}
}
@article{CINGILLIOGLU2023259,
title = {Detecting AI-generated essays: the ChatGPT challenge},
journal = {International Journal of Information and Learning Technology},
volume = {40},
number = {3},
pages = {259-268},
year = {2023},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-03-2023-0043},
url = {https://www.sciencedirect.com/science/article/pii/S2056488023000033},
author = {Ilker Cingillioglu},
keywords = {AI generated Text detection, ChatGPT, OpenAI, Machine learning, Recall, F2 score},
abstract = {Purpose
With the advent of ChatGPT, a sophisticated generative artificial intelligence (AI) tool, maintaining academic integrity in all educational settings has recently become a challenge for educators. This paper discusses a method and necessary strategies to confront this challenge.
Design/methodology/approach
In this study, a language model was defined to achieve high accuracy in distinguishing ChatGPT-generated essays from human written essays with a particular focus on “not falsely” classifying genuinely human-written essays as AI-generated (Negative).
Findings
Via support vector machine (SVM) algorithm 100% accuracy was recorded for identifying human generated essays. The author discussed the key use of Recall and F2 score for measuring classification performance and the importance of eliminating False Negatives and making sure that no actual human generated essays are incorrectly classified as AI generated. The results of the proposed model's classification algorithms were compared to those of AI-generated text detection software developed by OpenAI, GPTZero and Copyleaks.
Practical implications
AI-generated essays submitted by students can be detected by teachers and educational designers using the proposed language model and machine learning (ML) classifier at a high accuracy. Human (student)-generated essays can and must be correctly identified with 100% accuracy even if the overall classification accuracy performance is slightly reduced.
Originality/value
This is the first and only study that used an n-gram bag-of-words (BOWs) discrepancy language model as input for a classifier to make such prediction and compared the classification results of other AI-generated text detection software in an empirical way.}
}
@article{SASIWAT2024100532,
title = {Implementation and test of a Device-Free localization system with a modified desync network protocol and a weighted k-nearest neighbor algorithm},
journal = {Egyptian Informatics Journal},
volume = {27},
pages = {100532},
year = {2024},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2024.100532},
url = {https://www.sciencedirect.com/science/article/pii/S1110866524000951},
author = {Yoschanin Sasiwat and Dujdow Buranapanichkit and Apidet Booranawong},
keywords = {Device-free localization, Desync protocols, RSSI, Fingerprinting, Weighted k-nearest neighbors},
abstract = {A device-free localization system is a technology for tracking targets or individuals without requiring them to carry any electronic devices. The system works by monitoring and processing changes in the received signal strength to detect changes in the environment. However, due to unreliable wireless communications and radio-based tracking solutions, an efficient system concerning both wireless communication and tracking performance should be developed. This paper presents a study of the 2.4 GHz IEEE 802.15.4 device-free localization system, focusing on the effectiveness of wireless network protocols and the accuracy of localization algorithms. The novelty and contribution of our work is that we develop a modified desync protocol for network synchronization and the weighted k-nearest neighbor algorithm for location tracking. The study provides both simulation and experimental evaluations, considering hardware configurations such as the CC2538 + CC2592 device. Results demonstrate that the modified desync protocol can effectively operate in real-world environments. The network’s performance is evaluated through the packet delivery ratios for different network sizes and the convergence time, which refers to the ability to restore synchronization among network nodes. In our experiment case, the packet delivery ratio and the convergence time for a twenty-node network size are 97.98 % and 6.976 s, respectively. In addition, the weighted k-nearest neighbor algorithm with an additional solution provides a high estimation accuracy of 99.93 % as accessed from various fixed human locations. Results also indicate that our algorithm can track the locations of a movement person, achieving an average accuracy of 85.75 % for different movement patterns. Finally, we suggest that the effect of new generative artificial intelligence approaches in this field should be investigated.}
}
@article{ACETO2024103926,
title = {Synthetic and privacy-preserving traffic trace generation using generative AI models for training Network Intrusion Detection Systems},
journal = {Journal of Network and Computer Applications},
volume = {229},
pages = {103926},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.103926},
url = {https://www.sciencedirect.com/science/article/pii/S1084804524001036},
author = {Giuseppe Aceto and Fabio Giampaolo and Ciro Guida and Stefano Izzo and Antonio Pescapè and Francesco Piccialli and Edoardo Prezioso},
keywords = {Network Intrusion Detection System, User privacy, Traffic trace generation, Traffic malware classification, Generative artificial intelligence, Conditional variational autoencoder},
abstract = {Network Intrusion Detection Systems (NIDS) are crucial tools for protecting networked devices from cyberattacks. Recent development in the field of Artificial Intelligence (AI) has provided tremendous advantages in implementing NIDSs able to monitor network traffic and block cyberattacks in real-time. In the literature, it is widely recognized that the effective training of a NIDS requires a large quantity of labeled traffic, representative of attacks. Nonetheless, the availability of public and abundant datasets remains remarkably restricted due to the cost of gathering and labeling real traffic traces and privacy concerns for sharing them. To tackle these challenges, in this paper we present a generative AI model capable of synthesizing anonymized traffic traces from real ones, thus dealing with privacy, abundance, and representativeness. The proposal is based on a Conditional Variational Autoencoder (CVAE) and a preprocessing procedure specifically designed for the generation of new traffic traces. To validate our solution, we conduct an extensive empirical study leveraging three recent and publicly-available datasets, containing benign and malicious traffic. The validation is carried out from both the perspectives of classification performance of a robust NIDS and the quality of synthetic data, in comparison to the utilization of real data. We compare our CVAE with two state-of-the-art AI-based traffic data generators and prove that, trained with traces emitted by our generative model, a NIDS has a limited F1-score loss compared to training on real data; competing models instead struggle or fail to generate traces that are as effective for NIDS training and as statistically similar to the original. We make the synthetic datasets available in both PCAP and tabular formats, to facilitate the reproducibility of our findings and encourage further exploration in the field of generative AI for networking.}
}
@article{ALKHALAF2024104662,
title = {Applying generative AI with retrieval augmented generation to summarize and extract key clinical information from electronic health records},
journal = {Journal of Biomedical Informatics},
volume = {156},
pages = {104662},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104662},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000807},
author = {Mohammad Alkhalaf and Ping Yu and Mengyang Yin and Chao Deng},
keywords = {Generative AI, Nursing notes, LLAMA, Malnutrition, Summarization, RAG},
abstract = {Background
Malnutrition is a prevalent issue in aged care facilities (RACFs), leading to adverse health outcomes. The ability to efficiently extract key clinical information from a large volume of data in electronic health records (EHR) can improve understanding about the extent of the problem and developing effective interventions. This research aimed to test the efficacy of zero-shot prompt engineering applied to generative artificial intelligence (AI) models on their own and in combination with retrieval augmented generation (RAG), for the automating tasks of summarizing both structured and unstructured data in EHR and extracting important malnutrition information.
Methodology
We utilized Llama 2 13B model with zero-shot prompting. The dataset comprises unstructured and structured EHRs related to malnutrition management in 40 Australian RACFs. We employed zero-shot learning to the model alone first, then combined it with RAG to accomplish two tasks: generate structured summaries about the nutritional status of a client and extract key information about malnutrition risk factors. We utilized 25 notes in the first task and 1,399 in the second task. We evaluated the model’s output of each task manually against a gold standard dataset.
Result
The evaluation outcomes indicated that zero-shot learning applied to generative AI model is highly effective in summarizing and extracting information about nutritional status of RACFs’ clients. The generated summaries provided concise and accurate representation of the original data with an overall accuracy of 93.25%. The addition of RAG improved the summarization process, leading to a 6% increase and achieving an accuracy of 99.25%. The model also proved its capability in extracting risk factors with an accuracy of 90%. However, adding RAG did not further improve accuracy in this task. Overall, the model has shown a robust performance when information was explicitly stated in the notes; however, it could encounter hallucination limitations, particularly when details were not explicitly provided.
Conclusion
This study demonstrates the high performance and limitations of applying zero-shot learning to generative AI models to automatic generation of structured summarization of EHRs data and extracting key clinical information. The inclusion of the RAG approach improved the model performance and mitigated the hallucination problem.}
}
@article{KRANZ2025109138,
title = {Exploring Latent Diffusion Models for ECG Generation on the Minute Scale},
journal = {Computer Methods and Programs in Biomedicine},
pages = {109138},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2025.109138},
url = {https://www.sciencedirect.com/science/article/pii/S0169260725005541},
author = {Dominik D. Kranz and Jan F. Krämer and Oruç Kahriman and Alexander Nelde and Niels Wessel and Christian Meisel},
keywords = {Generative Artificial Intelligence, Latent Diffusion Models, Electrocardiogram (ECG)},
abstract = {Background and Objective
AI models for electrocardiogram (ECG) interpretation rely on large, diverse datasets, but existing clinical datasets are skewed, overrepresenting normal rhythms and lacking rare pathologies. This limits model performance and generalizability. While generative AI has shown promise in other domains, its application to biosignals has so far been restricted to short segments, reducing clinical utility. Additionally, potentially promising tools like inpainting for artefact removal have not yet been explored in the biosignal domain. To overcome these limitations, we propose ECGEN, a latent diffusion model (LDM) designed to synthesize long-duration, realistic ECGs for data augmentation, rhythm-specific generation, and signal restoration.
Methods
We developed ECGEN in three configurations: (1) ECGEN-Small, a 30-second conditional generator for sinus rhythm and AFib; (2) ECGEN-Medium, a 90-second model for inpainting tasks; and (3) ECGEN-Large, an unconditional model for generating 320-second ECGs. Models were trained on real clinical ECGs from stroke patients using a vector quantized-variational autoencoder (VQ-VAE) for encoding and a denoising diffusion implicit model (DDIM) as the latent space backbone. We evaluated model outputs using heart rate (HR), heart rate variability (HRV), and morphological coherence.
Results
ECGEN-Small achieved an AUC of 0.98 for the atrial fibrillation (AFib) vs. sinus rhythm classification. ECGEN-Medium successfully inpainted missing segments with plausible HR dynamics. ECGEN-Large generated long ECGs with consistent morphology but showed distributional shifts in HRV (e.g., inflated standard deviation of NN intervals, SdNN), indicating incomplete modeling of global temporal dependencies. Network depth was found to significantly influence output quality and training stability.
Conclusions
ECGEN demonstrates the feasibility of long-duration ECG generation using LDMs, offering applications in dataset augmentation and signal restoration. However, distributional mismatches and occasional artefacts highlight challenges in unsupervised biosignal synthesis. Future work should address long-range temporal modeling and refine realism through conditioning or adversarial training.}
}
@article{RUSSELL2025102483,
title = {Toward amplifying the good in nursing education: A quality improvement study on implementing artificial intelligence-based assistants in a learning system},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102483},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102483},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001368},
author = {Regina G. Russell and Jules White and Allen Karns and Karely Rodriguez and Pamela R. Jeffries and Patricia Sengstack},
keywords = {Nursing education, Artificial intelligence, Generative AI, Large language models, Innovation, Systems thinking, Leadership, Change management, Quality improvement, Interprofessional education},
abstract = {ABSTRACT
Effective integration of artificial intelligence-based tools into nursing care and science will depend on aligned integration in nursing education. Our quality improvement study documents the process and short-term outcomes of introducing a generative AI-based tool into a nursing education system. Nursing school faculty and staff at one private, southeastern university (n = 364) piloted an internally constrained chatbot system for 2 months in 2024. Data were captured to evaluate the (a) costs of implementation, (b) use cases in nursing education, and (c) projected system impact. Costs were lower than $2 per month, per user. There were 148 diverse case reports from 35 unique users. On a separate survey, 35 respondents rated technology acceptability as 5.2/7.0. Projected impact is high (6.3/7.0), but not entirely positive (5.9/7.0). Benefits and challenges were identified. Nursing will need to invest expert time and community resources to evolve education systems along with these evolving technologies.}
}
@article{JIANG2024104103,
title = {Estimating and explaining regional land value distribution using attention-enhanced deep generative models},
journal = {Computers in Industry},
volume = {159-160},
pages = {104103},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104103},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000319},
author = {Feifeng Jiang and Jun Ma and Christopher John Webster and Weiwei Chen and Wei Wang},
keywords = {Land price estimation, Generative adversarial networks (GAN), Generative artificial intelligence (generative AI), Deep learning, Attention mechanism, Deep generative models},
abstract = {Accurate land valuation is crucial in sustainable urban development, influencing pivotal decisions on resource allocation and land-use strategies. Most existing studies, primarily using point-based modeling approaches, face challenges on granularity, generalizability, and spatial effect capturing, limiting their effectiveness in regional land valuation with high granularity. This study therefore proposes the LVGAN (i.e., land value generative adversarial networks) framework for regional land value estimation. The LVGAN model redefines land valuation as an image generation task, employing deep generative techniques combined with attention mechanisms to forecast high-resolution relative value distributions for informed decision-making. Applied to a case study of New York City (NYC), the LVGAN model outperforms typical deep generative methods, with MAE (Mean Absolute Error) and MSE (Mean Squared Error) averagely reduced by 36.58 % and 59.28 %, respectively. The model exhibits varied performance across five NYC boroughs and diverse urban contexts, excelling in Manhattan with limited value variability, and in areas characterized by residential zoning and high density. It identifies influential factors such as road network, built density, and land use in determining NYC land valuation. By enhancing data-driven decision-making at early design stages, the LVGAN model can promote stakeholder engagement and strategic planning for sustainable and well-structured urban environments.}
}
@article{DUONG2023100883,
title = {Applying a modified technology acceptance model to explain higher education students’ usage of ChatGPT: A serial multiple mediation model with knowledge sharing as a moderator},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100883},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100883},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723001210},
author = {Cong Doanh Duong and Trong Nghia Vu and Thi Viet Nga Ngo},
keywords = {Technology acceptance model, Behavior intention to use ChatGPT, Actual use of ChatGPT, Knowledge sharing},
abstract = {Generative artificial intelligence (AI), such as ChatGPT, has taken the world by storm, especially in the education sector, because of its capacity to produce responses that are contextually relevant and appear to imitate human language. This has increased concerns from both scholars and practitioners regarding the potential impacts of ChatGPT on students' learning. However, research on higher education students' adoption of ChatGPT is still scant. Drawing on the modified technology acceptance model (TAM) and a sample of 1389 higher education students recruited in 11 universities in Vietnam with a stratified random sampling approach, the findings of this study indicated that effort expectancy not only directly affected students' actual usage of ChatGPT, but also serially indirectly increased their actual use of ChatGPT through performance expectancy and intentions to use ChatGPT. Additionally, knowledge sharing was found to significantly increase higher education students’ transformation from having the intention to use ChatGPT to actual users of ChatGPT. The theoretical and managerial implications of this are discussed in this paper in order to gain benefits and manage the potential threats from this new technology.}
}
@article{CHEN2024112113,
title = {Enhancing interaction in virtual-real architectural environments: A comparative analysis of generative AI-driven reality approaches},
journal = {Building and Environment},
volume = {266},
pages = {112113},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324009557},
author = {Xinxing Chen and Weizhi Gao and Yingnan Chu and Yehao Song},
keywords = {Mixed reality, Generative AI, Computational design, Architectural environments},
abstract = {The architectural environment is expanding into digital, virtual, and informational dimensions, introducing challenges in virtual-real space interaction. Traditional design methods struggle with real-time interaction, integration with existing workflows, and rapid space modification. To address these issues, we present a generative design method that enables symbiotic interaction between virtual and real spaces using Mixed Reality (MR) and Generative Artificial Intelligence (AI) technologies. We developed two approaches: one using the Rhino modeling platform and the other based on the Unity3D game engine, tailored to different application needs. User experience testing in exhibition, leisure, and residential spaces evaluated our method's effectiveness. Results showed significant improvements in design flexibility, interactive efficiency, and user satisfaction. In the exhibition scenario, the Unity3D-based method excelled in rapid design modifications and immersive experiences. Questionnaire data indicated that MR offers good visual comfort and higher immersion than VR, effectively supporting architects in interface and scale design. Clustering analysis of participants' position and gaze data revealed diverse behavioral patterns in the virtual-physical exhibition space, providing insights for optimizing spatial layouts and interaction methods. Our findings suggest that the generative AI-driven MR method simplifies traditional design processes by enabling real-time modification and interaction with spatial interfaces through simple verbal and motion interactions. This approach streamlines workflows by reducing steps like measuring, modeling, and rendering, while enhancing user engagement and creativity. Overall, this method offers new possibilities for experiential exhibition and architectural design, contributing to future environments where virtual and real spaces coexist seamlessly.}
}
@article{ZHU2025,
title = {The Impact of ChatGPT Exposure on User Interactions With a Motivational Interviewing Chatbot: Quasi-Experimental Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/56973},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25002288},
author = {Jiading Zhu and Alec Dong and Cindy Wang and Scott Veldhuizen and Mohamed Abdelwahab and Andrew Brown and Peter Selby and Jonathan Rose},
keywords = {chatbot, digital health, motivational interviewing, natural language processing, ChatGPT, large language models, artificial intelligence, experimental, smoking cessation, conversational agent},
abstract = {Background
The worldwide introduction of ChatGPT in November 2022 may have changed how its users perceive and interact with other chatbots. This possibility may confound the comparison of responses to pre-ChatGPT and post-ChatGPT iterations of pre-existing chatbots, in turn affecting the direction of their evolution. Before the release of ChatGPT, we created a therapeutic chatbot, MIBot, whose goal is to use motivational interviewing to guide smokers toward making the decision to quit smoking. We were concerned that measurements going forward would not be comparable to those in the past, impacting the evaluation of future changes to the chatbot.
Objective
The aim of the study is to explore changes in how users interact with MIBot after the release of ChatGPT and examine the relationship between these changes and users’ familiarity with ChatGPT.
Methods
We compared user interactions with MIBot prior to ChatGPT’s release and 6 months after the release. Participants (N=143) were recruited through a web-based platform in November of 2022, prior to the release of ChatGPT, to converse with MIBot, in an experiment we refer to as MIBot (version 5.2). In May 2023, a set of (n=129) different participants were recruited to interact with the same version of MIBot and asked additional questions about their familiarity with ChatGPT, in the experiment called MIBot (version 5.2A). We used the Mann-Whitney U test to compare metrics between cohorts and Spearman rank correlation to assess relationships between familiarity with ChatGPT and other metrics within the MIBot (version 5.2A) cohort.
Results
In total, 83(64.3%) participants in the MIBot (version 5.2A) cohort had used ChatGPT, with 66 (51.2%) using it on a regular basis. Satisfaction with MIBot was significantly lower in the post-ChatGPT cohort (U=11,331.0; P=.001), driven by a decrease in perceived empathy as measured by the Average Consultation and Relational Empathy Measure (U=10,838.0; P=.01). Familiarity with ChatGPT was positively correlated with average response length (ρ=0.181; P=.04) and change in perceived importance of quitting smoking (ρ=0.296; P<.001).
Conclusions
The widespread reach of ChatGPT has changed how users interact with MIBot. Post-ChatGPT users are less satisfied with MIBot overall, particularly in terms of perceived empathy. However, users with greater familiarity with ChatGPT provide longer responses and demonstrated a greater increase in their perceived importance of quitting smoking after a session with MIBot. These findings suggest the need for chatbot developers to adapt to evolving user expectations in the era of advanced generative artificial intelligence.}
}
@article{CARL202491,
title = {Comparing Patient’s Confidence in Clinical Capabilities in Urology: Large Language Models Versus Urologists},
journal = {European Urology Open Science},
volume = {70},
pages = {91-98},
year = {2024},
issn = {2666-1683},
doi = {https://doi.org/10.1016/j.euros.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S2666168324010942},
author = {Nicolas Carl and Lisa Nguyen and Sarah Haggenmüller and Martin {Joachim Hetz} and Jana {Theres Winterstein} and Friedrich {Otto Hartung} and Britta Gruene and Jakob {Nikolas Kather} and Tim Holland-Letz and Maurice {Stephan Michel} and Frederik Wessels and Titus {Josef Brinker}},
keywords = {Clinical trial, Generative artificial intelligence, Implementation science, Large language models, Patient interaction},
abstract = {Background and objective
Data on interaction of patients with artificial intelligence (AI) are limited, primarily derived from small-scale studies, cross-sectional surveys, and qualitative reviews. Most patients have not yet encountered AI in their clinical experience. This study explored patients’ confidence in AI, specifically large language models, after a direct interaction with a chatbot in a clinical setting. Through hands-on experience, the study sought to reduce potential biases due to an anticipated lack of AI experience in a real-world urological patient sample.
Methods
A total of 300 patients scheduled for counseling were enrolled from February to July 2024. Participants voluntarily conversed about their medical questions with a GPT-4 powered chatbot, followed by a survey assessing their confidence in clinical capabilities of AI compared with their counseling urologists. Clinical capabilities included history taking, diagnostics, treatment recommendation, anxiety reduction, and time allocation.
Key findings and limitations
Of the 292 patients who completed the study, AI was significantly preferred to physicians for consultation time allocation (p < 0.001). However, urologists were overwhelmingly favored for all other capabilities, especially treatment recommendations and anxiety reduction. Notably, age did not influence patients’ confidence in AI. Limitations include a potential social desirability bias.
Conclusions and clinical implications
Our study demonstrates that urological patients prefer AI as a powerful complement to—rather than a replacement for—human expertise in clinical care. Patients appreciated the additional consultation time provided by AI. Interestingly, age was not associated with confidence in AI, suggesting that large language models are user-friendly tools for patients of all age groups.
Patient summary
In this report, we explored how patients feel about using an artificial intelligence (AI)-powered chatbot in a medical setting. Patients interacted with the AI for medical questions and compared its skills with those of doctors through a survey. They appreciated the AI for providing more time during consultations but preferred doctors for other tasks, for example, diagnostics, recommendation of treatments, and reduction of anxieties.}
}
@article{PARISE2025108523,
title = {CTGAN-driven synthetic data generation: A multidisciplinary, expert-guided approach (TIMA)},
journal = {Computer Methods and Programs in Biomedicine},
volume = {259},
pages = {108523},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108523},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724005169},
author = {Orlando Parise and Rani Kronenberger and Gianmarco Parise and Carlo {de Asmundis} and Sandro Gelsomino and Mark {La Meir}},
keywords = {Generative artificial intelligence, Synthetic structured data, SARS-CoV-2, Pandemic, COVID-19},
abstract = {Objective
We generated synthetic data starting from a population of two hundred thirty-eight adults SARS-CoV-2 positive patients admitted to the University Hospital of Brussels, Belgium, in 2020, utilizing a Conditional Tabular Generative Adversarial Network (CTGAN)-based technique with the aim of testing the performance, representativeness, realism, novelty, and diversity of synthetic data generated from a small patient sample. A Multidisciplinary Approach (TIMA) incorporates active participation from a medical team throughout the various stages of this process.
Methods
The TIMA committee scrutinized data for inconsistencies, implementing stringent rules for variables unlearned by the system. A sensitivity analysis determined 100,000 epochs, leading to the generation of 10,000 synthetic data. The model's performance was tested using a general-purpose dataset, comparing real and synthetic data.
Results
Outcomes indicate the robustness of our model, with an average contingency score of 0.94 across variable pairs in synthetic and real data. Continuous variables exhibited a median correlation similarity score of 0.97. Novelty received a top score of 1. Principal Component Analysis (PCA) on synthetic values demonstrated diversity, as no patient pair displayed a zero or close-to-zero value distance. Remarkably, the TIMA committee's evaluation revealed that synthetic data was recognized as authentic by nearly 100%.
Conclusions
Our trained model exhibited commendable performance, yielding high representativeness in the synthetic dataset compared to the original. The synthetic dataset proved realistic, boasting elevated levels of novelty and diversity.}
}
@incollection{SAAVEDRAALAMILLAS2025623,
title = {Library Instruction and Research Training in the Context of Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {623-629},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00122-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395689500122X},
author = {César Saavedra-Alamillas and Josmel Pacheco-Mendoza and Erik M. Ortiz-Díaz and Youness {El Hamzaoui} and Marc A. Astbury},
keywords = {Academic production., Artificial intelligence, Embedded librarian, Information literacy, Liaison librarian, Librarian, Library instruction, Research, Researcher training, Scientific communication},
abstract = {The librarian has played a crucial role throughout history, evolving from a guardian of humanity׳s collective memory to guiding the use of collections and, in recent years, a trainer in the use of information and emerging digital technologies. Currently, the librarian is an active collaborator who understands scientific communication processes and the mechanisms for improving high-impact academic production.}
}
@article{MAIBAUM2024114269,
title = {Selecting textual analysis tools to classify sustainability information in corporate reporting},
journal = {Decision Support Systems},
volume = {183},
pages = {114269},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114269},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624001027},
author = {Frederik Maibaum and Johannes Kriebel and Johann Nils Foege},
keywords = {Sustainability, Natural language processing, Corporate reporting, Performance evaluation, ChatGPT},
abstract = {Information on firms' sustainability often partly resides in unstructured data published, for instance, in annual reports, news, and transcripts of earnings calls. In recent years, researchers and practitioners have started to extract information from these data sources using a broad range of natural language processing (NLP) methods. While there is much to be gained from these endeavors, studies that employ these methods rarely reflect upon the validity and quality of the chosen method—that is, how adequately NLP captures the sustainability information from text. This practice is problematic, as different NLP techniques lead to different results regarding the extraction of information. Hence, the choice of method may affect the outcome of the application and thus the inferences that users draw from their results. In this study, we examine how different types of NLP methods influence the validity and quality of extracted information. In particular, we compare four primary methods, namely (1) dictionary-based techniques, (2) topic modeling approaches, (3) word embeddings, and (4) large language models such as BERT and ChatGPT, and evaluate them on 75,000 manually labeled sentences from 10-K annual reports that serve as the ground truth. Our results show that dictionaries have a large variation in quality, topic models outperform other approaches that do not rely on large language models, and large language models show the strongest performance. In large language models, individual fine-tuning remains crucial. One-shot approaches (i.e., ChatGPT) have lately surpassed earlier approaches when using well-designed prompts and the most recent models.}
}
@article{LI2025110496,
title = {Solid propellant grain reverse design via generative deep learning},
journal = {Aerospace Science and Technology},
volume = {165},
pages = {110496},
year = {2025},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2025.110496},
url = {https://www.sciencedirect.com/science/article/pii/S127096382500567X},
author = {W.T. Li and Y.Q. He and G.Z. Liang},
keywords = {Solid rocket motor, Propellant grain reverse design, Generative artificial intelligence, Auto-decoder, Latent space, Diffusion model},
abstract = {The primary objective of solid propellant grain reverse design is to determine the optimal grain geometries, which may be not standard traditional grain shapes, that can produce an internal ballistic performance curve (abbreviated as performance curve) matching the target curve. To address the fundamental challenges of grain shape interpolation, reconstruction, and generation, a deep learning approach is proposed. Firstly, the fast-sweeping method is introduced to rapidly realize the calculation of burning surface regression and performance curve prediction. Secondly, a deep neural field with conditional auto-decoder is constructed, which can output the phase field of the grain shape matching the target performance curve according to a latent vector and conditional vector. Thirdly, a latent denoising diffusion probability model is developed to realize grain generation in latent space. The latent vector can be generated from a Gauss noisy through a stochastic process. Moreover, the intensity of classifier-free guidance can be manipulated to adjust the diversity of the results. Finally, the grain shape interpolation, reconstruction, and generation are verified through typical cases. All the optimal and suboptimal solutions are successfully identified by our model. The reconstructed and generated dual-thrust grain achieves performance matching degrees of 0.9852 and 0.9870, respectively, which closely align with the best results reported in previous method of single-objective evolutionary neural network. Consequently, the deep neural field and generative diffusion model proposed in this study offer promising solutions to grain reverse design problems. These findings can provide a solid foundation for future investigations into complex 3D grain reverse design.}
}
@article{LI2025150926,
title = {Artificial Intelligence and Machine Learning in Transfusion Practice: An Analytical Assessment},
journal = {Transfusion Medicine Reviews},
volume = {39},
number = {4},
pages = {150926},
year = {2025},
note = {Horizons in Transfusion Medicine: Perspectives after the first quarter of the 21st century},
issn = {0887-7963},
doi = {https://doi.org/10.1016/j.tmrv.2025.150926},
url = {https://www.sciencedirect.com/science/article/pii/S0887796325000513},
author = {Na Li and Ruchika Goel and Sheharyar Raza and Kiarash Riazi and Jie Pan and Huong Quynh Nguyen and Andrew W. Shih and Adam D’Souza and Rounak Dubey and Aaron A.R. Tobian and Donald M. Arnold},
keywords = {Transfusion medicine, Artificial intelligence, Clinical decision support, Supervised learning, Unsupervised learning, Reinforcement learning, Generative artificial intelligence},
abstract = {Transfusion medicine is vital to healthcare and affects clinical outcomes, patient safety, and system resilience while addressing challenges such as blood shortages, donor variability, and rising costs. The integration of artificial intelligence (AI) and machine learning (ML) presents new opportunities to improve clinical decision-making and operational effectiveness in this field. This structured narrative review identified and evaluated studies applying AI and ML in transfusion medicine. A search of PubMed and Scopus for articles published between January 2018 and April 2025 yielded 565 publications. Studies were included if they applied AI or ML techniques, focused on transfusion management or decision support, and were evaluated using electronic health records or expert review. Four exemplar studies were selected, each representing a distinct AI paradigm: supervised, unsupervised, reinforcement, and generative learning. These studies were critically appraised for methodological rigor, clinical relevance, and potential for implementation in practice. The reviewed studies reflected a clear shift from traditional analytic methods toward more advanced computational approaches to improve prediction accuracy, optimize resource allocation, and support clinical decision-making. Three overarching themes emerged: the need to balance model complexity with interpretability and clinical feasibility; the impact of data quality and preprocessing on model performance and fairness; and the barriers to broader applicability and cross-institutional deployment. As technological barriers continue to decline, future challenges will increasingly center on privacy regulations, infrastructure constraints, and aligning model complexity with practical utility. Thoughtful integration of these considerations through scalable, clinical-grade, and transparent solutions will be critical in realizing the full potential of AI and ML in transfusion medicine.}
}
@article{NGUYEN2024100899,
title = {Detecting and assessing AI-generated and human-produced texts: The case of second language writing teachers},
journal = {Assessing Writing},
volume = {62},
pages = {100899},
year = {2024},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2024.100899},
url = {https://www.sciencedirect.com/science/article/pii/S1075293524000928},
author = {Loc Nguyen and Jessie S. Barrot},
keywords = {ChatGPT, Computer-assisted language learning, Generative artificial intelligence, Second language writing, Writing assessment},
abstract = {Artificial intelligence (AI) technologies have recently attracted the attention of second language (L2) writing scholars and practitioners. While they recognize the tool’s viability, they also raised the potential adverse effects of these tools on accurately reflecting students’ actual level of writing performance. It is, therefore, crucial for teachers to discern AI-generated essays from human-produced work for more accurate assessment. However, limited information is available about how they assess and distinguish between essays produced by AI and human authors. Thus, this study analyzed the scores and comments teachers gave and looked into their strategies for identifying the source of the essays. Findings showed that essays by a native English-speaking (NS) lecturer and ChatGPT were rated highly. Meanwhile, essays by an NS college student, non-native English-speaking (NNS) college student, and NNS lecturer scored lower, which made them distinguishable from an AI-generated text. The study also revealed that teachers could not consistently identify the AI-generated text, particularly those written by an NS professional. These findings were attributed to teachers’ past engagement with AI writing tools, familiarity with common L2 learner errors, and exposure to native and non-native English writing. From these results, implications for L2 writing instruction and future research are discussed.}
}
@article{KOMPLEUKKUNEN2024103382,
title = {How ChatGPT shapes the future labour market situation of software engineers: A Finnish Delphi study},
journal = {Futures},
volume = {160},
pages = {103382},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103382},
url = {https://www.sciencedirect.com/science/article/pii/S001632872400065X},
author = {Kathrin Komp-Leukkunen},
keywords = {Artificial Intelligence, Large Language Models, Software architects, Scenarios, Possible futures, Probable futures},
abstract = {ChatGPT is changing our working lives, conjuring visions of revolutionary shifts ahead. ChatGPT is a chatbot based on generative artificial intelligence, which can, e.g., write computer code. This article explores how it might shape the future labour market situation of software engineers. A Delphi study with 14 experts was conducted in Finland. The first round identified possible futures, and the second round assessed their probabilities. Five scenarios prevailed: the unlikely scenario that the status quo persists; the ambivalent scenario that ChatGPT can replace software engineers to a large extent; the likely scenario that computer departments in startups embrace ChatGPT; the likely scenario that ChatGPT use proliferates among software engineers to increase productivity; and the highly likely scenario that ChatGPT makes computer programming accessible to the masses. Findings contradict previous discussions that technological advancements might take over especially routine tasks. ChatGPT can also take over non-routine tasks. Moreover, findings underline that digitalisation does not only bring about a choice between upskilling and employability loss, but also a democratisation of knowledge and expertise. Software engineers and companies might use the findings as an impetus for upskilling, while universities might feel nudged to incorporate ChatGPT more strongly into their curricula.}
}
@article{NIE2024100172,
title = {SkyGPT: Probabilistic ultra-short-term solar forecasting using synthetic sky images from physics-constrained VideoGPT},
journal = {Advances in Applied Energy},
volume = {14},
pages = {100172},
year = {2024},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2024.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666792424000106},
author = {Yuhao Nie and Eric Zelikman and Andea Scott and Quentin Paletta and Adam Brandt},
keywords = {Cloud motion prediction, Probabilistic solar forecasting, Deep learning, Generative models, Stochastic video prediction, Sky images, Photovoltaic power},
abstract = {The variability of solar photovoltaic (PV) power output, driven by rapidly changing cloud dynamics, hinders the transition to reliable renewable energy systems. Information on future sky conditions, especially cloud coverage, holds the promise for improving PV output forecasting. Leveraging recent advances in generative artificial intelligence (AI), we introduce SkyGPT, a physics-constrained stochastic video prediction model, which predicts plausible future images of the sky using historical sky images. We show that SkyGPT can accurately capture cloud dynamics, producing highly realistic and diverse future sky images. We further demonstrate its efficacy in 15-minute-ahead probabilistic PV output forecasting using real-world power generation data from a 30-kW rooftop PV system. By coupling SkyGPT with a U-Net-based PV power prediction model, we observe superior prediction reliability and sharpness compared with several benchmark methods. The propose approach achieves a continuous ranked probability score (CRPS) of 2.81 kW, outperforming a classic convolutional neural network (CNN) baseline by 13% and the smart persistence model by 23%. The findings of this research could aid efficient and resilient management of solar electricity generation, particularly as we transition to renewable-heavy grids. The study also provides valuable insights into stochastic cloud modeling for a broad research community, encompassing fields such as solar energy meteorology and atmospheric sciences.}
}
@incollection{2026261,
title = {Index},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {261-264},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00483-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244004835}
}
@article{ARGUELLES2025112048,
title = {Conservative treatment of ameloblastic fibroma a case report with review of literature},
journal = {International Journal of Surgery Case Reports},
volume = {136},
pages = {112048},
year = {2025},
issn = {2210-2612},
doi = {https://doi.org/10.1016/j.ijscr.2025.112048},
url = {https://www.sciencedirect.com/science/article/pii/S2210261225012349},
author = {Gerardo Bardales Arguelles and Francisco Díaz Ayala and Claudette Marcelle Arambú Turcios and Gustavo Alberto Sierra Larios and Hugo Romero Alvarenga and Juan José Guifarro Sierra},
keywords = {Ameloblastic fibroma, Odontogenic tumors, Case report},
abstract = {Introduction and importance
Ameloblastic fibroma (AF) is a benign mixed odontogenic tumor composed of epithelial and mesenchymal tissues. It accounts for approximately 1.5–4.5 % of all odontogenic tumors and is most commonly diagnosed during the first and second decades of life. Due to documented cases of malignant transformation, the optimal therapeutic approach for AF remains a subject of debate.
Case presentation
A 15-year-old female patient presented with pain, swelling, and purulent discharge in the right posterior mandible. Panoramic radiography revealed a unilocular radiolucent lesion associated with tooth 48. The patient had no significant medical history.
Clinical discussion
An incisional biopsy was performed with the presumptive diagnosis of odontogenic keratocyst, followed by decompression tube placement. Histopathological examination confirmed the diagnosis of ameloblastic fibroma. Given the patient's age and the low likelihood of malignant transformation, a conservative treatment approach was adopted, consisting of enucleation, curettage, peripheral osteotomy, and extraction of retained teeth. Due to the compromised lingual and vestibular cortices at the mandibular basal border—observed on computed tomography (CT)—a reconstruction plate was placed to prevent pathological fracture.
Conclusion
AF is a rare, often asymptomatic odontogenic tumor. Therapeutic management remains controversial due to its recurrence rate (18.3 %–43.5 %) and potential for malignant transformation (reported in one-third of cases). In this case, at the 9-month follow-up, the patient exhibited preserved mandibular function, remained asymptomatic, and showed no clinical or radiographic evidence of recurrence. Conservative treatment with rigorous long-term monitoring may be the preferred approach for young patients to optimize functional outcomes and quality of life. No generative artificial intelligence (AI) tools were used in the conception, design, data collection, analysis, or interpretation of the research presented in this manuscript. Furthermore, no AI-assisted technologies were employed in the drafting, editing, or revision of the manuscript.}
}
@article{DESIANO2025107785,
title = {Translating code with Large Language Models and human-in-the-loop feedback},
journal = {Information and Software Technology},
volume = {186},
pages = {107785},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107785},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001247},
author = {Gabriele Dario {De Siano} and Anna Rita Fasolino and Giancarlo Sperlí and Andrea Vignali},
keywords = {Large Language Model, Human-centered AI, Code translation, Software engineering},
abstract = {Context:
In recent years, the code translation task has arisen as one of the major software issues in maintaining software quality during migration over complex infrastructure. This task involves human subjects with different background knowledge and could introduce errors due to the semantic gap between the programming languages and the complexity of the task. Generative Artificial Intelligence (AI) showed good capabilities in code generation, albeit this is highly dependent on the human factor.
Objective:
This paper investigates, from the human perspective, the use of three Generative AI tools (ChatGPT, Google Bard, and GitHub Copilot) in the context of translation tasks from code written in query languages to code written in framework-specific code languages, specifically focused on SQL dialects and PySpark. This translation is especially crucial during the migration from centralized architectures to cloud-based architectures.
Methods:
We evaluate the usefulness of these tools, the quality of the generated code, and their impact on performance. The models are tested with queries of various type in three different SQL dialects considering three usage scenarios of increasing complexity. It involves 15 participants with diverse programming backgrounds, who aim to solve tasks by interacting multiple times with the tools and manually changing the code.
Results:
The findings show a positive performance, demonstrating their reliability in generating coherent translations, achieving 100% precision in most tasks with a slight decrease in more complex scenarios, and producing well-documented code, with a response time of under 2 min, with Google Bard responding 50% faster than the others.
Conclusion:
In conclusion, this paper establishes a methodology and both quantitative and qualitative metrics for evaluating how generative AI tools streamline code translation, shifting the emphasis from production to refinement. It underscores the importance of continuously improving these tools to integrate them into developers’ workflows and to provide guidelines for intelligent use.}
}
@article{RENSHAW2024100154,
title = {Linking online activity to offline behavior: A meta-review of three decades of online-to-offline scholarship with future implications for AI},
journal = {Emerging Trends in Drugs, Addictions, and Health},
volume = {4},
pages = {100154},
year = {2024},
issn = {2667-1182},
doi = {https://doi.org/10.1016/j.etdah.2024.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2667118224000138},
author = {Scott Leo Renshaw and Kathleen M. Carley},
keywords = {Network analysis, Social reinforcement, Meta-review, Online influences, Offline behavior},
abstract = {As society grapples with the emerging significance and implications of Large Language Models (LLMs), such as OpenAI’s ChatGPT, or Google’s Gemini, as well as other advancements in modern generative Artificial Intelligence (AI), it is crucial to recognize the existing role that data, algorithms, and online social networks have already played in shaping our contemporary society. This review article provides the first comprehensive examination of the current state of knowledge, across disciplinary divides, on how online influences impact offline behaviors, laying the necessary groundwork for investigating and researching the potential impact that these new technologies will have on our “offline” lives. Through a deep-dive collection of articles (n=149), we review and analyze research with measurable Online-to-Offline impacts (n=88). Within this Online-to-Offline criteria, we identify five emergent cross-cutting themes, namely: Social Diffusion, Social Reinforcement, Social Boundary & Identity Maintenance, Cognitive and Attitudinal Research, and Research on Vulnerable & Marginalized Impacts. Through a second wave snowball collection process, we construct a citation network from the broader Online and Offline research literature, allowing us to locate the Online-to-Offline subset as part of a larger intellectual discussion. Finally, we conduct a Term Frequency-Inverse Document Frequency (TF-IDF) analysis of terms used in the titles of these online/offline research papers, from 1990 to 2023, to identify the evolution of researchers’ conceptualization and framing of Online and Offline research across the past 30 years. The meta-review, presentation of high-level cross-cutting interdisciplinary themes, co-citation network analysis, and TF-IDF analysis collectively provide a cohesive and deeper understanding of the research space of online/offline influences. By taking stock of the ways in which online factors have already shaped individual, group, or organizational behaviors and social dynamics broadly in “offline” contexts, this work aims to provide a cohesive theoretical and empirical foundation for future researchers to better anticipate, address, and frame the future consequences of the rapidly evolving digitally influenced landscape we find ourselves in today.}
}
@article{MASROURI2024100492,
title = {Towards data-efficient mechanical design of bicontinuous composites using generative AI},
journal = {Theoretical and Applied Mechanics Letters},
volume = {14},
number = {1},
pages = {100492},
year = {2024},
issn = {2095-0349},
doi = {https://doi.org/10.1016/j.taml.2024.100492},
url = {https://www.sciencedirect.com/science/article/pii/S2095034924000035},
author = {Milad Masrouri and Zhao Qin},
keywords = {Generative artificial intelligence, Stable diffusion, Composite design, Phase field model, Molecular dynamics simulation},
abstract = {The distribution of material phases is crucial to determine the composite's mechanical property. While the full structure-mechanics relationship of highly ordered material distributions can be studied with finite number of cases, this relationship is difficult to be revealed for complex irregular distributions, preventing design of such material structures to meet certain mechanical requirements. The noticeable developments of artificial intelligence (AI) algorithms in material design enables to detect the hidden structure-mechanics correlations which is essential for designing composite of complex structures. It is intriguing how these tools can assist composite design. Here, we focus on the rapid generation of bicontinuous composite structures together with the stress distribution in loading. We find that generative AI, enabled through fine-tuned Low Rank Adaptation models, can be trained with a few inputs to generate both synthetic composite structures and the corresponding von Mises stress distribution. The results show that this technique is convenient in generating massive composites designs with useful mechanical information that dictate stiffness, fracture and robustness of the material with one model, and such has to be done by several different experimental or simulation tests. This research offers valuable insights for the improvement of composite design with the goal of expanding the design space and automatic screening of composite designs for improved mechanical functions.}
}
@article{SHAIKH2025104005,
title = {Fields of the future: Digital transformation in smart agriculture with large language models and generative AI},
journal = {Computer Standards & Interfaces},
volume = {94},
pages = {104005},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104005},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000340},
author = {Tawseef Ayoub Shaikh and Tabasum Rasool and Waseem Ahmad Mir},
keywords = {Language models, Agricultural text classification, Very large pre-trained language model, Generative pre-trained enerative pre-trained transformer (GPT), ChatGPT, Generative AI, Natural language processing, Semantic matching},
abstract = {Language models (LLMs) have shown to be very useful in many fields like healthcare and finance, as natural language comprehension and generation have advanced. The capacity of LLM to participate in textual discussion has been the subject of much research, and the findings have proved encouraging across several domains. The inability of conventional image classification networks to comprehend the causes of crop diseases and etiology further impedes precise diagnosis. Agricultural diagnostic models on a grand scale will be based on generative pre-trained transformers (GPT) assisted with agrarian settings. By examining the efficacy of text corpora linked to agriculture for pretraining transformer-based language (TBL) models, this research delves into agricultural natural language processing (ANLP). To make the most of it, we looked at several important aspects, including prompt building, response parsing, and several ChatGPT versions. Despite the proven effectiveness and huge potential, there has been little exploration of LLM and Generative AI to agriculture artificial intelligence (AI). Therefore, this study aims to explore the possibility of LLM and Generative AI in smart agriculture. In particular, we present conceptual tools and technical background to facilitate understanding the problem space and uncover new research directions in this field. The paper presents an overview of the evolution of generative adversarial network (GAN) architectures followed by a first systematic review of various applications in smart agriculture and precision farming systems, involving a diversity of visual recognition tasks for smart farming and livestock, precision agriculture, agricultural language processing (ALP), agricultural robots (AR), plant phenotyping (PP), and postharvest quality assessment. We outline the possibilities, difficulties, constraints, and shortcomings. The study lays forth a road map of accessible areas in agriculture where LLM integration is likely to happen shortly. The research suggests exciting directions for further study in this area, which could lead to better agricultural NLP applications.}
}
@article{ARSLAN2025116276,
title = {Monitoring indoor environmental conditions in office buildings using a sustainable Agentic RAG-LLM system},
journal = {Energy and Buildings},
volume = {347},
pages = {116276},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.116276},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825010060},
author = {Muhammad Arslan and Saba Munawar and Lamine Mahdjoubi and Patrick Manu},
keywords = {Thermal Comfort Monitoring (TCM), Building Information Modeling (BIM), Sensors, Large Language Models (LLMs), Sustainable Building Management},
abstract = {Indoor Environmental Conditions (IEC) play a crucial role in determining the health, productivity, and overall building performance of employees, as well as their energy consumption. Key parameters, such as temperature and humidity, are not only vital for thermal comfort but also offer opportunities to enhance energy efficiency when effectively monitored and managed. Accurate Thermal Comfort Monitoring (TCM) remains challenging to achieve because it requires the integration of diverse data sources and intelligent analysis, particularly in light of evolving global energy and sustainability standards. Although Building Information Modeling (BIM) is increasingly being adopted to manage complex building data, its integration with real-time sensor inputs remains vastly underutilized. Existing thermal monitoring systems are often development-intensive, require significant domain expertise, lack Natural Language (NL) interaction capabilities, and are not inherently adaptable, necessitating frequent technical upgrades. These limitations give rise to pressing concerns about long-term scalability, usability, and sustainability. To address these limitations, this study introduces ThermalComfortBot, an integrated Information System (IS) powered by Generative Artificial Intelligence (GenAI). ThermalComfortBot utilizes open-source technologies, including Large Language Models (LLMs) and Agentic Retrieval-Augmented Generation (RAG), to enhance thermal comfort and support energy optimization in buildings. The system integrates Building Information Modeling (BIM), sensor data, and external datasets to generate actionable insights, delivered through both textual explanations and graphical visualizations. This system utilizes flexible and adjustable LLMs that are guided by principles of sustainability, thereby making them cost-efficient, scalable, and practical for a diverse range of organizational environments. In a real-world case study, ThermalComfortBot outperforms traditional RAG-LLM, achieving 94% accuracy, 92% precision, and 89% recall, enhancing comfort and efficiency.}
}
@article{ZHANG2025127587,
title = {Dual-archive guided multi-objective neural architecture search with decomposition},
journal = {Expert Systems with Applications},
volume = {282},
pages = {127587},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127587},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425012096},
author = {Kexin Zhang and Hao Sun and Lixin Wei and Ziyu Hu},
keywords = {Neural architecture search, Multi-objective optimization, Dual-archive, Decomposition-based optimization, Training-free metrics},
abstract = {The rapid development of generative artificial intelligence puts forward higher requirements for efficient neural network architecture design. Traditional neural architecture search (NAS) focuses on single-objective optimization, while multi-objective NAS (MONAS) needs to balance performance, parameter number, inference delay and other objectives at the same time. The existing methods based on multi-objective evolutionary algorithms often deviate from the optimal search direction due to target conflict, and rely on time-consuming weight pre-training, which seriously limits the practical application efficiency. Therefore, this paper proposes a dual-archive guided decomposition-based DANAS algorithm. The algorithm employs a dynamic decomposition strategy to map the multi-objective space into a set of subproblems. A convergence archive is utilized to preserve solutions approximating the Pareto front, while a diversity archive maintains the distribution characteristics of the solution set. The dual-archive mechanism effectively coordinates exploitation and exploration during the search process. On this basis, two training-free metrics are introduced, and an efficient variant without parameter training called TF-DANAS is proposed, which greatly reduces the search cost. In EvoXbench, NAS-Bench-101,and NAS-Bench-201 benchmark tests, DANAS algorithm obtains the optimal HV value on 57.6% of the test sets on EvoXbench. On NAS-Bench-101, the proposed method achieved a top average accuracy of 93.83% on CIFAR-10. Furthermore, it attained average accuracies of 94.34%, 73.42%, and 46.50% on CIFAR-10, CIFAR-100, and ImageNet16-120 respectively when evaluated on NAS-Bench-201.}
}
@article{MENDEZ2025101585,
title = {Comparative Analysis of Monocular Depth Generation and Camera Depth for Non-Invasive Rabbit Live Weight Estimation},
journal = {Smart Agricultural Technology},
pages = {101585},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101585},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525008160},
author = {Daniel Alexander Méndez and Carmen Cano and Alberto Martínez and Carlos Ruiz and Enrique Aguilar and Sergio Cubero and Arantxa Villagra},
keywords = {machine learning, precision livestock farming, generative artificial intelligence, deep learning, monocular depth estimation},
abstract = {In contemporary commercial rabbit farming, accurate live weight assessment is essential for efficient production management. Traditional manual weighing is labour-intensive, stressful for animals, and impractical for frequent monitoring. This study evaluates computer vision approaches for non-invasive liveweight prediction by comparing RGB, real depth, and AI-generated depth images as input modalities. A dataset of synchronized RGB and depth images was collected from 1113 weaned and near-slaughter rabbits (1.2–7.7 kg) under controlled conditions. Image segmentation was performed using YOLOv11 without fine-tuning, demonstrating its feasibility for rabbit detection. Morphological pre-processing was applied to assess its impact, while tabular features from RGB were used to train traditional models (Extra Trees, Gradient Boosting). Deep learning models EfficientNetV2, MobileNetV4, and a dual-stream fusion model were trained on RGB, camera depth, and generated depth inputs. Results show that generated depth maps match or exceed the performance of RGB, with EfficientNetV2 achieving the highest accuracy using MG_4 (Marigold monocular depth model with 4 denoise steps)-an AI-generated depth map synthesized from RGB images (R² = 0.945, RMSE = 368.36 g). In our experiments, morphological pre-processing degraded performance across all tested models and input types, suggesting that such operations may remove features information that are informative for model prediction. The fusion model achieved competitive results (R² = 0.941, RMSE = 379.935 g), but gains were marginal compared to unimodal inputs. Notably, Extra Trees achieved R² = 0.945, RMSE = 366.241 g without pre-processing, rivalling deep learning models. MobileNetV4 offered the best efficiency-accuracy trade-off (31.18 MB, 1.79 GFLOPS), making it suitable for edge deployment. These findings highlight AI-generated depth as a scalable, cost-effective alternative to hardware depth sensors and advocate for pre-processing-free pipelines in precision rabbit farming.}
}
@article{JACOBS2023,
title = {Reimagining Core Entrustable Professional Activities for Undergraduate Medical Education in the Era of Artificial Intelligence},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/50903},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000909},
author = {Sarah Marie Jacobs and Neva Nicole Lundy and Saul Barry Issenberg and Latha Chandran},
keywords = {artificial intelligence, entrustable professional activities, medical education, competency-based education, educational technology, machine learning},
abstract = {The proliferation of generative artificial intelligence (AI) and its extensive potential for integration into many aspects of health care signal a transformational shift within the health care environment. In this context, medical education must evolve to ensure that medical trainees are adequately prepared to navigate the rapidly changing health care landscape. Medical education has moved toward a competency-based education paradigm, leading the Association of American Medical Colleges (AAMC) to define a set of Entrustable Professional Activities (EPAs) as its practical operational framework in undergraduate medical education. The AAMC’s 13 core EPAs for entering residencies have been implemented with varying levels of success across medical schools. In this paper, we critically assess the existing core EPAs in the context of rapid AI integration in medicine. We identify EPAs that require refinement, redefinition, or comprehensive change to align with the emerging trends in health care. Moreover, this perspective proposes a set of “emerging” EPAs, informed by the changing landscape and capabilities presented by generative AI technologies. We provide a practical evaluation of the EPAs, alongside actionable recommendations on how medical education, viewed through the lens of the AAMC EPAs, can adapt and remain relevant amid rapid technological advancements. By leveraging the transformative potential of AI, we can reshape medical education to align with an AI-integrated future of medicine. This approach will help equip future health care professionals with technological competence and adaptive skills to meet the dynamic and evolving demands in health care.}
}
@article{ARSLAN2025106793,
title = {Empowering SMEs with SustainWater Bot to advance urban water sustainability},
journal = {Sustainable Cities and Society},
volume = {132},
pages = {106793},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106793},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725006675},
author = {Muhammad Arslan and Saba Munawar and Zainab Riaz},
keywords = {Urban water decision-making, Sustainable transitions, Small and medium-sized enterprises (SMEs), Large language models (LLMs), Retrieval-augmented generation (RAG)},
abstract = {Climate change, population growth, and resource constraints are intensifying pressure on urban water systems (UWSs), prompting a shift toward integrated information management. Due to their agility and reach, small- and medium-sized enterprises (SMEs) are central to this transition. However, many SMEs lack access to robust information systems (ISs) that consolidate government initiatives, industry trends, and broader water-related data, impeding sustainable adoption. This study introduces SustainWater Bot, a chatbot driven by generative artificial Intelligence (GenAI), including large language models (LLMs) and retrieval-augmented generation (RAG). Designed to fill this information gap, SustainWater Bot addresses the shortcomings of conventional LLMs, such as information misalignment, over-complexity, and information deficiencies. RAG enables semantic consolidation of various sources, such as news, government reports, industry insights, academic research, and social media, into an integrated IS. The evaluation results showed that RAG with LLM-based methods outperformed traditional information retrieval (IR) techniques, with Llama3.2:3b achieving top scores in precision (95 %), completeness (95 %), and exact match (90 %). Traditional IR techniques such as term frequency-inverse document frequency (TF-IDF) and best matching 25 (BM25) performed lower but offered quicker responses. SustainWater Bot supports informed decision-making through a question-answering (QA) framework that delivers relevant insights on sustainable urban water initiatives (SUWIs). It is built on open-source technologies and offers SMEs a cost-effective, scalable, and sustainable solution to enhance eco-friendly water practices and operational efficiency.}
}
@article{NABILA2025100501,
title = {Data efficiency assessment of generative adversarial networks in energy applications},
journal = {Energy and AI},
volume = {20},
pages = {100501},
year = {2025},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2025.100501},
url = {https://www.sciencedirect.com/science/article/pii/S2666546825000333},
author = {Umme Mahbuba Nabila and Linyu Lin and Xingang Zhao and William L. Gurecky and Pradeep Ramuhalli and Majdi I. Radaideh},
keywords = {Generative AI, Generative adversarial networks, Critical heat flux, Data augmentation, Power grid energy forecasting},
abstract = {This study investigates the data requirements of generative artificial intelligence (AI), particularly generative adversarial networks (GANs), for reliable data augmentation in energy applications. Generative AI, though seen as a solution to data limitations, requires substantial data to learn meaningful distributions—a challenge often overlooked. This study addresses the challenge through synthetic data generation for critical heat flux (CHF) and power grid demand, focusing on renewable and nuclear energy. Two variants of GAN employed are conditional GAN (cGAN) and Wasserstein GAN (wGAN). Our findings include the strong dependency of GAN on data size, with performance declining on smaller datasets and varying performance when generalizing to unseen experiments. Mass flux and heated length significantly influence CHF predictions. wGAN is more robust to feature exclusion, making it suitable for constrained synthetic data generation. In energy demand forecasting, wGAN performed well for solar, wind, and load predictions. Longer lookback hours and larger datasets improved predictions, especially for load power. Seasonal variations posed challenges, with wGAN achieving a relatively high error of Root Mean Squared Error (RMSE) of 0.32 for load power prediction, compared to RMSE of 0.07 under same-season conditions. Feature exclusions impacted cGAN the most, while wGAN showed greater robustness. This study concludes that, while generative AI is effective for data augmentation, it requires substantial data and careful training to generate realistic synthetic data and generalize to new experiments in engineering applications.}
}
@article{LIANG2026103792,
title = {Diffusion masked autoencoders as casual-aware curriculum learner for graph out-of-distribution generalization},
journal = {Information Fusion},
volume = {127},
pages = {103792},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103792},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008541},
author = {Jiahao Liang and Wuxing Chen and Zhiwen Yu and Tong Zhang and C. L. Philip Chen and Kaixiang Yang},
keywords = {Graph representation learning, Out-of-distribution generalization, Self-supervised learning, Generative artificial intelligence},
abstract = {Graph Out-of-Distribution (GraphOOD) problems have become increasingly important in the field of graph neural networks (GNNs). GNNs are particularly vulnerable to performance degradation when faced with distribution shifts, due to the complex interdependencies among nodes in graph data and the absence of environmental labels, which complicates ensuring model reliability. Recent advancements in computer vision have demonstrated that Diffusion Models (DMs) exhibit strong generalization capabilities, effectively capturing and generating data distributions through a stepwise denoising process. While diffusion models have shown robust generalization in other domains, particularly by capturing data distributions through iterative denoising, their application to Graph OOD problems remains limited, especially in addressing causal relationships to mitigate spurious correlations. To tackle this, we propose the Causal-aware Curriculum Diffusion Graph Masked AutoEncoder (CCD-GMAE), a novel pre-training framework for robust Graph OOD generalization. Our approach first utilizes a causal-complexity curriculum measurer to rank the causal importance of edges, followed by a self-paced mask scheduler that progressively applies causally guided diffusion. Additionally, we introduce a causal-aware diffusion masked autoencoder to address the issue of diffusion models failing to capture causal information. This model integrates causal importance into the encoding process and applies step-by-step denoising with causal regularization. The design of CCD-GMAE allows it to learn invariant, causally informed representations, thus improving robustness to distributional shifts. Extensive experiments on Graph OOD benchmarks demonstrate substantial performance improvements over existing methods. Ablation studies further confirm that our causal-guided curriculum and diffusion processes outperform traditional graph pre-training approaches in tackling Graph OOD challenges.}
}
@article{CHIA2025100468,
title = {A design-based approach to analysing student engagement with a GenAI-Enabled brainstorming app},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100468},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100468},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001080},
author = {Joanne Chia and Angela Frattarola},
keywords = {GenAI for education, Writing assistant apps, Customised apps, Personalization in technology, Student engagement, Human-AI interactions, Design thinking, Data storytelling, Technological use and innovation in institutes of higher learning, Faculty and student collaborations},
abstract = {While there are several “writing buddy” Generative Artificial Intelligence (GenAI) apps that check grammar and language usage, not many focus exclusively on enhancing the brainstorming process for writing across disciplines. To fill this gap, a team of staff and student assistants with programming and User Interface (UI) and User Experience (UX) expertise designed and prototyped a web app named “Waai,” which rhymes with ‘why,’ that could assist students throughout the writing process for a first-year general writing module for all undergraduate students at a Singaporean university. Utilising surveys, focus group discussions, and app data that shows the nature and type of student engagement with the Waai app, this paper studies the impact of one aspect of the Waai app, an uni-directional chatbot named “Nudgy,” as a first step to optimising interactions with an AI chatbot for writing purposes. Overall, we found that students were able to benefit from the GenAI chatbot Nudgy in 5 distinct ways: 1) its pre-engineered prompts, which were tailored to the course assignment rubrics; 2) its tendency to recommend topics to research rather than give students answers; 3) its suggested research topics, which helped students to consider different perspectives on their topics; 4) how it modelled ways to ideate new insights; and 5) its constant availability. Students, however, expressed reservations about the Nudgy, particularly in terms of: 1) the limitations of pre-engineered prompts within the app; 2) difficulty in discerning the most relevant of the Nudgy feedback; 3) mistrust in GenAI and Aigiarism; and 4) a recognition of the limitations of GenAI in supporting argumentative writing. “Waai” essentially presents a decision-making framework for brainstorming based on cognitive socialisation, a method of learning that emphasises inductive as opposed to deductive experience that could be applied to online environments, as an ideology of learning that considers, among other aspects, the development of selfhood, where learning is both guided and mediated (Kesebir & Gardner, 2010). In the context of asynchronous learning, meaning is not intrinsic but rather picked up through interactions on online platforms. Interacting with a chatbot with pre-designed prompts result in a ritual that both define and explore the limits of knowledge building. Symbolic interactionism (Aksan et al., 2009) through the medium of technology is a key objective of 21st century education, where ‘learning’ is internalised as an individual experience. Waai offers educatros additional understanding of the effects of personalization (Mygland et al., 2021) as proposed by this design-based study of the role of instruction in the creation of online ‘learning’ experiences. The centrality of instruction and standards of reasoning through the process of brainstorming suggests that the developmental stages of ‘learning’ concepts could empower a process for self-regulation (Zimmerman, 1989) that goes beyond immediate causes and effects to inspire a spiral of reflection and change essential to ideation.}
}
@article{HANDLER2024102811,
title = {Large language models present new questions for decision support},
journal = {International Journal of Information Management},
volume = {79},
pages = {102811},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102811},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000598},
author = {Abram Handler and Kai R. Larsen and Richard Hackathorn},
keywords = {Decision support systems, Generative artificial intelligence, Large language models, Natural language processing, Business intelligence},
abstract = {Large language models (LLMs) have proven capable of assisting with many aspects of organizational decision making, such as helping to collect information from databases and helping to brainstorm possible courses of action ahead of making a choice. We propose that broad adoption of these technologies introduces new questions in the study of decision support systems, which assist people with complex and open-ended choices in business. Where traditional study of decision support has focused on bespoke tools to solve narrow problems in specific domains, LLMs offer a general-purpose decision support technology which can be applied in many contexts. To organize the wealth of new questions which result from this shift, we turn to a classic framework from Herbert Simon, which proposes that decision making requires collecting evidence, considering alternatives, and finally making a choice. Working from Simon’s framework, we describe how LLMs introduce new questions at each stage of this decision-making process. We then group new questions into three overarching themes for future research, centered on how LLMs will change individual decision making, how LLMs will change organizational decision making, and how to design new decision support technologies which make use of the new capabilities of LLMs.}
}
@article{PFLEDERER2025e772,
title = {Development of an In-House Application that Uses Generative AI to Summarize Oncology Histories},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {123},
number = {1, Supplement },
pages = {e772-e773},
year = {2025},
note = {ASTRO 2025: 67th Annual Meeting},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2025.06.3239},
url = {https://www.sciencedirect.com/science/article/pii/S0360301625038441},
author = {T. Pflederer and Z. Zhang and E. Covington and L. Higgins and J.D. Nieto and C. Mayo and J.R. Evans},
abstract = {Purpose/Objective(s)
While the development of the electronic health record (EHR) has led to improvements in patient care and quality, EHR systems have also led to increased physician time burden for documentation. Oncology histories are complex - generating accurate, extensive histories by gathering data manually scattered throughout the EHR contributes significantly to physician workload prior to meeting the patient in consultation. Generative artificial intelligence (GenAI) has been implemented to improve efficiency, with examples including but not limited to scribing of clinical visits. We aim to utilize GenAI to automate the generation of accurate, complex oncology histories prior to initial consultation.
Materials/Methods
We developed an in-house application that pulls pertinent elements of an oncology history (imaging, pathology, clinical notes from specific subspecialties, etc.) from the enterprise EHR reporting database in health care software and summarizes it in a succinct format via an institutionally sponsored OpenAI-compatible application programming interface. We used a prompt engineering approach to distill the information into a condensed and readable format. The histories are organized into a chronological format. Prompts were iteratively developed and tailored for each oncologic disease site. For this study we initially focused on a small retrospective cohort of early-stage lung cancer and localized prostate cancer patients.
Results
We crafted 11 prompts for each component of an early-stage lung cancer oncologic history and 5 prompts for localized prostate cancer. We found that prompts asking for summarization, rather than interpretation, subjectively led to fewer errors. We found that hallucinations were possible – for example, if a radiology report does not comment on lymph nodes, this could be misinterpreted by AI as there being no evidence of lymphadenopathy. Errors like this were avoided if explicit instructions were included to only comment on what is stated in the radiology report. Multiple iterations of these prompts will be required and recorded as our retrospective patient population grows.
Conclusion
We developed a proof-of-concept GenAI custom software utility for summarizing oncology histories. We plan to continue prompt engineering to expand our retrospective cohort to those with more complex oncologic histories. Our preliminary results highlight the importance of prompt engineering to clinically optimize results from current generations of GenAI. We plan on testing, scoring, and modifying this software with real-time physician input for a larger prospective patient cohort in our department. As this is developed further, our goal is to significantly reduce the pre-consultation EHR burden on physicians.}
}
@article{SHIN2025108662,
title = {Artificial intelligence versus clinical judgement: how accurately do generative models reflect CNS guidelines for chiari malformation?},
journal = {Clinical Neurology and Neurosurgery},
volume = {248},
pages = {108662},
year = {2025},
issn = {0303-8467},
doi = {https://doi.org/10.1016/j.clineuro.2024.108662},
url = {https://www.sciencedirect.com/science/article/pii/S0303846724005493},
author = {David Shin and Hyunah Park and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Justin Dye and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Chiari malformation, Guidelines},
abstract = {Objective
This study investigated the response and readability of generative artificial intelligence (AI) models to questions and recommendations proposed by the 2023 Congress of Neurological Surgeons (CNS) guidelines for Chiari 1 malformation.
Methods
Thirteen questions were generated from CNS guidelines and asked to Perplexity, ChatGPT 4o, Microsoft Copilot, and Google Gemini. AI answers were divided into two categories, "concordant" and "non-concordant," according to their alignment with current CNS guidelines. Non-concordant answers were sub-categorized as “insufficient” or “over-conclusive.” Responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, SMOG (Simple Measure of Gobbledygook) Index, and Flesch Reading Ease test.
Results
Perplexity displayed the highest concordance rate of 69.2 %, with non-concordant responses classified as 0 % insufficient and 30.8 % over-conclusive. ChatGPT 4o had the lowest concordance rate at 23.1 %, with 0 % insufficient and 76.9 % over-conclusive classifications. Copilot showed a 61.5 % concordance rate, with 7.7 % insufficient and 30.8 % over-conclusive. Gemini demonstrated a 30.8 % concordance rate, with 7.7 % insufficient and 61.5 % as over-conclusive. Flesch-Kincaid Grade Level scores ranged from 14.48 (Gemini) to 16.48 (Copilot), Gunning Fog Index scores varied between 16.18 (Gemini) and 18.8 (Copilot), SMOG Index scores ranged from 16 (Gemini) to 17.54 (Copilot), and Flesch Reading Ease scores were low across all models, with Gemini showing the highest mean score of 21.3.
Conclusion
Perplexity and Copilot emerged as the best-performing for concordance, while ChatGPT and Gemini displayed the highest over-conclusive rates. All responses showcased high complexity and difficult readability. While AI can be valuable in certain aspects of clinical practice, the low concordance rates show that AI should not replace clinician judgement.}
}
@article{WIEDENMANN2024100591,
title = {An Immunofluorescence-Guided Segmentation Model in Hematoxylin and Eosin Images Is Enabled by Tissue Artifact Correction Using a Cycle-Consistent Generative Adversarial Network},
journal = {Modern Pathology},
volume = {37},
number = {11},
pages = {100591},
year = {2024},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100591},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224001716},
author = {Marcel Wiedenmann and Mariya Barch and Patrick S. Chang and Jennifer Giltnane and Tyler Risom and Andries Zijlstra},
keywords = {cross-modality learning, cycle-consistent generative adversarial network, deep learning, digital pathology, generative adversarial network, generative artificial intelligence, image segmentation},
abstract = {Despite recent advances, the adoption of computer vision methods into clinical and commercial applications has been hampered by the limited availability of accurate ground truth tissue annotations required to train robust supervised models. Generating such ground truth can be accelerated by annotating tissue molecularly using immunofluorescence (IF) staining and mapping these annotations to a post-IF hematoxylin and eosin (H&E) (terminal H&E) stain. Mapping the annotations between IF and terminal H&E increases both the scale and accuracy by which ground truth could be generated. However, discrepancies between terminal H&E and conventional H&E caused by IF tissue processing have limited this implementation. We sought to overcome this challenge and achieve compatibility between these parallel modalities using synthetic image generation, in which a cycle-consistent generative adversarial network was applied to transfer the appearance of conventional H&E such that it emulates terminal H&E. These synthetic emulations allowed us to train a deep learning model for the segmentation of epithelium in terminal H&E that could be validated against the IF staining of epithelial-based cytokeratins. The combination of this segmentation model with the cycle-consistent generative adversarial network stain transfer model enabled performative epithelium segmentation in conventional H&E images. The approach demonstrates that the training of accurate segmentation models for the breadth of conventional H&E data can be executed free of human expert annotations by leveraging molecular annotation strategies such as IF, so long as the tissue impacts of the molecular annotation protocol are captured by generative models that can be deployed prior to the segmentation process.}
}
@article{NAZAR2025,
title = {How to Design, Create, and Evaluate an Instruction-Tuning Dataset for Large Language Model Training in Health Care: Tutorial From a Clinical Perspective},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/70481},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125003863},
author = {Wojciech Nazar and Grzegorz Nazar and Aleksandra Kamińska and Ludmila Danilowicz-Szymanowicz},
keywords = {generative artificial intelligence, large language models, instruction-tuning datasets, tutorials, evaluation framework, health care},
abstract = {High-quality data are critical in health care, forming the cornerstone for accurate diagnoses, effective treatment plans, and reliable conclusions. Similarly, high-quality datasets underpin the development and performance of large language models (LLMs). Among these, instruction-tuning datasets (ITDs) used for instruction fine-tuning have been pivotal in enhancing LLM performance and generalization capabilities across diverse tasks. This tutorial provides a comprehensive guide to designing, creating, and evaluating ITDs for health care applications. Written from a clinical perspective, it aims to make the concepts accessible to a broad audience, especially medical practitioners. Key topics include identifying useful data sources, defining the characteristics of well-designed datasets, and crafting high-quality instruction-input-output examples. We explore practical approaches to dataset construction, examining the advantages and limitations of 3 primary methods: fully manual preparation by expert annotators, fully synthetic generation using artificial intelligence (AI), and an innovative hybrid approach in which experts draft the initial dataset and AI generates additional data. Moreover, we discuss strategies for metadata selection and human evaluation to ensure the quality and effectiveness of ITDs. By integrating these elements, this tutorial provides a structured framework for establishing ITDs. It bridges technical and clinical domains, supporting the continued interdisciplinary advancement of AI in medicine. Additionally, we address the limitations of current practices and propose future directions, emphasizing the need for a global, unified framework for ITDs. We also argue that artificial general intelligence (AGI), if realized, will not replace empirical research in medicine. AGI will depend on human-curated datasets to process and apply medical knowledge. At the same time, ITDs will likely remain the most effective method of supplying this knowledge to AGI, positioning them as a critical tool in AI-driven health care.}
}
@article{GONG2025132587,
title = {TCWD: Temporal compressive coherent diffraction imaging enhanced by weighted wavelet domain diffusion model},
journal = {Optics Communications},
pages = {132587},
year = {2025},
issn = {0030-4018},
doi = {https://doi.org/10.1016/j.optcom.2025.132587},
url = {https://www.sciencedirect.com/science/article/pii/S0030401825011150},
author = {Rundong Gong and Dingxiang Yuan and Yaolong Fa and Xianghong Zou and Tianshui Yu and Wenbo Wan and Qiegen Liu},
keywords = {Coherent diffraction imaging, Prior learning, Weighted wavelet domain, Image reconstruction, Generative diffusion model},
abstract = {ABSTRACT
Temporal compressive coherent diffraction imaging is a lensless imaging technique that enables the visualization of dynamic processes in coherent diffraction imaging by compressively sampling snapshots in the frequency domain. Although generative artificial intelligence, represented by diffusion models, improves reconstruction quality, it remains less effective in handling complex targets. To enhance reconstruction quality, this study proposes temporal compressive coherent diffraction imaging enhanced by a weighted wavelet domain diffusion model (TCWD). A frequency domain diffusion model in the weighted wavelet domain is introduced to balance high- and low-frequency components while enhancing image details. A spatial domain diffusion model is also employed to reduce distortions and artifacts. These learned priors jointly guide the iterative hybrid input-output algorithm, improving reconstruction accuracy and maintaining model interpretability. Validation on the Fashion MNIST, Quick Draw datasets and measured data demonstrate that the proposed TCWD algorithm accurately reconstructs dynamic targets with complex structural features. Compared to state-of-the-art methods, TCWD achieves more detailed reconstruction, better artifact suppression, and improved structural integrity, with an average PSNR of 28.14 dB and SSIM of 0.970.}
}
@article{PAN2025100991,
title = {Effects of GenAI-empowered interactive support on university EFL students' self-regulated strategy use and engagement in reading},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100991},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2024.100991},
url = {https://www.sciencedirect.com/science/article/pii/S1096751624000538},
author = {Mengru Pan and Chun Lai and Kai Guo},
keywords = {Artificial intelligence, Self-regulated learning, EFL learners, Reading engagement, Chatbots},
abstract = {Reading poses challenges for learners of English as a foreign language (EFL), as it requires strategic engagement with the text through an interactive meaning-making process. Self-regulated learning (SRL) training, which helps learners develop the ability to make strategic efforts to manage their reading process and maintain engagement in reading, has been increasingly used to assist EFL learners. However, one limitation of existing SRL training is the lack of interactive personalised support tailored to the specific needs of individual students. Recent developments in generative artificial intelligence (GenAI) may help address this limitation. This study explores how interactive personalised SRL support via a GenAI chatbot might affect university EFL learners' self-regulated strategy use and engagement in reading. Sixty-one Chinese EFL students from two classes at a university received a 45-min training session on SRL in reading and then engaged in a 12-week self-directed reading using an online reading platform embedded with SRL support. One class (the experimental group, N = 31) had access to the chatbot on the platform to support their self-regulated reading, while the other class (the control group, N = 30) received no chatbot assistance on the platform. Self-regulated reading strategy use and reading engagement were assessed through pre- and post-questionnaires, log data on the platform, and semi-structured interviews. It was found that the intervention significantly improved students' self-regulated reading strategy use and reading engagement, indicating the positive effect of GenAI-enabled interactive personalised SRL support. This study substantiates the value of interactive SRL support in the context of EFL reading.}
}
@article{CAHYANA2024100078,
title = {Application of ChatGPT in soil science research and the perceptions of soil scientists in Indonesia},
journal = {Artificial Intelligence in Geosciences},
volume = {5},
pages = {100078},
year = {2024},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2666544124000194},
author = {Destika Cahyana and Agus Hadiarto and  Irawan and Diah Puspita Hati and Mira Media Pratamaningsih and Vicca Karolinoerita and Anny Mulyani and  Sukarman and Muhammad Hikmat and Fadhlullah Ramadhani and Rachmat Abdul Gani and Edi Yatno and R. Bambang Heryanto and  Suratman and Nuni Gofar and Abraham Suriadikusumah},
keywords = {Artificial intelligence, ChatGPT, Soil science, Tools, Paradigm},
abstract = {Since its arrival in late November 2022, ChatGPT-3.5 has rapidly gained popularity and significantly impacted how research is planned, conducted, and published using a generative artificial intelligence approach. ChatGPT-4 was released four months later and became more popular in November 2023. However, there is little study about the perception of scientists of these chatbots, especially in soil science. This article presents the new findings of a brief research investigating soil scientists' responses and perceptions towards chatbots in Indonesia. This artificial intelligence application facilitates conversation-based interactions in text format. The study evaluated ten ChatGPT answers to fundamental questions in soil science, which has developed into a normal science with a mutually agreed-upon paradigm. The evaluation was carried out by seven soil scientists recognized for their expertise in Indonesia, using a scale of 1–100. In addition, a questionnaire was distributed to soil scientists at the National Research and Innovation Agency of the Republic of Indonesia (BRIN), universities, and Indonesian Soil Science Society (HITI) members to gauge their perception of ChatGPT's presence in the research field. The study results indicate that the scores of ChatGPT answers range from 82.99 to 92.24. ChatGPT-4 is better than both the paid and free versions of ChatGPT-3.5. There is no significant difference between the English and Indonesian versions of ChatGPT-4.0. However, the perception of general soil scientists about the level of trust is only 55%. Furthermore, 80% of soil scientists believe that chatbots can only be used as digital tools to assist in soil science research and cannot be used without the involvement of soil scientists.}
}
@incollection{NAYYAR2025241,
title = {Chapter 9 - Prompt engineering: Ethical considerations and challenges},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {241-264},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00002-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000021},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {Biasing, Cyber-attacks, Generative AI, Intellectual property},
abstract = {Generative artificial intelligence (AI) stands at the forefront of technological innovation, yet it remains an evolving domain where prompt engineering plays a pivotal role in shaping the quality and accuracy of model outputs. This chapter serves as both an introduction and an explainer, emphasizing the critical need to address ethical considerations surrounding AI performance, especially as these technologies permeate diverse sectors. The chapter delves into pressing issues of bias and fairness, highlighting how historical biases in training data can lead to discriminatory outcomes in AI applications. This necessitates vigilant monitoring to mitigate such risks effectively. Furthermore, the discussion encompasses privacy and security concerns related to data handling, underscoring the importance of user confidentiality. Central themes of transparency and accountability emerge, advocating for clear communication regarding the capabilities and limitations of AI systems. We propose the establishment of moral standards that unite AI developers and users in a shared commitment to responsible practices. When AI predictions are made, accountability must be ensured through transparent logic that is open to scrutiny, fostering ethical norms within organizations. The chapter also addresses the unique challenges faced by small and medium-sized enterprises (SMEs) in adopting generative AI, offering insights into the specific risks they may encounter. By maintaining a focus on ethical considerations, this chapter aims to provide practitioners in prompt engineering with a comprehensive understanding of the implications of their work. Ultimately, it calls for collaborative efforts to define and uphold clear ethical standards that will facilitate the responsible development and application of generative AI technologies, enabling progress that benefits all stakeholders.}
}
@article{MAHMOUDI2025,
title = {Critical Assessment of Large Language Models’ (ChatGPT) Performance in Data Extraction for Systematic Reviews: Exploratory Study},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/68097},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000705},
author = {Hesam Mahmoudi and Doris Chang and Hannah Lee and Navid Ghaffarzadegan and Mohammad S Jalali},
keywords = {large language models, generative artificial intelligence, systematic reviews, evidence synthesis, human-AI collaboration},
abstract = {Background
Systematic literature reviews (SLRs) are foundational for synthesizing evidence across diverse fields and are especially important in guiding research and practice in health and biomedical sciences. However, they are labor intensive due to manual data extraction from multiple studies. As large language models (LLMs) gain attention for their potential to automate research tasks and extract basic information, understanding their ability to accurately extract explicit data from academic papers is critical for advancing SLRs.
Objective
Our study aimed to explore the capability of LLMs to extract both explicitly outlined study characteristics and deeper, more contextual information requiring nuanced evaluations, using ChatGPT (GPT-4).
Methods
We screened the full text of a sample of COVID-19 modeling studies and analyzed three basic measures of study settings (ie, analysis location, modeling approach, and analyzed interventions) and three complex measures of behavioral components in models (ie, mobility, risk perception, and compliance). To extract data on these measures, two researchers independently extracted 60 data elements using manual coding and compared them with the responses from ChatGPT to 420 queries spanning 7 iterations.
Results
ChatGPT’s accuracy improved as prompts were refined, showing improvements of 33% and 23% between the initial and final iterations for extracting study settings and behavioral components, respectively. In the initial prompts, 26 (43.3%) of 60 ChatGPT responses were correct. However, in the final iteration, ChatGPT extracted 43 (71.7%) of the 60 data elements, showing better performance in extracting explicitly stated study settings (28/30, 93.3%) than in extracting subjective behavioral components (15/30, 50%). Nonetheless, the varying accuracy across measures highlighted its limitations.
Conclusions
Our findings underscore LLMs’ utility in extracting basic as well as explicit data in SLRs by using effective prompts. However, the results reveal significant limitations in handling nuanced, subjective criteria, emphasizing the necessity for human oversight.}
}
@article{HASSANIPOUR2024,
title = {The Ability of ChatGPT in Paraphrasing Texts and Reducing Plagiarism: A Descriptive Analysis},
journal = {JMIR Medical Education},
volume = {10},
year = {2024},
issn = {2369-3762},
doi = {https://doi.org/10.2196/53308},
url = {https://www.sciencedirect.com/science/article/pii/S2369376224000783},
author = {Soheil Hassanipour and Sandeep Nayak and Ali Bozorgi and Mohammad-Hossein Keivanlou and Tirth Dave and Abdulhadi Alotaibi and Farahnaz Joukar and Parinaz Mellatdoust and Arash Bakhshi and Dona Kuriyakose and Lakshmi D Polisetty and Mallika Chimpiri and Ehsan Amini-Salehi},
keywords = {ChatGPT, paraphrasing, text generation, prompts, academic journals, plagiarize, plagiarism, paraphrase, wording, LLM, LLMs, language model, language models, prompt, generative, artificial intelligence, NLP, natural language processing, rephrase, plagiarizing, honesty, integrity, texts, text, textual, generation, large language model, large language models},
abstract = {Background
The introduction of ChatGPT by OpenAI has garnered significant attention. Among its capabilities, paraphrasing stands out.
Objective
This study aims to investigate the satisfactory levels of plagiarism in the paraphrased text produced by this chatbot.
Methods
Three texts of varying lengths were presented to ChatGPT. ChatGPT was then instructed to paraphrase the provided texts using five different prompts. In the subsequent stage of the study, the texts were divided into separate paragraphs, and ChatGPT was requested to paraphrase each paragraph individually. Lastly, in the third stage, ChatGPT was asked to paraphrase the texts it had previously generated.
Results
The average plagiarism rate in the texts generated by ChatGPT was 45% (SD 10%). ChatGPT exhibited a substantial reduction in plagiarism for the provided texts (mean difference −0.51, 95% CI −0.54 to −0.48; P<.001). Furthermore, when comparing the second attempt with the initial attempt, a significant decrease in the plagiarism rate was observed (mean difference −0.06, 95% CI −0.08 to −0.03; P<.001). The number of paragraphs in the texts demonstrated a noteworthy association with the percentage of plagiarism, with texts consisting of a single paragraph exhibiting the lowest plagiarism rate (P<.001).
Conclusion
Although ChatGPT demonstrates a notable reduction of plagiarism within texts, the existing levels of plagiarism remain relatively high. This underscores a crucial caution for researchers when incorporating this chatbot into their work.}
}
@article{QORICH2025128405,
title = {Detection of artificial intelligence-generated essays for academic assessment integrity using large language models},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128405},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128405},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502024X},
author = {Mohammed Qorich and Rajae {El Ouazzani}},
keywords = {Artificial intelligence (AI), AI-Generated essays detection, Automatic optimization, ChatGPT, Education, Large language models (LLMs), Plagiarism detection},
abstract = {Across various fields of human life, the lightning adoption of generative artificial intelligence (AI) tools is driven by their ease of use and ability to produce high-quality outputs, transforming communication and productivity. However, the growing popularity and influence of models such as ChatGPT have raised concerns in education regarding academic integrity, as AI-generated content challenges the authenticity of student work and complicates traditional assessment practices. Existing plagiarism detection tools, such as Turnitin and GPTZero, attempt to identify AI-generated content; however, their reliability remains limited, as most struggle to accurately differentiate between human and AI essays. To address existing tools limitations, we propose a novel detection model leveraging three large language models (LLMs): Generative Pre-trained Transformer 2 (GPT-2), Robustly Optimized BERT Pretraining Approach (RoBERTa), and Bidirectional and Auto-Regressive Transformers (BART). We first fine-tuned each model on two large-scale datasets to evaluate their effectiveness in distinguishing between human and AI-generated essays. To further enhance the performance, we applied both manual and automated hyperparameter optimization techniques, including Random Search, Grid Search, and Bayesian Optimization. Building on these experiments, we developed our BART-CNN model, which incorporates the best-performing BART configuration with an additional convolutional head classifier. Our BART-CNN model achieved impressive Macro F1-scores of 99.78 % and 98.10 % on the Kaggle and Hugging Face datasets, respectively, and demonstrated significant performance gains over baseline methods in cross-domain validation. Our study offers a critical advancement in AI plagiarism detection, helping to uphold academic standards and the assessment quality in an evolving AI landscape.}
}
@article{NODA2025,
title = {Exploring Generative Pre-Trained Transformer-4-Vision for Nystagmus Classification: Development and Validation of a Pupil-Tracking Process},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/70070},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005001},
author = {Masao Noda and Ryota Koshu and Reiko Tsunoda and Hirofumi Ogihara and Tomohiko Kamo and Makoto Ito and Hiroaki Fushiki},
keywords = {nystagmus, GPT-4Vision, generative AI, deep learning, dizziness, artificial intelligence},
abstract = {Background
Conventional nystagmus classification methods often rely on subjective observation by specialists, which is time-consuming and variable among clinicians. Recently, deep learning techniques have been used to automate nystagmus classification using convolutional and recurrent neural networks. These networks can accurately classify nystagmus patterns using video data. However, associated challenges including the need for large datasets when creating models, limited applicability to address specific image conditions, and the complexity associated with using these models.
Objective
This study aimed to evaluate a novel approach for nystagmus classification that used the Generative Pre-trained Transformer 4 Vision (GPT-4V) model, which is a state-of-the-art large-scale language model with powerful image recognition capabilities.
Methods
We developed a pupil-tracking process using a nystagmus-recording video and verified the optimization model’s accuracy using GPT-4V classification and nystagmus recording. We tested whether the created optimization model could be evaluated in six categories of nystagmus: right horizontal, left horizontal, upward, downward, right torsional, and left torsional. The traced trajectory was input as two-dimensional coordinate data or an image, and multiple in-context learning methods were evaluated.
Results
The developed model showed an overall classification accuracy of 37% when using pupil-traced images and a maximum accuracy of 24.6% when pupil coordinates were used as input. Regarding orientation, we achieved a maximum accuracy of 69% for the classification of horizontal nystagmus patterns but a lower accuracy for the vertical and torsional components.
Conclusions
We demonstrated the potential of versatile vertigo management in a generative artificial intelligence model that improves the accuracy and efficiency of nystagmus classification. We also highlighted areas for further improvement, such as expanding the dataset size and enhancing input modalities, to improve classification performance across all nystagmus types. The GPT-4V model validated only for recognizing still images can be linked to video classification and proposed as a novel method.}
}
@incollection{CHEN202537,
title = {Chapter Two - Game changer: Navigating between challenges and hopes in geropharmacology},
editor = {Mehmet Can Atayik and Ufuk Çakatay},
series = {Advances in Pharmacology},
publisher = {Academic Press},
volume = {104},
pages = {37-85},
year = {2025},
booktitle = {Theoretical and Clinical Geropharmacology},
issn = {1054-3589},
doi = {https://doi.org/10.1016/bs.apha.2025.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1054358925000481},
author = {Qian Chen and Reid Hartman and Lidia Dankiv and Emily Yan and Lindon Young and Robert Barsotti},
keywords = {Geropharmacology, Aging, Heterogeneity, Plasticity, Aging-associated diseases, Inflammation, Cell senescence, Stem cell, Mitochondrial dysfunction, Nicotinamide adenine dinucleotide, Metformin, Rapamycin, Senolytics, Incretin mimetics, Artificial intelligence},
abstract = {The aging population is expanding rapidly to reshape the social and economic structures. Aging signifies the close to the end of life and threatens health because it features unavoidable compression of body reserve and gradual suppression of organ function. Tremendous research has established twelve essential aging hallmarks that shed light on mitigation frameworks. Interestingly, aging harbors inherent heterogeneity and plasticity, reflecting its multifaceted nature. Additionally, age-related diseases, such as cardiovascular and neurodegenerative diseases, often undergo the exact mechanisms with more devastating damage and speed. Therefore, interventions to promote healthy aging improve life quality and delay the disease’s prevalence to later age. Clinical studies in humans have demonstrated the potential of several interventions, including lifestyle modifications, NAD+ supplementation, gut microbiota modulation, antidiabetic drugs (e.g., metformin), rapamycin, and senolytics, to mitigate the aging process and delay the onset of age-related diseases. Remarkably, clinical trials exhibit heterogeneity by showing substantial inter-individual differences in response to the interventions. It is often attributed to basal health status, tissue senescent burden, and immunity level. Continuous research would validate these correlations and solidify the personalized approaches. Lastly, generative artificial intelligence can pave a promising avenue to revolutionize anti-aging research and tailor aging management to promote healthy aging and extend health span.}
}
@article{IGNACZ2023100040,
title = {Data-driven future for nanofiltration: Escaping linearity},
journal = {Journal of Membrane Science Letters},
volume = {3},
number = {1},
pages = {100040},
year = {2023},
issn = {2772-4212},
doi = {https://doi.org/10.1016/j.memlet.2023.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2772421223000041},
author = {Gergo Ignacz and Aron K. Beke and Gyorgy Szekely},
keywords = {Machine learning, Big data, Inverse design, Data science, Process analytical technologies},
abstract = {Compared with traditional membrane separation methods such as distillation and chromatography, nanofiltration (NF) affords decreased waste generation and energy consumption. Despite the multiple advantages of NF and materials available for NF membranes, the industrial applicability of this process requires improvement. To address these challenges, we propose four important pillars for the future of membrane materials and process development. These four pillars are digitalization, structure–property analysis, miniaturization, and automation. We fill gaps in the development of NF membranes and processes by fostering the most promising contemporary technologies, e.g., the integration of process analytical technologies and the development of a parallel artificial nanofiltration permeability assay (PANPA) or large online databases. Moreover, we propose the extensive use of density functional theory-aided structure–property relationship methods to understand solute transport process at a molecular level. Realizing an inverse design would allow researchers and industrial scientists to develop custom membranes for specific applications using optimized properties.}
}
@article{CURRY2024100082,
title = {Generative AI for corpus approaches to discourse studies: A critical evaluation of ChatGPT},
journal = {Applied Corpus Linguistics},
volume = {4},
number = {1},
pages = {100082},
year = {2024},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2023.100082},
url = {https://www.sciencedirect.com/science/article/pii/S2666799123000424},
author = {Niall Curry and Paul Baker and Gavin Brookes},
keywords = {ChatGPT, Corpus linguistics, Discourse analysis, Generative AI, Qualitative analysis},
abstract = {This paper explores the potential of generative artificial intelligence technology, specifically ChatGPT, for advancing corpus approaches to discourse studies. The contribution of artificial intelligence technologies to linguistics research has been transformational, both in the contexts of corpus linguistics and discourse analysis. However, shortcomings in the efficacy of such technologies for conducting automated qualitative analysis have limited their utility for corpus approaches to discourse studies. Acknowledging that new technologies in data analysis can replace and supplement existing approaches, and in view of the potential affordances of ChatGPT for automated qualitative analysis, this paper presents three replication case studies designed to investigate the applicability of ChatGPT for supporting automated qualitative analysis within studies using corpus approaches to discourse analysis. The findings indicate that, generally, ChatGPT performs reasonably well when semantically categorising keywords; however, as the categorisation is based on decontextualised keywords, the categories can appear quite generic, limiting the value of such an approach for analysing corpora representing specialised genres and/or contexts. For concordance analysis, ChatGPT performs poorly, as the results include false inferences about the concordance lines and, at times, modifications of the input data. Finally, for function-to-form analysis, ChatGPT also performs poorly, as it fails to identify and analyse direct and indirect questions. Overall, the results raise questions about the affordances of ChatGPT for supporting automated qualitative analysis within corpus approaches to discourse studies, signalling issues of repeatability and replicability, ethical challenges surrounding data integrity, and the challenges associated with using non-deterministic technology for empirical linguistic research.}
}
@article{CHAN2026101147,
title = {Between pause and pulse: How travel time shapes opt-out preferences in Hong Kong’s urban street experiments},
journal = {Travel Behaviour and Society},
volume = {42},
pages = {101147},
year = {2026},
issn = {2214-367X},
doi = {https://doi.org/10.1016/j.tbs.2025.101147},
url = {https://www.sciencedirect.com/science/article/pii/S2214367X25001656},
author = {Ho-Yin Chan and Chloe Lai and Enrica Papa and Anthony Chen},
keywords = {Urban street experiment, Travel time trade-offs, Generative AI visualizations, Discrete choice experiments, Landscape preference},
abstract = {Street experimental interventions are increasingly used to test alternative street functions, yet their impacts on travel time and their trade-offs with aesthetic and social benefits remain poorly quantified, particularly in dense urban environments. Existing approaches rely heavily on qualitative, trial-and-error experimentation, offering limited empirical guidance for intervention design. This study introduces a quantitative framework combining generative artificial intelligence (GenAI) and stated preference modeling to assess public acceptance of street experiments in Hong Kong. GenAI-produced photorealistic visualizations were used in a survey of 150 participants (1,200 observations). A nested logit model was estimated, extending the multinomial logit (MNL) approach by relaxing the Independence of Irrelevant Alternatives (IIA) property inherited from MNL. This structure captures correlated preferences among intervention types while treating the opt-out alternative as a distinct manifestation of status quo bias. Preferences were examined across road types (alleys, pavements, minor, major), temporality (temporary vs. permanent, time of day), intervention forms (bike lanes, shared spaces, pocket parks, outdoor dining), and travel time impacts. Results indicate strong aversion to travel time disruptions, with even minor delays significantly reducing acceptance. Visually appealing, socially vibrant interventions featuring seating and greenery are preferred, while bike-related infrastructure encounters cultural and spatial resistance. Opt-out behavior is particularly pronounced among older adults, residents of high-density areas, individuals with lower educational attainment, and frequent public transport users, reflecting heightened time sensitivity, space constraints, and reliance on existing transit networks. Findings underscore the importance of explicitly modeling opt-out choices and provide a transferable, data-driven framework for designing incremental and socially accepted street experiments suited to high-density Asian cities, thereby advancing the evidence base for tactical urbanism.}
}
@article{DUIVENVOORDE2025106141,
title = {Generative AI and the future of marketing: A consumer protection perspective},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106141},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106141},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000148},
author = {Bram Duivenvoorde},
keywords = {Generative AI, Marketing, Synthetic advertising, Consumer protection, Unfair commercial practices, Artificial Intelligence Act, Digital Services Act},
abstract = {Generative AI has the potential to be the biggest disruption in marketing since the emergence of digital commerce in the early 2000s. This article will focus on three ways in which generative AI is expected to change marketing. First, generative AI enables companies to automatically create advertising copy and images, potentially leading to significant cost reductions. Secondly, generative AI offers possibilities to improve and automate personalised marketing, potentially enabling companies to send the right persuasive message at the right time to each potential customer. Thirdly, generative AI potentially offers possibilities to market products to consumers via generative AI chatbots. These developments offer potential advantages but also bear risks for consumers. For example, deepfakes in advertising can mislead consumers, AI-generated personalised marketing can exploit consumer vulnerabilities, and B2C chatbots can deceive consumers by providing biased advice. This article shows that EU law does in principle provide protection to consumers in relation to AI-generated marketing, but is also likely to fall short in effectively protecting consumers against the identified risks in several ways.}
}
@article{PRUSTY2024111714,
title = {Enhancing medical image classification with generative AI using latent denoising diffusion probabilistic model and wiener filtering approachImage 1},
journal = {Applied Soft Computing},
volume = {161},
pages = {111714},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111714},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624004885},
author = {Manas Ranjan Prusty and Rohit Madhavan Sudharsan and Philip Anand},
keywords = {Latent Diffusion, Generative Modelling, Deep Learning, Synthetic Data Generation, Medical Imaging},
abstract = {In the evolving landscape of medical diagnostics, a paradigm shift is being catalysed by the advent of generative artificial intelligence. Medical X-ray, CT and MRI images are essential diagnostic tools used by healthcare professionals to assess various musculoskeletal conditions. However, obtaining a sufficient number of medical images for training deep learning models can be challenging due to limited access to labelled data. Hence, the authors propose a novel Latent diffusion process for synthesizing medical images that closely resemble real patient images, aiming to address the challenge of limited access to labelled data in medical diagnostics. Leveraging deep learning and generative modelling techniques, this method synthesizes high-fidelity images that closely mimic real patient scans. By introducing noise and subsequently training the model to denoise, the approach captures intricate patterns inherent in authentic medical images. Among the four datasets utilized, the Diabetes Retinopathy dataset demonstrates superior performance, achieving the highest Mean Structural Similarity Index (MSSIM) score of 0.57 (compared to the dataset baseline of 0.62) and an accuracy of 93.75% when passed through the proposed pipeline. The Cataract dataset, registered a MSSIM score of 0.51 (versus the dataset baseline of 0.53) and an accuracy score of 97.52%, while the Knee OA dataset follows closely with MSSIM and accuracy scores of 0.65 (in contrast to the dataset baseline of 0.63) and 68.66% respectively. The results obtained are then compared with the results generated by the other state of the art models.}
}
@article{EBNALIHARARI2025105701,
title = {A randomized controlled trial on evaluating clinician-supervised generative AI for decision support},
journal = {International Journal of Medical Informatics},
volume = {195},
pages = {105701},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105701},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624003642},
author = {Rayan {Ebnali Harari} and Abdullah Altaweel and Tareq Ahram and Madeleine Keehner and Hamid Shokoohi},
keywords = {Telemedicine, AI, ChatGPT, Clinician supervision of AI, Trust, Technology acceptance},
abstract = {Background
The integration of generative artificial intelligence (AI) as clinical decision support systems (CDSS) into telemedicine presents a significant opportunity to enhance clinical outcomes, yet its application remains underexplored.
Objective
This study investigates the efficacy of one of the most common generative AI tools, ChatGPT, for providing clinical guidance during cardiac arrest scenarios.
Methods
We examined the performance, cognitive load, and trust associated with traditional methods (paper guide), autonomous ChatGPT, and clinician-supervised ChatGPT, where a clinician supervised the AI recommendations. Fifty-four subjects without medical backgrounds participated in randomized controlled trials, each assigned to one of three intervention groups: paper guide, ChatGPT, or supervised ChatGPT. Participants completed a standardized CPR scenario using an Augmented Reality (AR) headset, and performance, physiological, and self-reported metrics were recorded.
Main Findings
Results indicate that the Supervised-ChatGPT group showed significantly higher decision accuracy compared to the paper guide and ChatGPT groups, although the scenario completion time was longer. Physiological data showed a reduced LF/HF ratio in the Supervised-ChatGPT group, suggesting potentially lower cognitive load. Trust in AI was also highest in the supervised condition. In one instance, ChatGPT suggested a risky option, highlighting the need for clinician supervision.
Conclusion
Our findings highlight the potential of supervised generative AI to enhance decision-making accuracy and user trust in emergency healthcare settings, despite trade-offs with response time. The study underscores the importance of clinician oversight and the need for further refinement of AI systems to improve safety. Future research should explore strategies to optimize AI supervision and assess the implementation of these systems in real-world clinical settings.}
}
@article{HUY2024100295,
title = {Appraisal model on how accounting data analytics impacts public sector sustainability reporting},
journal = {Sustainable Futures},
volume = {8},
pages = {100295},
year = {2024},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2024.100295},
url = {https://www.sciencedirect.com/science/article/pii/S2666188824001448},
author = {Pham Quang Huy and Vu Kien Phuc},
keywords = {Accounting information system, Artificial intelligence, Large language model, Internal control, Sustainability reporting},
abstract = {The current manuscript establishes and validates a conceptual framework that focuses on the correlation between accounting data analytics (ADA) and the quality of digital sustainability reporting (QDSR). Moreover, it aims to examine how the sustainable green internal control system (SGICS) facilitates the relationship between ADA and QDSR. The current manuscript employed a three-pronged methodology comprising of expert interviews, a literature review, and a self-administered survey, in sequential sequence. To determine the measuring scales and relevant concerns, the qualitative methodology originally involved conducting several semi-structured interviews with specialists and doing a thorough examination of the relevant literature. In the quantitative phase, statistical data were collected by two-wave paper-and-pencil surveys given to respondents in Vietnamese public sector organizations. The survey was conducted using a snowball and convenience sampling method. The data analysis was conducted utilizing the Partial Least Squares Structural Equation Modeling (PLS-SEM) technique with the assistance of SmartPLS 4.1.0.3. The statistical results validated the significantly positive connection between ADA and QDSR. This link was partially mediated by SGICS.}
}
@article{ISSA2024e38759,
title = {A teamwork framework for preventing breaches of academic integrity and improving students’ collaborative skills in the AI era},
journal = {Heliyon},
volume = {10},
number = {19},
pages = {e38759},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e38759},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024147901},
author = {Tomayess Issa and Mahnaz Hall},
keywords = {Teamwork assessment, Self/peer evaluation, Teamwork framework, AI, Academic integrity},
abstract = {Generative artificial intelligence (AI) tools have become a major challenge in the education sector in terms of the way that students use and manage them. This study examines the development, implementation, and evaluation of a teamwork framework by using academic integrity standards and formative feedback to minimise the use of generative AI tools in the Business Project Management (BPM) unit and promote students' learning skills through teamwork and self/peer evaluation. This teamwork assessment was designed to transform students into independent learners by improving their cultural awareness, self-confidence, teamwork, communication, leadership, as well as personal and interpersonal skills. The study's objectives are to determine whether a teamwork framework can help to maintain academic integrity and transform BPM students into independent learners and leaders in the era of generative AI, and to determine whether lecturers' formative feedback enhances students' skills in teamwork assessment. This research comprises an empirical study of 408 local and international BPM students from different cultural backgrounds. A mixed-methods approach was used to collect data and achieve a broader perspective of the research topic. BPM students reported their satisfaction with this type of assessment since it helped them acquire skills such as intercultural effectiveness and teamwork. Following the implementation of the teamwork framework, the number of instances of academic misconduct and requests for extensions have decreased dramatically, while the assessment's average marks increased by 10 %. A set of recommendations is offered that will ensure the successful implementation of the proposed framework for teamwork assessment and self/peer evaluation. This study was limited to the Business Project Management unit, but in 2024, the same study will be conducted involving other postgraduate units at Curtin University with a future rollout in other universities to compare how students perceive teamwork assessment.}
}
@article{LOTHERINGTON2024525,
title = {Exploring opportunities for language immersion in the posthuman spectrum: lessons learned from digital agents},
journal = {Interactive Technology and Smart Education},
volume = {22},
number = {4},
pages = {525-547},
year = {2024},
issn = {1741-5659},
doi = {https://doi.org/10.1108/ITSE-02-2024-0038},
url = {https://www.sciencedirect.com/science/article/pii/S1741565924000145},
author = {Heather Lotherington and Mark Pegrum and Kurt Thumlert and Brittany Tomin and Taylor Boreland and Tanya Pobuda},
keywords = {Artificial intelligence (AI), Conversational AI, Generative AI, Mobile-assisted language learning (MALL), Posthumanist applied linguistics},
abstract = {Purpose
Technologically-enhanced language education has shifted from computer-assisted language learning (CALL) to mobile-assisted language learning (MALL), including the use of conversational digital agents, and more recently, towards the use of generative artificial intelligence (AI) large language model (LLM) programmes for language learning purposes. This paper aims to explore the interplay between such posthuman communication and posthumanist applied linguistics, and between digital agents and human agency in response to the increasing permeation of AI in life and learning.
Design/methodology/approach
A core team of four researchers investigated how digital agents could be leveraged to support immersive target language learning and practice, focusing specifically on the conversational AI that pervaded digitally-mediated communication prior to the release of generative AI. Each researcher engaged in a digital autoethnography using conversational agents found in the digital wilds to learn a target second language via digital immersion.
Findings
Through qualitative data analysis of autoethnographic narratives using NVIVO, four key thematic codes characterizing the learning journeys emerged: context, language learning, posthuman engagement and technological parameters. The posthuman learning experiences conflicted with the multisensory, embodied and embedded ethos of posthumanist applied linguistics, indicating that informed human pedagogical agency must crucially be exercised to benefit from the learning potential of posthuman agents. Interactions with conversational agents did provide small-scale, just-in-time learning opportunities, but these fell short of immersive learning.
Originality/value
The methodology and findings offer a unique and valuable lens on the language learning potential of emerging LLM-based generative agents that are rapidly infusing conversational practices.}
}
@article{ZHANG2025115116,
title = {Automatic building energy model development and debugging using large language models agentic workflow},
journal = {Energy and Buildings},
volume = {327},
pages = {115116},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115116},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824012325},
author = {Liang Zhang and Vitaly Ford and Zhelun Chen and Jianli Chen},
keywords = {Building energy modeling, Complex system modeling, Large language model, Generative artificial intelligence, Agentic workflow},
abstract = {Building energy modeling (BEM) is a complex process that demands significant time and expertise, limiting its broader application in building design and operations. While Large Language Models (LLMs) agentic workflow have facilitated complex engineering processes, their application in BEM has not been specifically explored. This paper investigates the feasibility of automating BEM using LLM agentic workflow. We developed a generic LLM-planning-based workflow that takes a building description as input and generates an error-free EnergyPlus building energy model. Our robust workflow includes four core agents: 1) Building Description Pre-Processing, 2) IDF Object Information Extraction, 3) Single IDF Object Generator Suite, and 4) IDF Debugging Agent. These agents divide the complex tasks into manageable sub-steps, enabling LLMs to generate accurate and reliable results at each stage. The case study demonstrates the successful translation of a building description into an error-free EnergyPlus model for the iUnit modular building at the National Renewable Energy Laboratory. The effectiveness of our workflow surpasses: 1) naive prompt engineering, 2) other LLM-based workflows, and 3) manual modeling, in terms of accuracy, reliability, and time efficiency. The paper concludes with a discussion on the interplay between foundational models and LLM agent planning design, advocating for the use of fine-tuned, specialized models to advance this field.}
}
@article{RADTKE2025100350,
title = {Generative AI in academic writing: Does information on authorship impact learners’ revision behavior?},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100350},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100350},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2400153X},
author = {Anna Radtke and Nikol Rummel},
keywords = {AI-assisted writing, Text revision, Generative AI, Academic writing, Collaborative writing},
abstract = {The role of generative artificial intelligence (AI) in education has expanded significantly over recent years. AI-based text generators such as ChatGPT provide an accessible and effective tool for learners, particularly in academic writing. While revision is considered an essential part of both individual and collaborative writing, research on the revision of AI-generated texts remains limited. However, with the growing adoption of generative AI in education, learners’ ability to effectively revise AI-generated content is likely to become increasingly important in the future. The aim of this study was to investigate whether learners exhibit different revision behaviors when presented with different information about the author of a text (peer vs. AI). We further examined the impact of learners’ prior experiences, attitudes, and gender on text revision. Therefore, N = 303 learners revised two different texts: one labeled as peer-written and the other as AI-generated. The results revealed that while learners invested less time in revising a text labeled as AI-generated, information about the author did not affect the number of areas identified as requiring improvement or the number of revisions made. Moreover, learners who indicated greater prior exposure to media reports about AI-based text generators, a higher level of trust in AI, and a tendency toward ‘loafing’ in AI-assisted writing spent less time revising a text labeled as AI-generated. Conversely, learners with more experience in academic writing identified more areas for improvement and made more extensive revisions, regardless of the labeled authorship.}
}
@article{FLEURENCE2025,
title = {ELEVATE-GenAI: Reporting Guidelines for the Use of Large Language Models in Health Economics and Outcomes Research: An ISPOR Working Group Report},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525024556},
author = {Rachael L. Fleurence and Dalia Dawoud and Jiang Bian and Mitchell K. Higashi and Xiaoyan Wang and Hua Xu and Jagpreet Chhatwal and Turgay Ayer},
keywords = {artificial intelligence, generative AI, large language model, reporting guidelines},
abstract = {Objectives
Generative artificial intelligence (AI), particularly large language models (LLMs), holds significant promise for health economics and outcomes research (HEOR). However, standardized reporting guidance for LLM-assisted research is lacking. This article introduces the ELEVATE-GenAI framework and checklist—reporting guidelines specifically designed for HEOR studies involving LLMs.
Methods
The framework was developed through a targeted literature review of existing reporting guidelines, AI evaluation frameworks, and expert input from the ISPOR Working Group on Generative AI. It comprises 10 domains—including model characteristics, accuracy, reproducibility, and fairness and bias. The accompanying checklist translates the framework into actionable reporting items. To illustrate its use, the framework was applied to 2 published HEOR studies: one focused on a systematic literature review tasks and the other on economic modeling.
Results
The ELEVATE-GenAI framework offers a comprehensive structure for reporting LLM-assisted HEOR research, while the checklist facilitates practical implementation. Its application to the 2 case studies demonstrates its relevance and usability across different HEOR contexts.
Conclusions
Although the framework provides robust reporting guidance, further empirical testing is needed to assess its validity, completeness, usability, and generalizability across diverse HEOR use cases. The ELEVATE-GenAI framework and checklist address a critical gap by offering structured guidance for transparent, accurate, and reproducible reporting of LLM-assisted HEOR research. Future work will focus on extensive testing and validation to support broader adoption and refinement.}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@incollection{TAKEDA20242689,
title = {Prediction Method for Reaction Yield of Deuteration of Polyfluoroperylene using Generative AI Techniques},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {2689-2694},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50449-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044328824150449X},
author = {Kazuhiro Takeda and Naoya Ohtsuka and Toshiyasu Suzuki and Norie Momiyama},
keywords = {generative artificial intelligence, small data, prediction of reaction conditions, in-silico data generation, digitalization of organic molecules},
abstract = {Deuterated organic electroluminescent materials are gaining interest due to their enhanced luminous efficiency and durability with applications spanning academia and industry (Saito et al., 1994). Perylene is a typical organic molecule for organic lightemitting devices. Deuterated polyfluoroperylene (PFDPR), in which the hydrogen of the polyfluoroperylene is replaced by a deuterium, has potential as a new luminescent material. However, synthesizing PFDPR is challenging due to the complexity and scale of the required deuteration processes. On the other hand, in machine learning, large amounts of data are required to improve the estimation accuracy. Takeda et al. (2023) has proposed the virtual variables-enabled generation of datasets for the prediction of the yield of the iodination reactions of the polyfluoronaphthalenes. Using this method, this study proposes a model to estimate the non-experimental yield of PFDPR with a high accuracy from a small amount of data. The experimental conditions investigated in this study were two variables; i.e., temperature and time, across 16 conditions. While comprehensive data for the polyfluoronaphthalenes were fully available, the polyfluoroperylene data were limited to only 8 conditions. the experimental data from polyfluoronaphthalenes determined the yield prediction of the polyfluoroperylene under untested conditions. This process involved optimization using virtual variables to maximize the coefficient of determination between the actual and predicted yields of PFDPR. The model's efficacy is highlighted by the close alignment of the predicted and actual yields, offering a promising tool for accelerating the PFDPR synthesis research.}
}
@article{PILGRAM2025101320,
title = {A consensus privacy metrics framework for synthetic data},
journal = {Patterns},
volume = {6},
number = {10},
pages = {101320},
year = {2025},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2025.101320},
url = {https://www.sciencedirect.com/science/article/pii/S2666389925001680},
author = {Lisa Pilgram and Fida Kamal Dankar and Jörg Drechsler and Mark Elliot and Josep Domingo-Ferrer and Paul Francis and Murat Kantarcioglu and Linglong Kong and Bradley Malin and Krishnamurty Muralidhar and Puja Myles and Fabian Prasser and Jean Louis Raisaro and Chao Yan and Khaled {El Emam}},
keywords = {synthetic data, privacy, generative artificial intelligence, membership disclosure, attribute disclosure, identity disclosure, data sharing},
abstract = {Summary
Synthetic data generation is a promising approach for sharing data for secondary purposes in sensitive sectors. However, to meet ethical standards and legislative requirements, it is necessary to demonstrate that the privacy of the individuals upon which the synthetic records are based is adequately protected. Through an expert consensus process, we developed a framework for privacy evaluation in synthetic data. The most commonly used metrics measure similarity between real and synthetic data and are assumed to capture identity disclosure. Our findings indicate that they lack precise interpretation and should be avoided. There was consensus on the importance of membership and attribute disclosure, both of which involve inferring personal information. The framework provides recommendations to effectively measure these types of disclosures, which also apply to differentially private synthetic data if the privacy budget is not close to zero. We further present future research opportunities to support widespread adoption of synthetic data.}
}
@article{SUN2025105388,
title = {Real-world implementation of an AI learning tool-MetaGP-Edu in medical education: A multi-center cohort study},
journal = {Computers & Education},
volume = {237},
pages = {105388},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105388},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001563},
author = {Yili Sun and Fei Liu},
keywords = {Artificial intelligence in education (AIEd), Large language models (LLMs), Medical education, Improving classroom teaching, Evaluation methodologies},
abstract = {This study aimed to evaluate the real-world educational impact associated with the implementation of MetaGP-Edu, a bespoke generative artificial intelligence tool fine-tuned for medical learning, within the undergraduate Internal Medicine curriculum. We conducted a large-scale, multi-center retrospective cohort study utilizing historical academic records from six major medical schools in China (N = 1632). We evaluated student performance across multiple dimensions, including final scores that assessed both foundational knowledge recall and clinical reasoning—defined as the cognitive process of analyzing patient data to formulate a diagnosis and management plan. Formative in-tool skill metrics were also included. These outcomes were then compared between pre- and post-implementation cohorts (Pre-MetaGP-Edu vs. Post-MetaGP-Edu) using adjusted multivariable regression models. Analysis also included usage patterns and embedded competency test scores for the post-implementation cohort. Results indicated that students with access to MetaGP-Edu achieved significantly higher overall Internal Medicine scores (Adjusted Mean Difference: +8.2 points, P < 0.001). This improvement was primarily associated with significantly higher scores in clinical reasoning assessments (P < 0.001), with no significant difference observed in knowledge recall scores (P > 0.05). The positive association also varied across clinical topics, being more pronounced in complex system modules. Furthermore, within the post-implementation cohort, significant skill development was observed over time, and higher total usage time significantly predicted greater skill gains (Adjusted OR = 2.42, P < 0.001). In conclusion, supplementary integration of a domain-specific AI educational tool like MetaGP-Edu shows a positive association with enhanced medical student performance, particularly for higher-order reasoning skills, although student engagement appears critical to realizing these benefits.}
}
@article{LI2024101916,
title = {A privacy risk identification framework of open government data: A mixed-method study in China},
journal = {Government Information Quarterly},
volume = {41},
number = {1},
pages = {101916},
year = {2024},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2024.101916},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X2400008X},
author = {Ying Li and Rui Yang and Yikun Lu},
keywords = {Privacy risks, Open government data, Privacy risk identification framework, Mixed methods},
abstract = {Open government data (OGD) has great potential to promote economic growth, stimulate innovation, and improve service efficiency. However, as more and more private information is collected by government information systems, private data become increasingly vulnerable. Thus, governments must monitor the privacy risks of OGD. The focus of this study is to identify privacy risk factors in the process of developing OGD. Using a mixed-method design, we developed a privacy risk identification framework based on evidence from China. According to the results of qualitative interviews, the privacy risk identification framework mainly includes five risk dimensions: data risk, institutional risk, technical risk, structural risk, and behavioral risk. We identified 17 risk factors under these five dimensions. We further developed the measurement items for each risk factor and verified the indicator framework through quantitative methods. Our research provides a theoretical basis for identifying the privacy risks in OGD, supporting governments in discovering and dealing with them accordingly. Future research can continuously explore potential privacy risks arising from merging technologies such as generative artificial intelligence when applied to OGD.}
}
@article{PILGRAM2025,
title = {Magnitude and Impact of Hallucinations in Tabular Synthetic Health Data on Prognostic Machine Learning Models: Validation Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/77893},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125011215},
author = {Lisa Pilgram and Samer {El Kababji} and Dan Liu and Khaled {El Emam}},
keywords = {synthetic data, data utility, hallucinations, generative models, artificial intelligence, AI},
abstract = {Background
Generative artificial intelligence (AI) for tabular synthetic data generation (SDG) has significant potential to accelerate health care research and innovation. A critical limitation of generative AI, however, is hallucinations. Although this has been commonly observed in text-generating models, it may also occur in tabular SDG.
Objective
This study aims to investigate the magnitude of hallucinations in tabular synthetic data, whether their frequency increases with training data complexity, and the extent to which they impact the utility of synthetic data for downstream prognostic machine learning (ML) modeling tasks.
Methods
On the basis of 12 large and high-dimensional real-world health care datasets, 6354 training datasets of different complexity were created by varying the subset of variables included in each dataset. Synthetic data were generated using 7 different SDG models. Hallucinations were defined as synthetic records that did not exist in the population, and the hallucination rate (HR) was the proportion of hallucinations in a synthetic dataset. Classification was the downstream prognostic modeling task, conducted via an ML approach (light gradient boosted machine) and an artificial neural network (multilayer perceptron). Mixed-effects models were fitted to examine the relationship between training data complexity and the HR and the HR and the predictive performance of AI and ML models when trained on the synthetic data.
Results
The HR ranged from 0.3% to 100% (median 99.1%, IQR 98.5%-100.0%) and increased with training data complexity. However, in most SDG models, the HR did not affect AI and ML prognostic model performance. In the SDG models in which a significant association was detected, the estimated effect was very small, with a maximum decrease in the area under the receiver operating characteristic curve of –0.0002 (95% CI –0.0003 to –0.0002, P<.001) in light gradient boosting machine and –0.0001 (95% CI –0.0002 to –0.0001, P=.002) in multilayer perceptron.
Conclusions
These findings suggest that while hallucinations may be very common in synthetic tabular health data, they do not necessarily impair its utility for prognostic modeling.}
}
@article{ZHANG2025,
title = {ChatGPT in Medical Education: Bibliometric and Visual Analysis},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/72356},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001321},
author = {Yuning Zhang and Xiaolu Xie and Qi Xu},
keywords = {ChatGPT, medical education, bibliometric, VOSviewer, CiteSpace, artificial intelligence, AI},
abstract = {Background
ChatGPT is a generative artificial intelligence–based chatbot developed by OpenAI. Since its release in the second half of 2022, it has been widely applied across various fields. In particular, the application of ChatGPT in medical education has become a significant trend. To gain a comprehensive understanding of the research developments and trends regarding ChatGPT in medical education, we conducted an extensive review and analysis of the current state of research in this field.
Objective
This study used bibliometric and visualization analysis to explore the current state of research and development trends regarding ChatGPT in medical education.
Methods
A bibliometric analysis of 407 articles on ChatGPT in medical education published between March 2023 and June 2025 was conducted using CiteSpace, VOSviewer, and Bibliometrix (RTool of RStudio). Visualization of countries, institutions, journals, authors, keywords, and references was also conducted.
Results
This bibliometric analysis included a total of 407 studies. Research in this field began in 2023, showing a notable surge in annual publications until June 2025. The United States, China, Türkiye, the United Kingdom, and Canada produced the most publications. Networks of collaboration also formed among institutions. The University of California system was a core research institution, with 3.4% (14/407) of the publications and 0.17 betweenness centrality. BMC Medical Education, Medical Teacher, and the Journal of Medical Internet Research were all among the top 10 journals in terms of both publication volume and citation frequency. The most prolific author was Yavuz Selim Kiyak, who has established a stable collaboration network with Isil Irem Budakoglu and Ozlem Coskun. Author collaboration in this field is usually limited, with most academic research conducted by independent teams and little communication between teams. The most frequent keywords were “AI,” “ChatGPT,” and “medical education.” Keyword analysis further revealed “educational assessment,” “exam,” and “clinical practice” as current research hot spots. The most cited paper was “Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models,” and the paper with the strongest citation burst was “Are ChatGPT’s Knowledge and Interpretation Ability Comparable to Those of Medical Students in Korea for Taking a Parasitology Examination?: A Descriptive Study.” Both papers focus on evaluating ChatGPT’s performance in medical exams.
Conclusions
This study reveals the significant potential of ChatGPT in medical education. As the technology improves, its applications will expand into more fields. To promote the diversification and effectiveness of ChatGPT in medical education, future research should strengthen interregional collaboration and enhance research quality. These findings provide valuable insights for researchers to identify research perspectives and guide future research directions.}
}
@article{STORNAIUOLO202483,
title = {Digital writing with AI platforms: the role of fun with/in generative AI},
journal = {English Teaching: Practice & Critique},
volume = {23},
number = {1},
pages = {83-103},
year = {2024},
issn = {1175-8708},
doi = {https://doi.org/10.1108/ETPC-08-2023-0103},
url = {https://www.sciencedirect.com/science/article/pii/S1175870824000189},
author = {Amy Stornaiuolo and Jennifer Higgs and Opal Jawale and Rhianne Mae Martin},
keywords = {Creativity, Artificial intelligence, Literacy, AI, Platforms, Multiliteracies, Character.ai, Digital writing, Postdigital},
abstract = {Purpose
With the rapid advancement of generative artificial intelligence (AI), it is important to consider how young people are making sense of these tools in their everyday lives. Drawing on critical postdigital approaches to learning and literacy, this study aims to center the experiences and perspectives of young people who encounter and experiment with generative AI in their daily writing practices.
Design/methodology/approach
This critical case study of one digital platform – Character.ai – brings together an adolescent and adult authorship team to inquire about the intertwining of young people’s playful and critical perspectives when writing on/with digital platforms. Drawing on critical walkthrough methodology (Light et al., 2018), the authors engage digital methods to study how the creative and “fun” uses of AI in youths’ writing lives are situated in broader platform ecologies.
Findings
The findings suggest experimentation and pleasure are key aspects of young people’s engagement with generative AI. The authors demonstrate how one platform works to capitalize on these dimensions, even as youth users engage critically and artfully with the platform and develop their digital writing practices.
Practical implications
This study highlights how playful experimentation with generative AI can engage young people both in pleasurable digital writing and in exploration and contemplation of platforms dynamics and structures that shape their and others’ literate activities. Educators can consider young people’s creative uses of these evolving technologies as potential opportunities to develop a critical awareness of how commercial platforms seek to benefit from their users.
Originality/value
This study contributes to the development of a critical and humanist research agenda around generative AI by centering the experiences, perspectives and practices of young people who are underrepresented in the burgeoning research devoted to AI and literacies.}
}