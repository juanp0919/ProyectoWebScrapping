@article{SHEN2025137905,
title = {Energy-system characteristic shifts and their quantitative impacts on China's CO2 trajectory: Evidence from a high-resolution energy allocation analysis–LMDI sectoral decomposition},
journal = {Energy},
volume = {335},
pages = {137905},
year = {2025},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2025.137905},
url = {https://www.sciencedirect.com/science/article/pii/S0360544225035479},
author = {Minglin Shen and Yanping Hou and Keying Liang and Wenjing Zhu and Chin Hao Chong and Yuejing Bin and Xiaoyong Zhou and Linwei Ma},
keywords = {Energy allocation analysis, LMDI, Sankey diagram, Influencing factors, CO emissions},
abstract = {Understanding how policy, technology and structural change interact along China's energy chain is essential for meeting its 2030 carbon peak and 2060 carbon neutrality goals. This study constructed a carbon-tracking framework integrating energy allocation analysis with the logarithmic mean Divisia index (EAA-LMDI). Using energy input-output tables, the authors derived the primary energy consumption responsibility conversion factor (KPECR), fossil fuel component factor (Kfossil), and primary CO2 emission factor (KC), and visualized carbon flows with Sankey diagrams. The approach captured hidden conversion losses across extraction, conversion, and end-use, and decomposed influencing factors of CO2 emissions for 27 economic and residential sectors during 2005–2020. Total CO2 responsibility increased from 5534 Mt in 2005 to 10,177 Mt in 2020, with 88 %–92 % from the economic sector. GDP per capita was the main driver (7788 Mt), while lower energy intensity (−2731 Mt) and declining Kfossil (−501 Mt) helped restrain growth. Between 2015 and 2020, the rebound of energy-intensive industries and rapid electrification offset the emissions reductions from economic restructuring. Although electrification is clean at the end-use stage, it increases upstream emissions, as over 60 % of electricity still comes from coal. Improved coal-fired unit efficiency reduced the electricity's KPECR, avoiding 88 Mt of emissions. Policy priorities include: (1) flexibility retrofits of coal-fired power plants with industrial waste-heat recovery; (2) tighter controls to avert cyclical overcapacity in heavy industry; and (3) cross-sector digital platforms for energy-carbon coordination. The EAA-LMDI framework links sectoral behaviour and technical change, providing a robust analytical tool for multi-stage decarbonization pathways in coal-dependent economies.}
}
@article{GUO2025122905,
title = {Biologically logic-gated Trojan-horse strategy for personalized triple-negative breast cancer precise therapy by selective ferroptosis and STING pathway provoking},
journal = {Biomaterials},
volume = {315},
pages = {122905},
year = {2025},
issn = {0142-9612},
doi = {https://doi.org/10.1016/j.biomaterials.2024.122905},
url = {https://www.sciencedirect.com/science/article/pii/S0142961224004393},
author = {Shuai Guo and Tianwang Guan and Yushen Ke and Yuping Lin and Rundong Tai and Jujian Ye and Zhilin Deng and Shaohui Deng and Caiwen Ou},
keywords = {Biological logic-gate, Stimulator interferon genes (STING) pathway, Ferroptosis, Triple-negative breast cancer (TNBC), Trojan-horse strategy},
abstract = {Amidst the therapeutic quandaries associated with triple-negative breast cancer (TNBC), an aggressive malignancy distinguished by its immune resistance and limited treatment avenues, the urgent need for innovative solutions is underscored. To conquer the dilemma, we present a groundbreaking approach that ingeniously employs DNA-fragments-containing exosomes (DNA-Exo) and the concept of “biological logic-gates” to achieve precise homing and controlled selective activation of ferroptosis and stimulator interferon genes (STING) pathways. Leveraging insights from our previous research, a nano-Trojan-horse, Fe0@HMON@DNA-Exo, is engineered via in situ Fe0 synthesis within the glutathione (GSH)-responsiveness degradable hollow mesoporous organosilica nanoparticles (HMON) and subsequently enveloped in DNA-Exo derived from 7-ethyl-10-hydroxycamptothecin (SN38)-treated 4T1 cells. Emphasizing the precision of our approach, the DNA-Exo ensures specific ‘homing’ to TNBC cells, rendering a targeted delivery mechanism. Concurrently, the concept of “biological logic-gates” is employed to dictate a meticulous and selective activation of STING in antigen-presenting cells (APCs) under OR logic-gating with robust immune response and Fe0-based ferroptosis in TNBC cells under AND logic-gating with reactive oxygen species (ROS) storm generation. In essence, our strategy exhibits great potential in transforming the “immunologically cold” nature of TNBC, enabling precise control over cellular responses, illuminating a promising therapeutic paradigm that is comprehensive and productive in pursuing precision oncology and paving the way for personalized TNBC therapies.}
}
@article{DIPAOLO2025105072,
title = {Leveraging social capital for destination promotion in the metaverse: The Enoverse case},
journal = {Tourism Management},
volume = {107},
pages = {105072},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2024.105072},
url = {https://www.sciencedirect.com/science/article/pii/S0261517724001912},
author = {Francesco {Di Paolo} and Debora Bettiga and Lucio Lamberti},
abstract = {This study examines the challenges of metaverse-driven community innovation in the context of rural tourism. Through an in-depth case study, we analyse the social capital dynamics within an Italian winery consortium that ventured into the metaverse through a project called Enoverse to promote local wine and rural territory. The results show that the complexity and novelty inherent in the implementation of a presence in the metaverse to provide a consistent and authentic territorial and product experience requires and fosters stakeholder cohesion and participation. This promotes tourism by enhancing stakeholder engagement, inclusion, and satisfaction. Drawing on social capital theory, the establishment of network mechanisms and actor connectivity facilitates innovative promotion of rural destinations. This study contributes to the growing body of literature on the role of virtual environments in promoting tourism, specifically in the wine industry.}
}
@article{LEUE2024112816,
title = {Working memory ability, suggestibility and conflict monitoring: On psychometrics and the nomological network},
journal = {Personality and Individual Differences},
volume = {231},
pages = {112816},
year = {2024},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2024.112816},
url = {https://www.sciencedirect.com/science/article/pii/S0191886924002769},
author = {Anja Leue and Fee-Elisabeth Bertram},
keywords = {Online Gudjonsson Suggestibility Scale 1 (GSS 1), Working memory ability, Suggestibility, Conflict monitoring},
abstract = {This study investigates psychometric properties and construct validity of the German online Gudjonsson Suggestibility Scale 1 (GSS 1). In Study 1, N = 206 participants performed the online GSS 1. The number of immediately, correctly recalled details of the GSS 1 story indicated sufficient psychometric properties and was negatively correlated with suggestibility subscales (Yield 1, Yield 2, and Shift). In Study 2, N = 101 participants performed the online GSS 1, the online working memory ability test of the Intelligence-Structure-Test 2000 R, and the online Conflict-Monitoring-Questionnaire (CMQ-28). Individual differences of working memory ability measured by means of GSS 1 story recall and the Intelligence-Structure-Test 2000 R emerged to be convergent constructs. Individual differences of working memory ability and suggestibility are diverging constructs correlating either negatively or non-significantly. Individual differences of suggestibility and CMQ-28 subscales are widely diverging constructs correlating mainly non-significantly despite sufficient a-priori calculated sample size. The present results on individual differences of working memory ability, suggestibility and CMQ-conflict monitoring contribute to the investigation of convergent and discriminant validity in a non-forensic domain with a low level of social pressure. Neuro-cognitive mechanisms of these performance and personality dimensions remain to be investigated.}
}
@article{MANDON2025100136,
title = {Beyond the AI divide: A straightforward approach to identifying global and local overperformers in AI preparedness},
journal = {Digital Business},
volume = {5},
number = {2},
pages = {100136},
year = {2025},
issn = {2666-9544},
doi = {https://doi.org/10.1016/j.digbus.2025.100136},
url = {https://www.sciencedirect.com/science/article/pii/S2666954425000316},
author = {Pierre Mandon},
keywords = {AI preparedness, Economic complexity, Peer learning, Policy Overperformance},
abstract = {This study introduces a straightforward data-driven framework to identify countries that outperform in artificial intelligence (AI) preparedness relative to their economic complexity, utilizing the IMF's Artificial Intelligence Preparedness Index and a multidimensional Economic Complexity Index derived from trade and research data. Employing weighted least squares, the study estimates expected AIPI scores and classifies countries as global or local overperformers if their observed scores exceed predictions and surpass income-group medians. The analysis identifies 10 high-income global overperformers and 14 local overperformers across middle- and low-income groups, revealing regulation and ethics as universal drivers of overperformance, with digital infrastructure and human capital varying by economic context. Case studies elucidate diverse coordination models—state-led, market-responsive, and distributed innovation—while highlighting transferability constraints due to institutional and historical factors, among others. The replicable methodology provides policymakers and other key actors a robust tool to benchmark AI readiness and design context-specific strategies, addressing the global AI divide. The study opens avenues for future research into refined AI preparedness metrics, alternative identification techniques, and comparative analyses of national innovation systems.}
}
@article{MAZIRIRI2024100051,
title = {From perceived parental entrepreneurial passion to technopreneurship intention: The moderating role of perseverance and perceived parental entrepreneurial rewards},
journal = {Sustainable Technology and Entrepreneurship},
volume = {3},
number = {1},
pages = {100051},
year = {2024},
issn = {2773-0328},
doi = {https://doi.org/10.1016/j.stae.2023.100051},
url = {https://www.sciencedirect.com/science/article/pii/S2773032823000147},
author = {Eugine Tafadzwa Maziriri and Mufaro Dzingirai and Brighton Nyagadza and Brian Mabuyana},
keywords = {Technopreneurship, Technopreneurship intention, Parental entrepreneurship, Passion, Parental entrepreneurial rewards},
abstract = {In light of significant advancements in both theoretical and practical aspects of technopreneurship, supported by empirical research, there remains an unexplored area within the academic domain pertaining to the impact of perceived parents’ entrepreneurial passion towards a career in technopreneurship and technopreneurship intention among Generation Z students remains unexplored in the academic domain. This study thus aims to examine how perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility would stimulate attitude towards a career in technopreneurship and technopreneurship intention among Generation Z students in Zimbabwe. It is based on a nomothetic quantitative methodology, where a survey was applied to collect responses from Generation Z university students in the Harare Metropolitan Province of Zimbabwe. Through structural equation modelling, the findings are validated, confirming that perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility do indeed influence attitudes towards pursuing a career in technopreneurship. The study also discovered that attitude towards a career in technopreneurship has a positive and a significant impact on technopreneurship intention. Moreover, the results support the moderation role of perseverance and perceived parental entrepreneurial rewards on the nexus between attitude towards a career in technopreneurship and technopreneurship intention. Based on the results, the study concludes that perceived parents’ entrepreneurial passion, perceived desirability and perceived feasibility would stimulate attitude towards a career in technopreneurship and technopreneurship intention among Generation Z students.}
}
@article{WANG2025100449,
title = {Challenges and perspectives towards multi-physics modeling for porous electrode of ultrahigh performance durable polymer electrolyte membrane fuel cells},
journal = {eTransportation},
volume = {25},
pages = {100449},
year = {2025},
issn = {2590-1168},
doi = {https://doi.org/10.1016/j.etran.2025.100449},
url = {https://www.sciencedirect.com/science/article/pii/S2590116825000566},
author = {Ning Wang and Tao Lai and Wenkai Wang and Zhiguo Qu and Xuhui Wen and Guangyou Xie and Wenquan Tao},
keywords = {PEMFCs, Porous electrodes, Multi-physics transfers, Cross-scale modeling, Perspective},
abstract = {The development of ultrahigh-performance, durable polymer electrolyte membrane fuel cells (PEMFCs) is crucial for achieving large-scale commercialization. A comprehensive insight into multi-physics phenomena within advanced porous electrode designs provide motivation for the ambitious targets. Modeling is an indispensable tool in multi-physics transfer understanding and offers a promising pathway for electrode structural designs and material architecture selections. Despite the progress, the modeling community continues to face significant challenges, including oversimplification, difficulties in coupling complex features, unclear physical knowledge, and unavoidable discrepancies. This perspective highlights the current status of porous electrode modeling, identifies ongoing challenges, and explores future directions for key technologies and potential countermeasures. Specifically, the characteristics and limitations of macro-scale, meso-scale, and micro-scale models regarding intricate porous electrode microstructures are compared, including ordered structure, mesoporous carbon support, various catalyst architectures, etc. Potential solutions to these challenges are proposed for the next generation of porous electrode designs. Furthermore, three alternatives to advancing cross-scale, full-morphology, and full-coupling modeling are developed and discussed, including layer-by-layer physical property transfer, interfacial data transfer and direct numerical simulation, and data-driven assisted cross-scale modeling, which are expected to be evaluated and validated in the foreseeable future.}
}
@article{TAECHARUNGROJ202349,
title = {Assessing place experiences in Luton and Darlington on Twitter with topic modelling and AI-generated lexicons},
journal = {Journal of Place Management and Development},
volume = {17},
number = {1},
pages = {49-73},
year = {2023},
issn = {1753-8335},
doi = {https://doi.org/10.1108/JPMD-04-2023-0041},
url = {https://www.sciencedirect.com/science/article/pii/S1753833523000027},
author = {Viriya Taecharungroj and Ioana S. Stoica},
keywords = {Place experience, Twitter, LDA, Generative AI, GPT-4, Place analytics},
abstract = {Purpose
The purpose of this paper is to examine and compare the in situ place experiences of people in Luton and Darlington.
Design/methodology/approach
The study used 109,998 geotagged tweets from Luton and Darlington between 2020 and 2022 and conducted topic modelling using latent Dirichlet allocation. Lexicons were created using GPT-4 to evaluate the eight dimensions of place experience for each topic.
Findings
The study found that Darlington had higher counts in the sensorial, behavioural, designed and mundane dimensions of place experience than Luton. Conversely, Luton had a higher prevalence of the affective and intellectual dimensions, attributed to political and faith-related tweets.
Originality/value
The study introduces a novel approach that uses AI-generated lexicons for place experience. These lexicons cover four facets, two intentions and two intensities of place experience, enabling detection of words from any domain. This approach can be useful not only for town and destination brand managers but also for researchers in any field.}
}
@article{ZHANG2024100115,
title = {Researching L2 investment in EMI courses: Techno-reflective narrative interviews},
journal = {Research Methods in Applied Linguistics},
volume = {3},
number = {2},
pages = {100115},
year = {2024},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2024.100115},
url = {https://www.sciencedirect.com/science/article/pii/S2772766124000211},
author = {Yue Zhang},
keywords = {Investment, L2 investment, Identity, Translanguaging, Interview},
abstract = {In response to the call for integrating a praxis orientation to understand processes of language development through active engagement with teachers and learners, this article introduces techno-reflective narrative interview (TRNI) as a tool to understand how learners invest in their English as a second language (ESL) language and literacy practices as social practices in English medium instruction (EMI) courses. It is timely in integrating both technical and critical guidance for methodological innovations in the field of applied linguistics. To illustrate how this aim is achieved, this article first justifies the significance and theoretical basis of TRNI by elaborating on the definitions of and underpinning rationale for it, followed by the relationship among second language (L2) learners, investment, and TRNI. It then discusses the methods adopted by the 69 most cited empirical studies from Google Scholar that used the model of L2 investment as the theoretical model and compares these methods with TRNI. Finally, it discusses how TRNI was developed and adopted in two action research projects conducted by the author and two lecturers among local undergraduate students in the Hong Kong context. Through these steps, I demonstrate how TRNIs can be adopted or adapted to provide an interactive space for ESL learners to reconstruct and perform their English speaker and learner identities, share their learning experiences with the agency to introduce their positions, voices, and stories, and therefore, claim legitimacy as English users in EMI courses.}
}
@article{DEIVAYANAI2025293,
title = {Advances in nanoparticle-mediated cancer therapeutics: Current research and future perspectives},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {4},
pages = {293-308},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713224000880},
author = {V.C. Deivayanai and P. Thamarai and S. Karishma and A. Saravanan and P.R. Yaashikaa and A.S. Vickram and R.V. Hemavathy and R Rohith Kumar and S. Rishikesavan and S. Shruthi},
keywords = {Cancer, Chemotherapy, Drug delivery, Nanomedicine, Therapeutics, Toxicity},
abstract = {One in six deaths worldwide is caused by cancer, making it a major global health concern. Despite their effectiveness, traditional treatment approaches such as radiation therapy, chemotherapy, and surgery frequently have negative side effects and high costs. New approaches, such as gene therapy, are promising but are hampered by high costs and accessibility problems. Nanoparticles (NPs) facilitate targeted drug delivery by leveraging passive targeting mechanisms, such as the enhanced permeability and retention (EPR) effect, and by actively targeting surfaces with ligands for site-specific binding through the functionalization of surfaces. This approach enhances therapeutic results while lowering off-target toxicities. Notably, chemotherapeutic medications, immunotherapeutic agents, and photothermal therapies can now be delivered more precisely to the affected site using NP-based systems. By boosting particularity, reducing side effects, and tackling drug resistance, nanomedicine has the potential to revolutionize cancer treatment and ultimately advance personalized oncological care. These advancements highlight the possibilities for field growth, and future development regulations are detailed.}
}
@article{SATALKAR20242790,
title = {Generative β-hairpin design using a residue-based physicochemical property landscape},
journal = {Biophysical Journal},
volume = {123},
number = {17},
pages = {2790-2806},
year = {2024},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2024.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0006349524000705},
author = {Vardhan Satalkar and Gemechis D. Degaga and Wei Li and Yui Tik Pang and Andrew C. McShan and James C. Gumbart and Julie C. Mitchell and Matthew P. Torres},
abstract = {De novo peptide design is a new frontier that has broad application potential in the biological and biomedical fields. Most existing models for de novo peptide design are largely based on sequence homology that can be restricted based on evolutionarily derived protein sequences and lack the physicochemical context essential in protein folding. Generative machine learning for de novo peptide design is a promising way to synthesize theoretical data that are based on, but unique from, the observable universe. In this study, we created and tested a custom peptide generative adversarial network intended to design peptide sequences that can fold into the β-hairpin secondary structure. This deep neural network model is designed to establish a preliminary foundation of the generative approach based on physicochemical and conformational properties of 20 canonical amino acids, for example, hydrophobicity and residue volume, using extant structure-specific sequence data from the PDB. The beta generative adversarial network model robustly distinguishes secondary structures of β hairpin from α helix and intrinsically disordered peptides with an accuracy of up to 96% and generates artificial β-hairpin peptide sequences with minimum sequence identities around 31% and 50% when compared against the current NCBI PDB and nonredundant databases, respectively. These results highlight the potential of generative models specifically anchored by physicochemical and conformational property features of amino acids to expand the sequence-to-structure landscape of proteins beyond evolutionary limits.}
}
@article{CACCAVALE2025100354,
title = {ChatGMP: A case of AI chatbots in chemical engineering education towards the automation of repetitive tasks},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100354},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100354},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001577},
author = {Fiammetta Caccavale and Carina L. Gargalo and Julian Kager and Steen Larsen and Krist V. Gernaey and Ulrich Krühne},
keywords = {Artificial Intelligence, Large Language Models, Prompt engineering, Education 4.0, Higher education, Chatbots in education},
abstract = {Artificial Intelligence (AI) is rapidly and consistently becoming more integrated in various aspects of our lives. One of the areas where these systems are increasingly used is education. In fact, it is both being incorporated into specific curricula, allowing students the possibility to acquire skills within this field, and more recently AI has been used as a tool to facilitate the teaching and learning process. However, an increased demand and availability of these tools do not imply a successful switch from traditional to AI-supported learning. In this work, ChatGMP, a chatbot leveraging a Large Language Model (LLM) able to conduct an interview exercise in a Master's Degree course taught at the Technical University of Denmark (DTU), is introduced. The exercise consists in a student interview of a fictitious company, represented by the teachers or ChatGMP, regarding its Good Manufacturing Practices (GMP). The aim is for the students to ask sensible and well-reasoned questions to acquire the necessary documentation to make an exhaustive report indicating whether the company is a potential fit for business. To evaluate the initiative, we compare the performance of ChatGMP to the one of the physical teachers of the course, as well as the perception of the students towards it. The results show no significant difference in the information provided by the teachers and the model, enabling the students to achieve similar learning. The students that interacted with ChatGMP are satisfied with the initiative and would likely recommend future students to perform the audit with the digital tool. This initial experiment and its positive results lay the foundation for opening the discussion on how to use LLMs in education, the opportunities they could provide, as well as their limitations and drawbacks.}
}
@article{SHAIKAT2025,
title = {Investigating hypoxia-inducible factor signaling in cancer: mechanisms, clinical implications, targeted therapeutic strategies, and resistance},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000904},
author = {Abdul Halim Shaikat and S.M. Asadul Karim Azad and Md. Azizur Rahman Tamim and Mohammed Sailim Ullah and Mohammad Nurul Amin and Mofazzal K. Sabbir and Md Towhidul Islam Tarun and Md Saqline Mostaq and Shohana Sabrin and Md Zihad Mahmud and Md Ashiq Mahmud},
keywords = {Hypoxia, Drug Resistance, Molecular Mechanisms, HIF-related factor, Angiogenesis, Vascular Endothelial Growth Factor, Tumor Microenvironment, Prolyl Hydroxylases},
abstract = {Hypoxia, a defining feature of the tumor microenvironment (TME), significantly contributes to cancer progression by influencing immune regulation, promoting angiogenesis, altering metabolic pathways, and driving uncontrolled cell proliferation. This review explores the diverse functions of hypoxia-inducible factor (HIF) signaling in cancer development and progression, providing a comprehensive overview of the molecular pathways. HIFs, particularly HIF-1α and HIF-2α, regulate several genes related to cancer hallmarks such as invasion, metabolic reprogramming, angiogenesis, and therapy resistance, thus mediating a significant portion of the hypoxic response. Hydroxylation of proline and asparagine residues in HIF-α subunits, which occurs in an oxygen-dependent manner, serves as a key regulatory mechanism for both their stability and transcriptional function. Notably, this complex interaction is regulated by multiple signaling pathways, including the extracellular signal-regulated kinase/mitogen-activated protein kinase (ERK/MAPK), phosphoinositide 3-kinase/ protein kinase B/ mechanistic target of rapamycin (PI3K/Akt/mTOR), and Janus kinase/signal transducer and activator of transcription (JAK/STAT) pathways. In cancer, HIF signaling affects several aspects of tumor cell biology that contribute to the cancerous characteristic, including angiogenesis induction through the upregulation of vascular endothelial growth factor (VEGF) expression, metabolic reprogramming through the enhancement of the Warburg effect, facilitation of cancer invasion and metastasis by driving epithelial-to-mesenchymal transition and matrix remodeling patterns, and mediation of therapeutic resistance partly due to the effects on drug efflux pumps and DNA damage repair. Several types of direct and indirect inhibitors, including small molecule inhibitors, peptidomimetics, antibodies, and PROteolysis-TArgeting Chimeras, are being investigated for therapeutic potential. Preclinical and early clinical trials have demonstrated significant synergistic effects in inhibiting tumor development when HIF inhibition is combined with traditional therapies (chemotherapy or radiation) or immunotherapies, emphasizing major clinical implications and the potential for improving patient outcomes. Although challenges exist, particularly regarding drug resistance, further research to improve therapeutic efficacy and prolong survival for patients is warranted.}
}
@article{STREMERSCH20241,
title = {How can academics generate great research ideas? Inspiration from ideation practice},
journal = {International Journal of Research in Marketing},
volume = {41},
number = {1},
pages = {1-17},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2023.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S016781162300071X},
author = {Stefan Stremersch},
keywords = {Research, Ideation, Innovation, Scientometrics, Marketing},
abstract = {How can academic scholars come up with great ideas, such that their research becomes even more important, relevant, and interesting? Based on ideation practices of sophisticated companies, this paper triggers academic researchers to self-reflect on: (1) the source used for ideation, (2) the scope applied to ideation, (3) the sharing of ideas during ideation, and (4) the selection of ideas. The paper also offers concrete improvements that researchers can implement in their ideation practices on ideation processes, tools, and methods along three ideation phases: domain exploration, domain immersion, and research project design. It reviews recent advances in AI and how researchers can leverage AI in their research ideation. The paper aims to stimulate more research on (academic) research ideation (i.e., “more research on research”) and advances a research agenda.}
}
@article{CHEN2024129888,
title = {NMR structures of small molecules bound to a model of a CUG RNA repeat expansion},
journal = {Bioorganic & Medicinal Chemistry Letters},
volume = {111},
pages = {129888},
year = {2024},
issn = {0960-894X},
doi = {https://doi.org/10.1016/j.bmcl.2024.129888},
url = {https://www.sciencedirect.com/science/article/pii/S0960894X24002907},
author = {Jonathan L. Chen and Amirhossein Taghavi and Alexander J. Frank and Matthew A. Fountain and Shruti Choudhary and Soma Roy and Jessica L. Childs-Disney and Matthew D. Disney},
keywords = {RNA, Repeat expansion, Small molecules, NMR, Solution structure},
abstract = {Trinucleotide repeat expansions fold into long, stable hairpins and cause a variety of incurable RNA gain-of-function diseases such as Huntington’s disease, the myotonic dystrophies, and spinocerebellar ataxias. One approach for treating these diseases is to bind small molecules to these structured RNAs. Both Huntington’s disease-like 2 (HDL2) and myotonic dystrophy type 1 (DM1) are caused by a r(CUG) repeat expansion, or r(CUG)exp. The RNA folds into a hairpin structure with a periodic array of 1 × 1 nucleotide UU loops (5′CUG/3′GUC; where the underlined nucleotides indicate the Us in the internal loop) that sequester various RNA-binding proteins (RBPs) and hence the source of its gain-of-function. Here, we report nuclear magnetic resonance (NMR)-refined structures of single 5′CUG/3′GUC motifs in complex with three different small molecules, a di-guandinobenzoate (1), a derivative of 1 where the guanidino groups have been exchanged for imidazole (2), and a quinoline with improved drug-like properties (3). These structures were determined using NMR spectroscopy and simulated annealing with restrained molecular dynamics (MD). Compounds 1, 2, and 3 formed stacking and hydrogen bonding interactions with the 5′CUG/3′GUC motif. Compound 3 also formed van der Waals interactions with the internal loop. The global structure of each RNA-small molecule complexes retains an A-form conformation, while the internal loops are still dynamic but to a lesser extent compared to the unbound form. These results aid our understanding of ligand-RNA interactions and enable structure-based design of small molecules with improved binding affinity for and biological activity against r(CUG)exp. As the first ever reported structures of a r(CUG) repeat bound to ligands, these structures can enable virtual screening campaigns combined with machine learning assisted de novo design.}
}
@article{AN2025128684,
title = {Machine learning-assisted development of conductive polymers},
journal = {Polymer},
volume = {333},
pages = {128684},
year = {2025},
issn = {0032-3861},
doi = {https://doi.org/10.1016/j.polymer.2025.128684},
url = {https://www.sciencedirect.com/science/article/pii/S0032386125006706},
author = {Jin An and Tailai Chen and Hossein Pouri and Tianlong Liu and Jin Zhang},
keywords = {Machine learning, Conductive polymers, Interdisciplinary integration, Computational analysis},
abstract = {Machine learning (ML) techniques are increasingly being used to predict and enhance the performance of new materials, including conductive polymers, which are valued for their unique electrical properties. These materials are crucial for a range of applications, such as electronics, energy storage, and sensors. This paper provides a comprehensive review of the properties and applications of major types of conductive polymers, including intrinsic, doped, and nanocomposite-based systems. The concept of “Face IDs” is introduced as an analogy for the key chemical features and properties of conductive polymers, helping to translate complex chemical structures, fabrication parameters, and performance indicators into machine-readable descriptors. This approach bridges experimental polymer science with advanced data-driven methodologies. Additionally, the paper explores the current progress of ML-assisted design in advancing conductive polymers, with a focus on optimizing properties such as electrical conductivity, mechanical strength, and thermal stability. However, challenges persist in applying ML for the development of new conductive polymers with desired properties, such as the limited availability of high-quality datasets, the complexity of polymer structures, and the need for better models for reverse design. This review aims to facilitate collaboration between researchers in the fields of polymer science and ML, highlighting the potential of interdisciplinary efforts to drive innovation in the development of next-generation conductive polymers.}
}
@article{XU2025100135,
title = {What makes children perceive or not perceive minds in generative AI?},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100135},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100135},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000192},
author = {Ying Xu and Trisha Thomas and Chi-Lin Yu and Echo Zexuan Pan},
keywords = {Generative AI, Children, Mind perception, Communication, Speech, Embodiment},
abstract = {Children are increasingly engaging in dialogue and interactions with generative AI agents that can mimic human behaviors, raising questions about how children perceive and communicate with AI compared to humans. In an experimental study with 119 children aged 4–8, participants co-created stories in three conditions: with a generative AI agent via a speaker, with a physically present human partner, or with a human partner who was hidden and audible only through a speaker. Results showed a clear distinction in children's communication and perception of visible human partners compared to AI. Nuanced differences also emerged in children's perceptions of hidden human partners versus AI. When physical appearance was absent, children relied on linguistic and paralinguistic cues to assess human-likeness and form perceptions, but physical appearance became a more dominant factor when available. These results shed light on implications for the design of child-facing AI technologies, offering insights into how speech and physical features can be optimized to meet children's developmental and communicative needs.}
}
@article{YU2024101551,
title = {An ESTs detection research based on paper entity mapping: Combining scientific text modeling and neural prophet},
journal = {Journal of Informetrics},
volume = {18},
number = {4},
pages = {101551},
year = {2024},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2024.101551},
url = {https://www.sciencedirect.com/science/article/pii/S1751157724000646},
author = {Dejian Yu and Bo Xiang},
keywords = {Emerging scientific topic, Scientific text modeling, Neural prophet, Strategic market theory, Knowledge diffusion},
abstract = {Existing studies on the detection of emerging scientific topics (ESTs) overemphasize the newness and neglect content innovation of knowledge. Moreover, they also ignore the lag existing in knowledge diffusion. In this paper, we propose a four-stage detection framework for ESTs that maps emerging attributes from paper entities to scientific topics. Empirical studies based on two significantly different disciplinary datasets, IS-LS, and AI, which contain 73,601 and 255,620 publications, respectively, are employed to validate our approach. First, we generate 29 and 47 candidate scientific topics based on topic modeling, respectively. Second, we represent the novelty of paper entities based on pre-trained language models, which is mapped to scientific topic entities along with knowledge distributions to obtain topic emerging attributes: topic novelty, relative share and growth. Third, we propose to predict future trends of these attributes with Neural Prophet, which outperforms four baseline models in R2, MAE and RMSE. Finally, combining future values of candidate scientific topics, they are grouped into 8 clusters containing two ESTs types through strategic market theory and clustering model. From the correlation and feature distribution analysis of emerging attributes, we discover the existence of resilience and scale advantage in the diffusion of scientific knowledge. There also exists significant uncertainty in previous citation-based scientific topic evaluation patterns caused by the complexity of citation behavior. Overall, this research enriches theoretical knowledge and detection frameworks of ESTs, and provides detailed insights into comprehensive assessment and dissemination of scientific topics.}
}
@article{ZHANG2025102313,
title = {From approach to avoidance: How AI agent cognitive and affective empathy elicits the uncanny valley effect},
journal = {Telematics and Informatics},
volume = {101},
pages = {102313},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102313},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000759},
author = {Shuai Zhang and Yuxing Qian and Zhizhen Yao and Zhenni Ni and Yang Zhang},
keywords = {Artificial intelligence, Agents, Empathy, Mind, Uncanny valley, Approach-avoidance intentions},
abstract = {The empathy expressed by AI agents is crucial in human-AI interactions, especially within mental health contexts. However, the mechanisms underlying users’ responses to cognitive and affective empathy from AI agents are not well understood. This study examines the theoretical mechanisms and boundary conditions that determine how AI empathy influences users’ approach-avoidance intentions. Drawing on the computers are social actors (CASA) paradigm and the uncanny valley effect (UVE), we propose a moderated dual mediation model. This model is empirically tested using two experimental studies. The results reveal distinct pathways by which cognitive and affective empathy affect approach-avoidance intentions. Specifically, cognitive empathy primarily influences approach-avoidance intentions via perceived novelty, whereas affective empathy exerts its effect through perceived warmth. Additionally, perceived warmth and eeriness together mediate the impact of affective empathy on approach-avoidance intentions. Notably, mindful AI agents strengthen the effect of affective empathy on the UVE but diminish the influence of cognitive empathy on approach-avoidance intentions, relative to mindless agents. These findings provide important insights for AI designers and companies seeking to develop empathetic, user-centered conversational agents for mental health applications.}
}
@article{KUMAR2024107457,
title = {Dual attention and channel transformer based generative adversarial network for restoration of the damaged artwork},
journal = {Engineering Applications of Artificial Intelligence},
volume = {128},
pages = {107457},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.107457},
url = {https://www.sciencedirect.com/science/article/pii/S095219762301641X},
author = {Praveen Kumar and Varun Gupta and Manan Grover},
keywords = {Attention mechanism, Artwork restoration, Image translation, Generative adversarial networks, Transformers, Deep learning},
abstract = {Artworks are treasures of valuable cultural and historical heritage. Artworks get damaged due to environmental and other factors. The artificial intelligence-based restoration of digitized artwork images can guide the artists in physically restoring the damaged artworks. Previous methods have not been able to restore artwork images well. This paper proposes a dual (spatial and channel) attention and channel transformer-based generative adversarial network to restore damaged artwork images digitally. The proposed generative adversarial network has spatial and channel attention layers in the encoder part of the generator and a channel transformer between skip connections from the encoder to the decoder part of the generator. Spatial and channel attention helps learn inter-spatial and inter-channel global relationships among image features. Channel transformer ensures multiscale feature fusion and reduces the semantic gap between encoder and decoder layer features. Moreover, the proposed network has been trained using a linear combination of perceptual, adversarial, and structured similarity index measure loss, which helps better train the network. Further, the proposed network has been validated on two different datasets, and the results indicate that the proposed method outperforms state-of-the-art artwork restoration methods.}
}
@article{LUO2024124098,
title = {Dynamic Attribute-guided Few-shot Open-set Network for medical image diagnosis},
journal = {Expert Systems with Applications},
volume = {251},
pages = {124098},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124098},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424009643},
author = {Yiwen Luo and Xiaoqing Guo and Li Liu and Yixuan Yuan},
keywords = {Few-shot learning, Open-set recognition, Attribute generation, Dynamic feature alignment},
abstract = {The scarcity of data on rare diseases poses a significant challenge to the development of diagnostic systems. While few-shot learning (FSL) offers promise in low-data regimes, it often struggles in open-set scenarios, failing to identify unknown diseases. In this paper, we introduce a Dynamic Attribute-guided Few-shot Open-set Network (DAFON), representing the first effort to simultaneously address closed-set classification and open-set recognition in rare disease diagnosis. To alleviate incomprehensive category knowledge stemming from data scarcity, we propose a Global Attribute Generator to create attributes and produce image attribute activations for closed-set data as auxiliary information. An attribute space is then constructed and employed to generate the pseudo open-set attribute activations using a designed Open-set Data Sampler. By incorporating closed-set and open-set attribute activations as conditions, we propose a Dynamic Attribute Guided Alignment module to align feature space with attribute space, so as to derive feature space with intra-class compactness for closed-set and open-set classes. Our DAFON achieves state-of-the-art performance on two public medical image datasets, demonstrating its effectiveness for FSOSR in medical image diagnosis.}
}
@article{WANG2025125577,
title = {Automobile exterior emotional design method based on deep learning and multiple views imagery integrating calculation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125577},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125577},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424024448},
author = {Su Wang and Yuelin Liu and Li Sun and Guoqiang Chen},
keywords = {Automobile exterior emotion design, User emotional needs, Kansei engineering (KE), ResNet101-Attention, Multiple views imagery, LoRA},
abstract = {In the context of the increasingly dynamic experience economy, users’ emotional experience with automobile has become a leading factor in consumption, making automobile exterior crucial carriers of emotional needs and design expression. However, users’ emotion expression is from three-dimensional automobile entities, with a single perspective potentially causing deviations. Thus, this paper presents a novel automobile exterior emotion design method based on deep learning and multiple views imagery integrating calculation. This approach enables a seamless transition from users’ emotional needs to automobile exterior design. First, we explore users’ emotional evaluation of automobile exterior using the semantic differential method. The improved model of ResNet101-Attention mechanism was used to predict users’ emotion. Additionally, based on above emotional evaluation values, this study proposed a calculation method of multiple views automobile imagery integrating using the Analytic Hierarchy Process and Entropy Weight, calculate the automobile imagery weights of different views, and obtain the final automobile exterior emotional imagery. Finally, the Captum toolkit and the LoRA fine-tuning training technique are used to construct an automobile exterior design optimization generation model, producing a design that meets users’ emotion needs. By comparing the results obtained using both manual and automatic evaluations, and comparing to classical deep learning models. we verify the model’s validity and the advantages of the proposed method. This intelligent method assists designers in quickly identifying users’ responses for automobile design and provides automobile design that meet their emotional needs.}
}
@article{HARDCASTLE2025114979,
title = {The co-existence of brand value co-creation and co-destruction across the customer journey in a complex higher education brand},
journal = {Journal of Business Research},
volume = {186},
pages = {114979},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114979},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324004831},
author = {Kimberley Hardcastle and Prabash Edirisingha and Paul Cook and Matthew Sutherland},
keywords = {Complex Service Brands, Value Co-Creation, Value Co-Destruction, Value-in-Use, Stakeholders, Experiential Customer Journey},
abstract = {Brand value co-creation (VCC) and value co-destruction (VCD) have critical implications for brand experience. This study addresses theoretical gaps in the brand value co-creation literature by empirically exploring how multiple stakeholders with competing interests generate resource imbalances, revealing the coexistence of VCC and VCD within a complex service setting. Drawing from the higher education (HE) context, this research maps the customer experiential journey of focal primary stakeholders through netnography, focus groups and semi-structured in-depth interviews. We examine brand value dynamics at key touchpoints (pre-purchase, initial purchase and established consumption). Findings unveil four experiential states and demonstrate the dynamic interplay between VCC and VCD, shaping interpretations of value-in-use. Data extends current theoretical understandings by illustrating how these phenomena coexist within specific contexts, emphasising their tangible impact on brand value. Implications extend to practitioners seeking to manage stakeholder interactions, resources and value outcomes in diverse service environments.}
}
@article{ASHRAF2024,
title = {Multifactor Quality and Safety Analysis of Semaglutide Products Sold by Online Sellers Without a Prescription: Market Surveillance, Content Analysis, and Product Purchase Evaluation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/65440},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007568},
author = {Amir Reza Ashraf and Tim Ken Mackey and Róbert György Vida and Győző Kulcsár and János Schmidt and Orsolya Balázs and Bálint Márk Domián and Jiawei Li and Ibolya Csákó and András Fittler},
keywords = {semaglutide, Ozempic, Wegovy, search engines, online pharmacies, patient safety, medication safety, nondelivery schemes, counterfeit, substandard and falsified medical products},
abstract = {Background
Over the past 4 decades, obesity has escalated into a global epidemic, with its worldwide prevalence nearly tripling. Pharmacological treatments have evolved with the recent development of glucagon-like peptide 1 agonists, such as semaglutide. However, off-label use of drugs such as Ozempic for cosmetic weight loss has surged in popularity, raising concerns about potential misuse and the emergence of substandard and falsified products in the unregulated supply chain.
Objective
This study aims to conduct a multifactor investigation of product quality and patient safety risks associated with the unregulated online sale of semaglutide by examining product availability and vendor characteristics and assessing product quality through test purchases.
Methods
We used a complex risk and quality assessment methodology combining online market surveillance, search engine results page analysis, website content assessment, domain traffic analytics, conducting targeted product test purchases, visual quality inspection of product packaging, microbiological sterility and endotoxin contamination evaluation, and quantitative sample analysis using liquid chromatography coupled with mass spectrometry.
Results
We collected and evaluated 1080 links from search engine results pages and identified 317 (29.35%) links belonging to online pharmacies, of which 183 (57.7%) led to legal pharmacies and 134 (42.3%) directed users to 59 unique illegal online pharmacy websites. Web traffic data for the period between July and September 2023 revealed that the top 30 domains directly or indirectly affiliated with illegal online pharmacies accumulated over 4.7 million visits. Test purchases were completed from 6 illegal online pharmacies with the highest number of links offering semaglutide products for sale without prescription at the lowest price range. Three injection vial purchases were delivered; none of the 3 Ozempic prefilled injection pens were received due to nondelivery e-commerce scams. All purchased vials were considered probable substandard and falsified products, as visual inspection indicated noncompliance in more than half (59%-63%) of the evaluated criteria. The semaglutide content of samples substantially exceeded labeled amounts by 28.56%-38.69%, although no peptide-like impurities were identified. The lyophilized peptide samples were devoid of viable microorganisms at the time of testing; however, endotoxin was detected in all samples with levels ranging between 2.1645 EU/mg and 8.9511 EU/mg. Furthermore, the measured semaglutide purity was significantly low, ranging between 7.7% and 14.37% and deviating from the 99% claimed on product labels by manufacturers.
Conclusions
Glucagon-like peptide 1 agonist drugs promoted for weight loss, similar to erectile dysfunction medications more than 2 decades ago, are becoming the new blockbuster lifestyle medications for the illegal online pharmacy market. Protecting the pharmaceutical supply chain from substandard and falsified weight loss products and raising awareness regarding online medication safety must be a public health priority for regulators and technology platforms alike.}
}
@article{TEE202417191,
title = {Toward the Design of Allosteric Effectors: Gaining Comprehensive Control of Drug Properties and Actions},
journal = {Journal of Medicinal Chemistry},
volume = {67},
number = {19},
pages = {17191-17206},
year = {2024},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c01043},
url = {https://www.sciencedirect.com/science/article/pii/S1520480424009475},
author = {Wei-Ven Tee and Sylvester J. M. Lim and Igor N. Berezovsky},
abstract = {While the therapeutic potential of allosteric drugs is increasingly realized, the discovery of effectors is largely incidental. The rational design of allosteric effectors requires new state-of-the-art approaches to account for the distinct characteristics of allosteric ligands and their modes of action. We present a broadly applicable computational framework for obtaining allosteric site–effector pairs, providing targeted, highly specific, and tunable regulation to any functional site. We validated the framework using the main protease from SARS-CoV-2 and the K-RasG12D oncoprotein. High-throughput per-residue quantification of the energetics of allosteric signaling and effector binding revealed known drugs capable of inducing the required modulation upon binding. Starting from fragments of known well-characterized drugs, allosteric effectors and binding sites were designed and optimized simultaneously to achieve targeted and specific signaling to distinct functional sites, such as, for example, the switch regions of K-RasG12D. The generic framework proposed in this work will be instrumental in developing allosteric therapies aligned with a precision medicine approach.
}
}
@article{STETTINGER2025100320,
title = {Exploring the potential of standardized behaviour competencies in automated driving systems},
journal = {IFAC Journal of Systems and Control},
volume = {33},
pages = {100320},
year = {2025},
issn = {2468-6018},
doi = {https://doi.org/10.1016/j.ifacsc.2025.100320},
url = {https://www.sciencedirect.com/science/article/pii/S2468601825000264},
author = {Georg Stettinger and Patrick Weissensteiner and Nayel Fabian Salem and Marcus Nolte and Siddartha Khastgir},
keywords = {ADS regulation, Behaviour competencies, Manoeuvre, Operational design domain, Risk assessment, Standards, Trustworthy},
abstract = {This paper presents a comprehensive impact assessment to explore the potential benefits of harmonized behaviour competencies (BC) for automated driving systems (ADS). Typically, ADS-equipped vehicles operate within certain boundaries specified by an operational design domain (ODD), utilizing the relevant implemented BCs. Nonetheless, many regulatory and standardization-relevant documents employ BC attributes in a non-harmonized manner. The study delves into BC-related activities and applications throughout the entire ADS life cycle, affecting all aspects of the ADS value chain, to gain a deeper understanding of the diverse needs of various stakeholders. BCs are linked to one of the four primary requirement sources at the system level. ADS-related BCs are defined through a multidisciplinary approach driven by their underlying core operating principle: the well-known sense-plan-act cycle. The crucial element within the BC specification is the identified manoeuvre pool, which forms the basis for implementing any route from point A to point B. The individual manoeuvres within the manoeuvre pool are defined by considering the needs of multiple stakeholders. They are based on three essential components: the initial condition, the expected manoeuvre, and the final condition. Furthermore, trustworthy behaviour competencies are specified, encompassing three pillars: robustness, ethics, and lawfulness. Following a detailed stakeholder analysis, several related applications are discussed to highlight the concrete advantages of implementing standardized BCs. The study concludes with a summary of the impact analysis, emphasizing key findings and action points. Lastly, a roadmap is proposed to integrate trustworthy BCs into future ADS. Concretely, the authors developed the following innovations within the scope of this article: (1) Concept for trustworthy behaviour competencies driven by law, ethics, and robustness. (2) Robustness is defined as passenger & ODD awareness and plannable & executable manoeuvre. (3) Manoeuvre pool necessary to implement an arbitrary route from point A to point B. (4) Manoeuvre specification via initial condition, expected behaviour, and final condition. (5) The potential benefits of harmonized behaviour competencies drive impact assessment.}
}
@article{WANG2023109342,
title = {Supplementation of chestnut tannins in diets can improve meat quality and antioxidative capability in Hu lambs},
journal = {Meat Science},
volume = {206},
pages = {109342},
year = {2023},
issn = {0309-1740},
doi = {https://doi.org/10.1016/j.meatsci.2023.109342},
url = {https://www.sciencedirect.com/science/article/pii/S0309174023002486},
author = {Zhongyu Wang and Long Guo and Xing Ding and Fadi Li and Hui Xu and Shirong Li and Xinji Wang and Kaidong Li and Xiangpeng Yue},
keywords = {Chestnut tannins, Hu sheep, 16S rRNA, Transcriptomes, Meat quality, Antioxidant status},
abstract = {Chestnut tannins (CNT), as a source of hydrolyzable tannins, positively affect the antioxidant status of livestock. In the current study, 90 male Hu lambs were used to investigate the effect of dietary CNT intake on growth performance, nutrient digestibility, meat quality and oxidative stability, rumen microbial, and the transcriptomes of muscle and liver. A completely randomized design with three CNT intake levels (0, 0.3%, and 0.6%) was used. Rumen microbial and nutrient digestibility were not significantly altered by CNT intake. Diets with 0.3% CNT intake significantly reduced the shear force, yellowness at 24 h, and C20:2 polyunsaturated fatty acids of lamb meat and malondialdehyde in serum and longissimus thoracis (LT) muscle. Meanwhile, the 0.3% CNT diet significantly increased average daily gain during the 1– 21 days and 64– 90 days, dry matter intake during the 1– 21 days, the slaughter weight, and liver index of lambs. The 0.3% CNT diet significantly increased C26:0 saturated fatty acids, total antioxidant capacity, glutathione peroxidase, superoxide dismutase, and catalase in LT muscle. The meat shelf life of 0.3% CNT and 0.6% CNT groups was prolonged by 8.7 h and 5.4 h, respectively. Transcriptomic analysis revealed that CNT supplementation can induce the expression of antioxidant enzyme gene (CAT, SOD1), and the differentially expressed genes were mainly involved in antioxidant activity, transferase activity, and adenosine triphosphate binding. These results suggest that 0.3% CNT intake can relieve the oxidative stress of lambs, and improve the stability of meat color and meat tenderness, due to the enhanced antioxidative capacity.}
}
@article{ZHANG2025107596,
title = {CMPNet: A cross-modal multi-scale perception network for RGB-T crowd counting},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107596},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107596},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005600},
author = {Shihui Zhang and Kun Chen and Gangzheng Zhai and He Li and Shaojie Han},
keywords = {RGB-T crowd counting, Cross-modal perception fusion, Multi-scale feature aggregation, Spatial context awareness},
abstract = {The cross-modal crowd counting method demonstrates better scene adaptability under complex conditions by introducing independent supplementary information. However, existing methods still face problems such as insufficient fusion of modal features, underutilization of crowd structure, and the neglect of scale information. In response to the above issues, this paper proposes a cross-modal multi-scale perception network (CMPNet). Specifically, CMPNet mainly consists of a cross-modal perception fusion module and a multi-scale feature aggregation module. The cross-modal perception fusion module effectively suppresses noise features while sharing features between different modalities, thereby significantly improving the robustness of the crowd counting process. The multi-scale feature aggregation module obtains rich crowd structure information through a spatial context aware graph convolution unit, and then integrates feature information from different scales to enhance the network’s perception ability of crowd density. To the best of our knowledge, CMPNet is the first attempt to model the crowd structure and mine its semantics in the field of cross-modal crowd counting. The experimental results show that CMPNet achieves state-of-the-art performance on all RGB-T datasets, providing an effective solution for cross-modal crowd counting. We will release the code at https://github.com/KunChenKKK/CMPNet.}
}
@article{MEDLIN2025121068,
title = {Atomic-scale arrangement of dislocations at grain-boundary facet junctions},
journal = {Acta Materialia},
volume = {292},
pages = {121068},
year = {2025},
issn = {1359-6454},
doi = {https://doi.org/10.1016/j.actamat.2025.121068},
url = {https://www.sciencedirect.com/science/article/pii/S1359645425003581},
author = {Douglas L. Medlin and Elton Y. Chen and James E. Nathaniel and Rémi Dingreville and C. Barry Carter},
keywords = {Grain boundaries, Interfaces, Dislocations, Facet junctions, Atomic structure},
abstract = {This study investigates the atomic-scale arrangement of dislocations at grain-boundary facet junctions. We focus on the junctions between Σ3 {112} grain-boundary facets (often termed "incoherent" or "lateral" twin boundaries) in face-centered-cubic metals. Planar Σ3 {112} boundaries have long been modeled as dense arrays of Shockley partial dislocations distributed on adjacent {111} planes. Here, we analyze how such dislocations must be arranged at grain-boundary facet junctions. We find that these junctions constrain the sequences of dislocations that can allow for motion of the junctions through coordinated, conservative glide, a result we investigate with complementary molecular-dynamics simulations. For some facet arrangements, namely those for which facets are terminated at both ends by junctions of the same sense, the Shockley partial dislocations must change planes at the junctions, forming a2〈110〉 unit jogs. Because the unit jogs require the absorption or emission of point defects to move, they will limit motion of facet junctions. Such considerations offer insights into the mechanisms governing grain-boundary junction behavior.}
}
@article{PRETORIUS2025101038,
title = {Empowering international PhD students: Generative AI, Ubuntu, and the decolonisation of academic communication},
journal = {The Internet and Higher Education},
volume = {67},
pages = {101038},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101038},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000478},
author = {Lynette Pretorius and Huy-Hoang Huynh and Anak Agung Ayu Redi Pudyanti and Ziqi Li and Abdul Qawi Noori and Zhiheng Zhou},
keywords = {Generative AI, AI Literacy, Democratisation, Decolonisation, Academia, Doctoral Education, Ubuntu, Autoethnography},
abstract = {Generative AI (GenAI) provides distinct affordances that contribute meaningfully to learning. However, there are also several challenges, most notably ethical considerations. While much of the current research on GenAI in academia focuses on technical capabilities or ethical concerns, few studies have examined how GenAI can be leveraged to promote equity and inclusivity, particularly in academic communication. In this study, we adopt the theoretical lens of Ubuntu, a Southern African philosophy that emphasises interconnectedness and community, to reconceptualise GenAI as a democratising force. Five international PhD students in Education and their PhD supervisor (all multilingual users of English) explored their experiences of using GenAI. We used a collaborative autoethnographic approach, incorporating reflective prompting, individual writing, group sharing and refining, and group-based writing. We demonstrate that GenAI reshaped power dynamics and challenged academic hierarchies by providing real-time language support and improving academic writing clarity. This empowered us to participate in academic discourse, disrupting traditional gatekeeping mechanisms. By automating routine tasks, GenAI also shifted our academic focus from technical skills to intellectual contributions, fostering inclusivity and equity. This study highlights the potential of GenAI in terms of knowledge creation and academic discourse, particularly for doctoral scholars navigating linguistic and cultural barriers. Academia is predominantly Anglophone-centric, marginalising non-English-speaking scholars by imposing additional barriers to participation and recognition, perpetuating inequities in knowledge creation and dissemination. We argue that embracing GenAI can help to decolonise these academic practices, thereby promoting epistemic justice and creating a more equitable scholarly environment for all.}
}
@article{EGGER2025102582,
title = {Refining the process picture: Unstructured data in object-centric process mining},
journal = {Information Systems},
volume = {134},
pages = {102582},
year = {2025},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2025.102582},
url = {https://www.sciencedirect.com/science/article/pii/S0306437925000663},
author = {Andreas Egger and Tobias Fehrer and Wolfgang Kratsch and Niklas Wördehoff and Fabian König and Maximilian Röglinger},
keywords = {Object-centric process mining, Unstructured data, Reference architecture, Design science research, Business process management},
abstract = {Process mining aims to discover, monitor, and improve processes. To this end, process mining techniques use event data, typically extracted from information systems and organized along process instances. The inherent complexity of real-world processes has driven the recent introduction of object-centric process mining, allowing for a more comprehensive view of processes. Another avenue of research contributing to more complete process analyses is integrating unstructured data, which can enhance traditional event logs by extracting hitherto unidentified process information. Although combining the object-centric perspective with event log enrichment from unstructured data sources holds promising potential, such investigation remains in its infancy. Against this background, this study presents the OCRAUD, a reference architecture that provides guidance on using unstructured data sources and traditional event logs for object-centric process mining. A design science research process was employed to design and evaluate the OCRAUD. This involved conducting a total of 20 expert interviews over two rounds, comparing the OCRAUD to competing artifacts, instantiating the artifact for the use of video and sensor data, developing a software prototype, and applying the prototype to real-world data. This work contributes to process mining by guiding the combination of unstructured data with traditional event logs, incorporating an object-centric representation of event data. The instantiation targets video and sensor data, thereby demonstrating the use of the artifact. This enables researchers and practitioners to instantiate the artifact for other data types or specific use cases. The published code of the software prototype allows for further development of the implemented algorithms.}
}
@article{LIN2025115621,
title = {Active multi-mode data analysis to improve fault diagnosis in AHUs},
journal = {Energy and Buildings},
volume = {337},
pages = {115621},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.115621},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825003512},
author = {Guanjing Lin and John House and Yimin Chen and Jessica Granderson and Wanpeng Zhang},
keywords = {Fault diagnosis, Air handling unit, Multi-mode data analysis, Energy management and information system, Smart building},
abstract = {Faults in heating, ventilation and air conditioning systems can lead to increased energy consumption, occupant comfort issues, and reduced equipment lifetime. Commercial fault detection and diagnosis (FDD) tools has been increasingly deployed in U.S. commercial buildings. While they are helping to achieve energy efficiency and operational reliability, there remain gaps in their fault diagnostic capabilities. The diagnostic results often contain multiple distinct candidate root causes (CRCs) or offer no insight into CRCs. This study developed a novel active rule-based multi-mode data analysis method to enhance diagnostic resolution by applying proven rule sets and additional new rules to data from multiple known operational modes. The proposed method was demonstrated using enhanced air handling unit performance assessment rule sets and validated with the simulated data of two air handling units. New metrics, namely, reduced number of CRCs and improvement ratio, were developed to quantify the improvement of fault diagnostic resolution. The validation results showed that the proposed method effectively reduced the number of CRCs in contrast to analyzing data solely for a single mode of operation. It achieved a median improvement ratio of 80% in 19 test cases.}
}
@article{DARTORA2023113569,
title = {Understanding the effect of fermentation time on physicochemical characteristics, sensory attributes, and volatile compounds in green tea kombucha},
journal = {Food Research International},
volume = {174},
pages = {113569},
year = {2023},
issn = {0963-9969},
doi = {https://doi.org/10.1016/j.foodres.2023.113569},
url = {https://www.sciencedirect.com/science/article/pii/S0963996923011171},
author = {Bruna Dartora and Lilian Raquel Hickert and Mariana Fensterseifer Fabricio and Marco Antônio Zachia Ayub and Júnior Mendes Furlan and Roger Wagner and Karla Joseane Perez and Voltaire Sant'Anna},
keywords = {Fermented beverage, Aromatic compounds, Metagenomics, Sensory analysis},
abstract = {Kombuchas are a trend in the fermented beverage field and the effect of fermentation time on their characteristics is necessary to better understand the process, mainly concerning volatile compounds, which are scarce information in the current literature. Thus, the present work aimed to evaluate the features of green tea kombucha during fermentation, monitoring the changes in pH, acidity, turbidity, polyphenols, ethanol, acetic acid, volatile compounds, and sensory profile and acceptance up to 14 days of fermentation. Kombuchas’ pH and acidity decreased through time as expected, but after 4 days of fermentation, the beverage exceeded the Brazilian legal limits of acidity (130 mEq/L) and produced more than 0.5% AVB, which labels the beverage as alcoholic. Total polyphenols and condensed tannins content enhanced until the seventh day of fermentation and remained constant. Fermentation highly impacted the aroma of the infusion with a high formation of volatile acids, such as alcohols, esters, and ketones. Aldehydes were degraded during the bioprocess. Sensory characterization of kombucha showed that fermentation of 4 days increased perceived turbidity; vinegar, citric fruit, acid, and alcoholic aroma; and produced the beverage with sour, bitter, and vinegar flavor. Thus, the fermentation time of kombuchas must be controlled as they rapidly change and impact on the physicochemical parameters and sensory profile of the beverage can be negative.}
}
@article{DUI2025106523,
title = {A IoT-based novel methodology to optimize multidimensional flood resilience of drainage systems for sponge city},
journal = {Sustainable Cities and Society},
volume = {130},
pages = {106523},
year = {2025},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2025.106523},
url = {https://www.sciencedirect.com/science/article/pii/S2210670725003981},
author = {Hongyan Dui and Huanqi Zhang and Shaomin Wu},
keywords = {Sponge city, Multidimensional flood resilience, Drainage system, Optimization strategy},
abstract = {With the study of intra-city flooding, the construction of sponge cities has advanced significantly. Sponge cities enhance a city’s capacity to absorb and retain rainwater, thereby reducing the frequency and severity of urban flooding. However, in recent years, extreme rainfall events have led to poor performance in terms of rainwater absorption, storage, and release, resulting in severe casualties and significant economic losses. This paper focuses on both the internal operation and external environment of sponge city drainage systems. Externally, the goal is to reduce surface runoff after heavy rainfall, while internally, the aim is to improve the drainage system's ability to prevent, withstand, and recover from exceptionally heavy rainstorms. A novel multidimensional flood resilience assessment method is proposed, leveraging Internet of Things (IoT) technology to evaluate the performance of sponge cities. Corresponding multidimensional flood resilience optimization strategies are introduced to enhance surface runoff management after rainfall and improve the sponge city performance in the prevention, resistance, and recovery stages. Finally, a software, Storm Water Management Model (SWMM), was used to simulate an area in of Zhengzhou City during the “720″ rainstorm, validating the feasibility of the proposed method.}
}
@article{DESMARCHELIER2025105297,
title = {Beyond the reverse product cycle: An exploration of the digital, social and spatial transformation of libraries11We sincerely thank the anonymous reviewers for their insightful comments and suggestions, which significantly helped enhance our article.},
journal = {Research Policy},
volume = {54},
number = {8},
pages = {105297},
year = {2025},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2025.105297},
url = {https://www.sciencedirect.com/science/article/pii/S004873332500126X},
author = {Benoît Desmarchelier and Faridah Djellal and Faïz Gallouj and Nassim Gallouj},
keywords = {Innovation, ICTs, Services, Reverse product cycle, Libraries},
abstract = {Focusing on innovation dynamics in public libraries, this article begins by revisiting one of the very first attempts to construct a theory of innovation in services: the reverse product cycle (RPC), published in Research Policy (Barras, 1986, 1990). With reference to ICT-based innovation trajectories in libraries, the article validates the RPC by identifying a cycle that begins with a stage dominated by process innovations, followed by one dominated by product innovations. It goes further by extending – and in some respects updating – the model, taking into account forgotten technologies and introducing new waves of enabling technologies associated with Industry 4.0 and 5.0. The rise of the internet and digitization posed an existential threat to libraries. Their survival, however, is due to their ability to reinvent themselves – transforming this threat into an opportunity, and embracing innovative trajectories that aren't solely ICT-based. These include book-, object-, individual-, and space-based trajectories.}
}
@article{HAEFNER2023122878,
title = {Implementing and scaling artificial intelligence: A review, framework, and research agenda},
journal = {Technological Forecasting and Social Change},
volume = {197},
pages = {122878},
year = {2023},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.122878},
url = {https://www.sciencedirect.com/science/article/pii/S0040162523005632},
author = {Naomi Haefner and Vinit Parida and Oliver Gassmann and Joakim Wincent},
keywords = {Artificial intelligence, Machine learning, Review, Scaling, Innovation, Technology},
abstract = {Artificial intelligence (AI) will have a substantial impact on firms in virtually all industries. Without guidance on how to implement and scale AI, companies will be outcompeted by the next generation of highly innovative and competitive companies that manage to incorporate AI into their operations. Research shows that competition is fierce and that there is a lack of frameworks to implement and scale AI successfully. This study begins to address this gap by providing a systematic review and analysis of different approaches by companies to using AI in their organizations. Based on these experiences, we identify key components of implementing and scaling AI in organizations and propose phases of implementing and scaling AI in firms.}
}
@article{GUPTA2025104875,
title = {Rapid review: Growing usage of Multimodal Large Language Models in healthcare},
journal = {Journal of Biomedical Informatics},
volume = {169},
pages = {104875},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2025.104875},
url = {https://www.sciencedirect.com/science/article/pii/S1532046425001042},
author = {Pallavi Gupta and Zhihong Zhang and Meijia Song and Martin Michalowski and Xiao Hu and Gregor Stiglic and Maxim Topaz},
keywords = {Multimodal Large Language Models (MLLMs), Multimodal LLMs, Multi-modal LLMs, Healthcare, Multimodal Generative AI},
abstract = {Objective:
Recent advancements in large language models (LLMs) have led to multimodal LLMs (MLLMs), which integrate multiple data modalities beyond text. Although MLLMs show promise, there is a gap in the literature that empirically demonstrates their impact in healthcare. This paper summarizes the applications of MLLMs in healthcare, highlighting their potential to transform health practices.
Methods:
A rapid literature review was conducted in August 2024 using World Health Organization (WHO) rapid-review methodology and PRISMA standards, with searches across four databases (Scopus, Medline, PubMed and ACM Digital Library) and top-tier conferences—including NeurIPS, ICML, AAAI, MICCAI, CVPR, ACL and EMNLP. Articles on MLLMs healthcare applications were included for analysis based on inclusion and exclusion criteria.
Results:
The search yielded 115 articles, 39 included in the final analysis. Of these, 77% appeared online (preprints and published) in 2024, reflecting the emergence of MLLMs. 80% of studies were from Asia and North America (mainly China and US), with Europe lagging. Studies split evenly between pre-built MLLMs evaluations (60% focused on GPT versions) and custom MLLMs/frameworks development with task-specific customizations. About 81% of studies examined MLLMs for diagnosis and reporting in radiology, pathology, and ophthalmology, with additional applications in education, surgery, and mental health. Prompting strategies, used in 80% of studies, improved performance in nearly half. However, evaluation practices were inconsistent with 67% reported accuracy. Error analysis was mostly anecdotal, with only 18% categorized failure types. Only 13% validated explainability through clinician feedback. Clinical deployment was demonstrated in just 3% of studies, and workflow integration, governance, and safety were rarely addressed.
Discussion and Conclusion:
MLLMs offer substantial potential for healthcare transformation through multimodal data integration. Yet, methodological inconsistencies, limited validation, and underdeveloped deployment strategies highlight the need for standardized evaluation metrics, structured error analysis, and human-centered design to support safe, scalable, and trustworthy clinical adoption.}
}
@article{JANSON2023107954,
title = {How to leverage anthropomorphism for chatbot service interfaces: The interplay of communication style and personification},
journal = {Computers in Human Behavior},
volume = {149},
pages = {107954},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107954},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003059},
author = {Andreas Janson},
keywords = {Chatbots, Conversational agents, Anthropomorphic design, Social presence, Empathy, Trust},
abstract = {Although chatbots are oftentimes used in customer service encounters, interactions are oftentimes perceived as not satisfactory. One key aspect for designing chatbots is the use of anthropomorphic design elements. In this experimental study, we examine the two anthropomorphic chatbot design elements of personification, which includes a human-like appearance, and social orientation of communication style, which means a more sensitive and extensive communication. We tested the influence of the two design elements on social presence, satisfaction, trust and empathy towards a chatbot. First, the results show a significant influence of both anthropomorphic design elements on social presence. Second, our findings illustrate that social presence influences trusting beliefs, empathy, and satisfaction. Third, social presence acts as a mediator for both anthropomorphic design elements for satisfaction with a chatbot. Our implications provide a better understanding of anthropomorphic chatbot design elements when designing chatbots for short-term interactions, and we offer actionable implications for practice that enable more effective chatbot implementations.}
}
@incollection{NAYYAR2025309,
title = {Chapter 11 - Future trends in large language models and prompt engineering},
editor = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
booktitle = {Mastering Prompt Engineering},
publisher = {Morgan Kaufmann},
pages = {309-336},
year = {2025},
isbn = {978-0-443-33904-2},
doi = {https://doi.org/10.1016/B978-0-443-33904-2.00009-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443339042000094},
author = {Anand Nayyar and Ajantha Devi Vairamani and Kuldeep Kaswan},
keywords = {Artificial intelligence, Bidirectional encoder, Contrastive language-image pre-training, Natural language processing},
abstract = {The chapter delves into the transformative landscape of Large Language Models (LLMs) and prompt engineering, highlighting their impact on various sectors and the future of human-Artificial intelligence (AI) collaboration. It begins by examining recent advancements in LLM architectures and training techniques, emphasizing the evolution from traditional models to multimodal systems capable of processing diverse data types. The chapter discusses the significance of augmented prompt engineering as a means to enhance the synergy between human creativity and AI capabilities, facilitating more effective content generation across fields such as marketing, education, and healthcare. Additionally, the chapter addresses the critical need for explainability and interpretability in LLMs, advocating for transparency to build user trust and ensure ethical AI applications. It explores the democratization of access to AI technologies, emphasizing the role of user-friendly tools that enable individuals with varying technical expertise to engage with AI effectively. Interdisciplinary collaboration is presented as a key strategy for improving prompt engineering, drawing insights from linguistics, cognitive science, and ethics to foster innovation and address ethical concerns. The chapter concludes with a discussion on the potential of human-AI co-creation, envisioning a future where collaborative efforts lead to meaningful outcomes and enhanced creativity. By synthesizing these themes, the chapter provides a comprehensive roadmap for navigating the evolving landscape of LLMs and prompt engineering, underscoring their potential to positively impact society while addressing the challenges that lie ahead.}
}
@article{LIM2025743,
title = {Biological strategies in aquaculture disease management: Towards a sustainable blue revolution},
journal = {Aquaculture and Fisheries},
volume = {10},
number = {5},
pages = {743-763},
year = {2025},
issn = {2468-550X},
doi = {https://doi.org/10.1016/j.aaf.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468550X25000449},
author = {Keng Chin Lim and Fatimah Md Yusoff and Fatin M.I. Natrah and Mahanama {De Zoysa} and Ina Salwany {Md Yasin} and Jasmin Yaminudin and Murni Karim},
keywords = {Aquatic animals, Biological control, Functional ingredients, Infectious diseases, Quorum-sensing interference},
abstract = {Although the aquaculture industry has undergone monumental development worldwide, the ever-present threats of infectious diseases have become a constraining factor, imperiling its sustainability. Antimicrobial resistance (AMR) remains a real menace to industrial aquaculture due to the careless adoption of preventive therapies (antimicrobial therapeutic drugs) to forestall disease outbreaks in aquatic food production. Suitable strategies, or at least supplementary measures, should therefore be developed to curb the emergence and widespread transmission of AMR. Vaccination represents one of the primary options to substantially mitigate the economic damages imposed by emerging infectious diseases on global aquaculture; nevertheless, the availability of commercial aquatic vaccines is usually limited, and many vaccines only confer minimal or poor protection against infections (during the early stages of animal development). Accordingly, a large body of research has been enthusiastically exploring alternate approaches for managing animal health challenges. These efforts have led to the establishment of various biocontrol strategies, such as the versatile use of high-value functional ingredients (e.g., probiotics, prebiotics, synbiotics, paraprobiotics, postbiotics, and phytogenics), phage therapy, and quorum-sensing interference (QSI), to promote the health and welfare of farmed aquatic species in a responsive or preventative manner. This review article addresses the state-of-the-art pertinent to biological control as an eco-friendly green approach for aquatic disease management, paving the route to a sustainable blue revolution. The potential biological mechanisms of these strategies are also described, along with the impediments to scientific progress and topics that merit further investigation.}
}
@article{XU2025104006,
title = {Standardization in artificial general intelligence model for education},
journal = {Computer Standards & Interfaces},
volume = {94},
pages = {104006},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2025.104006},
url = {https://www.sciencedirect.com/science/article/pii/S0920548925000352},
author = {Qiuxuan Xu and Yonghe Wu and Hao Zheng and Huan Yan and Huina Wu and Yu Qian and You Wu and Bowen Liu},
keywords = {Artificial intelligence, Artificial general intelligence model for education, Standardization, Specifications, Use cases},
abstract = {The application of Artificial General Intelligence Models (AGIMs) in education has been identified as a promising emerging field. However, extensive research has revealed limitations in using AGIM in education, particularly in terms of controllability, trustworthiness, explainability, evaluation and feedback, security, and privacy. Therefore, standardization in AGIMs for Education (AGIME) is urgently required to provide normative guidance for developing artificial intelligence systems in education. This study first explores an AGIME standardization process with the methodology of use case collection and iterative research. We then propose the definition and attributes of AGIME and establish a standard system framework for the AGIME life cycle. This framework includes published specifications such as information model, data specification, evaluation specification, and application requirements on teaching and learning. We introduce standard application cases to validate the effectiveness of AGIME standard system framework. Finally, we present several specifications currently under development within this standard system, including interface, regulatory, operation and maintenance, and security, ethics, and privacy specifications. This study provides references for AGIME development and deployment, ensuring the technical stability, data credibility, evaluation accuracy, and pedagogical applicability of AGIME.}
}
@article{ZHAO2026103554,
title = {Generalized multimodal depression severity prediction method based on topic prompts},
journal = {Information Fusion},
volume = {126},
pages = {103554},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103554},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525006268},
author = {Di Zhao and Qi Li and Qingyu Na and Hongyu Xie and Tingyun Jiang},
keywords = {Topic prompts, Multimodal, Depression severity prediction, Information fusion},
abstract = {Multimodal depression severity prediction holds significant potential for clinical diagnosis. However, existing methods tend to overfit in data-scarce environments and lack generalizability across diverse cultural contexts. To address these challenges, we propose a Topic Prompts Multimodal Network (TPMN), a novel framework that integrates topic-guided prompt learning with a Wide & Deep architecture for robust depression prediction. Specifically, topic prompts — contextual cues derived from underlying topic patterns in patient interviews — are constructed using a Latent Dirichlet Allocation (LDA)-based prompt collection, capturing personalized semantic topics to guide multimodal feature alignment. These prompts help the model prioritize clinically relevant interactions across modalities via a cross-attention coupling function, where complex transformations dynamically align multimodal features, effectively mitigating overfitting while enhancing interpretability. Extensive experiments on AVEC2013 and AVEC2014 demonstrate TPMN’s superiority over state-of-the-art methods, achieving a 53% reduction in MAE (2.86 vs. SOTA 6.08) and 58% lower RMSE (3.36 vs. SOTA 7.96) on average. Notably, experiments on our self-collected Chinese dataset show that TPMN outperforms existing baseline methods, demonstrating its potential as a scalable diagnostic tool for diverse populations. Furthermore, zero-shot evaluation across cultural datasets demonstrates TPMN’s strong generalizability, with results comparable to baseline methods. Beyond its technical contributions, this work bridges the gap between data-driven AI and clinical needs, offering a principled approach to personalized and culturally adaptive mental health assessment.}
}
@article{LAZCANO2025113063,
title = {Data preprocessing techniques and neural networks for trended time series forecasting},
journal = {Applied Soft Computing},
volume = {174},
pages = {113063},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113063},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625003746},
author = {Ana Lazcano and Miguel A. Jaramillo-Morán},
keywords = {Differentiation, Forecasting, Preprocessing, MLP, LSTM},
abstract = {Research on time series forecasting continues to attract significant attention, particularly in the use of Artificial Neural Networks (ANN) due to their ability to model nonlinear behaviors. However, forecasting economic time series with steep upward trends presents challenges, often leading to poorly fitting predictions. This study addresses the issue by applying differentiation as a preprocessing step. Three real-world time series exhibiting this behavior were analyzed and forecasted using two neural network models—Long Short-Term Memory (LSTM) and Multilayer Perceptron (MLP)—with and without preprocessing. The differentiated series were further processed using techniques such as Empirical Mode Decomposition (EMD) and trend-fluctuation decomposition via Moving Average of Wavelet Transform. The results demonstrate that differentiation significantly enhances forecasting accuracy across all tested models, reducing errors by up to 30 % compared to models without preprocessing. This approach effectively mitigates trend-related distortions, leading to more reliable predictions in complex economic time series.}
}
@article{CASTELLANOSREYES2025101001,
title = {Transforming online learning research: Leveraging GPT large language models for automated content analysis of cognitive presence},
journal = {The Internet and Higher Education},
volume = {65},
pages = {101001},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101001},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000107},
author = {Daniela Castellanos-Reyes and Larisa Olesova and Ayesha Sadaf},
keywords = {Cognitive presence, Online learning, Artificial intelligence in education, Automated content analysis, Discussion boards, Large language models, GPT},
abstract = {The last two decades of online learning research vastly flourished by examining discussion board text data through content analysis based on constructs like cognitive presence (CP) with the Practical Inquiry Model (PIM). The PIM sets a footprint for how cognitive development unfolds in collaborative inquiry in online learning experiences. Ironically, content analysis is a resource-intensive endeavor in terms of time and expertise, making researchers look for ways to automate text classification through ensemble machine-learning algorithms. We leveraged large language models (LLMs) through OpenAI's Generative Pre-Trained Transformer (GPT) models in the public API to automate the content analysis of students' text data based on PIM indicators and assess the reliability and efficiency of automated content analysis compared to human analysis. Using the seven steps of the Large Language Model Content Analysis (LACA) approach, we proposed an AI-adapted CP codebook leveraging prompt engineering techniques (i.e., role, chain-of-thought, one-shot, few-shot) for the automated content analysis of CP. We found that a fine-tuned model with a one-shot prompt achieved moderate interrater reliability with researchers. The models were more reliable when classifying students' discussion board text in the Integration phase of the PIM. A cost comparison showed an obvious cost advantage of LACA approaches in online learning research in terms of efficiency. Nevertheless, practitioners still need considerable data literacy skills to deploy LACA at a scale. We offer theoretical suggestions for simplifying the CP codebook and improving the IRR with LLM. Implications for practice are discussed, and future research that includes instructional advice is recommended.}
}
@incollection{ARORA2023373,
title = {Chapter 34 - Artificial intelligence and big data: technical considerations and clinical applications},
editor = {Kevin Gillmann and Kaweh Mansouri},
booktitle = {The Science of Glaucoma Management},
publisher = {Academic Press},
pages = {373-385},
year = {2023},
isbn = {978-0-323-88442-6},
doi = {https://doi.org/10.1016/B978-0-323-88442-6.00030-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323884426000303},
author = {Anmol Arora and Anthony P. Khawaja and Pearse A. Keane},
keywords = {Machine learning, innovation, datasets, ophthalmology, ethics, legal, regulation, glaucoma, fundoscopy, ophthalmoscopy},
abstract = {Artificial intelligence (AI) and big data have attracted widespread attention in recent years, with research breakthroughs showing the potential for AI to enhance care and improve patient outcomes. Ophthalmology has been particularly rapid in its adoption of AI development and glaucoma care is emerging as a pathway that may benefit from AI implementation, with a high disease burden and availability of large datasets. In order for AI to be implemented, there are a number of technical considerations that must be overcome, including the development and security of appropriate datasets. Furthermore, while recent years have highlighted the potential of AI to transform patient care, they have also exposed key risks associated with AI development, including accountability, fairness, and ethico-legal considerations. This chapter explores the clinical applications of AI in glaucoma care, with discussion of ethical and technical considerations at all stages of the innovation process, from invention to implementation.}
}
@article{ZHANG2025100385,
title = {U.S. college students’ acceptability and educational benefits of ChatGPT from a digital divide perspective},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100385},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100385},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000256},
author = {Ceciley (Xinyi) Zhang and Laurent H. Wang and Ronald E. Rice},
keywords = {Acceptability, Adoption, ChatGPT, College students, Digital divide},
abstract = {ChatGPT has diffused widely and rapidly, with diverse positive and negative implications. In educational settings it is important to understand students' perceptions of the acceptability of ChatGPT for various learning activities and to examine whether prior digital divide concerns pertain to this digital innovation, in order to provide guidance for users, inform policymakers and other stakeholders, and extend digital divide research. The purpose is to investigate the associations of socioeconomic status (SES, both family and student), gender, and race/ethnicity with students’ perceived acceptability of common ChatGPT activities as well as their opinion about how beneficial ChatGPT is for college education, and additionally, whether such relationships differ based on adoption experience. We analyzed survey data quantitatively in two phases (N = 360 and 1267), applying measurement reliability and validity, correlations, and structural equation modeling. The results indicate that students with higher family SES and lower individual SES, and females, tend to view the acceptability of ChatGPT uses more positively, although racial/ethnic minorities are more critical of displacement activities. ChatGPT adopters perceive two dimensions of ChatGPT activities (academic support and academic displacement) as more acceptable than do non-adopters, and they also perceive uses for academic support more positively than for displacement. Moreover, adoption is a significant moderator of some of these associations. At this early stage of ChatGPT diffusion, these digital divide influences on acceptability and general opinion are weak and variable. The discussion further considers theoretical and practical implications for digital education in the AI era.}
}
@article{ZBOINSKA2025105947,
title = {Digital tool integrations for architectural reuse of salvaged building materials},
journal = {Automation in Construction},
volume = {170},
pages = {105947},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105947},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006836},
author = {Malgorzata A. Zboinska and Frederik Göbel},
keywords = {Architectural reuse, Salvaged construction materials, Digital twins, Photogrammetry, Robot vision, Computer vision, Machine learning, Robotic fabrication, 3D printing, Data-driven toolpath design},
abstract = {Building material reuse can reduce the environmental impact of construction yet its advanced digital support is still limited. Which digital tools could effectively support repair of highly irregular, salvaged materials? To probe this question, a framework featuring six advanced digital tools is proposed and verified through six design and prototyping experiments. The experiments demonstrate that a digital toolkit integrating photogrammetry, robot vision, machine learning, computer vision, computational design, and robotic 3D printing effectively supports repair and recovery of irregular reclaimed materials, enabling their robust digitization, damage detection, and feature-informed computational redesign and refabrication. These findings contribute to the advancement of digitally aided reuse practices in the construction sector, providing valuable insights into accommodating highly heterogeneous reclaimed materials by leveraging advanced automation and digitization. They provide the crucial and currently missing technological and methodological foundation needed to inform future research on industrial digital solutions for reuse.}
}
@article{KNOTH2024100225,
title = {AI literacy and its implications for prompt engineering strategies},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100225},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100225},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000262},
author = {Nils Knoth and Antonia Tolzin and Andreas Janson and Jan Marco Leimeister},
keywords = {Large language model, AI literacy, Prompt engineering, AI interaction, Education},
abstract = {Artificial intelligence technologies are rapidly advancing. As part of this development, large language models (LLMs) are increasingly being used when humans interact with systems based on artificial intelligence (AI), posing both new opportunities and challenges. When interacting with LLM-based AI system in a goal-directed manner, prompt engineering has evolved as a skill of formulating precise and well-structured instructions to elicit desired responses or information from the LLM, optimizing the effectiveness of the interaction. However, research on the perspectives of non-experts using LLM-based AI systems through prompt engineering and on how AI literacy affects prompting behavior is lacking. This aspect is particularly important when considering the implications of LLMs in the context of higher education. In this present study, we address this issue, introduce a skill-based approach to prompt engineering, and explicitly consider the role of non-experts' AI literacy (students) in their prompt engineering skills. We also provide qualitative insights into students’ intuitive behaviors towards LLM-based AI systems. The results show that higher-quality prompt engineering skills predict the quality of LLM output, suggesting that prompt engineering is indeed a required skill for the goal-directed use of generative AI tools. In addition, the results show that certain aspects of AI literacy can play a role in higher quality prompt engineering and targeted adaptation of LLMs within education. We, therefore, argue for the integration of AI educational content into current curricula to enable a hybrid intelligent society in which students can effectively use generative AI tools such as ChatGPT.}
}
@article{WANG2024103508,
title = {Charting the trajectory of language teacher cognition development: What 15 years of research in System informs us},
journal = {System},
volume = {127},
pages = {103508},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103508},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24002902},
author = {Yonghua (Yoka) Wang and Lawrence Jun Zhang},
keywords = {Language teacher cognition, Teacher beliefs, Teacher learning, Teacher professional development},
abstract = {Teacher education has always been what our journal, System, plays much emphasis on, and this emphasis has gradually strengthened as research into teacher cognition has gained popularity, particularly following Borg's influential work in 2006. While earlier studies by Wood (1996) have already examined teacher beliefs and their relationships with classroom practices, the mounting attention to this area has significantly shaped the scope of our journal. In the interest of helping our readers to have a fresh memory of how System has been playing an ever-increasing role in disseminating information related to language teaching and learning, and in this case, research into language teacher cognition, we present a historical overview of studies on teacher cognition that have been published in System over the past fifteen years. In doing so, we would like to show the major themes and trends in teacher cognition research reflected in System from 2008 to 2023 and how System has contributed to advancing this line of study. It is hoped that, with our systematic documentation of important work that has been done along these lines in our journal, we aspire to retain our focus on teacher cognition in our journal in the years to come.}
}
@article{HALLAM2024107452,
title = {Comprehensive functional characterization of complement factor I rare variant genotypes identified in the SCOPE geographic atrophy cohort},
journal = {Journal of Biological Chemistry},
volume = {300},
number = {7},
pages = {107452},
year = {2024},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2024.107452},
url = {https://www.sciencedirect.com/science/article/pii/S0021925824019537},
author = {Thomas M. Hallam and Anneliza Andreadi and Scott J. Sharp and Vicky Brocklebank and Emanuela Gardenal and Anna Dreismann and Rashi Arora and Marcus Dennis and Christina Flaxel and Edward Hall and Carel Hoyng and Peter {Charbel Issa} and Nicolas Leveziel and Fanni Molnár and Rafael Navarro and Todd Schneiderman and David Steel and Ramin Tadayoni and Tongalp Tezel and Michel Weber and Andrew J. Lotery and Kevin J. Marchbank and Claire L. Harris and Amy V. Jones and David Kavanagh},
keywords = {complement, complement system, enzyme mutation, retinal degeneration, innate immunity, complement factor I, age-related macular degeneration (AMD), atypical hemolytic uremic syndrome (aHUS), C3 glomerulopathy(C3G)},
abstract = {Rare variants (RVs) in the gene encoding the regulatory enzyme complement factor I (CFI; FI) that reduce protein function or levels increase age-related macular degeneration risk. A total of 3357 subjects underwent screening in the SCOPE natural history study for geographic atrophy secondary to age-related macular degeneration, including CFI sequencing and serum FI measurement. Eleven CFI RV genotypes that were challenging to categorize as type I (low serum level) or type II (normal serum level, reduced enzymatic function) were characterized in the context of pure FI protein in C3b and C4b fluid phase cleavage assays and a novel bead-based functional assay (BBFA) of C3b cleavage. Four variants predicted or previously characterized as benign were analyzed by BBFA for comparison. In all, three variants (W51S, C67R, and I370T) resulted in low expression. Furthermore, four variants (P64L, R339Q, G527V, and P528T) were identified as being highly deleterious with IC50s for C3b breakdown >1 log increased versus the WT protein, while two variants (K476E and R474Q) were ∼1 log reduced in function. Meanwhile, six variants (P50A, T203I, K441R, E548Q, P553S, and S570T) had IC50s similar to WT. Odds ratios and BBFA IC50s were positively correlated (r = 0.76, p < 0.01), while odds ratios versus combined annotation dependent depletion (CADD) scores were not (r = 0.43, p = 0.16). Overall, 15 CFI RVs were functionally characterized which may aid future patient stratification for complement-targeted therapies. Pure protein in vitro analysis remains the gold standard for determining the functional consequence of CFI RVs.}
}
@article{KOLLAROS2025113763,
title = {Uncovering the hidden dynamics of pollination in kiwifruit maturity and ripening},
journal = {Postharvest Biology and Technology},
volume = {230},
pages = {113763},
year = {2025},
issn = {0925-5214},
doi = {https://doi.org/10.1016/j.postharvbio.2025.113763},
url = {https://www.sciencedirect.com/science/article/pii/S0925521425003758},
author = {Marios Georgios Kollaros and Michail Michailidis and Alexandra Poulouktsi and Daniil Achilleas Pavlidis and Christina Skodra and Chrysanthi Polychroniadou and Martina Samiotaki and Katerina Karamanoli and Georgia Tanou and Athanassios Molassiotis},
keywords = {Artificial pollination, Fruit quality, Open-field pollination, Proteomics, Postharvest, Tissue-specific, Volatiles},
abstract = {Artificial pollination has gained increasing attention in kiwifruit cultivation; however, how different pollination methods influence fruit maturity and ripening remains poorly understood. To address this, the physiological, metabolomic, proteomic and gene expression impact of pollination methods (artificial versus open-field pollination) on the pericarp, placenta and seed tissue of Actinidia chinensis var. deliciosa A. Chev. ‘Hayward’ kiwifruit at maturity harvest and during postharvest ripening following short and long cold storage was investigated. Artificial pollination enhanced fruit set and seed number, resulting in increased fruit size and weight at harvest compared to open-field pollination, supporting its role in improving kiwifruit yield. Metabolomic analysis revealed that carbon is primarily redirected from sugar synthesis toward organic acid production in artificially pollinated fruit. Tissue-specific proteomic analysis indicated that artificial pollination alters plant growth regulator dynamics and induce extensive stress-associated responses. Moreover, artificial pollination accelerated kiwifruit ripening as evidenced by increased ethylene production and faster fruit softening. These changes were accompanied by altered expression of genes and proteins involved in ethylene signaling and cell wall structure, potentially reducing postharvest longevity. Additionally, artificial pollination decreased key esters and increased aldehydes, thus altering aroma volatile profiles. It also reduced the levels of important polyphenols, particularly catechin, epicatechin and procyanidin B2, which aligned with observed changes in gene expression. These findings highlight a critical trade-off: while artificial pollination enhances yield, it also modulates physiological processes that may compromise postharvest fruit quality. Overall, this study provides new insights into how pollination influences kiwifruit maturity and ripening, supporting pollination-based strategies to enhance both fruit yield and quality.}
}
@incollection{KHAN202545,
title = {Chapter 3 - Overview of AI technologies and their impact on healthcare},
editor = {Sameer Mohommed Khan},
booktitle = {Fundamentals of AI for Medical Education, Research and Practice},
publisher = {Academic Press},
pages = {45-71},
year = {2025},
isbn = {978-0-443-33584-6},
doi = {https://doi.org/10.1016/B978-0-443-33584-6.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443335846000037},
author = {Sameer Mohommed Khan},
keywords = {AI technologies in healthcare, Artificial neural network (ANN), Convolutional neural network (CNN), Deep learning, Feed forward neural network (FNN), Intelligent tutoring system (ITS), Internet of things (IOT), Machine learning, Perceptron, Reinforcement learning, Smart health card},
abstract = {In recent years, artificial intelligence (AI) has become more and more common, especially in the healthcare industry. Its influence has been so big that it has established itself as a pillar of the medical industry. Over the past few years, the application of AI technology to numerous fields in medical research and patient care has resulted in more precise diagnosis, individualized treatment regimens, and better patient outcomes. AI has a broad use in healthcare, including the analysis of radiological images for the purpose of early disease identification and the use of electronic health data to predict patient outcomes. As a result, millions of people worldwide may now receive the best treatment possible thanks to smarter, quicker, and more effective healthcare procedures. The chapter introduces the reader to various AI technologies and explores how a wide range of technologies, including computer vision, robotic processing automation, natural language processing, and machine learning, have significantly improved patient care and allowed for more accurate diagnosis and treatment.}
}
@article{MA2025114169,
title = {Actminer: Applying causality tracking and increment aligning for graph-based threat hunting},
journal = {Knowledge-Based Systems},
volume = {327},
pages = {114169},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114169},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125012109},
author = {Mingjun Ma and Tiantian Zhu and Shuang Li and Tieming Chen and Mingqi Lv and Zhengqiu Weng and Guolang Chen},
keywords = {Threat hunting, Attack scenario graph, Data provenance, Cyber threat intelligence, Graph-based knowledge,},
abstract = {To defend against advanced persistent threats on the endpoint, threat hunting employs security knowledge, such as cyber threat intelligence (CTI), to continuously analyze system audit logs through retrospective scanning, querying, or pattern matching, aiming to uncover attack patterns/graphs that traditional detection methods (e.g., recognition for point of interest) fail to capture. However, existing threat hunting systems based on provenance graphs face challenges of high false negatives (FNs), high false positives (FPs), and low efficiency when confronted with diverse attack tactics and voluminous audit logs. To address these issues, we propose a system called Actminer, which constructs query graphs from descriptive relationships in CTI reports for precise threat hunting (i.e., graph alignment) on provenance graphs. First, we present a heuristic search strategy based on equivalent semantic transfer to reduce FNs. Second, we establish a filtering mechanism based on causal relationships of attack behaviors to mitigate FPs. Finally, we design a tree structure to incrementally update the alignment results, significantly improving hunting efficiency. Evaluation on the DARPA Engagement dataset demonstrates that compared with the SOTA POIROT, Actminer reduces FPs by 39.1 %, eliminates all FNs, and effectively counters adversarial attacks.}
}
@article{KNIGHT2024102972,
title = {The evolution of contemporary education hubs: Fad, brand or innovation?},
journal = {International Journal of Educational Development},
volume = {104},
pages = {102972},
year = {2024},
issn = {0738-0593},
doi = {https://doi.org/10.1016/j.ijedudev.2023.102972},
url = {https://www.sciencedirect.com/science/article/pii/S0738059323002481},
author = {Jane Knight},
keywords = {Education hub, Education city, Knowledge city, Research/innovation, Branch campus, Transnational education},
abstract = {The purpose of this article is to examine the evolution of education hubs over the last two decades and revisit the question as to whether they are a fad, brand or innovation. Key features of ten different education hub countries, at different stages of development and sustainability, are analyzed leading to the identification of contemporary trends and challenges for student, talent/workforce and knowledge/innovation hubs. Given that education hubs are a seriously understudied phenomenon, critical issues relating to potential impact of geo-political instability, recognition of credentials, quality assurance, recruitment and retention of students for workforce and transition to knowledge economy, collaboration and/or competition between local/foreign actors, research integrity and knowledge security, private ownership/funders of branch campuses, will be of interest to policy makers, academic leaders, and researchers/scholars.}
}
@article{LI2024128185,
title = {Urban park attributes as predictors for the diversity and composition of spontaneous plants − A case in Beijing, China},
journal = {Urban Forestry & Urban Greening},
volume = {91},
pages = {128185},
year = {2024},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2023.128185},
url = {https://www.sciencedirect.com/science/article/pii/S1618866723003564},
author = {Xiaopeng Li and Xiaolu Li and Mengyuan Zhang and Qinyu Luo and Yilun Li and Li Dong},
keywords = {Taxonomic composition, Urban parks, Diversity and similarity, Landscape pattern, Planting design},
abstract = {Urban biodiversity homogenization and native species habitat loss are becoming increasingly severe. The overuse of lawn grasses and cultivars in green spaces is one of the most important drivers. Scholars have asserted that spontaneous vegetation provides various ecological benefits and should be widely incorporated in planting design. Factors influencing spontaneous plant diversity have mainly been studied in specific habitats or at the city scale, and findings surrounding the attributes of urban parks that support the diversity of spontaneous plants are lacking. This study aimed to provide a perspective on conserving spontaneous plants through inferring the urban park attributes associated with plant diversity. Twenty-two urban park samples in Beijing were examined to identify the correlation between various park variables and spontaneous vegetation. This study recorded 199 spontaneous plant species, with large historic parks containing the most number of species. Park size was a remarkable predictive variable for the diversity of spontaneous plants. Species richness and diversity in large parks were significantly higher than in small parks; not only in total richness due to the species–area relationship but also in richness and diversity at the community level independent of plot number. Microhabitat heterogeneity and the percentage of green area had the strongest positive association with the richness of spontaneous plants. In contrast, the maintenance intensity, perimeter–area ratio, and fragmentation of green area, deciduous forest, and open lawn patches had negative associations with spontaneous plant richness. Redundancy analysis demonstrated that park area, maintenance intensity, microhabitat heterogeneity, and deciduous forest patches were the most remarkable variables predicting species composition. The correlations of variables related to water and open lawn patches with spontaneous plant diversity were more evident in summer. The predicted variables were also more significantly correlated with the diversity of exotic species in summer than in spring. Perennial herbs were more sensitive to the evaluated park attributes. This study elucidates how spontaneous plants are associated with the attributes of urban parks in Beijing, with critical implications for other large cities.}
}
@article{JIA2025104130,
title = {Breaking data barriers in medical diagnosis with MSDGD framework based on Gaussian Diffusion Generation},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104130},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104130},
url = {https://www.sciencedirect.com/science/article/pii/S030645732500072X},
author = {Fengwei Jia and Fengyuan Jia and Huale Li and Shuhan Qi and Hongli Zhu},
keywords = {Medical Service Data, Decision support systems, Data generation, Categorical data modeling, Diffusion framework},
abstract = {Domain knowledge gaps and scarcity of data on rare medical conditions pose significant challenges to leveraging Medical Service Data (MSD) effectively, resulting in compromised research quality and uninformed medical decision-making. To address these limitations, we propose a novel Gaussian diffusion-based MSD generation framework, MSDGD. This framework includes embedding modules such as the Parents-Children Numerical encoding scheme (ParentChild), which encodes column pair interactions, the Random Column Rearrangement algorithm (RamCol), which uncovers hidden multi-column relationships, and a Spatial Dimensional Transformation strategy (DimTrans) for optimal multi-row feature extraction. Additionally, we develop a new UNet model (MSDUNet) and a column relationship predictive process to enhance MSDGD optimization. We perform three sub-experiments to evaluate the effectiveness of MSDGD in generating MSD, and to assess the framework across five metrics, we use (1) a Simulation Table without Column Relationship, (2) a Simulation Table with Column Relationship, and even (3) a complex relationship table derived from real-world U.S. Chronic Disease Indicators datasets. This table contains more than 40 columns and 8x4 categories. The experimental results indicate that MSDGD has a high potential for improving medical service quality, achieving a 97.97% reduction in errors rate, thus promoting research by generating dependable and diversified generation of medical services data.}
}
@article{LIU2024100025,
title = {Unveiling the potential of digital twins in logistics and supply chain management: Services, capabilities, and research opportunities},
journal = {Digital Engineering},
volume = {3},
pages = {100025},
year = {2024},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100025},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000256},
author = {Yu Liu and Shenle Pan and Eric Ballot},
keywords = {Digital twin, Logistics, Supply chain management, Asset management, Operations management, Service innovation, Data integration, Interoperability, Supply chain collaboration, Intelligent transportation systems, Cold chain logistics},
abstract = {Logistics is a labor- and asset-intensive industry, characterized by numerous operational processes managed by heterogeneous partners, which are tightly interconnected. Maximizing resource utilization and ensuring efficient stakeholder coordination within logistics operations pose significant challenges. Recently, Digital Twin (DT) technology has gained increasing interest for its potential to enhance asset and operations management in logistics. However, few studies offer a comprehensive view of DT applications across end-to-end global logistics services, particularly in relation to service innovations and the technological maturity of different service types. This paper conducts a Systematic Literature Review (SLR) to explore the state of the art in DT applications in logistics, offering an in-depth understanding of recent research foci, advancements, and opportunities for service innovation. Following the screening process, 70 papers were selected and analyzed. A three-axis framework is used to categorize key aspects of effective DT application, focusing on application areas, service types, and technological maturity as measured by the Technology Readiness Level (TRL). In logistics operations, DT has the potential to innovate or enhance eight key services: Monitoring, Evaluation, Prediction, Optimization, Control, System Management, System Integration, and Adaptation. DTs must be proficient in five core capabilities to deliver these eight services: integration, computation, simulation, interoperation, and evolution. In terms of DT technology maturity, most research focuses on early-stage development, emphasizing conceptual frameworks and exploring potential services. While many studies have tested proposed DT services in simulated environments, only a few have evaluated them in real-world operational settings. Finally, research avenues are explored, providing valuable insights for future investigations and continued development of DT applications in logistics and supply chain management.}
}
@article{PRAMUDYO2024212586,
title = {Permeability enhancement by CO2 injection and chelating agent stimulation for creating geothermal reservoirs in granite},
journal = {Geoenergy Science and Engineering},
volume = {234},
pages = {212586},
year = {2024},
issn = {2949-8910},
doi = {https://doi.org/10.1016/j.geoen.2023.212586},
url = {https://www.sciencedirect.com/science/article/pii/S2949891023011739},
author = {Eko Pramudyo and Luis Salalá and Ryota Goto and Jiajie Wang and Kazumasa Sueyoshi and Lena Muhl and Kiyotoshi Sakaguchi and Noriaki Watanabe},
keywords = {CO fracturing, Chelating agent injection, Permeability enhancement, Differential stress, Geothermal reservoir},
abstract = {Existing research indicates that to create geothermal reservoirs using CO2 injection, additional stimulation methods are necessary. N, N-bis(carboxymethyl)-L-glutamic acid (GLDA) injection has been predicted to increase the permeability of CO2 injection-induced cloud-fracture networks (CFNs) and could serve as an additional stimulation method. Nevertheless, the influence of differential stress, flow geometry, and scale on the characteristics of permeability enhancement by GLDA injection is yet to be clarified. Accordingly, this study experimentally elucidated the permeability enhancement characteristics of injecting a chelating agent in fractured granite under differential stress conditions as an additional method for creating geothermal reservoirs using CO2 injection. GLDA injection experiments were conducted on fractured-granite samples under conventional- and true-triaxial stress states under varying differential stress and pH conditions. Regardless of the differential stress and pH conditions, rock deformation and acoustic emission (AE) were negligible during the chelating agent flow-through experiments on the fractured samples, whereas similar permeability enhancement factors were achieved within the same duration. Thus, stress did not affect the permeability enhancement by chelating agent injections. The permeability enhancement factors were inferred to be high near the injection borehole because of the high viscosity of the solution. Therefore, reservoir stimulation should be conducted using low-concentration chelating agent solutions at constant injection pressures. The study provides insights into the stimulation strategies for creating geothermal reservoirs using CO2 injection.}
}
@article{FUNA2025101221,
title = {Policy guidelines and recommendations on AI use in teaching and learning: A meta-synthesis study},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101221},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2024.101221},
url = {https://www.sciencedirect.com/science/article/pii/S2590291124004182},
author = {Aaron A. Funa and Renz Alvin E. Gabay},
keywords = {AI ethics, AI integration, AI in education, AI in teaching and learning, Artificial intelligence, ChatGPT},
abstract = {As artificial intelligence becomes increasingly integral to educational systems, understanding policy guidelines and recommendations from various sources is crucial. This meta-synthesis examines AI policies and guidelines from peer-reviewed articles, reports, books, and websites from 2020 to 2024, with a focus on their implications for teaching and learning. Using a thematic analysis approach, the study categorizes findings into key themes and subthemes. Under the theme of policies and guidelines, notable subthemes include ethical AI use, AI literacy, and inclusivity and equity. In terms of implementation strategies, the synthesis identifies crucial areas such as student orientation and professional development, enhanced teaching tools and data-driven insights, improved student learning outcomes and engagement, and streamlined administrative processes. The study also determines practical constraints that challenge the successful integration of AI in education, including technical and integration challenges, training and support issues, ethical and fairness concerns, cost and accessibility, transparency and privacy issues, and misalignment with educational goals. Future research may explore the long-term impacts of AI integration policies and guidelines, refine practical implementation strategies, and foster collaboration among researchers, educators, and policymakers to tackle ongoing challenges and maximize AI's potential in education.}
}
@article{PETRIC2024,
title = {Everyone Talks Everything With ChatGPT:},
journal = {International Journal of Technology and Human Interaction},
volume = {20},
number = {1},
year = {2024},
issn = {1548-3908},
doi = {https://doi.org/10.4018/IJTHI.349225},
url = {https://www.sciencedirect.com/science/article/pii/S1548390824000030},
author = {Gregor Petrič},
keywords = {ChatGPT, Clustering, Factor Analysis, Large Language Models, Learning Performance, Motives, Problematic Use, Regression Analysis, Students, Typology, Uses and Gratifications},
abstract = {ABSTRACT
Research suggests that ChatGPT offers numerous affordances for students, who use it for various purposes, yet the field lacks quantitative studies that offer insight into a variety of students’ actual uses of ChatGPT and their impact on academic performance. The main aims of this paper were (a) to introduce and validate a typology of students’ ChatGPT uses, (b) to identify clusters of students with similar patterns of ChatGPT uses, and (c) to investigate the impact of ChatGPT uses on academic performance. An online survey research was conducted, which resulted in a typology of 10 distinct uses of ChatGPT and four distinct clusters of students. The strongest predictor of academic performance is information searching and explanation. Problematic use of ChatGPT, while resulting in improved grades, is found to be detrimental to competencies. Although the study might not fully represent the diversity of students’ experiences across academic institutions, the typology offers a baseline for nuanced research and interventions pertaining to particular ChatGPT uses among students.}
}
@article{MODEEL2025,
title = {Emerging Risk Factors and the Role of Gut Microbiota in Immunomodulation and Therapeutic Implications in Colorectal Cancer},
journal = {Cancer Pathogenesis and Therapy},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S294971322500076X},
author = {Sonakshi Modeel and Sneha Siwach and Padma Dolkar and Meenu Chaurasia and Pankaj Yadav and Apoorva Atri and Aarzoo Yadav and Tarana Negi and Ram Krishan Negi},
keywords = {Colorectal cancer, CRC therapy, Gastrointestinal Microbiome, Immunomodulation, Probiotics, Risk factors},
abstract = {The pathophysiology of many ailments, including neurological, gastrointestinal, and metabolic problems, is well known to be influenced by intestinal dysbiosis. Clinical research has provided evidence suggesting a strong correlation between dysbiosis of the gut microbiome and colorectal cancer (CRC) development. The active reprogramming of metabolic pathways to boost glycolysis, fatty acid production, lipogenesis, and glutaminolysis constitutes a major metabolic shift in cancer development, including CRC. The complex combination of different factors leads to CRC, making it an environmental disease. These factors include food and lifestyle choices, genetics and family history, age, underlying intestinal diseases, and dysbiosis of the gut microbiota. One of the primary risk factors for carcinoma development is diet, which impacts an individual's gut microbiome. In addition to impacting CRC formation, the gut microbiome also has immunomodulatory effects, including various immunological interactions and the underlying mechanisms governing them. Microbial interactions in CRC have been extensively studied, yet numerous unresolved queries exist on how gut bacteria can influence treatment. It is possible to perform microbiome-driven immunotherapies focusing on probiotics, prebiotics, and synbiotics. However, large-scale treatment utilization in CRC patients is limited by several issues, including variations in the microbial makeup of each patient's gut and a lack of established methods. The study highlights the impact of several risk factors, including dysbiosis of the gut microbiome and different approaches to halting and treating CRC progression with a focus on diet changes and modulation of the gut flora. Given the foregoing, we propose that if research gaps are addressed and immunotherapy is paired with microbial interventions, microbiota-based therapeutics could potentially impede the growth of tumors and treat CRC.}
}
@article{LYNDGAARD2024104027,
title = {Technological support for lifelong learning: The application of a multilevel, person-centric framework},
journal = {Journal of Vocational Behavior},
volume = {153},
pages = {104027},
year = {2024},
issn = {0001-8791},
doi = {https://doi.org/10.1016/j.jvb.2024.104027},
url = {https://www.sciencedirect.com/science/article/pii/S000187912400068X},
author = {Sibley F. Lyndgaard and Rebecca Storey and Ruth Kanfer},
keywords = {Reskilling, Upskilling, Adult learning, Technology, Online learning, Artificial intelligence, Lifelong learning},
abstract = {21st century career development is increasingly characterized by recurring participation in work-related skill learning, much of which is mediated by technology. However, integration of this technology into work-related lifelong learning contexts has been relatively atheoretical and non-systematic. Building on interdisciplinary adult learning research and our findings from several studies on an online graduate degree program in a high demand STEM field, we propose a multilevel, person-centric framework of adult learning processes related to: (1) knowledge and skill acquisition, (2) the development and maintenance of motivation and wellbeing over time, and (3) transfer of learning to career-related goals. For each level of the framework, we discuss issues related to the measurement and evaluation of learning. We outline affordances (i.e., functional benefits) of technology (including artificial intelligence) for supporting career-related learning at each level, and present future directions related to major gaps in the field's understanding of these affordances. Throughout the final section, we illustrate the implications of our framework with examples of its use in a research institute focused on AI adult learning technologies. Finally, we present guiding questions for researchers and practitioners interested in technology-mediated career-related learning.}
}
@article{KUO2023110976,
title = {A semantic web-based risk assessment framework for collaborative planning to enhance overall supply chain effectiveness for semiconductor industry},
journal = {Applied Soft Computing},
volume = {149},
pages = {110976},
year = {2023},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.110976},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623009948},
author = {Hsuan-An Kuo and Chen-Fu Chien and Hans Ehm and Thomas Ponsignon},
keywords = {Semantic web, Semiconductor manufacturing, Overall supply chain effectiveness, System interoperability, Root cause diagnosis},
abstract = {Semiconductor supply chain uncertainty is increasingly complicated due to shortening product life cycles, demand fluctuation and a series of collaborative decisions, yet little research focuses on risk assessment from operational planning level to supply chain planning level. Limitations of existing approaches can be traced in part to the lack of a framework within which the decisions involved in different levels can be integrated and aligned in light of supply chain dynamics. This study aims to develop a semantic web based risk assessment framework to integrate collaborative planning and enable the interpretability among real world and simulation modelling. This study starts by proposing a performance elevation metric from interpreting planning level for overall supply chain effectiveness. This study further constructs an ontology for planning and control decisions to support building the risk assessment simulation model to ensure information system interoperability and link domain knowledge for semiconductor supply chain network resilience. For validation, a simulation model is constructed for backend production from a leading semiconductor company in Germany. The contribution of the proposed semantic web-based framework provides the interoperability for supporting supply chain management and reduces the gaps between simulation modelling and physical setting to enhance overall supply chain effectiveness.}
}
@article{VONGILLERN2024104404,
title = {Media literacy, digital citizenship and their relationship: Perspectives of preservice teachers},
journal = {Teaching and Teacher Education},
volume = {138},
pages = {104404},
year = {2024},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2023.104404},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X2300392X},
author = {Sam {von Gillern} and Matthew Korona and William Wright and Hillary Gould and Brandon Haskey-Valerius},
keywords = {Media literacy, Digital citizenship, Preservice teachers},
abstract = {Scholarship has examined media literacy and digital citizenship in various ways, yet limited research has examined connections between these concepts, which may have implications for teaching and learning. This case study investigated 111 preservice teachers’ perspectives on media literacy, digital citizenship, and their relationship via examining their responses to essay questions. Data analysis revealed central themes in their perceptions of media literacy, digital citizenship, and their relationship, which aligned with both empowerment and protectionist perspectives of media and digital engagement. This study illuminates relational understandings of media literacy and digital citizenship and demonstrates the value of teaching them in concert.}
}
@incollection{LIN2025133,
title = {Chapter 9 - Bladder cancer treatment with artificial intelligence},
editor = {Andrew J. Hung},
booktitle = {Artificial Intelligence in Urology},
publisher = {Academic Press},
pages = {133-155},
year = {2025},
isbn = {978-0-443-22132-3},
doi = {https://doi.org/10.1016/B978-0-443-22132-3.00009-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443221323000095},
author = {Tianxin Lin},
keywords = {Artificial intelligence, bladder cancer, treatment, prognosis, neoadjuvant therapy, robot, multi-omics},
abstract = {Artificial intelligence (AI) research in bladder cancer has seen rapid growth since the 21st century, with AI diagnostic and predictive models set to lead the field. Meanwhile, robot-assisted surgery remains a vibrant area of interest, and the integration of AI into these fields holds great promise. In this chapter, we will comprehensively introduce the applications of AI in the treatment procedures for bladder cancer, including neoadjuvant chemotherapy and immunotherapy prediction, robot-assisted surgery, recurrence, and prognosis prediction. Moreover, we look forward to the greater advantages that AI may play in the future, especially the application of advanced AI algorithms and multimodal design.}
}
@article{MALAKAR2025109540,
title = {Compact representation for memory-efficient storage of images using genetic algorithm-guided key pixel selection},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109540},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109540},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016981},
author = {Samir Malakar and Nirwan Banerjee and Dilip K. Prasad},
keywords = {Compact representation, Genetic algorithm, Memory efficient, Gaussian kernel, Storage reduction},
abstract = {In the past few years, we have observed rapid growth in digital content. Even in the biological domain, the arrival of microscopic and nanoscopic images and videos captured for biological investigations increases the need for space to store them. Hence, storing these data in a storage-efficient manner is a pressing need. In this work, we have introduced a compact image representation technique with an eye on preserving the shape that can shrink the memory requirement to store. The compact image representation is different from image compression since it does not include any encoding mechanism. Rather, the idea is that this mechanism stores the positions of key pixels, and when required, the original image can be regenerated. The genetic algorithm is used to select key pixels, while the Gaussian kernel performs the reconstruction task with the help of the positions of the selected key pixels. The model is tested on four different datasets. The proposed technique shrinks the memory requirement by 87% to 98% while evaluated using the bit reduction rate. However, the reconstructed images’ quality is a bit low when evaluated using metrics like structural similarity index (ranges between 0.81 to 0.94), or root means squared error (ranges between 0.06 to 0.08). To investigate the impact of quality reduction in reconstructed images in real-life applications, we performed image classification using reconstructed samples and found 0.13% to 2.30% classification accuracy reduction compared to when classification is done using original samples. The proposed model’s performance is comparable to state-of-the-art’s similar solutions.}
}
@article{MUKHERJEE2025104402,
title = {Factors impeding buy now, pay later (BNPL) adoption in India: A mixed-method approach},
journal = {Journal of Retailing and Consumer Services},
volume = {87},
pages = {104402},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104402},
url = {https://www.sciencedirect.com/science/article/pii/S096969892500181X},
author = {Shreya Mukherjee},
keywords = {Buy now pay later (BNPL), Decision making trial and evaluation laboratory (DEMATEL), Financial technology adoption, Mixed-methods, Behavioral finance, Netnography, Innovation resistance theory},
abstract = {Buy Now, Pay Later (BNPL) services are reshaping digital credit access in India, yet their adoption remains limited due to complex and interrelated consumer barriers. While previous research has explored general fintech or digital payment adoption, there is a significant gap in understanding BNPL-specific barriers, particularly how these barriers influence one another within India’s distinct socio-economic and regulatory landscape. India’s rapid fintech growth, large unbanked population, evolving regulatory environment, and uneven levels of digital and financial literacy make it a unique and urgent case for such inquiry. Thus, this study aims to identify and rank the key barriers to BNPL adoption in the Indian context and analyze their causal interrelationships, and adopts a sequential mixed-methods design for the same. In the qualitative phase, a netnographic analysis of BNPL app reviews—supported by existing literature (specifically Innovation Resistance Theory) and expert insights—was used to identify barriers. In the quantitative phase, the ‘Decision-Making Trial and Evaluation Laboratory’ (DEMATEL) method was employed to analyze seven identified barriers, categorize them into causal and effect groups, and assess their interdependencies. The findings reveal digital illiteracy as the most influential causal barrier, affecting others such as inertia, privacy concerns, hidden fees and high penalty fees, and negative credit profiles. Impulse buying and regulatory concerns also emerged as key causal factors. The study offers practical recommendations, such as financial education, responsible lending, and regulatory reform, and contributes to BNPL literature by applying a novel methodological lens to an underexplored market. These insights can guide stakeholders seeking to responsibly scale BNPL adoption in India.}
}
@article{ESPANA2025102373,
title = {Ethical reasoning methods for ICT: What they are and when to use them},
journal = {Data & Knowledge Engineering},
volume = {155},
pages = {102373},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102373},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000971},
author = {Sergio España and Chris {van der Maaten} and Jens Gulden and Óscar Pastor},
keywords = {Conceptual modelling, Ethics, Ethical reasoning, Sustainability assessment, Method engineering, Situational factors},
abstract = {Information and communication technology (ICT) brings about numerous advantages across various domains of our lives. However, alongside these benefits, there is a growing awareness of its potential negative ethical, social, and environmental impacts. Consequently, stakeholders ranging from conceptual modellers to policy makers often find themselves grappling with ethical considerations stemming from ICT engineering and usage. This paper presents a review of 10 ethical reasoning methods suitable for the ICT domain. We have employed a method engineering technique to author metamodels for the methods, which were subsequently subjected to validation by experts proficient in the respective methods. Following a situational method engineering approach, we have also characterised each ethical reasoning method and validated the characterisation with the experts. This has allowed us to develop a tool that helps select the method that is most suitable for a given ethical reasoning situation. Furthermore, we deliberate on the practical application of ethical reasoning methods within conceptual modelling contexts. We are confident that we have laid the groundwork for further research into ethical reasoning of ICT, with a specific emphasis on its role during conceptual modelling.}
}
@article{BEG2025120538,
title = {Correlative activation free energy (CAFE) model: Application to viscous processes in inorganic oxide glass-formers},
journal = {Acta Materialia},
volume = {283},
pages = {120538},
year = {2025},
issn = {1359-6454},
doi = {https://doi.org/10.1016/j.actamat.2024.120538},
url = {https://www.sciencedirect.com/science/article/pii/S1359645424008838},
author = {Cameran Beg and Jaemin Byeon and Nova Berman and John Kieffer},
keywords = {Viscosity, Glass transition, Transition state theory, Logistic function, Energy landscape},
abstract = {We explore the concept of correlative activation free energy (CAFE) for the analysis and interpretation of viscosity data of a collection of 847 inorganic oxide glass formers that exhibit various degrees of non-Arrhenius behavior. The CAFE model formalism is strictly based on transition state theory and accounts for the variation in the activation barrier height for the viscous dissipation due to the structural evolution the system undergoes upon traversing the glass transition regime. Thus, fitting parameters are meaningful in a statistical thermodynamic context. Compared to the VFT and MYEGA equations, fits using the CAFE model are more robust when extrapolating to infinite temperature because the latter encodes non-enthalpic contributions to the rate coefficient more realistically. The CAFE model-based analysis reveals a strong connection between melt fragility and the degree of change in the potential energy landscape with temperature. Accordingly, while the average ground-state potential energy of the glass forming liquid gradually increases with temperature, the energy of the activated state remains relatively invariant. Our analysis also allows one to estimate the number of atoms involved in the viscous relaxation process, which ranges from approximately 10 to 50 atoms for the oxide glass formers studied. We observe that thermally activated dynamic phenomena exhibited by glassy networks, such as the mixed alkali effect, persist into the supercooled liquid state.}
}
@article{GAETA2024120050,
title = {An explainable prediction method based on Fuzzy Rough Sets, TOPSIS and hexagons of opposition: Applications to the analysis of Information Disorder},
journal = {Information Sciences},
volume = {659},
pages = {120050},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.120050},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523016365},
author = {Angelo Gaeta and Vincenzo Loia and Francesco Orciuoli},
keywords = {Fuzzy Rough Sets, Structures of opposition, TOPSIS, Information Disorder},
abstract = {This paper presents a novel approach for predicting and explaining instances of Information Disorder. The paper reports two significant findings: i) the use of structures of opposition to describe relationships between instances of Information Disorder, and ii) the development of an explainable prediction method that combines Fuzzy Rough Sets and TOPSIS with these structures. The findings have the potential to assist analysts and decision-makers in gaining a deeper understanding of the phenomenon of Information Disorder. The results are based on real data and demonstrate promising applications for future research.}
}
@article{MOHARRAK2024871,
title = {Generative AI in banking: empirical insights on integration, challenges and opportunities in a regulated industry},
journal = {International Journal of Bank Marketing},
volume = {43},
number = {4},
pages = {871-896},
year = {2024},
issn = {0265-2323},
doi = {https://doi.org/10.1108/IJBM-08-2024-0490},
url = {https://www.sciencedirect.com/science/article/pii/S0265232324000309},
author = {Moayad Moharrak and Emmanuel Mogaji},
keywords = {Generative AI, Banking innovation, Managerial preparedness, Regulatory compliance, Data privacy},
abstract = {Purpose
This study aims to fill critical research gaps by providing empirical evidence on the practical application of generative AI in the banking sector. It explores managerial preparedness, regulatory compliance and data privacy challenges in implementing this technology, offering insights into its operational effectiveness and potential in financial services.
Design/methodology/approach
The research employs a qualitative approach, conducting in-depth interviews with bank managers and industry experts. These interviews are analysed to identify key factors influencing the integration of generative AI in financial institutions.
Findings
The study identifies five critical factors – recognition, requirement, reliability, regulatory and responsiveness – that collectively impact the adoption and operational effectiveness of generative AI in banking. These factors highlight the challenges and opportunities of integrating this technology within the highly regulated financial industry.
Practical implications
The findings have significant theoretical and managerial implications. Theoretically, the research contributes to understanding AI integration in regulated industries, particularly financial services. Managerially, it provides a roadmap for financial institutions to adopt generative AI responsibly, balancing innovation with regulatory compliance and ethical considerations.
Originality/value
This study is among the first to provide empirical data on generative AI’s practical application in the banking sector, addressing the lack of real-world evidence and offering a comprehensive analysis of the factors influencing its successful implementation in a highly regulated environment.}
}
@article{DAI2024,
title = {Evaluating a Natural Language Processing–Driven, AI-Assisted International Classification of Diseases, 10th Revision, Clinical Modification, Coding System for Diagnosis Related Groups in a Real Hospital Environment: Algorithm Development and Validation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/58278},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124005855},
author = {Hong-Jie Dai and Chen-Kai Wang and Chien-Chang Chen and Chong-Sin Liou and An-Tai Lu and Chia-Hsin Lai and Bo-Tsz Shain and Cheng-Rong Ke and William Yu Chung Wang and Tatheer Hussain Mir and Mutiara Simanjuntak and Hao-Yun Kao and Ming-Ju Tsai and Vincent S Tseng},
keywords = {natural language processing, International Classification of Diseases, deep learning, electronic medical record, Taiwan diagnosis related groups},
abstract = {Background
International Classification of Diseases codes are widely used to describe diagnosis information, but manual coding relies heavily on human interpretation, which can be expensive, time consuming, and prone to errors. With the transition from the International Classification of Diseases, Ninth Revision, to the International Classification of Diseases, Tenth Revision (ICD-10), the coding process has become more complex, highlighting the need for automated approaches to enhance coding efficiency and accuracy. Inaccurate coding can result in substantial financial losses for hospitals, and a precise assessment of outcomes generated by a natural language processing (NLP)–driven autocoding system thus assumes a critical role in safeguarding the accuracy of the Taiwan diagnosis related groups (Tw-DRGs).
Objective
This study aims to evaluate the feasibility of applying an International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM), autocoding system that can automatically determine diagnoses and codes based on free-text discharge summaries to facilitate the assessment of Tw-DRGs, specifically principal diagnosis and major diagnostic categories (MDCs).
Methods
By using the patient discharge summaries from Kaohsiung Medical University Chung-Ho Memorial Hospital (KMUCHH) from April 2019 to December 2020 as a reference data set we developed artificial intelligence (AI)–assisted ICD-10-CM coding systems based on deep learning models. We constructed a web-based user interface for the AI-assisted coding system and deployed the system to the workflow of the certified coding specialists (CCSs) of KMUCHH. The data used for the assessment of Tw-DRGs were manually curated by a CCS with the principal diagnosis and MDC was determined from discharge summaries collected at KMUCHH from February 2023 to April 2023.
Results
Both the reference data set and real hospital data were used to assess performance in determining ICD-10-CM coding, principal diagnosis, and MDC for Tw-DRGs. Among all methods, the GPT-2 (OpenAI)-based model achieved the highest F1-score, 0.667 (F1-score 0.851 for the top 50 codes), on the KMUCHH test set and a slightly lower F1-score, 0.621, in real hospital data. Cohen κ evaluation for the agreement of MDC between the models and the CCS revealed that the overall average κ value for GPT-2 (κ=0.714) was approximately 12.2 percentage points higher than that of the hierarchy attention network (κ=0.592). GPT-2 demonstrated superior agreement with the CCS across 6 categories of MDC, with an average κ value of approximately 0.869 (SD 0.033), underscoring the effectiveness of the developed AI-assisted coding system in supporting the work of CCSs.
Conclusions
An NLP-driven AI-assisted coding system can assist CCSs in ICD-10-CM coding by offering coding references via a user interface, demonstrating the potential to reduce the manual workload and expedite Tw-DRG assessment. Consistency in performance affirmed the effectiveness of the system in supporting CCSs in ICD-10-CM coding and the judgment of Tw-DRGs.}
}
@article{DEZACRUZ2025109634,
title = {Mapping the evidence of the effects of environmental factors on the prevalence of antibiotic resistance in the non-built environment},
journal = {Environment International},
volume = {202},
pages = {109634},
year = {2025},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2025.109634},
url = {https://www.sciencedirect.com/science/article/pii/S016041202500385X},
author = {Iñaki Deza-Cruz and Alexandre {de Menezes} and Brian Gardner and Ílknur Aktan and Sarhad Alnajjar and Martha Betson and Adriana {Cabal Rosel} and Manuela Caniça and Mark A. Chambers and Georgina Tarrant and Francesca Contadini and Olukayode Daramola and Rani {de la Rivière} and Bernadette Egan and Abel Ekiri and Catherine Finnegan and Laura C. {Gonzalez Villeta} and Richard Green and Belinda Hall and Marwa M. Hassan and Martin Hawes and Sara Healy and Lisa Holbrook and Damla Kaya and Prashant Kumar and Roberto M. {La Ragione} and Daniel Maupin and Jai W. Mehat and Davide Messina and Kelly Moon and Elizabeth Mumford and Gordon Nichols and Daniel V. Olivença and Joaquin M. Prada and Claire Price and Christopher Proudman and Retha Queenan and Miguel Ramos and Jaime Riccomini Closa and Jennifer M. Ritchie and Lorenzo A. Santorelli and Nick Selemetas and Matt Spick and Yashwanth Subbannayya and Shelini Surendran and Pedro Teixeira and Mukunthan Tharmakulasingam and Damian Valle and Arnoud H.M. {van Vliet} and Marco Videira and Hazel Wallace-Williams and Klara M. Wanelik and Markus Woegerbauer and Sydney Wright and Giovanni {Lo Iacono}},
keywords = {Antibiotic resistant bacteria, ARB, Antibiotic resistance gene, ARG, Environment, One Health, Systematic evidence mapping, SEM},
abstract = {Background:
Antibiotic resistance increasingly threatens the interconnected health of humans, animals, and the environment. While misuse of antibiotics is a known driver, environmental factors also play a critical role. A balanced One Health approach—including the environmental sector—is necessary to understand the emergence and spread of resistance.
Methods:
We systematically searched English-language literature (1990–2021) in MEDLINE, Embase, and Web of Science, plus grey literature. Titles, abstracts, and keywords were screened, followed by full-text reviews using a structured codebook and dual-reviewer assessments.
Results:
Of 13,667 records screened, 738 met the inclusion criteria. Most studies focused on freshwater and terrestrial environments, particularly associated with wastewater or manure sources. Evidence of research has predominantly focused on Escherichia coli and Pseudomonas spp., with a concentration on ARGs conferring resistance to sulphonamides (sul1–3), tetracyclines (tet), and beta-lactams. Additionally, the People’s Republic of China has produced a third of the studies—twice that of the next country, the United States—and research was largely domestic, with closely linked author networks.
Conclusion:
Significant evidence gaps persist in understanding antibiotic resistance in non-built environments, particularly in marine, atmospheric, and non-agricultural settings. Stressors such as climate change and microplastics remain notably under-explored. There is also an urgent need for more research in low-income regions, which face higher risks of antibiotic resistance, to support the development of targeted, evidence-based interventions.}
}
@article{NI2025126420,
title = {Enhancing supply chain resilience and efficiency of HVAC systems in semiconductor manufacturing facilities using graph-based large multimodal models},
journal = {Applied Energy},
volume = {398},
pages = {126420},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.126420},
url = {https://www.sciencedirect.com/science/article/pii/S030626192501150X},
author = {Hsiao-Ping Ni and Chi-Yun Liu and Fermodelie Paul and Wai Oswald Chong and Jui-Sheng Chou},
keywords = {Large multimodal model, Graph neural network, HVAC systems, Semiconductor manufacturing facilities, Supply chain management, Circular economy},
abstract = {Semiconductor manufacturing facilities (SMFs) demand ultra-precise environmental conditions maintained by specialized HVAC systems, critical for a resilient and sustainable semiconductor supply chain. While AI-driven solutions have been applied to generic supply chain optimization, they often fail in addressing the unique challenges of SMFs, where HVAC systems must maintain sub-0.1 °C temperature stability, account for 40–60 % of facility energy consumption, and comply with stringent cleanroom standards. This paper proposes an innovative framework that integrates graph-based large multimodal models (G-LMMs), enhanced by graph neural networks (GNNs), to optimize SMF HVAC supply chains across the Design, Construction, Installation, Maintenance, and Operation (DCIMO) phases. GNNs enable the capture and analysis of complex relationships within HVAC systems, facilitating real-time anomaly detection and optimized material flows. Unlike conventional AI models, G-LMMs combine GNNs with multimodal data processing to achieve three key advancements: (1) real-time anomaly detection, (2) automated compliance monitoring, and (3) circular economy integration through resource reuse. G-LMMs enhance supply chain visibility by harmonizing diverse data types while meeting SMFs' precision requirements. As the first framework to unify GNNs and multimodal AI for HVAC optimization, this approach represents a paradigm shift in sustainable semiconductor manufacturing, with broader implications for industries reliant on precision-controlled environments.}
}
@article{BAIER2022325,
title = {Success factors of process digitalization projects – insights from an exploratory study},
journal = {Business Process Management Journal},
volume = {28},
number = {2},
pages = {325-347},
year = {2022},
issn = {1463-7154},
doi = {https://doi.org/10.1108/BPMJ-07-2021-0484},
url = {https://www.sciencedirect.com/science/article/pii/S146371542200019X},
author = {Marie-Sophie Baier and Jannik Lockl and Maximilian Röglinger and Robin Weidlich},
keywords = {Business process management, Digitalization, Success factors, Literature review, Exploratory interviews},
abstract = {Purpose
In an exploratory approach, the authors conducted a structured literature review to extract candidate process digitalization project (PDP) success factors (SFs) from the literature on business process management (BPM), project management (PM) and digitalization. After that, the authors validated, refined and extended these intermediate results through interviews with 21 members of diverse PDP teams. Finally, the authors proposed the PDP success model by linking the candidate SFs with relevant success criteria.
Design/methodology/approach
Digitalization substantially impacts organizations, which increasingly use digital technologies (DTs) to improve and innovate their business processes. While there are methods and tools for identifying process digitalization ideas and related projects (PDPs), guidance on the successful implementation of PDPs is missing. Hence, the authors set out to explore PDP SFs.
Findings
The PDP success model covers 38 PDP success factor candidates, whereof 28 are already backed by the literature and ten have emerged during the interviews. Furthermore, the SFs are structured according to seven categories from the literature covering a broad range of sociotechnical topics (i.e. strategy, structure, culture, people, process, project and technology) as well as equipped with preliminary success rationales.
Originality/value
The work is the first to systematically explore PDP SFs. The PDP success model shows that PDPs require a unique set of SFs, which combine established and hitherto underrepresented knowledge. It extends the knowledge on BPM and serves as foundation for future (confirmatory) research on business process digitalization and the successful implementation of PDPs.}
}
@article{JANG2024107557,
title = {Effects of time-of-use pricing for residential customers and wholesale market consequences in South Korea},
journal = {Energy Economics},
volume = {134},
pages = {107557},
year = {2024},
issn = {0140-9883},
doi = {https://doi.org/10.1016/j.eneco.2024.107557},
url = {https://www.sciencedirect.com/science/article/pii/S0140988324002652},
author = {Heesun Jang and Seongman Moon and Jihyo Kim},
keywords = {Time-of-use pricing, Residential electricity, Wholesale market, Load transfer, Producer surplus},
abstract = {Using a large-scale pilot test on time-of-use (TOU) pricing for residential customers, this study analyzes the effects of TOU pricing on the load patterns of residential customers and on producer surplus in South Korea. We estimate the difference in the electricity demand functions of residential customers across peak, intermediate, and off-peak periods before and after TOU pricing. In addition, we assess the supply curve in the wholesale electricity market and calculate the changes in electricity purchase costs by integrating the supply curve over the range of consumption changes across the periods. This study simulates the effects of TOU pricing on producer surplus that would be obtained if all residential customers in South Korea switch from increasing block pricing to TOU pricing. Our results show that TOU pricing can be an effective measure for load transfer and simultaneously increase producer surplus. We find that although the revenue of electric utility generally decreases, the cost savings are greater and thus producer surplus increases. The results can be a valuable reference for the South Korean government regarding the nationwide expansion of TOU for residential electricity in the future.}
}
@article{BERX2025100984,
title = {A harmonious synergy between robotic performance and well-being in human-robot collaboration: A vision and key recommendations},
journal = {Annual Reviews in Control},
volume = {59},
pages = {100984},
year = {2025},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2024.100984},
url = {https://www.sciencedirect.com/science/article/pii/S136757882400052X},
author = {Nicole Berx and Wilm Decré and Joris {De Schutter} and Liliane Pintelon},
abstract = {The transition from Industry 4.0 to Industry 5.0 marks a significant shift towards human-centric manufacturing processes, emphasizing the integration of collaborative robots with advanced sensory and cognitive abilities. Unlike previous industrial revolutions, Industry 5.0 prioritizes the integration of human workers alongside advanced technologies, emphasizing collaboration, and acknowledging the unique strengths of both humans and machines, with a focus on human well-being. However, this transition presents significant challenges to adopting cobots in industries due to safety concerns compromising efficiency. While robotics and automation traditionally focus on maximizing performance and minimizing human intervention, the latter no longer applies to human-robot collaboration. There is a need for developing approaches and technologies that can seamlessly combine high-level robotic performance with safety, as well as pursue operator well-being. This paper presents a vision and specific recommendations for a harmonious synergy between robot performance and operator well-being in human-robot collaboration. Our vision includes the need to develop cobots that are contextually intelligent, capable of meaningful conversation, and adaptable to changing conditions. The paper identifies current challenges, such as safety concerns impacting performance, a narrow safety focus and overlooked system-wide impacts, limited guidance on well-being, and insufficient interdisciplinary approaches. To overcome the identified challenges, key recommendations essential for achieving the vision are outlined, and pathways to overcome remaining obstacles are presented. These recommendations include designing context-aware, cognitively embodied, and socially proficient cobots; balancing autonomy and control in task allocation; and adopting a socio-technical systems perspective. Although numerous technical obstacles remain, the rapid advances in Artificial Intelligence (AI), particularly in generative AI, provide an extraordinary and previously unattainable catalyst for realizing our vision, serving as a fundamental enabler. Our methodology combines expert synthesis and a narrative literature review, drawing on diverse academic domains such as robotics, industrial manufacturing, safety, and human factors. This paper advances human-robot collaboration research by adopting a holistic approach that integrates engineering and non-engineering perspectives, emphasizing technical performance, safety, well-being, and socio-technical systems to optimize collaboration. We aim to inspire and guide both the engineering and robotics community and the human factors and safety community toward developing more holistic, safer, and human-centered collaborative robotic systems. By embracing the interdisciplinary approach, we advocate in this paper, both technical and non-technical experts can benefit from the insights provided.}
}
@article{GANT2024104829,
title = {High strain rate responses of some metals and alloys using a plate impact driven ring expansion test (PIDRET)},
journal = {International Journal of Impact Engineering},
volume = {184},
pages = {104829},
year = {2024},
issn = {0734-743X},
doi = {https://doi.org/10.1016/j.ijimpeng.2023.104829},
url = {https://www.sciencedirect.com/science/article/pii/S0734743X2300338X},
author = {Fanny Gant and Gabriel Seisson and Patrice Longère and Skander El Mai and Jean-Luc Zinszner},
keywords = {Ring expansion, Dynamic fracture, Necking, Fragmentation},
abstract = {A plate impact driven ring expansion test (PIDRET) has been developed to investigate the high strain rate response of metals and alloys under radial expansion. Combining photonic Doppler velocimetry (PDV) probes and ultra-high-speed cameras, it allows for measuring the radial expansion velocity of the ring and for recording the different stages of the ring deformation until necking and ultimate fragmentation. Four metallic materials with different physical and mechanical properties are tested under the same loading conditions leading to strain rates around 104 s−1. The materials exhibit different responses in terms of deformation history and fracture. A comparison is made on (i) the postmortem microstructure and ductility between low strain rate tension loaded specimens and high-strain rate expansion loaded rings and (ii) numbers of necks and fragments between experimental results and theoretical estimations.}
}
@article{VARCHANDI2024100488,
title = {An integrated best–worst method and fuzzy TOPSIS for resilient-sustainable supplier selection},
journal = {Decision Analytics Journal},
volume = {11},
pages = {100488},
year = {2024},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2024.100488},
url = {https://www.sciencedirect.com/science/article/pii/S2772662224000924},
author = {Sahar Varchandi and Ashkan Memari and Mohammad Reza Akbari Jokar},
keywords = {Multi-criteria decision-making, Fuzzy TOPSIS, Best–worst method, Supplier selection, Sustainability, Resiliency},
abstract = {Achieving a balance between economic, environmental, and social factors in supplier selection while prioritizing business continuity poses a considerable challenge. It is imperative to guarantee that selected suppliers adhere to sustainability and resilience requirements while supporting the company’s economic advancement. This study addresses this challenge through a novel approach that combines the Best–Worst Method (BWM) with the Fuzzy Technique Order of Preference by Similarity to Ideal Solution (F-TOPSIS). Integrating these methodologies reduces the burden of pairwise comparisons, a common challenge in supplier selection using multi-criteria decision-making, thereby streamlining the evaluation process. To assess the effectiveness of the proposed model, we implemented our method on an actual case study of e-commerce and conducted a sensitivity analysis of the results. The findings suggest that the proposed method offers improved consistency in rankings across criteria compared to traditional BWM. It also makes a balance between simplicity and accuracy, ensuring that selected suppliers are equipped to handle disruptions and uncertainties. This aligns practical simplicity with theoretical rigor which makes the proposed method more accessible and manageable for practitioners in real-world settings.}
}
@article{RAMOS20241364,
title = {State of the Science: Using Digital Mental Health Interventions to Extend the Impact of Psychological Services},
journal = {Behavior Therapy},
volume = {55},
number = {6},
pages = {1364-1379},
year = {2024},
note = {Special Issue: State of the Science in Behavior Therapy: Taking Stock and Looking Forward},
issn = {0005-7894},
doi = {https://doi.org/10.1016/j.beth.2024.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0005789424000443},
author = {Giovanni Ramos and Rosa Hernandez-Ramos and Madison Taylor and Stephen M. Schueller},
keywords = {digital mental health interventions, review, implementation, human support, equity},
abstract = {In recent years, digital mental health interventions (DMHIs) have emerged as a paradigm shift in care delivery that could expand the scale, efficiency, and effectiveness of psychological services. However, DMHI impact is constrained by issues related to limited reach, poor adoption, implementation barriers, and insufficient long-term maintenance. Organized by the Reach, Effectiveness, Adoption, Implementation, and Maintenance(RE-AIM) framework, this paper surveys the current state of DMHIs, highlighting research and practice gaps as well as potential strategies to move the field forward. Similarly, we discuss the role that emerging technologies and changes in the profession will play in shaping DMHIs in years to come. Finally, concrete and actionable steps to advance equity in the DMHI field are provided, with an emphasis on strategies to increase the representativeness of marginalized populations in DMHI research, the inclusion of these groups in the design and testing of DMHIs, and how to improve the contextual and cultural fit of DMHIs.}
}
@article{OH20241,
title = {The role of temperament and character in the anxiety-depression spectrum among Korean adults},
journal = {Journal of Affective Disorders},
volume = {359},
pages = {1-13},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724007857},
author = {Hyun Sook Oh and C. Robert Cloninger},
keywords = {Anxiety, Depression, Temperament and character, Resilience, Complex adaptive systems, Korean adults},
abstract = {Background
Temperament and character are useful in risk assessment and therapy of individuals in the anxiety-depression spectrum but understudied in South Korea.
Objective
The study aimed to identify the temperament and character features associated with anxiety and/or depression in individuals with clinical disorders and in the general population.
Methods
A representative sample of 1384 Korean adults over 18 years old (58 % female) were assessed with the Beck Depression Inventory (BDI), State-Trait Anxiety Inventory (STAI), and Temperament and Character Inventory (TCI). Multivariate analyses, including structural equation modeling and complex systems analysis, evaluated how personality influenced risk and resilience for anxiety and/or depression.
Results
The three groups with anxiety and/or depression were strongly distinguished by temperament and character: (i) In AD (n = 58), Harm Avoidance and Reward Dependence were higher than in DD, and Self-directedness was higher than in AD+DD; (ii) In DD (n = 90), Persistence, Self-Directedness and Cooperativeness were higher than in AD+DD; and (iii) In AD+DD (n = 101), Harm Avoidance was highest and Persistence and Self-directedness were lowest (i.e., they were lowest in Resilience). Structural equation models confirmed these risk relations with strong character development reducing the adverse effects of emotional hyperreactivity from extreme temperaments.
Limitations
Self-reports were measured only at one point in time, requiring collateral experimental data to support causal interpretation.
Conclusions
Interactions of temperament and character are strongly predictive of risk and resilience to anxiety and/or depression by regulating both positive and negative affect. Character mediates the adverse effects of extreme temperaments on affect.}
}
@article{YU2024115069,
title = {KCNH5 deletion increases autism susceptibility by regulating neuronal growth through Akt/mTOR signaling pathway},
journal = {Behavioural Brain Research},
volume = {470},
pages = {115069},
year = {2024},
issn = {0166-4328},
doi = {https://doi.org/10.1016/j.bbr.2024.115069},
url = {https://www.sciencedirect.com/science/article/pii/S0166432824002250},
author = {Lele Yu and Yamei Liu and Junyu Xia and Shini Feng and Fuxue Chen},
keywords = {, Autism spectrum disorder, Synaptic density, Electrophysiology, AKT/mTOR pathway},
abstract = {Recent clinical studies have highlighted mutations in the voltage-gated potassium channel Kv10.2 encoded by the KCNH5 gene among individuals with autism spectrum disorder (ASD). Our preliminary study found that Kv10.2 was decreased in the hippocampus of valproic acid (VPA) - induced ASD rats. Nevertheless, it is currently unclear how KCNH5 regulates autism-like features, or becomes a new target for autism treatment. We employed KCNH5 knockout (KCNH5-/-) rats and VPA - induced ASD rats in this study. Then, we used behavioral assessments, combined with electrophysiological recordings and hippocampal brain slice, to elucidate the impact of KCNH5 deletion and environmental factors on neural development and function in rats. We found that KCNH5-/- rats showed early developmental delay, neuronal overdevelopment, and abnormal electroencephalogram (EEG) signals, but did not exhibit autism-like behavior. KCNH5-/- rats exposed to VPA (KCNH5-/--VPA) exhibit even more severe autism-like behaviors and abnormal neuronal development. The absence of KCNH5 excessively enhances the activity of the Protein Kinase B (Akt)/Mechanistic Target of Rapamycin (mTOR) signaling pathway in the hippocampus of rats after exposure to VPA. Overall, our findings underscore the deficiency of KCNH5 increases the susceptibility to autism under environmental exposures, suggesting its potential utility as a target for screening and diagnosis in ASD.}
}
@article{AMOS2024102163,
title = {Consumer reactions to perceived undisclosed ChatGPT usage in an online review context},
journal = {Telematics and Informatics},
volume = {93},
pages = {102163},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102163},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000674},
author = {Clinton Amos and Lixuan Zhang},
keywords = {Generative AI, ChatGPT, Online review, Review Valence, Trust in online review},
abstract = {While artificial intelligence’s (AI) promise for fake online review detection has been investigated, other questions have emerged with ChatGPT’s introduction, a generative AI platform. This research provides a much-needed investigation into consumer reactions to reviews perceived to be generated by ChatGPT vs. a human. Results from three studies in TripAdvisor hotel review and Yelp restaurant review contexts revealed that consumers rate reviews as less useful, trustworthy, and authentic if they perceived ChatGPT generated them. Further, the findings were robust regardless of review valence and even when participants were informed the reviewer possessed a TripAdvisor Expert badge. These findings’ theoretical and practical implications are discussed, along with limitations.}
}
@article{YUE2025106390,
title = {Enhancing point cloud semantic segmentation of building interiors through diffusion-based scene-level synthesis},
journal = {Automation in Construction},
volume = {178},
pages = {106390},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106390},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525004303},
author = {Hongzhe Yue and Qian Wang and Lijie Huang and Mingyu Zhang},
keywords = {Synthetic point cloud, Diffusion model, Deep learning, Semantic segmentation},
abstract = {Synthetic point clouds have significant potential to enhance deep learning (DL)-based semantic segmentation, thereby facilitating the reconstruction of building interior scenes. However, current methods often rely on pre-built models for sampling, which limits their applicability when such models are unavailable. This paper proposes a Diffusion-Based Scene-Level Point Cloud Synthesis (DS-PCS) method, capable of generating unlimited synthetic point clouds solely through text prompts. A total of 34 sets of comparison experiments were conducted to assess the semantic segmentation performance across different algorithms, synthetic point cloud generation approaches, and training datasets. The results show that: (1) DS-PCS generated synthetic point cloud scenes in diverse styles, colors, and types; (2) incorporating these synthetic point clouds into training datasets alongside real point clouds significantly improved semantic segmentation accuracy on the S3DIS dataset; and (3) using mixed point cloud datasets further enhanced segmentation accuracy while substantially reducing the time required for preparing training data.}
}
@article{YUE2025128816,
title = {Enhancing decision support for type 2 diabetes mellitus comorbidity risk prediction: An end-to-end multi-task learning model},
journal = {Expert Systems with Applications},
volume = {294},
pages = {128816},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128816},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425024339},
author = {Jianjin Yue and Li Luo and Mengzhuo Guo and Chenxi Xu},
keywords = {Disease risk prediction, Multi-task learning, Clinical decision-making support, Comorbidity, Type 2 diabetes mellitus, Machine learning},
abstract = {The incidence of comorbidities exacerbates the affliction of patients with Type 2 Diabetes Mellitus (T2DM) and increases the complexity of therapeutic interventions for physicians, resulting in adverse patient outcomes. Accurate identification and prediction of the comorbidity risk in T2DM facilitates improved clinical diagnostic decisions and enhanced patient prognoses. Existing studies frequently utilize single-task learning (STL) models to assess individual disease risks in T2DM comorbidity, overlooking the intricate relationships between various diseases and thus failing to capture their inherent connections, which leads to inaccurate risk predictions. To this end, we propose an end-to-end multi-gate mixture-of-self-attention-based-experts (MMAE) model under the multi-task learning (MTL) scheme. The proposed MMAE model is based on the self-attention mechanism and incorporates a new comorbidity diffusion coefficient (CDC) index to characterize correlations between diseases. We conduct comparative experiments against eight baselines on a real-world dataset, and the results have demonstrated the superiority of the proposed MMAE. Our ablation experiments also show that the incorporation of the CDC index helps accurately identify high-risk patients. Furthermore, the proposed MMAE model can provide clinical decision support for physicians in assisting them in making more effective comorbidity diagnoses. This study has significant implications for clinical decision support and improving patient prognostic outcomes.}
}
@article{ALKIRE2024490,
title = {RAISE: leveraging responsible AI for service excellence},
journal = {Journal of Service Management},
volume = {35},
number = {4},
pages = {490-511},
year = {2024},
issn = {1757-5818},
doi = {https://doi.org/10.1108/JOSM-11-2023-0448},
url = {https://www.sciencedirect.com/science/article/pii/S1757581824000021},
author = {Linda Alkire and Anil Bilgihan and My (Myla) Bui and Alexander John Buoye and Seden Dogan and Seoyoung Kim},
keywords = {Artificial intelligence, Responsible AI, Sustainability, Well-being, SDGs, Generative AI},
abstract = {Purpose
This article introduces the Responsible AI for Service Excellence (RAISE) framework. RAISE is a strategic framework for responsibly integrating AI into service industries. It emphasizes collaborative AI design and deployment that aligns with the evolving global standards and societal well-being while promoting business success and sustainable development.
Design/methodology/approach
This multidisciplinary conceptual article draws upon the United Nations' Sustainable Development Goals (SDGs) and AI ethics guidelines to lay out three principles for practicing RAISE: (1) Embrace AI to serve the greater good, (2) Design and deploy responsible AI and (3) Practice transformative collaboration with different service organizations to implement responsible AI.
Findings
By acknowledging the potential risks and challenges associated with AI usage, this article provides practical recommendations for service entities (i.e. service organizations, policymakers, AI developers, customers and researchers) to strengthen their commitment to responsible and sustainable service practices.
Originality/value
This is the first service research article to discuss and provide specific practices for leveraging responsible AI for service excellence.}
}
@article{WLOCH2025102782,
title = {Who's afraid of automation? Examining determinants of fear of automation in six European countries},
journal = {Technology in Society},
volume = {81},
pages = {102782},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102782},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24003300},
author = {Renata Włoch and Katarzyna Śledziewska and Satia Rożynek},
keywords = {Technological change, Fear of automation, Technological unemployment, Labor market, Human resource management},
abstract = {This study develops an original conceptualization of fear of automation and examines its determinants, including the role of technology in the workplace (complementary or substitutive), task routineness, workers' exposure to technology, perceived lack of control over life, and position in the labor market. Using survey data from six Central EU countries—Austria, Czechia, Germany, Hungary, Poland, and Slovakia—we find that exposure to technology heightens fear of automation, as do task substitution and routineness. Younger, less-educated, and lower-income individuals, as well as those who perceive a greater lack of control, are more afraid of automation, while gender does not show a significant effect. In conclusion, we discuss how fear of automation may impact reskilling motivation in organizational practices.}
}
@article{HARRIS2024100162,
title = {Acceleration of benzo(a)pyrene-induced colon carcinogenesis by Western diet in a rat model of colon cancer},
journal = {Current Research in Toxicology},
volume = {6},
pages = {100162},
year = {2024},
issn = {2666-027X},
doi = {https://doi.org/10.1016/j.crtox.2024.100162},
url = {https://www.sciencedirect.com/science/article/pii/S2666027X2400015X},
author = {Kelly L. Harris and Kenneth J. Harris and Leah D. Banks and Samuel E. Adunyah and Aramandla Ramesh},
keywords = {Colon cancer, Benzo(a)pyrene, Polycyclic aromatic hydrocarbons, Western diet, DNA adducts, Lipid peroxidation},
abstract = {Colorectal cancer (CRC) is the third leading cause of cancer-related mortalities in the USA and around 52,550 people were expected to die from this disease by December 2023. The objective of this study was to investigate the effect of diet type on benzo(a)pyrene [B(a)P]-induced colon cancer in an adult male rat model, the Polyposis In the Rat Colon (PIRC) kindred type. Groups of PIRC rats (n = 10) were fed with AIN-76A regular diet (RD) or Western diet (WD) and received 25, 50 and 100 µg B(a)P/kg body wt. via oral gavage for 60 days. Rats fed diets alone, but no B(a)P, served as controls. After exposure, rats were euthanized; colon and liver samples were analyzed for activation of drug metabolizing enzymes (DMEs) CYP1A1, CYP1B1, SULT and GST. Plasma and tissue samples were analyzed by reverse phase-HPLC for B(a)P metabolites. In addition to these studies, DNA isolated from colon and liver tissues was analyzed for B(a)P-induced DNA adducts by the 32P-postlabeling method using a thin-layer chromatography system. Western diet consumption resulted in a marked increase in DME expression and B(a)P metabolite concentrations in rats that were administered 100 µg/kg B(a)P + WD (p < 0.05) compared to other treatment groups. Our findings demonstrate that WD accelerates the development of colon tumors induced by B(a)P through enhanced biotransformation, and the products of this process (metabolites) were found to bind with DNA and form B(a)P-DNA adducts, which may have given rise to colon polyps characterized by gain in tumor number, sizes, and dysplasia.}
}
@article{HOWLIDER2025133879,
title = {Partitioning of eddy covariance footprint evapotranspiration using field data, UAS observations and GeoAI in the U.S. Chihuahuan desert},
journal = {Journal of Hydrology},
volume = {662},
pages = {133879},
year = {2025},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2025.133879},
url = {https://www.sciencedirect.com/science/article/pii/S002216942501217X},
author = {Habibur R. Howlider and Hernan A. Moreno and Marguerite E. Mauritz and Stephanie N. Marquez},
keywords = {Evapotranspiration partitioning, Dryland ecosystems, Eddy covariance, Sapflux, Unmanned aerial systems, GeoAI},
abstract = {This study proposes a new method for computing transpiration across an eddy covariance footprint using field observations of plant sap flow, phytomorphology sampling, uncrewed aerial system (UAS), deep learning-based digital image processing, and eddy covariance micrometeorological measurements. The method is applied to the Jornada Experimental Range, New Mexico, where we address three key questions: (1) What are the daily summer transpiration rates of Mesquite (Prosopis glandulosa) and Creosote (Larrea tridentata) individuals, and how do these species contribute to footprint-scale evapotranspiration? (2) How can the plant-level measurements be integrated for terrain-wide transpiration estimates? (3) What is the contribution of transpiration to total evapotranspiration within the eddy covariance footprint? Data collected from June to October 2022, during the North American Monsoon season, include hourly evapotranspiration and precipitation rates from the Ameriflux eddy covariance system (US Jo-1 Bajada site) and sap flux rates from heat-balance sensors. We used plant biometric measurements and supervised classification of multispectral imagery to upscale from the patch to footprint-scale estimations. A proportional relationship between the plant’s horizontal projected area and the estimated number of water flow conduits was extended to the eddy covariance footprint via UAS data. Our results show that Mesquite’s average daily summer transpiration is 2.84 mm/d, while Creosote’s is 1.78 mm/d (a ratio of 1.6:1). The summer footprint integrated transpiration to evapotranspiration ratio (T/ET) was 0.50, decreasing to 0.44 during dry spells and increasing to 0.63 following significant precipitation. Further testing of this method is needed in different regions to validate its applicability. With appropriate adjustments, it could be relevant for other areas with similar ecological conditions.}
}
@article{WUYTS2024998,
title = {Effectiveness of pain medication tapering in chronic pain patients: a systematic review and meta-analysis},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {5},
pages = {998-1020},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0007091224004720},
author = {Elke Wuyts and Lisa Goudman and Cleo L. Crunelle and Maria {Merlano Gomez} and Koen Putman and Frenn Bultinck and Julie G. Pilitsis and Maarten Moens},
keywords = {anti-migraine medication, chronic noncancer pain, gabapentinoids, opioids, pain medication tapering},
abstract = {Background
This systematic review and meta-analysis aimed to inventory all outcome measures that are affected by tapering in chronic noncancer pain and to investigate the effectiveness of tapering.
Methods
A literature search was conducted from inception to April 2024 in MEDLINE via PubMed, Web of Science, SCOPUS, EMBASE, and PsycINFO.
Results
The initial database search identified 3969 articles, which were screened by two independent reviewers. Studies evaluating pain medication tapering in adults with chronic noncancer pain were eligible for inclusion. In total, 57 and 34 articles were included in the systematic review and meta-analysis, respectively. Risk of bias assessment demonstrated poor, fair, and good quality in 30, 24, and three studies, respectively. Pain intensity was the most reported outcome measure, as reported in 28 studies. Furthermore, a random-effect three-level meta-analysis was performed. An overall effect size of 0.917 (95% confidence interval 0.61–1.22; P<0.001) was found, indicating a beneficial effect of tapering. In addition, a statistically significant improvement was demonstrated after tapering for pain intensity, headache disability, the number of headache days per month, anxiety, depression, the number of pills consumed per month, the number of days with medication intake per month, pain catastrophising, and pain interference. No statistically significant effect was observed for physical functioning, mental health-related quality of life, opioid use, pain self-efficacy, and physical health-related quality of life.
Conclusions
This systematic review revealed a broad range of outcome measures affected by tapering. Owing to the high risk of bias of the included articles, the results of this meta-analysis must be interpreted with caution.
Systematic review protocol
CRD42023416343 (PROSPERO).}
}
@article{SUN2023101418,
title = {Relationships between perseverance of effort, subjective well-being, harmonious passion, and creativity among Chinese third-language students},
journal = {Thinking Skills and Creativity},
volume = {50},
pages = {101418},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101418},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123001864},
author = {Jiatong Sun and Rui Chen and Xiaojia Song and Lin Lei and Fei Lei},
keywords = {Perseverance of effort, Creativity, Subjective well-being, Harmonious passion, Third language (L3) learners},
abstract = {Fostering creativity among foreign language learners has consistently received attention from researchers. However, the positive psychological processes promoting creativity among third language (L3) learners remain understudied. Focusing specifically on L3 students, this study explored the associations between perseverance of effort (PE), subjective well-being (SWB), harmonious passion (HP), and creativity. Furthermore, the study investigated the possible mediating roles of SWB and HP in the relationship between PE and creativity. Participants were 430 Chinese college students who attended an obligatory L3 course. To analyze the data, the PROCESS macro for SPSS was used to perform a mediation analysis, and the results showed that (1) PE, SWB, and HP all positively related to creativity, (2) PE directly predicted creativity, (3) SWB and HP could serve as partial mediators in the relationship between PE and creativity, and (4) the direct impact of personal trait (i.e., PE) on creativity is smaller than the indirect impact of positive emotions (i.e., SWB and HP). These findings highlight the significance of PE, SWB, and HP in facilitating creativity among L3 students. Based on these findings, instructive suggestions for fostering creativity in L3 students are discussed.}
}
@article{XIA2024104040,
title = {Semantic knowledge-driven A-GASeq: A dynamic graph learning approach for assembly sequence optimization},
journal = {Computers in Industry},
volume = {154},
pages = {104040},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2023.104040},
url = {https://www.sciencedirect.com/science/article/pii/S0166361523001902},
author = {Luyao Xia and Jianfeng Lu and Yuqian Lu and Wentao Gao and Yuhang Fan and Yuhao Xu and Hao Zhang},
keywords = {Assembly sequence planning, Assembly semantic knowledge, Precedence graph, Dynamic graph learning},
abstract = {In the context of an increasingly automated and personalized manufacturing mode, efficient assembly sequence planning (ASP) has emerged as a critical factor for enhancing production efficiency, ensuring product quality, and satisfying diverse market demands. To address this need, our study first transforms the assembly topology and process into a weighted precedence graph, wherein parts represent nodes, and the assembly interconnections between parts constitute weighted edges. Then, we formulate the quantitative models of semantic knowledge, encompassing three facets: assembly direction changes, assembly stability, and part assembly interference, and thus constructs a heuristic function. We propose a novel dynamic graph learning algorithm, i.e., assembly-oriented graph attention sequence (A-GASeq), utilizing the heuristic information as edge weights of the assembly graph structure to incrementally direct the search towards optimal sequences. The performance of A-GASeq is first evaluated utilizing three key metrics: area under the receiver operation characteristic curve (AUC), precision score, and time consumption. The results reveal the superiority of our model over competing state-of-the-art graph learning models using a real-world dataset. Concurrently, we apply the algorithm to actual industrial products of diverse complexity, thereby demonstrating its broad utility across different complex products and its potential for addressing complex assembly sequence planning problems in the field of smart manufacturing.}
}
@article{MILLAT2025484,
title = {Inflammatory cytokines and specific factors influencing lung cancer progression},
journal = {Cancer Pathogenesis and Therapy},
volume = {3},
number = {6},
pages = {484-500},
year = {2025},
issn = {2949-7132},
doi = {https://doi.org/10.1016/j.cpt.2025.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949713225000370},
author = {Md. Shalahuddin Millat and Md. Mahmudul Hasan and Mohammad Sarowar Uddin and Md. Abdus Salam and Md. Abdul Aziz and Irin Akhter and Md. Saddam Hussain and Nor Mohammad and Farjana Afrin Tanjum and Md. Saqline Mostaq and Md. Ashiq Mahmud and Mohammad Nurul Amin and Mohammad Safiqul Islam},
keywords = {Lung cancer, Inflammation, Cytokines, Angiogenesis, Tumorigenesis},
abstract = {Lung cancer (LC) is one of the leading causes of cancer-related morbidity and mortality worldwide. Inflammation is a driver of cancer initiation and progression, affecting processes such as angiogenesis, antiapoptotic pathways, and DNA adduct formation. Cytokines are small proteins that can accelerate or slow tumor growth by controlling associated signaling processes such as cell proliferation, metastasis, and apoptosis. This review reveals the role of tumor necrosis factor-alpha (TNF-α), interferon-gamma (IFN-γ), transforming growth factor-beta (TGF-β), and interleukins in LC. Macrophages play a role in non-small cell lung cancer (NSCLC) pathogenesis and are associated with poor prognosis. A nested case–control study revealed that elevated concentrations of IL-6 and IL-8 were strongly associated with the risk of LC. Specifically, the odds ratio (OR) for IL-6 and IL-8 in former smokers (fourth quartile vs. first quartile) was 2.70 (95% confidence interval [CI], 1.55–4.70) and 2.83 (95% CI, 1.18–6.75), respectively. Because C-reactive protein levels are elevated in patients with NSCLC with larger and higher-grade tumors, CRP has been identified as a systemic indicator of chronic inflammation. Insulin-like growth factors influence cellular signal transduction pathways and contribute to tumorigenesis. Soluble tumor necrosis factor receptors have been explored for their role in NSCLC prognosis, highlighting their association with chromogranin. Transient receptor potential cation channel, subfamily M, member 7 (TRPM7), urokinase plasminogen activator, matrix metalloproteinases, and monocyte chemoattractant protein-1 have been identified with a focus on their expression patterns and prognostic significance in LC tissues. Moreover, lung angiogenesis induces vascular endothelial growth factor, soluble intercellular adhesion molecule-1, myeloperoxidase, and tissue inhibitors of metalloproteinase expressions. In conclusion, this review thoroughly summarized the inflammatory cytokines and specific factors influencing LC, providing the basis for further research on potential treatment approaches.}
}
@article{WANG2025102835,
title = {A resilient scheduling framework for multi-robot multi-station welding flow shop scheduling against robot failures},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102835},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102835},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524001224},
author = {Ming Wang and Peng Zhang and Guoqing Zhang and Kexin Sun and Jie Zhang and Mengyu Jin},
keywords = {Resilient scheduling framework, Multi-robot multi-station welding flow shop, Robot failures, Proactive scheduling, Recovery scheduling},
abstract = {With the development of intelligent manufacturing, robots are being increasingly applied in manufacturing systems due to their high flexibility. To avoid production disruptions caused by robot failures, higher requirements are imposed on the resilience of systems, specifically in terms of resistance, response, and recovery capabilities. In response to this, this paper investigates the resilient scheduling framework for multi-robot multi-station welding flow shop, thereby endowing and enhancing the resilience of the system. Within the resilient scheduling framework, a proactive scheduling method maximizing resistance capability is firstly proposed based on an improved NSGA-III with variable neighborhood search. Secondly, to improve the response and recovery capabilities of the system, a recovery scheduling method is presented. Therein, an adaptive trigger policy based on deep reinforcement learning is introduced to enhance the rapid response capability for disturbances, while the recovery optimization grants the system the ability to recover its performance that has been degraded due to the impact of disturbances. Finally, through simulation experiments and case study, it is verified that the proposed algorithms and framework possess superior performance of multi-objective optimization, which can endow the multi-robot multi-station welding flow shop with resilience to against uncertain robot failures.}
}
@article{SCHWEIGER2024635,
title = {A comprehensive examination of digital retailing: A text-mining review and research agenda},
journal = {Journal of Retailing},
volume = {100},
number = {4},
pages = {635-655},
year = {2024},
issn = {0022-4359},
doi = {https://doi.org/10.1016/j.jretai.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022435924000678},
author = {Elisa B. Schweiger and Virginia Vannucci and Valentina Mazzoli and Laura Grazzini and Anne L. Roggeveen and Dhruv Grewal and Raffaele Donvito and Gaetano Aiello},
keywords = {Retail management, Digital retailing, Digitalization, Technology, Text mining, Topic modeling},
abstract = {Digital retailing encompasses all the digital technology–enabled assets and retail activities that a retailer can use to create, capture, communicate, and deliver value throughout the customer journey. This comprehensive topic modeling analysis of 4,730 articles from 35 years of research across multiple disciplines showcases how the research is evolving overtime and within the disciplines. Results reveal 11 topics areas (consisting of 66 subtopics), as well as the prevalence of these topics within each discipline. Results highlight how the topics have evolved overtime. For example, research on consumer motivation to use technology, retail environmental factors, and firm factors is increasing, while research on trust and risk factors is declining. The trends vary across disciplines. Results also highlight the relationship among the topics, and the impact of publications in each of the topic areas by considering citations across time and disciplines. Implications for future research are discussed.}
}
@article{KUCUK2023,
title = {Deep Learning-Based Sentiment and Stance Analysis of Tweets About Vaccination},
journal = {International Journal on Semantic Web and Information Systems},
volume = {19},
number = {1},
year = {2023},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.333865},
url = {https://www.sciencedirect.com/science/article/pii/S1552628323000236},
author = {Doğan Küçük and Nursal Arıcı},
keywords = {Affective Computing, BERT, ChatGPT, Deep Learning, Health Informatics, Pre-trained Transformers, Public Health, Social Media Analysis},
abstract = {ABSTRACT
Sentiment analysis and stance detection are interrelated problems of affective computing, and their outputs commonly complement each other. The focus of this article is to determine sentiments and stances of Twitter users about vaccination. A tweet dataset on COVID-19 vaccination is compiled and jointly annotated with sentiment and stance. This deep learning approach employs BERT, which is a model based on pre-trained transformers. The generative deep learning model, ChatGPT, is also used for stance and sentiment analysis on the dataset. ChatGPT achieves the best performance for stance detection, while BERT is the best performer for sentiment analysis. This study is the first one to observe stance and sentiment detection performance of ChatGPT on health-related tweets. This article also includes a full-fledged system proposal based on automatic sentiment and stance analysis. COVID-19 pandemic is an impactful global public health phenomenon, and hence, joint extraction of sentiments and stances from health-related tweets can profoundly contribute to health-related decision-making processes.}
}
@article{GUO2025105433,
title = {Student-AI collaborative creative Problem-Solving: The role of human agency},
journal = {Computers & Education},
volume = {239},
pages = {105433},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105433},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002015},
author = {Wenxin Guo and Zheng Liang and Chengcheng Wang and Xing Li and Huiqing Hu and Shi Chen and Quanlei Yu and Qingbai Zhao},
keywords = {Human-computer interface, Cooperative/collaborative learning, 21st century abilities},
abstract = {As artificial intelligence (AI) becomes increasingly integrated into educational contexts, understanding how students collaborate with AI to enhance creativity is of growing importance. However, previous studies have shown that students tend to become overly reliant on AI during collaboration, leading to issues such as limited breakthrough innovations and homogenization of ideas in AI-dominated creative processes. Drawing on distributed cognition theory, which views AI as an extension of human cognition, this study explores how strengthening human agency can improve student-AI collaborative creative performance and support learners’ development. In Experiment 1 (N = 170), students collaborated with AI on a creative problem-solving task, during which they were asked to think independently before or after collaborating with AI. Subjective experiences such as agency and perceived cognitive improvement were measured by questionnaires. The results showed that pre-collaboration thinking improved prompts quality and perceived cognitive improvement but did not enhance final creative output, possibly due to the limited persistence of human agency. Furthermore, Experiment 2 (N = 176) employed a similar task and measurements, and required students to integrate their own ideas with AI-generated content. This led to sustained improvements in both human agency and prompts quality, ultimately enhancing the creativity of final outputs and perceived cognitive improvement. These findings extend the application of distributed cognition theory to AI-supported creativity, highlighting the critical role of human-led idea integration and offering a novel perspective for future research on computer-supported creativity cultivation.}
}
@article{ZHANG2025,
title = {Public Sense of Gain From Using AI-Driven Governmental Chatbots for Public Services},
journal = {International Journal of Information Systems in the Service Sector},
volume = {16},
number = {1},
year = {2025},
issn = {1935-5688},
doi = {https://doi.org/10.4018/IJISSS.387416},
url = {https://www.sciencedirect.com/science/article/pii/S1935568825000028},
author = {Mengyao Zhang and Beichen Lu and Yuanyuan Guo},
keywords = {User Experience, Governmental Chatbots, Public Sense of Gain, AI-driven Public Services, Knowledge-Based Grouping},
abstract = {ABSTRACT
This study investigates the relationship between public experience and sense of gain after using AI-driven governmental chatbots for public services, with a focus on two user groups: policy-oriented users and practical knowledge users. Governmental chatbots, as a significant tool in digital public service delivery, provide convenient interactive services that have the potential to enhance the public's sense of gain, particularly within the public administration and public policy domains. The innovation of this study lies in analyzing how public experience influences the sense of gain through internal mechanisms, and comparing these effects across the two user groups. Using mediation analysis and regression models, the results indicate that while both policy-oriented and practical knowledge users benefit from enhanced public experience, the sense of gain for practical knowledge users increases more significantly, especially when considering internal political efficacy.}
}
@article{DUI2025,
title = {Spatiotemporal Resilience of IoT-enabled Unmanned System of Systems},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925003224},
author = {Hongyan Dui and Huanqi Zhang and Shaomin Wu and Min Xie},
keywords = {Spatiotemporal performance, Spatiotemporal resilience, Unmanned equipment, Importance measure},
abstract = {As advancements in the Internet of Things (IoT) and unmanned technologies continues to progress, the development of unmanned system of systems (USS) has reached unprecedented levels. While prior research has predominantly examined temporal variations in USS resilience, spatial changes remain underexplored. However, USS may involve kinetic engagements and frequent spatial changes during mission execution, affecting signal interference in data layer communications. Although time-dependent factors primarily govern mission effectiveness of the USS, spatial factors influence the transmission stability of the data layer. Consequently, assessing spatiotemporal variations in USS performance is critical. To address these challenges, this study introduces a spatiotemporal resilience assessment framework, which evaluates USS resilience across both temporal and spatial dimensions. Furthermore, we propose a spatiotemporal resilience optimization scheme that enhances system adaptability throughout the mission lifecycle, with a particular emphasis on prevention and recovery strategies. Finally, we validate the validity of the proposed concepts and methods with a case study featuring a regular hexagonal deployment of USS. The results show that the spatiotemporal resilience can better reflect the spatial change characteristics of USS, and the proposed optimization strategy improves the prevention spatiotemporal resilience, recovery spatiotemporal resilience and entire-process spatiotemporal resilience of USS by 0.22%, 7.8% and 11.3%, respectively.}
}
@article{DAVIS2025102673,
title = {High and dry: A ∼300-year record of hydrologic extremes from the French Broad River in the southeastern U.S.},
journal = {Journal of Hydrology: Regional Studies},
volume = {61},
pages = {102673},
year = {2025},
issn = {2214-5818},
doi = {https://doi.org/10.1016/j.ejrh.2025.102673},
url = {https://www.sciencedirect.com/science/article/pii/S2214581825005026},
author = {M.A. Lisa Davis and Ray Lombardi and Matthew D. Gage and Glenn Tootle and Tammy Rittenour and Alexander C. Quimby},
keywords = {Hydrologic extremes, Floods, Flood variability, Droughts, Flood frequency analysis, Paleohydrology, Southeastern U.S},
abstract = {Study region
French Broad River Basin, southeastern United States
Study focus
We combined fluvial and dendro-based paleoflood hydrologic data with instrumented data to understand long-term changes in extreme flow events.
New hydrological insights for the region
Droughts and extreme floods are underrepresented in streamflow records because of short instrumentation records. This study is among the first to develop a centennial-scale record (1734–2024) of hydrologic extreme events in the southeastern U.S. Interannual and interdecadal variability of extreme floods and droughts was observed. This suggests that hydrologic volatility is a persistent pattern in basins where precipitation is heavily influenced by the Bermuda High (North Atlantic subtropical high) and El Niño Southern Oscillation. Landfalling hurricanes generated some of the largest floods in the record. A late spring flood in 1791 CE, however, surpassed the magnitude of all other floods (0.0025 annual exceedance probability), including the 2024 CE Hurricane Helene flood (0.02 annual exceedance probability). Flood frequency and magnitude has declined since the 1800s, however. In contrast, drought severity has increased in the last century. Taken as a whole, these findings suggest flood frequency analyses reliant on floods-of-record from the last century to represent flood extremes may be underestimating flood risks, and droughts and extreme floods both occur on annual and decadal timescales, setting the stage for frequent sequencing of hydrologic extremes in the southeastern U.S.}
}