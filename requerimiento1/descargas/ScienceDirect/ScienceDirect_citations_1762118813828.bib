@incollection{GAUR2026107,
title = {Chapter 7 - Ethical concern of data privacy and patient data ownership},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {107-130},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00014-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044333124400014X},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {AI data breaches, Data ownership, Generative AI, Healthcare AI ethics, HIPAA, Patient data privacy, Transparency in AI},
abstract = {Generative artificial intelligence (AI) in healthcare offers remarkable advancements in patient care, such as personalized treatment plans and predictive diagnostics, but also raises significant ethical concerns surrounding data privacy and patient data ownership. This chapter explores these dual-edged issues, beginning with the promise of AI-driven healthcare and the rising worries about data privacy violations. It delves into the core concepts of data privacy in healthcare, examining how generative AI processes patient data and the risks of breaches and unauthorized access. The chapter also addresses patient data ownership, exploring the ethical tension between the need for vast datasets to train AI models and the right of patients to control their personal health information. It further assesses the effectiveness of privacy laws like HIPAA, identifying gaps and limitations that require reform to protect patient data in AI applications. Through case studies, the chapter illustrates real-world ethical dilemmas, including data breaches and the monetization of patient information by AI companies. Finally, it proposes best practices for developing privacy frameworks and enhancing transparency and accountability to foster trust in AI-driven healthcare.}
}
@article{CHANG2025116501,
title = {Assessing bias in AI-driven psychiatric recommendations: A comparative cross-sectional study of chatbot-classified and CANMAT 2023 guideline for adjunctive therapy in difficult-to-treat depression},
journal = {Psychiatry Research},
volume = {348},
pages = {116501},
year = {2025},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2025.116501},
url = {https://www.sciencedirect.com/science/article/pii/S0165178125001490},
author = {Yu Chang and Yi-Chun Liu and Si-Sheng Huang and Wen-Yu Hsu},
keywords = {Generative artificial intelligence, Artificial intelligence, Depression, Guideline, Evidence-based medicine},
abstract = {The integration of chatbots into psychiatry introduces a novel approach to support clinical decision-making, but biases in their recommendations pose significant concerns. This study investigates potential biases in chatbot-generated recommendations for adjunctive therapy in difficult-to-treat depression, comparing these outputs with the Canadian Network for Mood and Anxiety Treatments (CANMAT) 2023 guidelines. The analysis involved calculating Cohen’s kappa coefficients to measure the overall level of agreement between chatbot-generated classifications and CANMAT guidelines. Differences between chatbot-generated and CANMAT classifications for each medication were assessed using the Wilcoxon signed-rank test. Results reveal substantial agreement for high-performing models, such as Google AI's Gemini 2.0 Flash, which achieved the highest Cohen’s kappa value of 0.82 (SE = 0.052). In contrast, OpenAI’s o1 model showed a lower agreement of 0.746 (SE = 0.057). Notable discrepancies were observed in the overestimation of medications such as quetiapine and lithium and the underestimation of modafinil and ketamine. Additionally, a distinct bias pattern was observed in OpenAI’s chatbots, which demonstrated a tendency to over-recommend lithium and bupropion. Our study highlights both the promise and the challenges of employing AI tools in psychiatric practice, and advocates for multi-model approaches to mitigate bias and improve clinical reliability.}
}
@article{AYYILDIZ2026103058,
title = {The use of ChatGPT in service recovery: Compensating customers},
journal = {Technology in Society},
volume = {84},
pages = {103058},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103058},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002489},
author = {Ahu Yazici Ayyildiz and Tugrul Ayyildiz and Erdogan Koc},
keywords = {Service failure, Service recovery, Compensation, Generative artificial intelligence, ChatGPT, Hospitality},
abstract = {Determining the appropriate compensation for customers is a crucial decision, as it may result in the wasting of resources and further exacerbating customer frustration. Making the right compensation decision requires a great deal of knowledge and expertise about the customers and their service encounters, as well as taking both the customers' and the service business's interests into account. This study investigates the usability of ChatGPT, as a generative AI tool, in identifying the severity of service failures for customers and producing an effective and efficient compensation suggestion accordingly. The two surveys in the study, carried out in two stages with 298 hotel customers and 54 managers from 5-star hotels, established that no single compensation strategy developed by ChatGPT can satisfy most of the customers, and a combination of compensation strategies needs to be used. The study has important theoretical and practical implications both regarding the field of generative AI, in terms of developing business solutions, and for the service recovery and compensation literature.}
}
@article{BARAKCORREN2024128,
title = {Harnessing the Power of Generative AI for Clinical Summaries: Perspectives From Emergency Physicians},
journal = {Annals of Emergency Medicine},
volume = {84},
number = {2},
pages = {128-138},
year = {2024},
issn = {0196-0644},
doi = {https://doi.org/10.1016/j.annemergmed.2024.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S0196064424000787},
author = {Yuval Barak-Corren and Rebecca Wolf and Ronen Rozenblum and Jessica K. Creedon and Susan C. Lipsett and Todd W. Lyons and Kenneth A. Michelson and Kelsey A. Miller and Daniel J. Shapiro and Ben Y. Reis and Andrew M. Fine},
abstract = {Study objective
The workload of clinical documentation contributes to health care costs and professional burnout. The advent of generative artificial intelligence language models presents a promising solution. The perspective of clinicians may contribute to effective and responsible implementation of such tools. This study sought to evaluate 3 uses for generative artificial intelligence for clinical documentation in pediatric emergency medicine, measuring time savings, effort reduction, and physician attitudes and identifying potential risks and barriers.
Methods
This mixed-methods study was performed with 10 pediatric emergency medicine attending physicians from a single pediatric emergency department. Participants were asked to write a supervisory note for 4 clinical scenarios, with varying levels of complexity, twice without any assistance and twice with the assistance of ChatGPT Version 4.0. Participants evaluated 2 additional ChatGPT-generated clinical summaries: a structured handoff and a visit summary for a family written at an 8th grade reading level. Finally, a semistructured interview was performed to assess physicians’ perspective on the use of ChatGPT in pediatric emergency medicine. Main outcomes and measures included between subjects’ comparisons of the effort and time taken to complete the supervisory note with and without ChatGPT assistance. Effort was measured using a self-reported Likert scale of 0 to 10. Physicians’ scoring of and attitude toward the ChatGPT-generated summaries were measured using a 0 to 10 Likert scale and open-ended questions. Summaries were scored for completeness, accuracy, efficiency, readability, and overall satisfaction. A thematic analysis was performed to analyze the content of the open-ended questions and to identify key themes.
Results
ChatGPT yielded a 40% reduction in time and a 33% decrease in effort for supervisory notes in intricate cases, with no discernible effect on simpler notes. ChatGPT-generated summaries for structured handoffs and family letters were highly rated, ranging from 7.0 to 9.0 out of 10, and most participants favored their inclusion in clinical practice. However, there were several critical reservations, out of which a set of general recommendations for applying ChatGPT to clinical summaries was formulated.
Conclusion
Pediatric emergency medicine attendings in our study perceived that ChatGPT can deliver high-quality summaries while saving time and effort in many scenarios, but not all.}
}
@article{POZDNIAKOV2024100289,
title = {Large language models meet user interfaces: The case of provisioning feedback},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100289},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100289},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000924},
author = {Stanislav Pozdniakov and Jonathan Brazil and Solmaz Abdi and Aneesha Bakharia and Shazia Sadiq and Dragan Gašević and Paul Denny and Hassan Khosravi},
keywords = {Artificial intelligence, Large language models, Generative artificial intelligence, Interfaces, Feedback, Learning analytics},
abstract = {Incorporating Generative Artificial Intelligence (GenAI), especially Large Language Models (LLMs), into educational settings presents valuable opportunities to boost the efficiency of educators and enrich the learning experiences of students. A significant portion of the current use of LLMs by educators has involved using conversational user interfaces (CUIs), such as chat windows, for functions like generating educational materials or offering feedback to learners. The ability to engage in real-time conversations with LLMs, which can enhance educators' domain knowledge across various subjects, has been of high value. However, it also presents challenges to LLMs' widespread, ethical, and effective adoption. Firstly, educators must have a degree of expertise, including tool familiarity, AI literacy and prompting to effectively use CUIs, which can be a barrier to adoption. Secondly, the open-ended design of CUIs makes them exceptionally powerful, which raises ethical concerns, particularly when used for high-stakes decisions like grading. Additionally, there are risks related to privacy and intellectual property, stemming from the potential unauthorised sharing of sensitive information. Finally, CUIs are designed for short, synchronous interactions and often struggle and hallucinate when given complex, multi-step tasks (e.g., providing individual feedback based on a rubric on a large scale). To address these challenges, we explored the benefits of transitioning away from employing LLMs via CUIs to the creation of applications with user-friendly interfaces that leverage LLMs through API calls. We first propose a framework for pedagogically sound and ethically responsible incorporation of GenAI into educational tools, emphasizing a human-centred design. We then illustrate the application of our framework to the design and implementation of a novel tool called Feedback Copilot, which enables instructors to provide students with personalized qualitative feedback on their assignments in classes of any size. An evaluation involving the generation of feedback from two distinct variations of the Feedback Copilot tool, using numerically graded assignments from 338 students, demonstrates the viability and effectiveness of our approach. Our findings have significant implications for GenAI application researchers, educators seeking to leverage accessible GenAI tools, and educational technologists aiming to transcend the limitations of conversational AI interfaces, thereby charting a course for the future of GenAI in education.}
}
@article{ZHENG20255635,
title = {Leveraging ChatGPT for Enhancing Learning in Radiology Resident Education},
journal = {Academic Radiology},
volume = {32},
number = {9},
pages = {5635-5642},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2025.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1076633225005677},
author = {Aaron Zheng and Cole J. Barker and Sergio S. Ferrante and Judy H. Squires and Barton F. {Branstetter IV} and Marion A. Hughes},
keywords = {ChatGPT, Artificial intelligence, Education, Resident, Multiple-choice question},
abstract = {Rationale and Objectives
Chat generative pre-trained transformer (ChatGPT) is a generative artificial intelligence chatbot based on a LLM at the forefront of technological development with promising applications in medical education. This study aims to evaluate the use of ChatGPT in generating board-style practice questions for radiology resident education.
Materials and Methods
Multiple-choice questions (MCQs) were generated by ChatGPT from resident lecture transcripts using a custom prompt. 17 of the ChatGPT-generated MCQs were selected for inclusion in the study and randomly combined with 11 attending radiologist-written MCQs. For each MCQ, the 21 participating radiology residents answered the MCQ, rated the MCQ from 1–10 on effectiveness in reinforcing lecture material, and responded whether they thought an attending radiologist at their institution wrote the MCQ versus an alternative source.
Results
Perceived MCQ quality was not significantly different between ChatGPT-generated (M=6.93, SD=0.29) and attending radiologist-written MCQs (M=7.08, SD=0.51) (p=0.15). MCQ correct answer percentages did not significantly differ between ChatGPT-generated (M=57%, SD=20%) and attending radiologist-written MCQs (M=59%, SD=25%) (p=0.78). The percentage of MCQs thought to be written by an attending radiologist was significantly different between ChatGPT-generated (M=57%, SD=13%) and attending radiologist-written MCQs (M=71%, SD=20%) (p=0.04).
Conclusion
LLMs such as ChatGPT demonstrate potential in generating and presenting educational material for radiology education, and their use should be explored further on a larger scale.}
}
@article{GREGORY2024106349,
title = {ChatGPT: A canary in the coal mine or a parrot in the echo chamber? Detecting fraud with LLM: The case of FTX},
journal = {Finance Research Letters},
volume = {70},
pages = {106349},
year = {2024},
issn = {1544-6123},
doi = {https://doi.org/10.1016/j.frl.2024.106349},
url = {https://www.sciencedirect.com/science/article/pii/S1544612324013783},
author = {Gadzinski Gregory and Liuzzi Vito},
keywords = {LLMs, FTX, Fraud detection, RAG},
abstract = {Does the paradigm shift brought by Large Language Models (LLMs) hold the promise of revolutionizing financial analysis? Our article tackles this question by exploring fraud detection in cryptocurrency exchanges, with a focus on FTX. We study the abilities of generative artificial intelligence tools like ChatGPT to serve as early-warning systems of fraud and identify red flags in the particular and difficult case where no financial information is available. We recognize several challenges to provide insights beyond human knowledge. To achieve a higher degree of scrutiny, we highlight the role of sequential interactions between the AI Chatbot and the researcher as well as the inclusion of external contents, a technique known as Retrieval Augmented Generation (RAG). Therefore, this article serves as a cautionary tale on the necessary conditions to achieve augmented intelligence.}
}
@article{BAUCON2024112027,
title = {Life in an Artinskian (Cisuralian) Permian megacaldera: Benthic palaeoecology in the shadow of the Bolzano Supervolcano (Athesian Volcanic District, Italy)},
journal = {Palaeogeography, Palaeoclimatology, Palaeoecology},
volume = {638},
pages = {112027},
year = {2024},
issn = {0031-0182},
doi = {https://doi.org/10.1016/j.palaeo.2024.112027},
url = {https://www.sciencedirect.com/science/article/pii/S0031018224000166},
author = {Andrea Baucon and Corrado Morelli and Carlos {Neto de Carvalho} and Evelyn Kustascher},
keywords = {Supervolcano, Freshwater, Trace fossils, Caldera, Planolites, Artificial intelligence},
abstract = {Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment.}
}
@article{CHEN2023100496,
title = {Generative design of therapeutics that bind and modulate protein states},
journal = {Current Opinion in Biomedical Engineering},
volume = {28},
pages = {100496},
year = {2023},
issn = {2468-4511},
doi = {https://doi.org/10.1016/j.cobme.2023.100496},
url = {https://www.sciencedirect.com/science/article/pii/S2468451123000521},
author = {Tianlai Chen and Lauren Hong and Vivian Yudistyra and Sophia Vincoff and Pranam Chatterjee},
keywords = {Post-translational modifications, Generative AI, Binder design},
abstract = {Numerous therapeutic approaches have been developed to enable interrogation and modulation of protein isoforms, but often require laborious experimental development or screening of binders to targets of interest. In this article, we focus on efficient, state-of-the-art computational methods to design both small molecule and protein-based binders to target proteins, and highlight recent generative artificial intelligence approaches to binder design, which represents the most promising direction to enable targeting and modulation of any protein state. Integrated with advances in protein-modifying architectures, the strategies described here may serve as the foundation for therapeutic development in the near future.}
}
@article{OBREJA2025100576,
title = {Mapping the multidimensional trend of generative AI: A bibliometric analysis and qualitative thematic review},
journal = {Computers in Human Behavior Reports},
volume = {17},
pages = {100576},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100576},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824002094},
author = {Dragoș M. Obreja and Răzvan Rughiniș and Daniel Rosner},
keywords = {Generative AI, Bibliometrics, ChatGPT, Ethical implications, Knowledge dimensions, Copyright, Thematic review},
abstract = {Generative artificial intelligence (AI) represents an increasingly popular topic that is visible even in most research areas within the social sciences and humanities fields. However, little attention has been paid to the knowledge dimensions reflecting the potential macro-social implications of generative technologies. This study utilizes a two-fold methodology, consisting of a bibliometric analysis of articles published in the last decade (N = 484) and a subsequent qualitative thematic review of the most influential articles in each research area (N = 246). The objective is to investigate the main conceptual dimensions associated with generative AI in the social sciences. Applying a thematic analysis framework, we notice that the most popular dimensions are technological, ethical, and social. These dimensions primarily focus on investigating the implications of the generative use of AI on employees in professional sectors as well as on students and teachers in the educational environment. Moreover, the political dimension reflects macro-social consequences on governance and legal components related to ensuring social protection for professions that risk becoming obsolete due to the widespread adoption of ChatGPT-type technologies. Overall, our research emphasizes concrete scholarly tensions through which generative AI-based technologies are predominantly encouraged in the educational and organizational sectors, but the potential risks associated with copyright infringement and job loss might constitute important drivers of social change. We also notice that a Foucauldian power/knowledge framework would prove useful in understanding the underdiscussed effects of generative AI on the societal/macro level.}
}
@article{AGNIHOTRI2025100681,
title = {Large Language Models in Ophthalmology: A Review of Publications from Top Ophthalmology Journals},
journal = {Ophthalmology Science},
volume = {5},
number = {3},
pages = {100681},
year = {2025},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100681},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524002173},
author = {Akshay Prashant Agnihotri and Ines Doris Nagel and Jose Carlo M. Artiaga and Ma. Carmela B. Guevarra and George Michael N. Sosuan and Fritz Gerald P. Kalaw},
keywords = {Large language models, Generative artificial intelligence, Chatbots, ChatGPT},
abstract = {Purpose
To review and evaluate the current literature on the application and impact of large language models (LLMs) in the field of ophthalmology, focusing on studies published in high-ranking ophthalmology journals.
Design
This is a retrospective review of published articles.
Participants
This study did not involve human participation.
Methods
Articles published in the first quartile (Q1) of ophthalmology journals on Scimago Journal & Country Rank discussing different LLMs up to June 7, 2024, were reviewed, parsed, and analyzed.
Main Outcome Measures
All available articles were parsed and analyzed, which included the article and author characteristics and data regarding the LLM used and its applications, focusing on its use in medical education, clinical assistance, research, and patient education.
Results
There were 35 Q1-ranked journals identified, 19 of which contained articles discussing LLMs, with 101 articles eligible for review. One-third were original investigations (32%; 32/101), with an average of 5.3 authors per article. The United States (50.4%; 51/101) was the most represented country, followed by the United Kingdom (25.7%; 26/101) and Canada (16.8%; 17/101). ChatGPT was the most used LLM among the studies, with different versions discussed and compared. Large language model applications were discussed relevant to their implications in medical education, clinical assistance, research, and patient education.
Conclusions
The numerous publications on the use of LLM in ophthalmology can provide valuable insights for stakeholders and consumers of these applications. Large language models present significant opportunities for advancement in ophthalmology, particularly in team science, education, clinical assistance, and research. Although LLMs show promise, they also show challenges such as performance inconsistencies, bias, and ethical concerns. The study emphasizes the need for ongoing artificial intelligence improvement, ethical guidelines, and multidisciplinary collaboration.
Financial Disclosure(s)
The author(s) have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{ZHANG2025,
title = {Generative Video Communications: Concepts, Key Technologies, and Future Research Trends},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925003157},
author = {Wenjun Zhang and Guo Lu and Zhiyong Chen and Geoffrey Ye Li},
keywords = {Video communications, Video compression, Video transmission, Video Evaluation},
abstract = {With the rapid growth of video traffic and the evolution of video formats, traditional video communication systems are encountering many challenges, such as limited data compression capacity, high energy consumption, and a narrow range of services. These challenges stem from the constraints of current systems, which rely heavily on discriminative methods for visual content reconstruction and achieve communication gains only in the information and physical domains. To address these issues, this paper introduces generative video communication, a novel paradigm that leverages generative artificial intelligence technologies to enhance video content expression. The core objective is to improve the expressive capabilities of video communication by enabling new gains in the cognitive domain (i.e., content dimension) while complementing existing frameworks. This paper presents key technical pathways for the proposed paradigm, including elastic encoding, collaborative transmission, and trustworthy evaluation, and explores its potential applications in task-oriented and immersive communication. Through this generative approach, we aim to overcome the limitations of traditional video communication systems, offering more efficient, adaptable, and immersive video services.}
}
@article{LI2025101003,
title = {Exploring human and AI collaboration in inclusive STEM teacher training: A synergistic approach based on self-determination theory},
journal = {The Internet and Higher Education},
volume = {65},
pages = {101003},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.101003},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000120},
author = {Tingting Li and Zehui Zhan and Yu Ji and Tongde Li},
keywords = {STEM education, Teacher professional learning, Collaborative learning, ChatGPT, AI-assisted learning},
abstract = {Inclusive STEM teacher training plays a critical role in shaping the future of STEM teaching practices and improving educational outcomes for all students, particularly those from marginalized and underrepresented backgrounds. This study investigates the inclusive collaborative learning framework for enhancing STEM teaching among student teachers, focusing on interpersonal and human-machine (generative artificial intelligence) collaboration. Employing a Self-Determination Theory guided approach, two rounds of exploratory studies were conducted. Study 1 compared the effects of interpersonal collaboration (TSPL: in-Service Teacher-Student Teacher Pair Learning) and human-machine collaboration (CSPL: ChatGPT-Student Teacher Pair Learning). Building on Study 1, Study 2 employed a hybrid inclusive collaborative learning model (iHMCL: integrated Human-Machine Collaborative Learning) with expanded participant demographics, blended course formats, and integrated peer, expert, and AI feedback mechanisms. The two-year iterative empirical research revealed differences in the impact of the three collaborative learning approaches on student teachers' learning. CSPL and iHMCL groups outperformed TSPL in STEM teaching knowledge and cognitive load, while TSPL and iHMCL excelled in STEM teaching ability compared to CSPL. The SDT-based inclusive collaborative learning framework for STEM teacher training proved effective, with noted implications. In the future, the integration of generative artificial intelligence and cross boundary learning in inclusive STEM teacher education will require educators to redefine their roles, emphasizing emotional support, critical thinking, and creativity, ensuring that AI complements rather than replaces hands-on, reality-based learning.}
}
@article{LASAROV2026105309,
title = {How practitioners can leverage GenAI to bridge the research-practice gap},
journal = {Tourism Management},
volume = {113},
pages = {105309},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105309},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001797},
author = {Wassili Lasarov and Melanie Trabandt and Stefan Hoffmann and Giampaolo Viglia},
keywords = {Research-practice gap, GenAI, Knowledge translation process, Toolkit, Literature review},
abstract = {Despite the practical relevance of many tourism research studies, organizations and policymakers often struggle to integrate them due to time constraints, language barriers, limited resources, and interaction challenges. Generative artificial intelligence (GenAI) offers new capabilities to overcome these barriers. We propose a GenAI-enabled knowledge translation process with three stages: (i) research curation to identify and translate relevant literature; (ii) content creation to produce materials; and (iii) market research using synthetic guests to pre-test their effectiveness. We examine the capabilities, limitations, and ethical implications of GenAI at each stage, drawing on a systematic review of GenAI and tourism literature. To equip managers with the knowledge and tools needed to harness research-based insights effectively, we offer a toolkit comprising a handbook, a promptbook, and tailored GPT models. The toolkit enables tourism and hospitality practitioners to apply research findings in their decision-making and content strategies without direct stakeholder interaction.}
}
@article{ZHANG2025125059,
title = {Deep generative models in energy system applications: Review, challenges, and future directions},
journal = {Applied Energy},
volume = {380},
pages = {125059},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.125059},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924024437},
author = {Xiangyu Zhang and Andrew Glaws and Alexandre Cortiella and Patrick Emami and Ryan N. King},
keywords = {Generative artificial intelligence, Deep generative models, Energy systems, Smart grid},
abstract = {In recent years, with the advent of mature machine learning products like ChatGPT, Stable Diffusion, and Sora, the world has witnessed tremendous changes driven by the rapid development of generative artificial intelligence (GAI). Beyond applications in text, speech, image, and video creation, deep generative models (DGMs) underpinning these cutting-edge technologies have also been employed by domain researchers to address scientific and engineering challenges. This paper aims to fill a gap in the research community by providing a comprehensive review of how DGMs have been utilized in energy system applications. Based on five of the most popular DGMs, we review and categorize 228 research articles into five focus areas: data generation, forecasting, situational awareness, modeling, and optimal decision-making. Through this classification, we uncover trends in how DGMs are employed for each type of problem, highlighting GAI techniques that contribute to breakthroughs over traditional methods. We discuss limitations in existing literature, engineering challenges, and propose future directions, all tailored to the unique nature of problems in energy system engineering. Our goal is to offer insights for energy system domain researchers, providing a comprehensive view of existing studies and potential future opportunities.}
}
@article{SPENNEMANN2024301821,
title = {Examining and detecting academic misconduct in written documents using revision save identifier numbers in MS Word as exemplified by multiple scenarios},
journal = {Forensic Science International: Digital Investigation},
volume = {51},
pages = {301821},
year = {2024},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2024.301821},
url = {https://www.sciencedirect.com/science/article/pii/S2666281724001458},
author = {Dirk HR. Spennemann and Rudolf J. Spennemann and Clare L. Singh},
keywords = {Academic misconduct, AI-Generated text, Authorship, Contract cheating, Document creation and editing, Digital forensics, Plagiarism},
abstract = {Deliberate academic misconduct by students often relies on the use of segments of externally authored text, generated either by commercial contract authoring services or by generative Artificial intelligence language models. While revision save identifier (rsid) numbers in Microsoft Word files are associated with edit and save actions of a document, MS Word does not adhere to the ECMA specifications for the Office Open XML. Existing literature shows that digital forensics using rsid requires access to multiple document versions or the user's machine. In cases of academic misconduct allegations usually only the submitted files are available for digital forensic examination, coupled with assertions by the alleged perpetrators about the document generation and editing process This paper represents a detailed exploratory study that provides educators and digital forensic scientists with tools to examine a single document for the veracity of various commonly asserted scenarios of document generation and editing. It is based on a series of experiments that ascertained whether and how common edit and document generation actions such as copy, paste, insertion of blocks of texts from other documents, leave tell-tale traces in the rsid encoding that is embedded in all MS Word documents. While digital forensics can illuminate document generation processes, the actions that led to these may have innocuous explanations. In consequence, this paper also provides academic misconduct investigators with a set of prompts to guide the interview with alleged perpetrators to glean the information required for cross-correlation with observations based on the rsid data.}
}
@article{HIROSAWA20231119,
title = {Comparative Evaluation of Diagnostic Accuracy Between Google Bard and Physicians},
journal = {The American Journal of Medicine},
volume = {136},
number = {11},
pages = {1119-1123.e18},
year = {2023},
issn = {0002-9343},
doi = {https://doi.org/10.1016/j.amjmed.2023.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0002934323005363},
author = {Takanobu Hirosawa and Kazuya Mizuta and Yukinori Harada and Taro Shimizu},
keywords = {Clinical decision supporting system, Diagnosis, Diagnostic excellence, Generative artificial intelligence, Large language model, Natural language processing},
abstract = {Background
In this study, we evaluated the diagnostic accuracy of Google Bard, a generative artificial intelligence (AI) platform.
Methods
We searched published case reports from our department for difficult or uncommon case descriptions and mock cases created by physicians for common case descriptions. We entered the case descriptions into the prompt of Google Bard to generate the top 10 differential-diagnosis lists. As in previous studies, other physicians created differential-diagnosis lists by reading the same clinical descriptions.
Results
A total of 82 clinical descriptions (52 case reports and 30 mock cases) were used. The accuracy rates of physicians were still higher than Google Bard in the top 10 (56.1% vs 82.9%, P < .001), the top 5 (53.7% vs 78.0%, P = .002), and the top differential diagnosis (40.2% vs 64.6%, P = .003). Even within the specific context of case reports, physicians consistently outperformed Google Bard. When it came to mock cases, the performances of the differential-diagnosis lists by Google Bard were no different from those of the physicians in the top 10 (80.0% vs 96.6%, P = .11) and the top 5 (76.7% vs 96.6%, P = .06), except for those in the top diagnoses (60.0% vs 90.0%, P = .02).
Conclusion
While physicians excelled overall, and particularly with case reports, Google Bard displayed comparable diagnostic performance in common cases. This suggested that Google Bard possesses room for further improvement and refinement in its diagnostic capabilities. Generative AIs, including Google Bard, are anticipated to become increasingly beneficial in augmenting diagnostic accuracy.}
}
@article{ZHAI2025132773,
title = {Data-driven machine learning improves prediction of sulfonamide antibiotic adsorption by biochar in aqueous phase},
journal = {Bioresource Technology},
volume = {434},
pages = {132773},
year = {2025},
issn = {0960-8524},
doi = {https://doi.org/10.1016/j.biortech.2025.132773},
url = {https://www.sciencedirect.com/science/article/pii/S0960852425007394},
author = {Mudi Zhai and Bomin Fu and Zhaozhong Wu and Junsen Wang and Weijie Wang and Hongtao Wang},
keywords = {Wastewater, Data augmentation, Wasserstein generative adversarial network, Generative artificial intelligence},
abstract = {Sulfonamide antibiotics (SAs) have attracted much attention due to their environmental risks to aquatic ecosystems. Biochars (BCs), as excellent adsorbent materials, have been used to remove SAs from aqueous phases. To achieve effective evaluation of adsorption, machine learning (ML) strategies are increasingly being developed. However, no applicable data-driven ML models have been studied to predict the adsorption of SAs by BCs in water. Therefore, this study employed an ML approach based on Wasserstein generative adversarial network (WGAN) data augmentation to predict the adsorption of SAs on BCs in the aqueous phase. The results indicated that the WGAN could generate virtual data highly similar to the original adsorption dataset. By expanding the original data using WGAN, the performance of the extreme gradient boosting model in predicting the adsorption amount improved. This study provides new insights into predicting the adsorption behavior of waste-based BCs for SAs in water environments.}
}
@article{SUK2025102261,
title = {Communicative AI in the scientific public sphere: An analysis of Twitter discourse on generative AI tools},
journal = {Telematics and Informatics},
volume = {98},
pages = {102261},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102261},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000231},
author = {Jiyoun Suk and Yini Zhang and Jiawei Liu and Yukyung Yang},
keywords = {Generative artificial intelligence, Scientific public sphere, Social media, Diffusion of innovation},
abstract = {Drawing on the concept of the scientific public sphere, this study examines the public sense-making of communicative AI (e.g., generative AI) on social media. Advancing a framework encompassing cognitive (technology vs. use) and affective (positive vs. negative) dimensions of the public discourse on communicative AI, we analyzed global Twitter (now X) conversations about generative AI tools. Findings showed that the text generator (ChatGPT) discussions centered more on the technology-centered themes, whereas the image generator discussions emphasized their uses. ChatGPT received mixed sentiments in technology-related discussions, while there was more positive sentiment about the its uses. Theoretical and practical implications are discussed.}
}
@article{AKHTAR2024109283,
title = {Smart product platforming powered by AI and generative AI: Personalization for the circular economy},
journal = {International Journal of Production Economics},
volume = {273},
pages = {109283},
year = {2024},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2024.109283},
url = {https://www.sciencedirect.com/science/article/pii/S0925527324001403},
author = {Pervaiz Akhtar and Arsalan Mujahid Ghouri and Aniqa Ashraf and Jia Jia Lim and Naveed R Khan and Shuang Ma},
keywords = {Smart product platforms and flexibility, Personalized product design and manufacturing, Environmentally friendly products and circular economy, Generative artificial intelligence and large language models, Big data analytics and machine learning},
abstract = {The interlocks between smart product platforming (SPP) powered by Artificial Intelligence (AI) and Generative AI, big data analytics, and machine learning are still in their infancy. Modern technology-driven SPP promotes personalized product design and manufacturing suited to support environmentally friendly products for the circular economy. In this study, we develop a framework pertaining to the interlinks between SPP, big data analytics, machine learning, and the circular economy. To test our framework, we apply structure equation modeling based on data collected from more than 200 automotive industry professionals operating in China. Our results demonstrate that SPP and big data analytics are the central determinants for manufacturing environmentally friendly products, ultimately promoting circular economy applications. SPP plays a pivotal role in innovative product design and in facilitating the relevant manufacturing procedures. Big data analytics significantly feed into SPP applications. Machine learning and flexibility in SPP perform moderating roles in strengthening environmentally friendly outcomes. The mediating role played by SPP between big data analytics and environmentally friendly products for the circular economy is partially encouraging. As SPP powered by AI and Generative AI is an emerging phenomenon, our study contributes to this new knowledge dimension. We conclude this paper by discussing the theoretical and practical implications of our study, its limitations, and directions for future research.}
}
@article{WANG2025103857,
title = {Impacts of GenAI-assisted collaborative prewriting on university EFL students’ interactions with GenAI, outline quality, and task motivation},
journal = {System},
volume = {135},
pages = {103857},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103857},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002672},
author = {Jun Wang and Kai Guo},
keywords = {Generative artificial intelligence, EFL writing, Collaborative writing, Prewriting, Outline writing},
abstract = {The integration of generative artificial intelligence (GenAI) tools in English as a foreign language (EFL) writing instruction has gained significant traction. However, existing research has mainly concentrated on the revision stage of writing, with limited exploration of how GenAI can support students during the prewriting phase, particularly in developing outlines. This study investigated the effects of a novel learning approach—GenAI-assisted collaborative prewriting (GACP)—and conducted a comparative analysis with GenAI-assisted individual prewriting (GAIP). The focus was on students' interactions with GenAI, the quality of their outlines, and their task motivation. Employing a within-subjects design, this study involved sixty-nine Chinese undergraduates. We collected and analyzed multiple data sources, including chat histories between students and a GenAI tool, writing outlines, and post-task questionnaires. The results revealed that students' objectives for using GenAI in outline creation were largely consistent across both conditions, with brainstorming emerging as the most common goal. Notably, peer collaboration was found to facilitate more effective prompts for eliciting desired responses from GenAI and to mitigate potential misuse of the tool. Additionally, GACP led to higher content quality in outline writing, although improvements in organization and language were less pronounced. Furthermore, students in the GACP setting reported greater confidence in their writing outcomes, although no statistically significant differences in overall task motivation were observed. These findings enhance our understanding of GenAI's potential in supporting EFL writing and suggest that collaborative use of GenAI can further enrich student learning experiences.}
}
@article{KRISHNAN20255962,
title = {A generative deep learning approach to de novo antibiotic design},
journal = {Cell},
volume = {188},
number = {21},
pages = {5962-5979.e22},
year = {2025},
issn = {0092-8674},
doi = {https://doi.org/10.1016/j.cell.2025.07.033},
url = {https://www.sciencedirect.com/science/article/pii/S0092867425008554},
author = {Aarti Krishnan and Melis N. Anahtar and Jacqueline A. Valeri and Wengong Jin and Nina M. Donghia and Leif Sieben and Andreas Luttens and Yu Zhang and Seyed Majed Modaresi and Andrew Hennes and Jenna Fromer and Parijat Bandyopadhyay and Jonathan C. Chen and Danyal Rehman and Ronak Desai and Paige Edwards and Ryan S. Lach and Marie-Stéphanie Aschtgen and Margaux Gaborieau and Massimiliano Gaetani and Samantha G. Palace and Satotaka Omori and Lutete Khonde and Yurii S. Moroz and Bruce Blough and Chunyang Jin and Edmund Loh and Yonatan H. Grad and Amir Ata Saei and Connor W. Coley and Felix Wong and James J. Collins},
keywords = {antibiotics, drug discovery, generative artificial intelligence, machine learning, fragments,  design, graph neural networks, , , bacterial infection},
abstract = {Summary
The antimicrobial resistance crisis necessitates structurally distinct antibiotics. While deep learning approaches can identify antibacterial compounds from existing libraries, structural novelty remains limited. Here, we developed a generative artificial intelligence framework for designing de novo antibiotics through two approaches: a fragment-based method to comprehensively screen >107 chemical fragments in silico against Neisseria gonorrhoeae or Staphylococcus aureus, subsequently expanding promising fragments, and an unconstrained de novo compound generation, each using genetic algorithms and variational autoencoders. Of 24 synthesized compounds, seven demonstrated selective antibacterial activity. Two lead compounds exhibited bactericidal efficacy against multidrug-resistant isolates with distinct mechanisms of action and reduced bacterial burden in vivo in mouse models of N. gonorrhoeae vaginal infection and methicillin-resistant S. aureus skin infection. We further validated structural analogs for both compound classes as antibacterial. Our approach enables the generative deep-learning-guided design of de novo antibiotics, providing a platform for mapping uncharted regions of chemical space.}
}
@article{JAYARAMAN20253203,
title = {Llama3 with Parameter Efficient Fine-Tuning Approach for 5G Cellular Network Security Text Classification},
journal = {Procedia Computer Science},
volume = {258},
pages = {3203-3210},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.578},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016825},
author = {Ashok Kumar Jayaraman and Magudeeswaran Muthappagounder and Vinoth Kannan Ranganathan},
keywords = {Security text classification, 5G Technology, Generative AI, large language models, multiclass classification},
abstract = {Third generation partnership project (3GPP) provides unified telecom standards in terms of numerous technical documents related to 5G cellular networks. Understanding these technical documents becomes a time-consuming task. Therefore, researchers use generative artificial intelligence based LLM models to create and understand the 3GPP knowledge base. This helps to improve network securities in terms of threats, incidents, vulnerability, policy compliance, and security intelligence. In this paper, a Llama3 model with parameter efficient fine-tuning (PEFT) approach is presented with the task of 3GPP 5G cellular network security text classification. This approach is compared with multiple transformer models. The 3GPP-based SPEC5G dataset is used for the task of security-related text classification. Our results indicate that the proposed Llama3 with PEFT approach significantly outperforms.}
}
@article{LIN2024110682,
title = {Circular supply chain for smart production in Industry 4.0},
journal = {Computers & Industrial Engineering},
volume = {198},
pages = {110682},
year = {2024},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2024.110682},
url = {https://www.sciencedirect.com/science/article/pii/S0360835224008040},
author = {Kuo-Yi Lin},
keywords = {Circular Supply Chain, Industry 4.0, Smart Production, Generative AI, Industry, Innovation and Infrastructure},
abstract = {Sustainable practices in industrial engineering are not just ideal but necessary. The push for Circular Supply Chain (CSC) in Industry 4.0 has become increasingly vital. Motivated by this, this study proposed the UNISONE framework, integrated with advanced smart production technologies grounded in CSC principles. The proposed framework resulted in enhanced operational efficiency and a sustainable production system that significantly minimizes waste. The research was validated through an empirical study within a bearing factory, successfully demonstrating the framework’s efficacy and creating value within the CSC paradigm. Key findings include the impact of different signal-to-noise ratios on model performance, with peak test accuracy at a noise ratio of 0.6, and the best results of 85.32 % accuracy achieved by combining sparse and noise reduction autoencoder techniques in generative artificial intelligence. This study underscores the framework’s potential to address industrial engineering challenges and promote scalable, efficient, and eco-conscious manufacturing, benefiting both the environment and the economy.}
}
@article{SENGUL2025104696,
title = {Annotating risk stratification of thyroid nodules: Assessing the suitability of ChatGPT for text-based analysis in thyroidology},
journal = {American Journal of Otolaryngology},
volume = {46},
number = {5},
pages = {104696},
year = {2025},
issn = {0196-0709},
doi = {https://doi.org/10.1016/j.amjoto.2025.104696},
url = {https://www.sciencedirect.com/science/article/pii/S0196070925000997},
author = {Ilker Sengul and Demet Sengul},
keywords = {Thyroid gland, Risk, Generative Artificial Intelligence, Artificial Intelligence, Thyroid nodule, Pathology, Thyroidology}
}
@article{HEREDIAALVARO2025103007,
title = {An advanced retrieval-augmented generation system for manufacturing quality control},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103007},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103007},
url = {https://www.sciencedirect.com/science/article/pii/S147403462400658X},
author = {José Antonio {Heredia Álvaro} and Javier González Barreda},
keywords = {Knowledge-based systems, Quality control, Ceramic tile, Retrieval-augmented generation, Large language models},
abstract = {The rise of Large Language Models (LLMs) with generative artificial intelligence has revolutionized the development of knowledge-based systems, enabling intuitive interactions through natural language. This paper explores the implementation of an advanced Retrieval-Augmented Generation (RAG) system, designed to improve manufacturing quality control by utilizing the capabilities of LLMs, particularly OpenAI’s GPT models. We focus on the ceramic tile manufacturing process, where the system retrieves and analyzes specialized bibliographic sources to diagnose defects and propose solutions. In addition to core RAG functionalities, the system incorporates tailored pre-processing and post-processing mechanisms to optimize document retrieval and response generation. The system’s effectiveness in solving quality issues is demonstrated through its application in identifying defect causes and generating actionable solutions, significantly improving non-conformities management. This approach not only streamlines troubleshooting but also enhances the quality control system, providing a comprehensive, scalable tool for manufacturers.}
}
@article{DANG2024101157,
title = {Ethical use of generative AI for writing practices: Addressing linguistically diverse students in U.S. Universities' AI statements},
journal = {Journal of Second Language Writing},
volume = {66},
pages = {101157},
year = {2024},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2024.101157},
url = {https://www.sciencedirect.com/science/article/pii/S106037432400064X},
author = {Anh Dang and Hui Wang},
keywords = {Generative AI, ChatGPT, L2 Writing and Generative AI, GenAI Statements, University, Policies, Critical AI Literacy},
abstract = {Given the rapid development in Generative Artificial Intelligence (GenAI) technologies, conversations regarding how these tools will shape the teaching and learning of writing can be difficult to unpack. Thus, higher-ed institutions across the U.S. are paying more attention to the discussion of GenAI in their own contexts and also establishing guidelines to support instructors and students in this GenAI era. To understand more about the direction of these universities, this research brief examines publicly available statements and resources from 100 U.S. universities on the teaching of writing and GenAI usage, and from there, guide institutions in developing effective strategies for the responsible implementation of these tools. This report also highlights the importance of including L2 students as a focus in the process of crafting these statements, especially when viewing GenAI through the lens of critical pedagogy, social justice and inequalities.}
}
@article{GROVES2025101103,
title = {Cultivating the experience of dignity at work during digital transformation: Protective & proactive strategies for leaders and organizations},
journal = {Organizational Dynamics},
volume = {54},
number = {3, Part 2},
pages = {101103},
year = {2025},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101103},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000767},
author = {Kevin S. Groves and Jaclyn Margolis and Cristina Gibson},
keywords = {Dignity, Leadership development, Meaningful work, Digital transformation, Employee engagement},
abstract = {Ubiquitous digital transformation technologies such as robotics, generative artificial intelligence (AI) tools, large language models (LLMs), and other digital applications automate both mechanistic and creative work processes, which represent potential advancements never imagined a decade ago. Yet many view digital transformation as not only redefining the experience of work, but also undermining the humanity of organizations. Employees across the spectrum of skill-levels, job classes, and wages also face unprecedented and existential threats to their sense of self-worth, value, and esteem, which collectively embody dignity. Given the onslaught of these technological advances and digital transformation initiatives across industries and sectors, leaders need a set of practical strategies that both protect employees from threats to their dignity as well as proactively cultivate the experience of dignity in their organizations. To meet this growing need, this article presents executives, management teams, HR professionals, and other leaders with evidence-based approaches for protecting and promoting the experience of dignity at work. Grounded in the latest thinking and research on dignity in the workplace, this article offers practical strategies for investing in protective mechanisms (policies and processes) that insulate employees from aspects of work that erode the experience of dignity, as well as proactive mechanisms (practices and behaviors) that cultivate meaningful opportunities to experience dignity at work.}
}
@article{ZENG2026103783,
title = {Hallucination-resistant multimodal content generation through knowledge graph-based reinforcement learning},
journal = {Information Fusion},
volume = {127},
pages = {103783},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103783},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008450},
author = {Liang Zeng and Xinyi Lin and Shanping Yu},
keywords = {Generative artificial intelligence, Knowledge graph, Reinforcement learning, Chain of thought, Hallucination},
abstract = {Multimodal large models exhibit remarkable capabilities in understanding and generating content by integrating diverse types of data, including text and images. However, they face significant challenges related to hallucination in practical applications, where generated content may be inaccurate or misleading. To address these concerns, this study introduces a chain of thought framework for trusted content generation based on knowledge graph reinforcement learning to mitigate hallucinations effectively. This framework incorporates a chain of thought mechanism to enhance model reasoning, thereby improving interpretability. By leveraging a external structured knowledge graph, the framework optimizes the trajectory of the generated content, ensuring that outputs are informed by reliable contextual information. Furthermore, the use of reinforcement learning techniques bolsters the credibility of the generated responses. Experimental evaluations on the VQA-RAD and SLAKE datasets demonstrate that this approach achieves significant improvements in medical visual question answering tasks. This framework not only elevates the quality of content generation but also enhances the interpretability of the model.}
}
@article{SURI2025818,
title = {An artificial intelligence-generated interactive carbon footprint calculator for anaesthesia},
journal = {British Journal of Anaesthesia},
volume = {135},
number = {3},
pages = {818-820},
year = {2025},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2025.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S0007091225003848},
author = {Aditi Suri and Gaurav Sindwani},
keywords = {anaesthesia, artificial intelligence, carbon footprint, climate change, generative artificial intelligence, global warming potential, sustainability}
}
@article{SINGH2025112220,
title = {Cybersecurity enhancement using conditional generative adversarial network with transformer-based conditional variational autoencoder},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112220},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112220},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625022286},
author = {Prithvipal Singh and Sandeep Singh and Gurupdesh Singh and Amritpal Singh},
keywords = {Conditional generative adversarial network, Conditional hybrid network, Cybersecurity enhancement, Generative artificial intelligence, Spatial-temporal attention mechanism, Transformer-based conditional variational AutoEncoder},
abstract = {Since, Artificial Intelligence is highly developing and concatenating into several domains, cybersecurity is an important field of delivering both the advantages and disadvantages. In addition to this, Artificial Intelligence is applied in a wide variety of applications like healthcare sector, content creation and entertainment and financial industries. Therefore, this work finds the efficiency of Artificial Intelligence -oriented cybersecurity metrics in succeeding the digital environment over elevating cyber threats. Here, the developed models consist of two different stages while implementing the model. In the first stage, the essential dataset is assembled from the benchmark data source. These datasets are assembled by using Generative Artificial Intelligence (Gen Artificial Intelligence networks). Consequently, the raw data is given as an input to Conditional Hybrid Network for cybersecurity enhancement. Further, the Transformer-based Conditional Variational Autoencoders with Spatial-temporal Attention are designed for feature extraction that is subjected to the Conditional Generative Adversarial Network for classifying the cyber attacks. Henceforth, the developed network is evaluated and designed with multiple measures. Comparing baseline models, the suggested network obtains higher performance for developing security over cyber networks.}
}
@article{YANG2024100309,
title = {Enhancing python learning with PyTutor: Efficacy of a ChatGPT-Based intelligent tutoring system in programming education},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100309},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100309},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001127},
author = {Albert C.M. Yang and Ji-Yang Lin and Cheng-Yan Lin and Hiroaki Ogata},
keywords = {Generative artificial intelligence, Intelligent tutoring system, Automatic hint generation, Programming education},
abstract = {Programming is regarded as a focal point in the current rapidly evolving educational landscape. To aid learning in this domain, we developed PyTutor, an innovative intelligent tutoring system (ITS) that is designed to assist beginners in Python programming. PyTutor utilizes the ChatGPT model to offer continuous guidance, problem-solving hints, and detailed code explanations. It features a structured hint system for each question, covering pseudocode, cloze, basic, and advanced coding solutions. In our 11-week experiment, we compared 35 students who used PyTutor with 36 students who did not. The results indicated the effectiveness of PyTutor, particularly for students with weak foundations in programming. Those with lower initial knowledge exhibited higher engagement, completion rates, and success rates in in-class and after-class programming exercises. Nevertheless, we observed a potential risk of overreliance on PyTutor among students, which may impede the development of independent problem-solving skills. Thus, we recommend the balanced usage of PyTutor. In conclusion, PyTutor is a valuable ITS in programming education that considerably improves the learning outcomes of beginners. Its tailored approach renders it a promising tool for bridging knowledge gaps and enhancing overall educational experiences in the field of programming.}
}
@article{DAGA2025100846,
title = {Process Knowledge Graphs (PKG): Towards unpacking and repacking AI applications},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100846},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100846},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000325},
author = {Enrico Daga},
keywords = {Knowledge graphs, Prompt engineering, Data science pipelines, Data pipelines documentation, Data pipelines design},
abstract = {In the past years, a new generation of systems has emerged, which apply recent advances in generative Artificial Intelligence (AI) in combination with traditional technologies. Specifically, generative AI is being delegated tasks in natural language or vision understanding within complex hybrid architectures that also include databases, procedural code, and interfaces. Process Knowledge Graphs (PKG) have a long-standing tradition within symbolic AI research. On the one hand, PKGs can play an important role in describing complex, hybrid applications, thus opening the way for addressing fundamental challenges such as explaining and documenting such systems (unpacking). On the other hand, by organising complex processes in simpler building blocks, PKGs can potentially increase accuracy and control over such systems (repacking). In this position paper, we discuss opportunities and challenges of PGRs and their potential role towards a more robust and principled design of AI applications.}
}
@article{HOLTZ20251888,
title = {Bridging Risk and Innovation: Generative AI in Scenario Creation},
journal = {Procedia Computer Science},
volume = {256},
pages = {1888-1895},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.330},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006982},
author = {Niklas Holtz and Sven Wittfoth and Jorge Marx Gómez},
keywords = {Natural Language Processing, Generative Artificial Intelligence, Information Retrieval, Risk Scenarios},
abstract = {Risk management is essential in decision-making, yet traditional methods for creating risk scenarios face challenges in modern, complex business environments. Despite various techniques available, these conventional approaches struggle with managing vast amounts of information. The rapid advancement of Generative AI offers a promising yet underexplored opportunity to transform this process. This paper explores integrating Generative AI to enhance and automate risk scenario generation, bridging the gap between traditional methods and cutting-edge AI. Our approach is twofold: first, we introduce a method to retrieve and structure relevant real-time data related to a risk topic using a combination of sentence embeddings and a Multi-Agent system; second, we derive risk scenarios from this data. By utilizing real-time data, this approach enhances the accuracy and relevance of risk scenarios compared to traditional methods. Furthermore, the automated nature of the process allows scenarios to be continuously monitored and updated over time, ensuring long-term applicability and adaptability for decision-makers.}
}
@article{SAFARI2026103086,
title = {Grid-to-Robot: Deep Wasserstein generative modeling of robot/power grid interaction using hybrid adversarial Residual Networks},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {97},
pages = {103086},
year = {2026},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2025.103086},
url = {https://www.sciencedirect.com/science/article/pii/S0736584525001401},
author = {Ashkan Safari and Hamed Kharrati and Afshin Rahimi and M. Ali Tavallaei},
keywords = {Generative Artificial Intelligence, Deep learning, Robotic manipulator, Renewable energy, Power grid},
abstract = {Smart Manufacturing (SM) is an important factor for driving innovation, enhancing operational efficiency, and increasing sustainable industrial growth in an increasingly competitive and resource-constrained world. However, it faces several challenges related to increasing energy consumption and climate change. The high energy demands of connected devices and robotic manipulators increase the carbon footprint. To resolve this issue, most enterprises are now transitioning to use Renewable Energy Sources (RES), and optimizing their power and energy usage, while holding the process efficient. To fully achieve this transition, a detailed power modeling of the robotic manufacturing system is crucial and, therefore, it is important to investigate this power modeling of the robotic manipulators’ consumption in a Smart Sustainable Manufacturing (SSM) to achieve the best power modeling results and better integrability analytics in optimal power planning of the robotic systems power supply. To this end, this paper presents a deep Generative Artificial Intelligence (GAI)-based modeling of robotic manipulators’ power supply interaction with the power grid, and RES. In the proposed system, which is powered by solar energy and the power grid, a SSM equipped with ten 6-Degrees of Freedom (DoF) robotic manipulators is considered in the presence of Battery Energy Storage Systems (BESSs). Subsequently, a Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) is employed to generate synthetic data for the system alongside the real data, thereby expanding the analytical horizons across varying operational characteristics of the system. Following this, a Residual Networks (ResNet) is developed to comprehensively analyze and predictively model the power consumption of the manipulators and their interactions with the power supply resources. Finally, the proposed hybrid GAI modeling strategy is numerically evaluated across a broad spectrum of Key Performance Indicators (KPIs) (MSE= 10−4, MAE= 3.6×10−3, R2= 99.98%, MARE= 1.97×10−2, RMSPE= 8.83×10−2%, MSRE= 7.8×10−3, RMSRE= 8.84×10−2, MAPE= 1.97×10−2%, and Max Error= 2.04×10−2), where these metrics demonstrate superior performance in power modeling. As a result, the concept of Grid-to-Robot (G2R) is introduced for the first time as a foundation for further advancements in SSM, enhancing sustainability and mitigating negative impacts on climate change while contributing to the development of an advanced manufacturing system.}
}
@article{ZHUANG2025112143,
title = {Inverse structural design with generative and probabilistic autoencoders and diffusion models},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112143},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112143},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625021517},
author = {Bozhou Zhuang and Adrien Gallet and Danny Smyl},
keywords = {Generative artificial intelligence, Structural design, Inverse problem, Continuous beams, Conditional autoencoders, Denoising diffusion models, Tabular data},
abstract = {Traditional structural design is a forward trial-and-error process. Designers need to iterate through different design solutions and conduct structural analysis until the design meets the codes and standards. This study proposes and investigates a generative machine learning (ML) framework for inverse design of continuous beam systems. Three generative ML models, including conditional variational autoencoder (CVAE), conditional autoencoder with maximum likelihood estimation (CAE-MLE), and denoising diffusion models (DDMs) are trained and fine-tuned on the CBeamXP (Continuous Beam Cross-section Predictors) dataset with 1,000,000 beam sections to generate the cross sectional properties. Research results show that CAE-MLE achieves the highest generation accuracy and robustness, while CVAE offers more variability through latent space sampling. DDMs provide controllable generation variability via a stochasticity parameter in the inverse diffusion process. The proposed framework enables efficient generation of multiple design solutions and can potentially accelerate the conceptual design workflows in structural engineering. This work also demonstrated the feasibility toward artificial intelligence (AI)-assisted structural design using generative approaches and tabular datasets.}
}
@article{WUNSCHNAGY2025102909,
title = {From multimodal space to digital multimodal text: Making choices in digital multimodal compositions inspired by museum visits in higher education},
journal = {Computers and Composition},
volume = {75},
pages = {102909},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102909},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000859},
author = {Nóra Wünsch-Nagy},
keywords = {Multimodal literacy, Multimodal texts, Digital multimodal composition, Digital literacy, Critical AI literacy},
abstract = {Access to generative artificial intelligence (AI) has transformed the pedagogical and creative potential of digital practices in multimodal pedagogies, and more specifically, digital multimodal compositions (DMC). This study aims to explore and understand choices in a DMC project from the perspectives of student experiences and the teacher's pedagogical practices including learning design, assessment, and the integration of AI in the context of a semester-long university course. To answer these questions, the case study presents the analysis of the teacher's choices in terms of course design, and scaffolding and assessment practices. It also explores the challenges students face through the analysis of their pre- and post-course questionnaires, digital multimodal composition artefacts and reflective notes. The study makes suggestions in terms of pedagogical sequences to support students’ choice-making, and the integration of semiotic software and generative AI tools into DMC projects.}
}
@article{SUN2026105271,
title = {When cutting edge meets silver tongue: Understanding the word-of-machine effect on travel decisions},
journal = {Tourism Management},
volume = {112},
pages = {105271},
year = {2026},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105271},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001414},
author = {Danni Sun and IpKin Anthony Wong and Xiling Xiong and Shina Li},
keywords = {Artificial intelligence, Word-of-machine, Persuasion strategy, Travel recommendation},
abstract = {The rapid development of generative artificial intelligence (GenAI) has fostered scholarly discussions on its persuasive capabilities when compared to traditional word-of-mouth recommendations. This study explores the “word-of-machine” effect by comparing AI-based recommendations with human-generated ones to assess their impact on user perceptions. Drawing from dual-system theory and the persuasion knowledge model, this research examines the interplay among persuasion strategies (informational vs. narrative) and three persuasion boundary conditions: recommender types (AI vs. human), AI attributes (functional vs. social), AI hallucination reminder (present vs. absent), and large language model (LLM) type (tourism-specific vs. generic). Seven studies indicate that AI recommenders, especially those perceived as functional and employing informational strategies, enhance the perceived usefulness of recommendations. Furthermore, the inclusion of an AI hallucination reminder or tourism-specific LLM acts as boundary conditions, moderating the persuasiveness of informational AI recommendations. Taken together, this research offers novel insights into AI-driven persuasion, contributing to the understanding of user responses to AI-generated content.}
}
@article{FERRARO2024549,
title = {The paradoxes of generative AI-enabled customer service: A guide for managers},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {549-559},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000582},
author = {Carla Ferraro and Vlad Demsar and Sean Sands and Mariluz Restrepo and Colin Campbell},
keywords = {Artificial intelligence, Generative AI, AI chatbots, Customer service, Customer support},
abstract = {Generative artificial intelligence (GenAI) presents a disruptive innovation for brands and society, and the power of which is still yet to be realized. In the context of customer service, gen AI affords companies new possibilities to communicate, connect, and engage customers. This article draws on scholarly research and consultation with customer service leaders to present and discuss the possibilities for GenAI in the context of customer service, specifically GenAI chatbots. Importantly, this article presents potential paradoxes of GenAI-enabled customer service, adding to the debate about the role and impact of GenAI for brands. Specifically, we present six paradoxes of GenAI customer service: (1) connected yet isolated, (2) lower cost yet higher price, (3) higher quality yet less empathy, (4) satisfied yet frustrated, (5) personalized yet intrusive, and (6) powerful yet vulnerable. For each paradox, we suggest brand response strategies to mitigate downside and manage potential upside.}
}
@article{HERNANDEZRAMIREZ2024414,
title = {The Future End of Design Work: A Critical Overview of Managerialism, Generative AI, and the Nature of Knowledge Work, and Why Craft Remains Relevant},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {414-440},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000960},
author = {Rodrigo Hernández-Ramírez and João Batalheiro Ferreira},
keywords = {creativity, design work, generative artificial intelligence (GenAI), knowledge work, managerialism},
abstract = {This article examines the transformation of design work under the influence of managerialism and the rise of Generative Artificial Intelligence (GenAI). Drawing on John Maynard Keynes’s projections of technological unemployment and the evolving nature of work, it argues that despite advancements in automation, work has not diminished but rather devalued. Design, understood as a type of knowledge work, faces an apparent existential crisis. GenAI grows adept at mimicking the output of creative processes. The article explores how the fear of the end of design work fueled by the rise of GenAI is rooted in a misunderstanding of design work. This misunderstanding is driven by managerialism—an ideology that prioritizes efficiency and quantifiable outcomes over the intrinsic value of work. Managerialism seeks to instrumentalize and automate design, turning it into a controllable procedure to generate quantifiable creative outputs. The article argues why design work cannot be turned into a procedure and automated using GenAI. Advocates of these systems claim they enhance productivity and open new opportunities. However, evidence so far shows that flawed GenAI models produce disappointing outcomes while operating at a significant environmental cost. The article concludes by arguing for a robust theory of design—one that acknowledges the unique ontological and epistemic boundaries of design work and underscores why design cannot be reduced to a procedural output.}
}
@article{GUDEPU2025111237,
title = {GEN-DRIFT: Generative AI-driven drift handling for beyond 5G networks},
journal = {Computer Networks},
volume = {263},
pages = {111237},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111237},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625002051},
author = {Venkateswarlu Gudepu and Bhargav Chirumamilla and Venkatarami Reddy Chintapalli and Piero Castoldi and Luca Valcarenghi and Bheemarjuna Reddy Tamma and Koteswararao Kondepu},
keywords = {Beyond fifth-generation (B5G) networks, Generative Artificial Intelligence (Gen-AI), Artificial Intelligence and Machine Learning (AI/ML), Drift detection and adaptation, Service Level Agreements (SLAs)},
abstract = {Beyond fifth-generation (B5G) networks enable high data rates, low latency, and massive machine communications, driving digital transformation across sectors. The integration of Artificial Intelligence and Machine Learning (AI/ML) technologies plays a vital role in enhancing the performance and efficiency of B5G networks. However, the dynamic and ever-evolving service demands associated with B5G use cases lead to the occurrence of drift, which can significantly degrade the performance of AI/ML models. Drift occurrence often results in violations of Service Level Agreements (SLAs) and over- or under-provisioning of resources, ultimately impacting user experience and network reliability. Drift detection and adaptation are essential for addressing the dynamic service demands of B5G networks. Existing threshold approach and various other frameworks, have significant limitations, — SLA violations from delayed drift detection and inefficient resource management due to frequent retraining. This paper proposes a drift handling framework that determines drift promptly after its occurrence using Generative Artificial Intelligence (Gen-AI). The proposed Gen-AI framework is evaluated for a Quality of Service Prediction use case on the Open Radio Access Network (O-RAN) Software Community (OSC) platform and compared to the existing threshold and other frameworks. Also, a real-time dataset from the Colosseum testbed is considered to evaluate the Network Slicing (NS) use case with the proposed Gen-AI framework for drift handling. The results demonstrate that the proposed Gen-AI framework leverages both Generative Adversarial Network (GAN) and Variational AutoEncoder (VAE), significantly enhances drift detection and adaptation time in B5G networks. Specifically, in the QoS prediction use case, GAN achieves 98% drift detection accuracy, while the VAE achieves 95% , compared to 85% for the classifier framework, 25% for the threshold-based approach. In addition, a similar kind of results is observed in case of the network slicing use case. These results highlight the effectiveness of the proposed Gen-AI framework in proactively handling drift with reduced detection and adaptation time, making it a promising solution for B5G networks.}
}
@article{FLORIDOBENITEZ2025106311,
title = {Towards a new generation of smart tourism cities–GenAI-enabled aerotainment},
journal = {Cities},
volume = {167},
pages = {106311},
year = {2025},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106311},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125006122},
author = {Lázaro Florido-Benítez and J. Andres Coca-Stefaniak},
keywords = {Artificial intelligence, Smart city marketing, Airports, Smart tourism, Digital twins},
abstract = {This article adopts a futures-based approach to explore the marketing of smart cities as tourism destinations with a specific focus on the role generative artificial intelligence (GenAI) can play in this process. Building on the novel concept of aerotainment, which advocates a holistic approach to urban destination management merging airports, theme parks, regional visitor attractions and tourism cities, the future impacts of GenAI on the planning and management of visitor experiences are discussed critically. A novel framework for the development of GenAI-enabled smart tourism cities - the urban tourism destination pyramid - is posited and discussed, including the use of tools such as digital twins and GenAI to monitor and predict future customer behaviour.}
}
@article{NGUYEN2025105463,
title = {How does GenAI reinforce higher education students' digital entrepreneurship? The curvilinear roles of perceived digital entrepreneurial desirability and feasibility},
journal = {Acta Psychologica},
volume = {259},
pages = {105463},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105463},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825007760},
author = {Thi Thu Thuy Nguyen and Cong Doanh Duong and Ngoc Huyen Nguyen and Huong Thao Pham and Thi Phuong Thu Nguyen and Van Tuan Le and Ngoc Duong Nguyen},
keywords = {Incorporation of GenAI, Infusion of GenAI, Digital entrepreneurial intentions, Entrepreneurial event model, Polynomial regression, Response surface analysis},
abstract = {Generative Artificial Intelligence (GenAI) is reshaping digital entrepreneurship by altering how individuals perceive and pursue new ventures. This study integrates GenAI adoption into the Entrepreneurial Event Model to examine its influence on perceived desirability, feasibility, and entrepreneurial intention. Using stratified random sampling, data from 1061 Vietnamese university students were analyzed via polynomial regression and response surface analysis. The findings confirm that both the incorporation and infusion of GenAI enhance entrepreneurial intentions, primarily by increasing desirability and feasibility. Cognitive alignment between desirability and feasibility emerged as critical: intentions peak when both are high and congruent, while misalignment dampens commitment. This study contributes to entrepreneurial intention theory by introducing GenAI as a cognitive trigger and uncovering curvilinear effects in cognitive evaluations. Practical implications underscore the need for AI literacy, the structured integration of AI into entrepreneurship education, and supportive ecosystems for AI-driven startups.}
}
@article{FOUNG2024100250,
title = {Reinventing assessments with ChatGPT and other online tools: Opportunities for GenAI-empowered assessment practices},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100250},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100250},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000535},
author = {Dennis Foung and Linda Lin and Julia Chen},
keywords = {GenAI, Online tools, Language learning, Assessments},
abstract = {The recent emergence of generative artificial intelligence (GenAI) tools, such as ChatGPT, has brought profound changes to higher education. While many studies have examined the potential use of ChatGPT in teaching and learning, few have explored the opportunities to develop assessments that facilitate the use of multiple technological innovations (i.e. traditional AI and GenAI tools). We conducted qualitative research to address this gap. The assessments of an elective English course in Hong Kong were re-designed to incorporate GenAI and other tools. Students were asked to employ and reflect on their use of these tools for their writing assessments. We analyzed the written reflections of 74 students and conducted focus group interviews with 28 students. The results suggest that the students possess an acumen for choosing the appropriate online tools for specific purposes. When they can choose freely, they develop skills that allow them to evaluate and select between traditional AI and GenAI tools when appropriate. Some students mentioned concerns with the different features of the free and premium versions. The results of this study call for (1) assessment practices that allow the flexibility to use different AI tools and (2) the equitable use of various AI tools.}
}
@article{FELICETTI2024100545,
title = {Artificial intelligence and project management: An empirical investigation on the appropriation of generative Chatbots by project managers},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100545},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000842},
author = {Alberto Michele Felicetti and Antonio Cimino and Alberto Mazzoleni and Salvatore Ammirato},
keywords = {Project managers, Generative artificial intelligence, Chatgpt, Appropriation Theory, Structural Equation Modeling},
abstract = {The integration of generative AI tools, such as chatbots, into project management is revolutionizing the field. This paper explores how project managers are adopting and adapting these tools, specifically focusing on ChatGPT, for enhanced project management. Using Adaptive Structuration Theory, the study examines project managers' appropriation of generative AI. It considers factors like Innovation Attitude, Peer Influence, and Task-Technology Fit, employing a survey of Italian project managers. The approach adopted to analyze data is based on Partial Least Square - Structural Equation Modeling. The research confirms the significance of the hypothesized antecedents in AI tool appropriation. Innovation Attitude and Peer Influence are shown to positively impact the creative and 'unfaithful' use of AI in project management. Task-Technology Fit is crucial for effective AI integration, impacting both creative behaviour and unfaithful appropriation. The study highlights the role of an innovative mindset, peer dynamics, and task compatibility in the effective use of AI tools in project management. It suggests potential areas for future research, including exploring cultural and organizational contexts and the rapid evolution of AI technologies.}
}
@article{CAMPBELL2025,
title = {The AI intelligence playbook: Decoding GenAI capabilities for strategic advantage},
journal = {Business Horizons},
year = {2025},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2025.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0007681325001405},
author = {Colin Campbell and Sean Sands and Lucas Whittaker and Alexis Mavrommatis},
keywords = {Generative AI, Creative intelligence, Human-AI collaboration, Intelligence management},
abstract = {The rapid adoption of Generative Artificial Intelligence (GenAI) across industries has created new opportunities for efficiency, creativity, and innovation. At the same time, it has introduced confusion about what GenAI is capable of, how it should be used, and where it fits within existing business structures. While GenAI is often treated as a singular capability, we argue that it is better understood as a collection of distinct intelligences that vary in maturity and application. Drawing from Gardner’s Multiple Intelligences theory, this paper introduces a taxonomy of GenAI intelligences and maps how they relate to current and emerging use cases. Leveraging this taxonomy, we then offer practical guidance to help businesses identify where GenAI can provide value today and where it remains limited. We propose that companies adopt an intelligence management approach that treats GenAI not as a generic tool but as a dynamic and evolving collaborator. By understanding the specific capabilities of different AI intelligences, business leaders can align GenAI adoption with strategic goals, communicate its role more clearly, and build long-term competitive advantage.}
}
@article{DAI2024292,
title = {Facilitating Students’ Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
journal = {Procedia CIRP},
volume = {128},
pages = {292-297},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006735},
author = {Yun Dai and Ziyan Lin and Ang Liu},
keywords = {help-seeking, peer support, learning analytics, design thinking, engineering education},
abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year’s course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students’ focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students’ design thinking and collaborative design.}
}
@article{ACOSTAENRIQUEZ2024100320,
title = {Exploring attitudes toward ChatGPT among college students: An empirical analysis of cognitive, affective, and behavioral components using path analysis},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100320},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100320},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001231},
author = {Benicio Gonzalo Acosta-Enriquez and Carmen Graciela {Arbulú Pérez Vargas} and Olger {Huamaní Jordan} and Marco Agustín {Arbulú Ballesteros} and Ana Elizabeth {Paredes Morales}},
keywords = {ChatGPT, University students, Attitudes, Cognitive component, Affective component, Behavioral component, Artificial intelligence, Higher education},
abstract = {The advent of generative artificial intelligence (AI) applications, such as ChatGPT, has significantly impacted various aspects of human life, including higher education. This study explores university students' attitudes toward ChatGPT, focusing on the cognitive, affective, and behavioral components of attitudes, on the basis of Mitcham's philosophical framework of attitudes toward technology. A total of 595 university students from six public and private universities in northern Peru participated in an online survey. The results of the structural equation modeling (SEM) analysis revealed that the affective component (β = 0.672∗∗∗) and the cognitive component (β = 0.260∗∗) positively influence the behavioral component of students' attitudes when ChatGPT is used. Moreover, the cognitive component (β = 0.931∗∗∗) positively influences the affective component of students' attitudes. However, gender and age did not have significant moderating effects on the relationships between the cognitive and affective components and the behavioral component. The discussion highlights that these findings contribute to understanding the psychological mechanisms underlying the adoption of ChatGPT in educational settings and offer valuable guidance for implementing this technology in teaching and learning processes. In conclusion, this study represents a significant advancement in comprehending attitudes toward generative AI technologies in higher education and opens new avenues for future research in this field.}
}
@article{HUANG2025100424,
title = {Academic cheating with generative AI: Exploring a moral extension of the theory of planned behavior},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100424},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100424},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000645},
author = {Dongpeng Huang and Nicole Hash and James J. Cummings and Kelsey Prena},
keywords = {Academic cheating, Generative AI, College students, Modified theory of planned behavior},
abstract = {As generative artificial intelligence (GenAI) tools become increasingly integrated into educational environments, concerns have emerged about their potential to facilitate academic dishonesty. Drawing on the modified theory of planned behavior, this study aimed to understand undergraduate students’ academic cheating behaviors using GenAI. The study conducted a mixed-method approach, utilizing focus groups and polls to gather insights from 25 undergraduate students enrolled in a course that incorporated GenAI into its pedagogical design in the United States. The results revealed that the integration of GenAI into higher education is perceived as inevitable. While students clearly recognized overt cheating, opinions varied regarding subtle forms of dishonesty and the effectiveness of formal deterrents. Peer influence and personal ethics were found to strongly shape cheating behaviors, with class policies enforced by instructors exerting a greater influence on student cheating behavior with GenAI than broader institutional policies. These insights can assist educators and policymakers in managing the challenges and opportunities presented by the integration of GenAI technologies into education.}
}
@article{RAUSCH202513,
title = {Towards effective continued pre-training of EU institutional LLMs on EuroHPC supercomputers},
journal = {Procedia Computer Science},
volume = {255},
pages = {13-22},
year = {2025},
note = {Proceedings of the Second EuroHPC user day},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.256},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006179},
author = {Ilja Rausch and Bhavani Bhaskar and Anna Safont-Andreu and Hans Ewetz and David Kolovratnik and Csaba Oravecz and Markus Runonen},
keywords = {generative artificial intelligence, large language models, distributed computing},
abstract = {Large Language Models (LLMs) are a significant advancement in artificial intelligence (AI), capable of learning from vast textual datasets and excelling in tasks such as text generation and translation. However, the current general LLMs often do not meet the specific requirements of the public sector and other entities in Europe due to various limitations, including in particular language coverage gaps. In response, the European Commission's Directorate-General for Translation (DGT), in the context of its partnership with the Directorate-General for Communications Networks, Content and Technology (DG CONNECT) under the Digital Europe programme, aims to leverage its high-quality multilingual data coming from all the European Union (EU) institutions to contribute to the European ecosystem of LLMs through continued pre-training of open-source models. This paper presents these ongoing efforts on the supercomputers provided by the European High Performance Computing Joint Undertaking (EuroHPC JU), with a focus on adapting Meta ’s open-weight LLMs to European linguistic diversity. To this end we leverage the datasets of the European Advanced Multilingual Information System (EURAMIS), a unique and voluminous corpus of multilingual text from all EU institutions. Our approach utilizes state-of-the-art AI tools, including Hugging Face libraries and DeepSpeed ’s ZeRO-3 data parallelism. We report on the results of our experiments, including the human evaluation of our models and various automated benchmarks such as ARC and HellaSwag, and machine translation tasks. Our findings demonstrate the potential of continued pre-training for enhancing the multilingual capabilities of open source LLMs for Europe.}
}
@article{WEI2025105356,
title = {Enhancing pre-service teachers' reflective thinking skills through generative AI-assisted digital storytelling creation: A three-dimensional framework analysis},
journal = {Computers & Education},
volume = {235},
pages = {105356},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105356},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525001241},
author = {Xiaodong Wei and Lei Wang and Tiffany A. Koszalka and Lap-Kei Lee and Ruixue Liu},
keywords = {Improving classroom teaching, Media in education, Teacher professional development, Teaching/learning strategies, 21st century abilities},
abstract = {Developing reflective thinking skills (RTS) in pre-service teachers remains a challenge in teacher education, particularly in the context of integrating emerging technologies. While digital storytelling (DST) has shown promise in fostering reflective practice, traditional methods often present technical barriers that hinder deeper reflection. Few studies have explored how generative artificial intelligence (GAI) tools can support RTS during DST creation. This study addresses these gaps by adopting a three-dimensional framework of RTS, which included the time of reflection, objects of reflection, and levels of reflection, to guide and assess the impact of GAI-assisted DST creation on pre-service teachers' reflective patterns. Employing a post-test quasi-experimental design, eighty pre-service teachers were divided into two groups: an experimental group utilizing GAI tools (e.g., ChatGPT, Midjourney, Runway) for DST creation, and a control group utilizing traditional methods. Results revealed that the experimental group significantly improved RTS in time, objects, and levels of reflection. Pre-service teachers in the experimental group reflected more on problem definition and solution generation during the design stages of reflection time. Regarding reflection objects, the experimental group exhibited significantly higher reflection frequencies across self, artifacts, and circumstances aspects. Additionally, pre-service teachers in experimental group demonstrated significantly higher reflection frequencies at all levels—single-loop, double-loop, and triple-loop—compared to the control group. Single-loop reflection was the most common, while triple-loop reflection was the least frequent in both groups. These findings underline GAI's potential to scaffold RTS and enhance the DST creation process, offering valuable insights for integrating GAI into teacher education to foster deeper reflective practice.}
}
@article{RAHIM2025101206,
title = {Harnessing generative AI: Reviewing applications, challenges, and solutions for out-of-school children in developing regions},
journal = {Sustainable Futures},
volume = {10},
pages = {101206},
year = {2025},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2025.101206},
url = {https://www.sciencedirect.com/science/article/pii/S2666188825007683},
author = {Sabit Rahim and Gul Sahar and Gul Jabeen and Sabila Khatoon and Dil Angaiz},
keywords = {AI, Generative AI, Out of school children, ChatGPT, AI integration},
abstract = {Out of school children in Gilgit-Baltistan (GB) face significant challenges due to geographical isolation, inadequate infrastructure, harsh weather, lack of schools, cultural barriers, and socio-economic constraints, especially for girls. Generative AI(GAI) has potential to bridge these gaps with adaptive, engaging and aligned curriculum content to support learning specially for out-of-school children. It enables adaptable access to education through visual, text and audio format in remote and underserved mountainous areas. This analysis includes key applications, challenges and solutions of GAI in education for out of school from an initial pool of 90 studies sourced from scholarly databases such as IEEE Xplore, Science Direct, and Google Scholar (different published included). After exhaustive screening, 30 major papers were reviewed to evaluate the potential of GAI in out-of-school children’s education. The findings highlight the significant role of Generative Artificial Intelligence (GAI) in enabling inclusive education by offering tailored content through Learning Management Systems (LMS). A theoretical model is proposed integrating GAI, LMS, adaptive and data-driven methodologies (A&DM), operational and ethical safety framework, implementation strategy, team structure, and financial considerations. Besides offering content, LMS gathers information to analyze individual needs and create appropriate instructional material. Local community facilitators are essential in reinforcing learning, bridging digital divides, and ensuring a supportive education atmosphere. The study addresses strengths, limitations, and suitability associated with GAI integration, such as integrity in assessment, critical thinking, potential disruptions, data reliability, and human interaction. This study shows GAI's potential in access, inclusivity, and engagement through strategic partnerships, adaptive approaches, and targeted efforts.}
}
@article{FAHRNI2025105150,
title = {Teachers' practices in the use of digital technology to promote students’ self-regulated learning and metacognition: A systematic review},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105150},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105150},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002276},
author = {Désirée Delia Diana Fahrni and Glena Iten and Doreen Prasse and Tina Hascher},
keywords = {Self-regulated learning, Metacognition, Digital technology, Teachers},
abstract = {This systematic review examined 45 studies published between January 1986 and January 2025 on how K-12 school teachers promote self-regulated learning (SRL) and metacognition using digital technology. We classified these instructional practices according to instruction, coaching, scaffolding, and feedback. Digital tools such as feedback systems, dashboards, or generative artificial intelligence (GenAI) were found to enhance SRL and metacognition, complementing traditional analog strategies. The findings suggest that an appropriate combination of digital and analog promotion increases the effectiveness of SRL and metacognitive development. Future research should explore the dynamic interplay among teachers, learners, and technology to further optimize SRL promotion.}
}
@article{BAI2025105242,
title = {Ethical perceptions of generative AI use and employee work outcomes: Role of moral rumination and AI-supported autonomy},
journal = {Tourism Management},
volume = {111},
pages = {105242},
year = {2025},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2025.105242},
url = {https://www.sciencedirect.com/science/article/pii/S0261517725001128},
author = {Jing Yi Bai and IpKin Anthony Wong and Tzung Cheng T.C. Huan and Fevzi Okumus and Aliana Man Wai Leong},
keywords = {Ethical perceptions, Generative AI use, Moral rumination, AI-Supported autonomy, Ethical voice behavior, Service innovative behavior},
abstract = {Despite the numerous ethical challenges in relation to the use of generative artificial intelligence (GAI), our understanding of whether ethical perceptions of using GAI influence employees' work-related outcomes remains limited. Drawing on cognitive rumination theory, we claim that moral rumination mediates the relationship between ethical perceptions of GAI use and employee work-related outcomes. AI-supported autonomy (AI-SA) moderates this relationship. We use two independent studies to test the proposed model: an experiment (Study 1) and a field survey study (Study 2). The research findings suggest that employees’ ethical perceptions of GAI use lead to moral rumination, which impairs their service innovative behavior and ethical voice behavior. Moreover, the negative mediating effects of moral rumination can be strengthened when employees have lower levels of AI-SA. Our research advances the understanding of whether and how GAI use generates unintended consequences through an ethical pathway.}
}
@article{CUSSENOT2025871,
title = {Eliciting the Impact of Metformin and Statins on Prostate Cancer Outcomes from a Real-life National Database Analysis},
journal = {European Urology Oncology},
volume = {8},
number = {4},
pages = {871-874},
year = {2025},
issn = {2588-9311},
doi = {https://doi.org/10.1016/j.euo.2025.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S258893112500121X},
author = {Olivier Cussenot and Yoann Taille and Jean-Jacques Portal and Géraldine Cancel-Tassin and Morgan Rouprêt and Alexandre {de la Taille} and Guillaume Ploussard and Romain Mathieu and Eric Vicaut},
keywords = {Prostate cancer, Statins, Metformin, Management, Mortality, Castration, Prostatectomy, Real-life data, Causal analysis, Bayesian network},
abstract = {Several large analyses have revealed contradictory results regarding the association between prostate cancer (PC) survival and the use of statins prescribed for prevention of dyslipidaemia or atherosclerosis complications, or of metformin prescribed for type 2 diabetes (T2D). Using data collected between 2006 and 2018 in French national health databases for 521 052 men with PC and 1 827 345 men without PC, we evaluated current evidence regarding overall survival for men with PC according to statin and/or metformin use. The highest mortality was observed in PC patients exposed to both statins and metformin (hazard ratio [HR] 2.29, 95% confidence interval [CI] 2.25–2.33). However, for patients whose first PC treatment was androgen deprivation therapy, a protective effect was observed for statin alone exposure (HR 0.91, 95% CI 0.88–0.93) and combined statin and metformin exposure (HR 0.86, 95% CI 0.85–0.87), whereas men with metformin exposure alone had higher mortality (HR 1.07, 95% CI 1.03–1.11) in comparison to non-users. This protective effect of statins was not observed for PC patients treated with radical prostatectomy. The result was confirmed using causal analysis in a Bayesian network, followed by semantic elicitation using generative artificial intelligence that compiles web-based human knowledge and dedicated literature.}
}
@article{UPADHYAY2024221,
title = {Generative AI and training employees with special needs},
journal = {Strategic HR Review},
volume = {23},
number = {6},
pages = {221-224},
year = {2024},
issn = {1475-4398},
doi = {https://doi.org/10.1108/SHR-05-2024-0039},
url = {https://www.sciencedirect.com/science/article/pii/S1475439824000163},
author = {Ashwani Kumar Upadhyay},
keywords = {Artificial intelligence, Diversity, Generative AI, Inclusion, Special needs, Training and development},
abstract = {Purpose
The viewpoint paper aims to highlight the assistive role that Generative artificial intelligence (Gen AI) can play in the design of learning and development programs for employees with special needs. The article discusses the challenges, benefits and reasons why Gen AI should be used to manage diversity, equity and inclusion by creating personalized and customized training and development programs.
Design/methodology/approach
The viewpoint paper is based on reviewing articles and videos on the application of Gen AI in learning and development.
Findings
Gen AI offers immense opportunities to design personalized learning solutions for employees with special needs due to disability that can be physical or cognitive. The AI-based solutions support special learners by customizing assistive technology-based solutions and content based on the level of disability and need of the learner. This paper also highlights the importance of synergy between the training department, government and technology solution providers.
Originality/value
The viewpoint paper fills in an important gap by discussing the role that Gen AI can play by facilitating the learning and development of employees with unique skills.}
}
@article{JI2025105313,
title = {Stop-and-go wave super-resolution reconstruction via iterative refinement},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {180},
pages = {105313},
year = {2025},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2025.105313},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X25003171},
author = {Junyi Ji and Alex Richardson and Derek Gloudemans and Gergely Zachár and Matthew Nice and William Barbour and Jonathan Sprinkle and Benedetto Piccoli and Daniel B. Work},
keywords = {Stop-and-go waves, Super resolution, Generative artificial intelligence, Diffusion model},
abstract = {Stop-and-go waves are a fundamental phenomenon in freeway traffic flow, contributing to inefficiencies, crashes, and emissions. Recent advancements in high-fidelity sensor technologies have improved the ability to capture detailed traffic dynamics, yet such systems remain scarce and costly. In contrast, conventional traffic sensors are widely deployed but suffer from relatively coarse-grain data resolution, potentially impeding accurate analysis of stop-and-go waves. This article explores whether generative AI models can enhance the resolution of conventional traffic sensor to approximate the quality of high-fidelity observations. We present a novel approach using a conditional diffusion denoising model, designed to reconstruct fine-grained traffic speed field from radar-based conventional sensors via iterative refinement. We introduce a new dataset, WaveX (Ji et al., 2025a), comprising 132 hours of data from both low and high-fidelity sensor systems, totaling over 2 million vehicle miles traveled. Our approach leverages this dataset to formulate the traffic state refinement problem as a spatio-temporal super-resolution task. We demonstrate that our model can effectively reproduce the patterns of stop-and-go waves, achieving high accuracy in capturing these critical traffic dynamics. Our results show promising advancements in traffic state refinement, offering a cost-effective way to leverage existing low spatio-temporal resolution sensor networks for improved traffic analysis and management. We also open-source our dataset, trained model and code to enable further research and applications.}
}
@article{BLAND2025,
title = {Enhancing Medical Student Engagement Through Cinematic Clinical Narratives: Multimodal Generative AI–Based Mixed Methods Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/63865},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000017},
author = {Tyler Bland},
keywords = {artificial intelligence, cinematic clinical narratives, cinemeducation, medical education, narrative learning, AI, medical student, pharmacology, preclinical education, long-term retention, AI tools, GPT-4, image, applicability},
abstract = {Background
Medical students often struggle to engage with and retain complex pharmacology topics during their preclinical education. Traditional teaching methods can lead to passive learning and poor long-term retention of critical concepts.
Objective
This study aims to enhance the teaching of clinical pharmacology in medical school by using a multimodal generative artificial intelligence (genAI) approach to create compelling, cinematic clinical narratives (CCNs).
Methods
We transformed a standard clinical case into an engaging, interactive multimedia experience called “Shattered Slippers.” This CCN used various genAI tools for content creation: GPT-4 for developing the storyline, Leonardo.ai and Stable Diffusion for generating images, Eleven Labs for creating audio narrations, and Suno for composing a theme song. The CCN integrated narrative styles and pop culture references to enhance student engagement. It was applied in teaching first-year medical students about immune system pharmacology. Student responses were assessed through the Situational Interest Survey for Multimedia and examination performance. The target audience comprised first-year medical students (n=40), with 18 responding to the Situational Interest Survey for Multimedia survey (n=18).
Results
The study revealed a marked preference for the genAI-enhanced CCNs over traditional teaching methods. Key findings include the majority of surveyed students preferring the CCN over traditional clinical cases (14/18), as well as high average scores for triggered situational interest (mean 4.58, SD 0.53), maintained interest (mean 4.40, SD 0.53), maintained-feeling interest (mean 4.38, SD 0.51), and maintained-value interest (mean 4.42, SD 0.54). Students achieved an average score of 88% on examination questions related to the CCN material, indicating successful learning and retention. Qualitative feedback highlighted increased engagement, improved recall, and appreciation for the narrative style and pop culture references.
Conclusions
This study demonstrates the potential of using a multimodal genAI-driven approach to create CCNs in medical education. The “Shattered Slippers” case effectively enhanced student engagement and promoted knowledge retention in complex pharmacological topics. This innovative method suggests a novel direction for curriculum development that could improve learning outcomes and student satisfaction in medical education. Future research should explore the long-term retention of knowledge and the applicability of learned material in clinical settings, as well as the potential for broader implementation of this approach across various medical education contexts.}
}
@article{DODSON2025390,
title = {Nursing students' AI literacy and ethical understanding of AI in nursing education},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {390-394},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002033},
author = {Tracy M. Dodson and Kimberley Thompson-Hairston and Janet M. Reed},
keywords = {AI literacy, Generative AI, Nursing education, Higher academia},
abstract = {Background
Generative artificial intelligence (GAI) offers opportunities to enhance learning in nursing education yet raises concerns about academic integrity and critical thinking. Limited research exists on nursing students' ethical understanding and prior GAI exposure.
Aim
To explore freshman nursing students’ understanding of ethical versus unethical uses of GAI, their foundational AI literacy, and prior exposure to AI training.
Methods
A cross-sectional descriptive study was conducted using a researcher-developed survey administered to 119 freshman BSN students at a large Midwestern university. The survey assessed knowledge of GAI ethics, GAI use, and perceptions of university-led GAI training.
Results
Students demonstrated a strong ability to differentiate between ethical and unethical uses of GAI (93 % accuracy). However, gaps were noted in understanding when AI-generated content crosses into academic dishonesty. Many students reported limited AI training and expressed strong interest in AI learning modules.
Conclusions
Freshman nursing students are eager to use GAI responsibly but lack foundational training. AI literacy education is essential to support ethical decision-making, preserve academic integrity, and prepare students for responsible AI use in nursing practice.}
}
@article{TAN2025102918,
title = {Voice in AI-assisted multimodal texts: What do readers pay attention to?},
journal = {Computers and Composition},
volume = {75},
pages = {102918},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2025.102918},
url = {https://www.sciencedirect.com/science/article/pii/S8755461525000052},
author = {Xiao Tan and Wei Xu and Chaoran Wang},
keywords = {Voice, Multimodal writing, Photo essay, GenAI-assisted writing, dialogic perspective},
abstract = {Despite the extensive research on voice in traditional text-based writing, there is a notable lack of empirical studies examining this concept within multimodal writing contexts. The shift towards multimodality in writing research, coupled with the rise of Generative Artificial Intelligence (GenAI) in content creation, calls for a deeper understanding of how voice is perceived by readers beyond traditional writing contexts. This mixed-method study addresses this gap by exploring voice construction in GenAI-assisted photo essays from a dialogic perspective. In this study, we invited writing teachers to rank five student-produced photo essays according to their perceived voice strengths and analyzed the rankings using Kendall's Coefficient Concordance. The statistical analysis shows a weak agreement (W = 0.27) among raters, suggesting that voice is perceived quite diversely. The follow-up interviews with six focal raters reveal that they could agree on the importance of having unique ideas and angles in writing, keeping writing coherent and focused, using appropriate quotations, and incorporating images to enhance storytelling. However, opinions diverge regarding using primary and secondary texts, adopting academic discourse features, and including AI-generated images. The study adds to scholarly conversation of voice in composition studies and suggests that divergence in perceiving voice could be leveraged to fuel the discussion about voice in writing pedagogy.}
}
@article{ZHANG2025129645,
title = {A comprehensive overview of Generative AI (GAI): Technologies, applications, and challenges},
journal = {Neurocomputing},
volume = {632},
pages = {129645},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129645},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225003170},
author = {Zhijun Zhang and Jian Zhang and Xiaodong Zhang and Weijian Mai},
keywords = {Generative artificial intelligence, Content generation, Pre-trained language models},
abstract = {Generative Artificial Intelligence (GAI) represents a forefront research domain and demonstrates the ability to generate innovative and creative content spanning text, images, audio, videos, and other technological forms. Recent breakthroughs in GAI, exemplified by remarkable products like ChatGPT and stable diffusion, have garnered significant attention and hold immense potential to shape the trajectory of societal development. This paper undertakes a comprehensive analysis of the current capabilities and limitations of GAI while exploring optimal strategies for its future application. Specifically, we provide an extensive overview of technical approaches employed in GAI, encompassing text, images, videos, audio, and multi-modal generation models. Furthermore, we summarize the commonly utilized training datasets and evaluation benchmarks of various modalities. These benchmarks serve as integral components for assessing the performance of GAI models. Subsequently, we delve into the current applications and future prospects of GAI across various fields. Finally, we discuss the challenges inherent in GAI and outline prospective directions for future advancements in the field, with the intention of offering valuable insights and inspiration to researchers.}
}
@article{NAHEED20251492,
title = {Analysing the Capabilities of Generative AI to Determine Its Role in Customer Experience Management for Effective Product Development},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {1492-1497},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.251},
url = {https://www.sciencedirect.com/science/article/pii/S2405896325010122},
author = {Saqib Naheed and Roberto Pinto and Fabiana Pirola},
keywords = {Customer experience management (CEM), Artificial intelligence (AI), Generative artificial intelligence (GAI), Customer experience (CX), Product management co-creation, Personalization},
abstract = {Customer expectations are no longer confined to product quality or price offerings. Modern firms now emphasize the overall customer experience associated with acquiring a product or service, recognizing its significance in shaping customer satisfaction and loyalty. Since the technological scenario is changing rapidly, with generative AI (GAI) enhancing the capabilities of AI, the proposed research intends to examine the future transformational role and capabilities of GAI in customer experience management (CEM) for effective product management. A comprehensive analysis of AI and GAI’s capabilities was conducted to identify the impact areas of traditional AI that are enhanced by GAI. The framework further mapped the functional enhancements offered by GAI across the core elements of CEM identified in the literature. This work highlighted GAI’s capabilities to enhance customer understanding, experience design and experience measurement while also addressing its potentiality within the context of effective product management.}
}
@article{JIANG2025103870,
title = {Enabling critical digital literacies through GenAI-assisted multimodal composing: A longitudinal inquiry of an ethnic minority english teacher},
journal = {System},
volume = {135},
pages = {103870},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103870},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002805},
author = {Lianjiang Jiang and Michelle Mingyue Gu},
keywords = {Critical digital literacies, GenAI, Digital multimodal composing, Ethnic minority, Narrative inquiry},
abstract = {The importance of teaching critical digital literacies (CDL) in the era of generative artificial intelligence (GenAI) is well documented. Yet CDL instruction remains a daunting challenge and scant attention has been paid to how language teachers enable CDL development. This study conceptualizes CDL as dynamic and multifaceted, comprising four major ways of being critical in awareness, relationship, identity and action, and documents how an ethnic minority English teacher, Norita, enabled CDL through implementing three GenAI-assisted digital multimodal composing (DMC) projects over two academic years. With longitudinal narrative inquiry as the design, this study gathered multiple sources of data from Norita and her students, including narrative interviews, informal dialogues, classroom observations, and student-authored multimodal compositions. The narrative analysis reveals a developmental and selectively focused progression in Norita's CDL enabling practice, which can be theorized as a continuum of celebrating differences, building solidarity and fostering activism. The findings also show that Norita drew upon not just her students' multicultural experiences, but also her sociopolitical awareness of being ethnic minority and her commitment to go beyond the conventional protection discourse to promote critical representation and transformation for linguistically minoritized students. Implications of how her practice can be sustained are also discussed.}
}
@article{BALLARD20253039,
title = {Impact of ChatGPT and Large Language Models on Radiology Education: Association of Academic Radiology—Radiology Research Alliance Task Force White Paper},
journal = {Academic Radiology},
volume = {32},
number = {5},
pages = {3039-3049},
year = {2025},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2024.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S1076633224007840},
author = {David H. Ballard and Alexander Antigua-Made and Emily Barre and Elizabeth Edney and Emile B. Gordon and Linda Kelahan and Taha Lodhi and Jonathan G. Martin and Melis Ozkan and Kevin Serdynski and Bradley Spieler and Daphne Zhu and Scott J. Adams},
keywords = {Large language models, Artificial intelligence, Curriculum, Teaching and learning, Assessment},
abstract = {Generative artificial intelligence, including large language models (LLMs), holds immense potential to enhance healthcare, medical education, and health research. Recognizing the transformative opportunities and potential risks afforded by LLMs, the Association of Academic Radiology—Radiology Research Alliance convened a task force to explore the promise and pitfalls of using LLMs such as ChatGPT in radiology. This white paper explores the impact of LLMs on radiology education, highlighting their potential to enrich curriculum development, teaching and learning, and learner assessment. Despite these advantages, the implementation of LLMs presents challenges, including limits on accuracy and transparency, the risk of misinformation, data privacy issues, and potential biases, which must be carefully considered. We provide recommendations for the successful integration of LLMs and LLM-based educational tools into radiology education programs, emphasizing assessment of the technological readiness of LLMs for specific use cases, structured planning, regular evaluation, faculty development, increased training opportunities, academic-industry collaboration, and research on best practices for employing LLMs in education.}
}
@article{FOUNG2025100248,
title = {Generating synthetic data for CALL research with GenAI: A proof-of-concept study},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100248},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100248},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000692},
author = {Dennis Foung and Lucas Kohnke},
keywords = {GenAI, CALL, Artificial intelligence, Synthetic data},
abstract = {Popular tools like ChatGPT have placed generative artificial intelligence (GenAI) in the spotlight in recent years. One use of GenAI tools is to generate simulated data—or synthetic data—when the full scope of the required microdata is unavailable. Despite suggestions for educational researchers to use synthetic data, little (if any) computer-assisted language learning (CALL) research has used synthetic data thus far. This study addresses this research gap by exploring the possibility of using synthetic datasets in CALL. The publicly available dataset resembles a typical study with a small sample size (n = 55) performed using a CALL platform. Two synthetic datasets are generated from the original datasets using the synthpop package and generative adversarial networks (GAN) in R (via the RGAN package), which are both common synthetic data generation methods. This study evaluates the synthetic datasets by (a) comparing the distribution between the synthetic and original datasets, (b) examining the model parameters of the rebuilt linear models using the synthetic and original datasets, and (c) examining the privacy disclosure metrics. The results suggest that synthpop better represents the original data and preserves privacy. Notably, the GAN-generated dataset does not produce satisfactory results. This demonstrates GAN’s key challenges alongside the potential benefits of generating synthetic data with synthpop.}
}
@article{GUAN2024100323,
title = {AI in informal digital English learning: A meta-analysis of its effectiveness on proficiency, motivation, and self-regulation},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100323},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100323},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001267},
author = {Lihang Guan and Shaofeng Li and Mingyue Michelle Gu},
keywords = {Generative artificial intelligence, Informal digital learning of English, English proficiency, Learning motivation, Self-regulation},
abstract = {This meta-analysis examines the efficacy of generative artificial intelligence (GenAI) in second language acquisition within self-directed, out-of-classroom informal contexts. A total of 15 studies meeting the inclusion criteria were identified that examined the impact of GenAI on second-language proficiency, motivation, and self-regulation. GenAI was shown to have significant effects on English proficiency and self-regulation, demonstrating its versatility in enhancing language learning outcomes. However, GenAI failed to show significant effects on learning motivation, and based on this finding we highlight the need to develop measures of motivation that are suitable for GenAI in education. Possible ways to apply GenAI in the informal language learning environment are also discussed based on the included literature.}
}
@article{LIMA20251277,
title = {Enhancing Rare Disease Management and Care: Proposal of an Evidence-Based Digital Platform for Second Opinions},
journal = {Procedia Computer Science},
volume = {256},
pages = {1277-1284},
year = {2025},
note = {CENTERIS - International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.239},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925006003},
author = {Vinícius Lima and Filipe Bernardi and Diego Yamada and Victor Cassão and Francisco Barbosa-Junior and Têmis Félix and Victor Ferraz and Amaury Dal Fabbro and Domingos Alves},
keywords = {rare disease, second opinion, digital health},
abstract = {The management and care of rare diseases pose significant challenges due to limited evidence, scarce specialized resources, and pronounced healthcare disparities, particularly in Brazil. To address these issues, the development of the Rare Disease Second Opinion Platform is presented, an evidence-based digital solution designed to provide comprehensive second opinions for rare disease cases. The primary objectives are to streamline the process of obtaining clinical and non-clinical second opinions, enhance the educational knowledge base for healthcare professionals, and improve patient outcomes. The platform is developed using action research and a sociotechnical approach, ensuring it is user-centric and effective. Business process modeling and platform design will ensure a structured and user-friendly development. Preliminary results highlight the platform’s potential to connect patients, healthcare facilities, and specialists through a centralized web portal. The use of Generative Artificial Intelligence models will accelerate content production and query responses. The platform aims to significantly improve healthcare outcomes for rare disease patients in Brazil by providing timely access to specialist opinions and creating a comprehensive educational database.}
}
@article{KHAN2024e24890,
title = {ChatGPT in finance: Applications, challenges, and solutions},
journal = {Heliyon},
volume = {10},
number = {2},
pages = {e24890},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24890},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024009216},
author = {Muhammad Salar Khan and Hamza Umer},
keywords = {ChatGPT, Finance, Ethical challenges, Policies, Applications, Artificial intelligence},
abstract = {The emergence of ChatGPT, a generative artificial intelligence tool, has sparked a revolution in the finance industry, enabling individuals to interact with technology in natural language. However, the use of ChatGPT in finance presents a profound array of ethical considerations that demand careful scrutiny to ensure its responsible and ethical use. After a concise exploration of ChatGPT's applications in finance, this policy article delves into the ethical challenges arising from the use of ChatGPT in finance, including outcomes contaminated with biases, incorporation of fake information in the financial decisions, concerns surrounding privacy and security, lack of transparency and accountability in the decision-making processes and financial services, human job displacement, and the intricate web of legal complexities. Our article asserts that financial institutions employing ChatGPT must proactively devise strategies to confront these burgeoning challenges, mitigating their adverse effects on both individuals and society as a whole. Additionally, we propose relevant policies to tackle these ethical quandaries head-on. In essence, this article illuminates the imperative need for a meticulous ethical framework, facilitating an informed and responsible use of ChatGPT in the realm of finance, safeguarding the welfare of individuals and society. While our work significantly contributes to the research and practice of finance, we also identify future research avenues.}
}
@article{LU2025100989,
title = {GenAI and human assessments of L2 Chinese writing: Interrater reliability and rater bias},
journal = {Assessing Writing},
volume = {66},
pages = {100989},
year = {2025},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2025.100989},
url = {https://www.sciencedirect.com/science/article/pii/S1075293525000765},
author = {Yuan Lu and Xiaoying Liles and Xi Ma},
keywords = {L2 Chinese writing, Generative AI, Human rater, Reliability, Severity, Rater bias},
abstract = {This study examines generative artificial intelligence (GenAI), specifically ChatGPT and DeepSeek, and human assessments of Chinese as a second language (L2) writing, with a focus on interrater reliability, severity, consistency, and potential genre-based biases. Agreement and correlation analyses revealed substantial variability in interrater reliability among human raters, regardless of their rating experience. ChatGPT consistently demonstrated higher agreement with human raters than DeepSeek. The lowest levels of agreement were observed between DeepSeek and human raters as well as between the two GenAI raters. A Many-Facet Rasch Model analysis showed that ChatGPT tended to rate essays more leniently than DeepSeek and closely resembled experienced human raters in terms of severity, but DeepSeek’s severity aligned more closely with that of novice human raters. No significant genre-based biases were identified for GenAI and human raters. The observed differences in GenAI rating performance may likely result from distinctions in their large language models’ training data, computing capacities, model architectures, and functionalities. These findings offer evidence-based practical implications for the integration of GenAI tools in L2 Chinese writing assessment.}
}
@article{ANDERSON2025296,
title = {Generative AI-driven personalization of the Community of Inquiry model: enhancing individualized learning experiences in digital classrooms},
journal = {International Journal of Information and Learning Technology},
volume = {42},
number = {3},
pages = {296-310},
year = {2025},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-10-2024-0240},
url = {https://www.sciencedirect.com/science/article/pii/S2056488025000034},
author = {Jeffrey E. Anderson and Carlin A. Nguyen and Gerardo Moreira},
keywords = {Social presence, Teaching presence, Personalized learning, Generative artificial intelligence (GenAI), Cognitive presence, Community of Inquiry (CoI)},
abstract = {Purpose
This paper explores the integration of generative artificial intelligence (GenAI) into the Community of Inquiry (CoI) framework, focusing on how GenAI can dynamically personalize online learning environments. The study aims to examine how GenAI can enhance social, cognitive and teaching presence, thus meeting the diverse needs of individual learners and improving engagement in digital classrooms.
Design/methodology/approach
The paper employs a conceptual approach, building on existing literature about the CoI framework and GenAI. It proposes a theoretical model that illustrates how GenAI can personalize social, cognitive and teaching presence in real-time, using engagement patterns, performance data and feedback mechanisms to adapt learning pathways for individual students.
Findings
The study finds that GenAI can significantly enhance personalized learning by dynamically adjusting the CoI framework’s elements. GenAI-driven interactions improve student engagement through personalized prompts and adaptive content delivery, while AI-generated feedback provides timely and individualized support, fostering a more responsive and student-centered learning experience.
Practical implications
For educators, the integration of GenAI into the CoI framework offers scalable solutions for personalized instruction and feedback. Institutions can leverage AI-driven insights to create more adaptive, learner-centered environments that improve learning outcomes, satisfaction and engagement, especially in large-scale online courses.
Social implications
The paper highlights the potential for AI-driven education to bridge gaps in personalized learning, promoting equity and inclusivity. However, it also addresses ethical concerns such as data privacy, algorithmic bias and the digital divide, urging careful implementation to ensure that AI enhances rather than undermines educational fairness.
Originality/value
This paper provides a novel perspective on the intersection of GenAI and the CoI framework, proposing a unique conceptual model for AI-enhanced online education. It offers valuable insights for educators, researchers and institutions aiming to create more personalized, effective and inclusive digital learning environments.}
}
@article{ARAMALI2025100191,
title = {Generative AI in project management: Impacts on corporate values, employee perceptions, and organizational practices},
journal = {Project Leadership and Society},
volume = {6},
pages = {100191},
year = {2025},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2025.100191},
url = {https://www.sciencedirect.com/science/article/pii/S266672152500016X},
author = {Vartenie Aramali and Namho Cho and Falguni Pande and M.K.S. Al-Mhdawi and Udechukwu Ojiako and Abroon Qazi},
keywords = {Generative artificial intelligence, GenAI, ChatGPT, Project management, Organizational adoption, Employee perceptions},
abstract = {This study examines the evolving role of generative AI tools, particularly ChatGPT, in project management, focusing on their impact on corporate values, employee perceptions, and practical application across project phases and roles. Using a mixed methods design comprising a literature review, two industry workshops, and a survey of 52 professionals from diverse sectors, the research integrates thematic qualitative analysis with exploratory quantitative assessment. The most prominent finding is that 74 % of participants expressed mixed or negative sentiments towards AI adoption, citing concerns about job security and data privacy, despite recognizing productivity and automation benefits. In addition, 42 % observed positive shifts in corporate values linked to AI adoption, and strong consensus emerged regarding AI's usefulness in Planning (86 %), Monitoring and Controlling (75 %), and Integration (83 %) project management process groups. While some statistically significant associations were identified, such as employer type (consultant vs. non-consultant) influencing AI use during the project execution phase, these findings are preliminary due to the small sample size. The results highlight the importance of balancing AI-driven efficiencies with ethical safeguards, human oversight, and targeted training. This study contributes to the digital transformation discourse by providing early empirical insights into how generative AI is reshaping project management practices and organisational culture.}
}
@article{BOONE2025104135,
title = {Generative AI: Opportunities, challenges, and research directions for supply chain resilience},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {199},
pages = {104135},
year = {2025},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2025.104135},
url = {https://www.sciencedirect.com/science/article/pii/S1366554525001760},
author = {Tonya Boone and Behnam Fahimnia and Ram Ganeshan and David M. Herold and Nada R. Sanders},
abstract = {Generative Artificial Intelligence (GenAI) is emerging as a transformative force in supply chain resilience, offering new ways to enhance decision-making, automate operations, and improve adaptability to disruptions. Unlike traditional AI, which relies on historical data for prediction and optimization, GenAI can generate novel solutions and simulate alternative scenarios in real time. Despite its potential, research on GenAI’s role in supply chain resilience remains limited. This paper explores GenAI applications and possible research questions across key supply chain areas while also addressing challenges such as misinformation, security risks, and governance. As GenAI integrates with existing technologies, its adoption raises critical questions about accountability and systemic dependencies. To ensure responsible implementation, further research is needed to refine oversight mechanisms, establish benchmarks, and develop hybrid decision-making models where AI enhances, rather than replaces, human expertise. These insights provide guidance to managers and policymakers to help make informed decisions about the strategic deployment of GenAI in resilience-oriented supply chains.}
}
@article{XU2025100205,
title = {Digital twins in ophthalmology: Concepts, applications, and challenges},
journal = {Asia-Pacific Journal of Ophthalmology},
pages = {100205},
year = {2025},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2025.100205},
url = {https://www.sciencedirect.com/science/article/pii/S2162098925000726},
author = {Kezheng Xu and Xiaolan Chen and Bowen Liu and Kai Jin and Mingguang He and Danli Shi},
keywords = {Digital twin, Computational modeling, Digital medicine, Generative artificial intelligence}
}
@article{LI2025759,
title = {Generative AI models for different steps in architectural design: A literature review},
journal = {Frontiers of Architectural Research},
volume = {14},
number = {3},
pages = {759-783},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S209526352400147X},
author = {Chengyuan Li and Tianyu Zhang and Xusheng Du and Ye Zhang and Haoran Xie},
keywords = {Generative AI, Architectural design, Diffusion models, 3D generative models, Large-scale models},
abstract = {Recent advances in generative artificial intelligence (AI) technologies have been significantly driven by models such as generative adversarial networks (GANs), variational autoencoders (VAEs), and denoising diffusion probabilistic models (DDPMs). Although architects recognize the potential of generative AI in design, personal barriers often restrict their access to the latest technological developments, thereby causing the application of generative AI in architectural design to lag behind. Therefore, it is essential to comprehend the principles and advancements of generative AI models and analyze their relevance in architecture applications. This paper first provides an overview of generative AI technologies, with a focus on probabilistic diffusion models (DDPMs), 3D generative models, and foundation models, highlighting their recent developments and main application scenarios. Then, the paper explains how the abovementioned models could be utilized in architecture. We subdivide the architectural design process into six steps and review related research projects in each step from 2020 to the present. Lastly, this paper discusses potential future directions for applying generative AI in the architectural design steps. This research can help architects quickly understand the development and latest progress of generative AI and contribute to the further development of intelligent architecture.}
}
@article{CHEN2026103877,
title = {Teacherness in the age of GenAI: An ethnographic exploration of pedagogical decision-making and AI integration in English language teaching},
journal = {System},
volume = {136},
pages = {103877},
year = {2026},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103877},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002878},
author = {Qinghua Chen and Upsorn Tawilapakul and Angel M.Y. Lin},
keywords = {Generative AI, Teacherness, Pedagogical content knowledge, ESP instruction, AI-Pedagogical knowledge},
abstract = {This study investigates how English language teachers maintain and express their professional expertise—"teacherness"—while integrating Generative Artificial Intelligence (GenAI) into their pedagogical practice. Through a three-month participatory ethnographic study of an experienced ESP instructor at a Thai university, we examine how teachers' pedagogical content knowledge (PCK) manifests in GenAI-enhanced instruction. Drawing on Shulman's PCK framework and Bakhtin's dialogic theory, we analyze cases of teacher-AI collaboration in materials development and assessment design. Our findings reveal the emergence of "AI-pedagogical knowledge"—the specialized ability to translate teaching intentions into AI-actionable instructions. This process requires teachers to deconstruct their typically intuitive PCK into explicit, sequential instructions for GenAI, highlighting both challenges and opportunities in this emerging practice. The study demonstrates that while GenAI can efficiently generate content, it lacks the contextual understanding and pedagogical judgment that characterize effective teaching. The findings suggest that successful GenAI integration requires preserving direct teacher-student interaction while leveraging AI capabilities strategically. This research contributes to debates about teacher professional identity in the AI era, arguing that GenAI integration reinforces the essential nature of teacherness through pedagogical judgment and human insight.}
}
@article{NG2025100373,
title = {Opportunities, challenges and school strategies for integrating generative AI in education},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100373},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100373},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X2500013X},
author = {Davy Tsz Kit Ng and Eagle Kai Chi Chan and Chung Kwan Lo},
keywords = {Artificial intelligence, Generative AI, Teacher education, Learning/teaching, School improvement, School policy, School management},
abstract = {The increasing accessibility of Generative Artificial Intelligence (GenAI) tools has led to their exploration and adoption in education. This qualitative study investigates the opportunities and challenges associated with integrating GenAI in education, and the strategies that encourage teachers and students to embrace GenAI in school settings. We recruited 76 educators in Canada to participate in a professional training seminar about GenAI and expressed their views through online surveys. Through written reflections, an optimistic outlook on GenAI's role in education was identified among the teachers, and some discipline-specific ideas were proposed. Thematic analysis reveals three key practices of AI implementation: teaching/learning, administration and assessments. However, three major challenges are also identified: school's readiness, teachers' AI competencies, and students' AI literacy and ethics. Teachers suggest several strategies to motivate GenAI integration, including professional development, clear guidelines, and access to AI software and technical support. Finally, Singh's Teach AI Global Initiative Guidance and Socio-ecological Model are adapted and proposed to support schools in becoming AI-ready by addressing teachers' and students' needs, facilitating organizational learning, and promoting improvement and transformation to foster their literacy development. Recommendations were provided for developing effective strategies to embrace GenAI in education.}
}
@article{AMANKWAHAMOAH2024102759,
title = {The impending disruption of creative industries by generative AI: Opportunities, challenges, and research agenda},
journal = {International Journal of Information Management},
volume = {79},
pages = {102759},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102759},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000070},
author = {Joseph Amankwah-Amoah and Samar Abdalla and Emmanuel Mogaji and Amany Elbanna and Yogesh K. Dwivedi},
keywords = {Creative industries, Generative AI, Collaboration, Automation, Transformation},
abstract = {Despite the debate on the potential effects of the adoption of generative artificial intelligence (AI) in modern societies in terms, there needs to be more clarity in the scholarly discourse and directions for the creative industries. In this editorial article, we discuss the potential impact of generative AI adoption on the creative industries and outline future research agendas. We argue that the successful adoption of generative AI in the creative industries lies in finding the delicate balance between maintaining human ingenuity and reaping the benefits of technological innovation. Unlike other industrial sectors, where AI primarily automates repetitive tasks, creative professionals can use generative AI as a collaborative tool to spark new avenues for creativity, streamline workflows, and accelerate creative processes. However, maintaining the human touch and authenticity that define the output of the creative industries remains a challenge for the industry and society. We examine these issues in the paper.}
}
@article{AMANO2025114600,
title = {Microscopy modality transfer of steel microstructures: Inferring scanning electron micrographs from optical microscopy using generative AI},
journal = {Materials Characterization},
volume = {220},
pages = {114600},
year = {2025},
issn = {1044-5803},
doi = {https://doi.org/10.1016/j.matchar.2024.114600},
url = {https://www.sciencedirect.com/science/article/pii/S1044580324009811},
author = {Nicholas Amano and Bo Lei and Martin Müller and Frank Mücklich and Elizabeth A. Holm},
keywords = {Generative artificial intelligence, Computer vision, Diffusion models, Microstructure, Steel, Modality transfer},
abstract = {Scanning electron microscopy (SEM) is resource intensive, which limits its throughput in some applications. As an alternative, we propose applying computer vision and machine learning to generate high-quality synthetic SEM micrographs from micrographs obtained using light optical microscopy (LOM). Working with a correlated LOM/SEM dataset of dual-phase steel images, we test generative models of various architectures, including encoder-decoder networks, generative adversarial networks (GANs), and diffusion-based models. We find that the diffusion models significantly outperform other methods on both qualitative and quantitative assessments, while preserving key metallurgical meaning. This work establishes diffusion as the state-of-the-art for microscopy modality transfer and demonstrates the potential of AI-powered microscopy to enhance LOM with micron scale structural recreation.}
}
@article{SQUALLIHOUSSAINI2024101491,
title = {Development of a design course for medical curriculum: Using design thinking as an instructional design method empowered by constructive alignment and generative AI},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101491},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101491},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000294},
author = {Mouna {Squalli Houssaini} and Ahmed Aboutajeddine and Imane Toughrai and Adil Ibrahimi},
keywords = {Design thinking, Medical education, Constructive alignment, Generative AI, ChatGPT},
abstract = {Doctors are nowadays experiencing many struggles in their daily practice, mainly due to new intricate challenges of the twenty-first century. However, despite the efforts of traditional medical education, it falls short in providing them with the required tools to effectively overcome these difficulties. In light of these shortcomings, this paper suggests the development of a new educational framework designed to guide medical educators in creating student-centered learning experiences. Which may be ensured by using Design Thinking (DT) as an instructional design method, merged with constructive alignment principles, and generative artificial intelligence. To demonstrate the effectiveness of this new educational approach, a case study is showcased wherein the framework was applied to design a new medical curriculum. The case study specifically focuses on first-year students in a Moroccan medical faculty and was developed based on DT principles, allowing students to engage in a transformative learning process that encourages innovation and creativity. The new curriculum includes lecture sessions, hands-on workshops, and project coaching where teams of medical students learn the design process and are given the opportunity to prototype and test their proposed solutions at local university hospital units. Overall, the showcased case study provides evidence of the framework's effectiveness in designing a new medical curriculum, illustrating its potential for enhancing medical education and engaging future doctors in impact-focused projects with long-term benefits for their career development.}
}
@article{URBINA202514,
title = {Disability Ethics and Education in the Age of Artificial Intelligence: Identifying Ability Bias in ChatGPT and Gemini},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {106},
number = {1},
pages = {14-19},
year = {2025},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2024.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0003999324011912},
author = {Jacob T. Urbina and Peter D. Vu and Michael V. Nguyen},
keywords = {Artificial intelligence, Bias, Digital health technology, Disability discrimination, Rehabilitation},
abstract = {Objective
To identify and quantify ability bias in generative artificial intelligence large language model chatbots, specifically OpenAI's ChatGPT and Google's Gemini.
Design
Observational study of language usage in generative artificial intelligence models.
Setting
Investigation-only browser profile restricted to ChatGPT and Gemini.
Participants
Each chatbot generated 60 descriptions of people prompted without specified functional status, 30 descriptions of people with a disability, 30 descriptions of patients with a disability, and 30 descriptions of athletes with a disability (N=300).
Interventions
Not applicable.
Main Outcome Measures
Generated descriptions produced by the models were parsed into words that were linguistically analyzed into favorable qualities or limiting qualities.
Results
Both large language models significantly underestimated disability in a population of people, and linguistic analysis showed that descriptions of people, patients, and athletes with a disability were generated as having significantly fewer favorable qualities and significantly more limitations than people without a disability in both ChatGPT and Gemini.
Conclusions
Generative artificial intelligence chatbots demonstrate quantifiable ability bias and often exclude people with disabilities in their responses. Ethical use of these generative large language model chatbots in medical systems should recognize this limitation, and further consideration should be taken in developing equitable artificial intelligence technologies.}
}
@article{ZHOU2025100982,
title = {Exploring the impact of generative AI on student learning in accounting},
journal = {Journal of Accounting Education},
volume = {72},
pages = {100982},
year = {2025},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2025.100982},
url = {https://www.sciencedirect.com/science/article/pii/S0748575125000338},
author = {Aner Zhou and Yan Luo},
keywords = {AI, ChatGPT, Accounting education, Student engagement with AI, Learning experience, AI in higher education},
abstract = {The rapid development of generative artificial intelligence (AI) is transforming accounting practices and education. This study provides descriptive evidence regarding how accounting students currently engage with AI tools in their learning experience. Survey data from 259 accounting students and 126 non-accounting students at a four-year public university in the U.S. reveals that 80 % of students use AI at least about once a week or more, primarily for help with difficult concepts. Students introduced to AI from their peers and friends feel more encouraged to use it than the rest of the students. While accounting and non-accounting students share many similar usage patterns, accounting students are less likely to use AI for creativity tasks or to accept AI-generated outputs without questioning their accuracy, bias, or currency, especially when it comes to decision making. Among the accounting disciplines, students are more likely to use AI for AIS. Both accounting and non-accounting students believe AI is able to reduce repetitive tasks and perceive AI with a positive impact on their learning experience, including improving GPA, helping with knowledge acquisition, making learning more enjoyable, and saving learning time. Such perceived benefits do vary by usage frequency and student GPA. This study highlights the importance of incorporating AI into accounting education to enhance student learning experience. It complements prior research focusing on educators and professionals, offering insights from students’ perspectives.}
}
@article{URBAN2025102156,
title = {Prompting for creative problem-solving: A process-mining study},
journal = {Learning and Instruction},
volume = {99},
pages = {102156},
year = {2025},
issn = {0959-4752},
doi = {https://doi.org/10.1016/j.learninstruc.2025.102156},
url = {https://www.sciencedirect.com/science/article/pii/S0959475225000805},
author = {Marek Urban and Jiří Lukavský and Cyril Brom and Veronika Hein and Filip Svacha and Filip Děchtěrenko and Kamila Urban},
keywords = {Generative artificial intelligence, Prompt engineering, Metacognitive skills, Hybrid human-AI regulation, Creative problem-solving},
abstract = {Background
Although generative-AI systems are increasingly used to solve non-routine problems, effective prompting strategies remain largely underexplored.
Aims
The present study investigates how university students prompt ChatGPT to solve complex ill-defined problems, specifically examining which prompts are associated with higher or lower problem-solving performance.
Sample
Seventy-seven university students (53 women; Mage = 22.4 years) participated in the study.
Methods
To identify various prompt types employed by students, the study utilized qualitative analysis of interactions with ChatGPT 3.5 during the resolution of the creative problem-solving task. Participants’ performance was measured by the quality, elaboration, and originality of their ideas. Subsequently, two-step clustering was employed to identify groups of low- and high-performing students. Finally, process-mining techniques (heuristics miner) were used to analyze the interactions of low- and high-performing students.
Results
The findings suggest that including clear evaluation criteria when prompting ChatGPT to generate ideas (rs = .38), providing ChatGPT with an elaborated context for idea generation (rs = .47), and offering specific feedback (rs = .45), enhances the quality, elaboration, and originality of the solutions. Successful problem-solving involves iterative human-AI regulation, with high performers using an overall larger number of prompts (d = .82). High performers interacted with ChatGPT through dialogue, where they monitored and regulated the generation of ideas, while low performers used ChatGPT as an information resource.
Conclusions
These results emphasize the importance of active and iterative engagement for creative problem-solving and suggest that educational practices should foster metacognitive monitoring and regulation to maximize the benefits of human-AI collaboration.}
}
@article{SOLODUCHOPELC20244461,
title = {Role of Business Intelligent Systems in Sustainable Strategic Management for Green Jobs Creation},
journal = {Procedia Computer Science},
volume = {246},
pages = {4461-4469},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.296},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023159},
author = {Letycja Sołoducho-Pelc and Adam Sulich},
keywords = {Artificial Intelligence, business development, competitive advantage, green labor market, Scopus AI, sustainable development},
abstract = {Contemporary generative AI tools are becoming integral to business development strategies. Organizations are seeking applications for innovative technologies in science and various areas of operations. Intelligent systems bridge the gap between the scientific world and business practice. This is significant in using generative artificial intelligence in Sustainable Strategic Management (SSM) to create Green Jobs (GJs). Despite the popularity of topics like sustainable strategic management and creating GJs, science rarely combines these into interdisciplinary research. This article stands out from other review articles by using the innovative Scopus AI tool to explore a significant construct from theoretical and practical perspectives. The aim of this article is to highlight the potential for collaboration between science and business in creating GJs using Business Intelligent Systems (BIS) in SSM. The methodology of exploratory scientific inquiry supports this goal. This article employs a new research method, the Scopus AI tool. The results undergo critical analysis and interpretation, presenting conclusions and recommendations for using intelligent systems to create GJs in sustainable strategic management.}
}
@article{LEMPE2025,
title = {Health Care Social Robots in the Age of Generative AI: Protocol for a Scoping Review},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/63017},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825002033},
author = {Paul Notger Lempe and Camille Guinemer and Daniel Fürstenau and Corinna Dressler and Felix Balzer and Thorsten Schaaf},
keywords = {robotics, social robots, artificial intelligence, generative AI, human-robot interaction, health care sector, PRISMA},
abstract = {Background
Social robots (SR), sensorimotor machines designed to interact with humans, can help to respond to the increasing demands in the health care sector. To ensure the successful use of this technology, acceptance is paramount. Generative artificial intelligence (AI) is an emerging technology with the potential to enhance the functionality of SR and promote user acceptance by further improving human-robot interaction.
Objective
We present a protocol for a scoping review of the literature on the implementation of generative AI in SR in the health care sector. The aim of this scoping review is to map out the intersection of SR and generative AI in the health care sector; to explore if generative AI is applied in SR in the health care sector; to outline which models of generative AI and SR are used for these implementations; and to explore whether user acceptance is reported as an outcome following these implementations. This scoping review supports future research by providing an overview of the state of connectedness of 2 emerging technologies and by mapping out research gaps.
Methods
We follow the methodological framework developed by Arksey and O'Malley and the recommendations by the Joanna Briggs Institute. Our protocol was drafted using the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-analyses extension for Scoping Reviews). We will conduct a systematic literature search of the online databases MEDLINE, Embase, CINAHL (Cumulative Index to Nursing and Allied Health Literature), Web of Science, and IEEE Xplore, aiming to retrieve relevant data items via tabular data charting from references meeting specific inclusion criteria which are studies published from 2010 onwards, set in the health care sector, focusing on SR with physical bodies and implemented generative AI. There are no restrictions on study types. Results will be categorized, clustered, and summarized using tables, graphs, visual representations, and narratives.
Results
After conducting a preliminary search and deduplication in the second quarter of 2024, we retrieved 3176 preliminary results. This scoping review will be supplemented with the next methodological steps, including retrieving the results in a reference management tool as well as screening titles, abstracts, and full text regarding specific inclusion criteria. The completion of these steps is scheduled for the second quarter of 2025. Limitations based on the heterogeneity of the included studies and the general breadth of a scoping review compared to a systematic review are to be expected. To reduce bias, we adopted a system of dual reviews and thorough documentation of the study selection.
Conclusions
The conducted preliminary search implies that there are a sufficient number of heterogeneous references to complete this scoping review. To our knowledge, this is the first scoping review on generative AI in health care SR.
International Registered Report Identifier (IRRID)
PRR1-10.2196/63017}
}
@incollection{ZHOU2026109,
title = {Chapter 7 - Generative models for drug design},
editor = {Qifeng Bai and Tingyang Xu and Junzhou Huang},
booktitle = {Deep Learning in Drug Design},
publisher = {Academic Press},
pages = {109-132},
year = {2026},
isbn = {978-0-443-32908-1},
doi = {https://doi.org/10.1016/B978-0-44-332908-1.00015-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443329081000155},
author = {Yijin Zhou and Yu Guang Wang},
keywords = {Generative models, Drug design, Molecule design, Protein generation},
abstract = {This chapter provides an overview of the role of generative artificial intelligence (GAI) in the innovative process of drug discovery and design. Traditional drug design is a lengthy, complex, and expensive process, often taking 3–6 years and costing hundreds of millions of dollars to bring a new drug to market. With advances in deep-generative models, mainly including Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Flow-Based Models, and Diffusion Models, researchers have shown promise in generating new drugs digitally. The chapter introduces progress in the design of novel molecules and proteins, respectively. The first section discusses the task classification, strategies, and evaluation metrics used in small molecule design. For protein generation, the chapter outlines various tasks, including sequence-to-structure, properties-to-sequence/structure, backbone design, and so on. Despite progress, challenges remain, such as the lack of standardized benchmarking methods and difficulties with tasks like fold classification and antibody CDR H3 generation. Therefore the chapter summarizes and emphasizes the vital problems and future trends in generative drug design in the last section.}
}
@article{ADLER2026105268,
title = {Hybrid Human-GenAI cognitive apprenticeship: Encouraging pre-service teachers to implement instructional practices to support students' self-regulated learning},
journal = {Teaching and Teacher Education},
volume = {169},
pages = {105268},
year = {2026},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105268},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25003452},
author = {Idit Adler and Yogev Shani},
keywords = {Augmentation, Cognitive apprenticeship model, Generative artificial intelligence, Pre-service teachers, Self-regulated learning},
abstract = {To support pre-service teachers in becoming agents of self-regulated learning (SRL), we developed a hybrid Human-GenAI (hH-GenAI) course, which leverages the potential of artificial intelligence within a Cognitive Apprenticeship Model (CAM) through a personalized GenAI-based chatbot (TeachPal). Using design-based research, we examined pre-service teachers' implementation of SRL-supporting instructional practices, approach components that affected their self-efficacy judgments, and the role of TeachPal in their professional development. We found that while hH-GenAI CAM provided an effective and scalable approach to support the pre-service teachers in implementing SRL-supporting instructional practices, it fostered engagement in metacognitive discourse to only a limited extent. Furthermore, the interactions and characteristics of the discourse with TeachPal hindered positive experiences and limited realization of the approach's full potential. These findings highlight the importance of the augmented approach that integrates the complementary strengths of human and GenAI while ensuring high-quality discourse in teacher education.}
}
@article{ZHANG2025100221,
title = {Development and validation of the generative AI engagement scale},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {6},
pages = {100221},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100221},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125001057},
author = {Da-Wei Zhang and Jia Yue Tan and Yu Yang Chew and Lisha Hew and Jia Yee Choo},
keywords = {Generative artificial intelligence, Scale development, Scale validation, Use frequency, Interaction style, Human–computer interaction},
abstract = {As generative AI becomes more integrated into everyday life, understanding the behavioral impact of generative AI usage becomes increasingly important. However, research lacks validated tools for capturing both the frequency and quality of generative AI use. This study presents the Generative AI Engagement Scale (GAIES), a multidimensional instrument that was developed following best practices in scale construction and validation. GAIES consists of two subscales: the Use Frequency scale, which measures how often users interact with generative AI for self-interested and task-oriented purposes, and the Interaction Style scale, which assesses how users interact with generative AI through Questioningness, Expressiveness, and Preciseness. This study included 414 participants. Several psychometric evaluations were involved, including classical test theory, exploratory and confirmatory factor analyses, and item response theory. The subscales showed strong internal consistency, a clear factor structure, and a good fit. Besides validating GAIES, we demonstrated its practical utility through two case studies. An analysis of a structural equation model revealed that predictors from the Unified Theory of Acceptance and Use of Technology explained Self-interest- and Task-oriented usage differentially, indicating the predictability of the scale. Further, latent profile analysis revealed four distinct user subgroups, demonstrating the usefulness of the scale in identifying meaningful patterns of engagement. These findings establish GAIES as a psychometrically and theoretically sound method of measuring generative AI engagement. A key contribution of GAIES is its ability to go beyond generic usage metrics and offer a foundation for future research into the behavioral implications of generative AI usage.}
}
@article{COGNETTARIEKE2025102519,
title = {Embracing innovation and GenAI in nursing: Early lessons from the field},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102519},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102519},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001721},
author = {Cheristi Cognetta-Rieke and Betty Jo Rocchio and Jill D. Seys and Tracy L. Breece and Cheryl L. Denison and Emily Barey},
keywords = {Healthcare transformation, Nursing, Innovation, Artificial intelligence, GenAI, Electronic health record},
abstract = {ABSTRACT
Innovation and the integration of Artificial Intelligence (AI) are essential in addressing the evolving challenges in healthcare, enhancing patient care, and supporting nursing practice. This article explores the opportunities associated with Generative Artificial Intelligence (GenAI) in nursing, considerations for how to leverage it to augment the work of nursing, and strategies to accelerate its adoption. By engaging in interprofessional collaboration, leveraging technology, and fostering a culture of continuous improvement, nurses can lead transformative changes in healthcare delivery. The article also highlights case studies from Mercy and Mayo Clinic, demonstrating the practical implications and successful implementation of AI in nursing practice. These examples emphasize the importance of strategic planning, ethical considerations, and active involvement of frontline nurses in the design and adoption of AI technologies.}
}
@article{WANG2025,
title = {The Application and Ethical Implication of Generative AI in Mental Health: Systematic Review},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/70610},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925000629},
author = {Xi Wang and Yujia Zhou and Guangyu Zhou},
keywords = {generative AI, mental health, large language models, mental health detection and diagnosis, therapeutic chatbots},
abstract = {Background
Mental health disorders affect an estimated 1 in 8 individuals globally, yet traditional interventions often face barriers, such as limited accessibility, high costs, and persistent stigma. Recent advancements in generative artificial intelligence (GenAI) have introduced AI systems capable of understanding and producing humanlike language in real time. These developments present new opportunities to enhance mental health care.
Objective
We aimed to systematically examine the current applications of GenAI in mental health, focusing on 3 core domains: diagnosis and assessment, therapeutic tools, and clinician support. In addition, we identified and synthesized key ethical issues reported in the literature.
Methods
We conducted a comprehensive literature search, following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines, in PubMed, ACM Digital Library, Scopus, Embase, PsycInfo, and Google Scholar databases to identify peer-reviewed studies published from October 1, 2019, to September 30, 2024. After screening 783 records, 79 (10.1%) studies met the inclusion criteria.
Results
The number of studies on GenAI applications in mental health has grown substantially since 2023. Studies on diagnosis and assessment (37/79, 47%) primarily used GenAI models to detect depression and suicidality through text data. Studies on therapeutic applications (20/79, 25%) investigated GenAI-based chatbots and adaptive systems for emotional and behavioral support, reporting promising outcomes but revealing limited real-world deployment and safety assurance. Clinician support studies (24/79, 30%) explored GenAI’s role in clinical decision-making, documentation and summarization, therapy support, training and simulation, and psychoeducation. Ethical concerns were consistently reported across the domains. On the basis of these findings, we proposed an integrative ethical framework, GenAI4MH, comprising 4 core dimensions—data privacy and security, information integrity and fairness, user safety, and ethical governance and oversight—to guide the responsible use of GenAI in mental health contexts.
Conclusions
GenAI shows promise in addressing the escalating global demand for mental health services. They may augment traditional approaches by enhancing diagnostic accuracy, offering more accessible support, and reducing clinicians’ administrative burden. However, to ensure ethical and effective implementation, comprehensive safeguards—particularly around privacy, algorithmic bias, and responsible user engagement—must be established.}
}
@article{YAVUZ2025106108,
title = {Adverse human rights impacts of dissemination of nonconsensual sexual deepfakes in the framework of European Convention on Human Rights: A victim-centered perspective},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106108},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106108},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000032},
author = {Can Yavuz},
keywords = {Deepfake, Generative artificial intelligence, Image-based sexual abuse, Deepfake pornography, Technology-facilitated violence, Gender-based violence, Sexual violence, European Convention on Human Rights, Right to respect for private and family life, Freedom of expression, Protection of property},
abstract = {Generative artificial intelligence systems have advanced significantly over the past decade and can now generate synthetic but highly realistic audio, photo, and video, commonly referred to as deepfake. Image-based sexual abuse was the first widespread (mis)use of deepfake technology and continues to be the most common form of its misuse. However, further (empirical) research is needed to examine this phenomenon's adverse human rights implications. This paper analyses the potential adverse human rights impacts of the dissemination of nonconsensual sexual deepfakes in the framework of the European Convention on Human Rights and argues that the dissemination of such deepfakes can hinder the rights protected by the Convention. These include the right to respect for private and family life, as nonconsensual sexual deepfakes can undermine data protection, harm one's image and reputation, and compromise psychological integrity and personal autonomy. Additionally, such deepfakes can threaten freedom of expression by creating a silencing effect on public watchdogs, politicians, and private individuals. Finally, nonconsensual sexual deepfakes can impair the economic and moral rights of pornography performers by abusing their work and bodies to abuse others without authorization and compensation. These findings highlight that the Council of Europe member states must fulfil their obligations to provide effective protection against this technology-facilitated, gender-based, and sexual violence.}
}
@article{SAGLAM2025104530,
title = {Living with and without AI: A mixed-methods study on AI usage, addiction, and 'AIlessphobia' in nursing students},
journal = {Nurse Education in Practice},
volume = {88},
pages = {104530},
year = {2025},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2025.104530},
url = {https://www.sciencedirect.com/science/article/pii/S1471595325002872},
author = {Rukiye Kevser Sağlam and Bilge Kalanlar},
keywords = {Artificial intelligence, Nursing students, Addiction, AIlessphobia},
abstract = {Aim
The aim of this study is to examine nursing students' attitudes toward AI use, their patterns of use and levels of AI addiction, as well as to evaluate the impact of emerging fears such as AIlessphobia.
Background
Generative artificial intelligence (AI) is rapidly evolving and is increasingly being used among university students. Concepts such as “AIlessphobia” -the fear of being without AI- highlight the emergence of these issues.
Design
This study used a mixed-methods design.
Methods
The study was carried out during the 2024–2025 Spring Semester with nursing students. Data were collected using the Scale for Dependence on Artificial Intelligence (DAI) and semi-structured interview questions. Qualitative interviews were conducted with students who scored 15 or higher on DAI. The quantitative sample consists of 200 students and the qualitative sample was determined based on quantitative and qualitative data.
Results
Most participants (81.5 %) reported using AI tools, with ChatGPT being the most preferred among them. The interview included 13 questions and the themes emerged during the individual interviews. Thematic analysis highlighted five themes: educational benefits, negative effects, AI addiction, future expectations and AIlessphobia. Students noted that AI eased learning but reduced critical thinking and reported emotional distress when deprived of AI access.
Conclusions
The widespread use of AI tools in education produces both positive and negative effects. It is essential for educators to support students in integrating these tools with critical thinking skills and digital awareness. Such support is crucial for preventing AI addiction and AIlessphobia.}
}
@article{ASAOUER2026104031,
title = {Generative AI-based intrusion detection systems for intra-vehicle networks},
journal = {Ad Hoc Networks},
volume = {180},
pages = {104031},
year = {2026},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2025.104031},
url = {https://www.sciencedirect.com/science/article/pii/S1570870525002793},
author = {Guettouche Asaouer and Djallel Eddine Boubiche},
keywords = {Generative AI, Intrusion detection, In-vehicle networks, Cybersecurity, CAN bus},
abstract = {With the rise of connected and autonomous vehicles, securing Intra-Vehicle Networks against cyber threats has become a critical challenge. The Controller Area Network bus, a widely used communication protocol in modern vehicles, remains highly vulnerable to sophisticated intrusion attacks. Traditional Machine Learning and Deep Learning based Intrusion Detection Systems have demonstrated limitations in adaptability, real-time performance, and handling zero-day attacks. This survey explores the emerging role of Generative Artificial Intelligence in enhancing IVN security. It examines key GenAI—assessing their potential to address the shortcomings of conventional IDS techniques. A comprehensive review of recent literature is conducted, analyzing the effectiveness of generative approaches in intrusion detection compared to deterministic methods. Key aspects such as detection time, adaptability to unknown threats, and real-time processing constraints are evaluated. Additionally, this paper identifies existing research gaps, emphasizing the need for standardized datasets, federated learning strategies, and improved deployment techniques to ensure the practical viability of GenAI-based IDS in real-world vehicular environments. The insights presented aim to guide future research toward more robust and adaptive security solutions for IVNs.}
}
@article{HWANG2025101230,
title = {Generative AI is useful for second language writing, but when, why, and for how long do learners use it?},
journal = {Journal of Second Language Writing},
volume = {69},
pages = {101230},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101230},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000554},
author = {Haerim Hwang and Xingyu Chang and Jiaxin Sun},
keywords = {Generative AI, Second language writing, Screen recording, Frequency, Duration, Semantic network analysis},
abstract = {Numerous studies have highlighted the benefits of recent advancements in generative artificial intelligence (AI) technology for second language (L2) writing. However, most of these studies have relied on pretest/posttest designs or interview/questionnaire methods that reflect the researchers’ perspectives. To expand the research on this topic, we take two approaches. Firstly, we investigate how L2 learners of English utilize ChatGPT in a writing task in real time by analyzing recordings of their computer screens collected throughout the writing process. Secondly, we explore how they perceive the usefulness of ChatGPT by analyzing their responses to an open-ended question. Frequency and time-series analyses show that the participants primarily utilized ChatGPT to generate ideas, particularly during the initial stages of writing. They also used it later in the writing process, albeit less frequently and for less time overall, for a word/grammar search/check, polishing, and example generation, alongside idea generation. Semantic network analyses of their responses to the open-ended question further reveal that the participants generally held a positive opinion of ChatGPT, valuing its assistance in content creation and time management, while expressing some concerns. The results emphasize the potential of generative AI in facilitating L2 writing and suggest the importance of digital literacy.}
}
@article{CHENG2025101821,
title = {Does generative AI facilitate investor Trading? Early evidence from ChatGPT outages},
journal = {Journal of Accounting and Economics},
pages = {101821},
year = {2025},
issn = {0165-4101},
doi = {https://doi.org/10.1016/j.jacceco.2025.101821},
url = {https://www.sciencedirect.com/science/article/pii/S0165410125000576},
author = {Qiang Cheng and Pengkai Lin and Yue Zhao},
keywords = {Generative AI, ChatGPT, Trading volume, Information asymmetry, Price informativeness},
abstract = {In this paper, we use ChatGPT outages to provide early evidence on whether investors rely on generative artificial intelligence (GenAI) to perform professional tasks and the associated impact on stock price informativeness. We document a significant decline in stock trading volume during ChatGPT outages. The effect is stronger for firms with corporate news released immediately before or during the outages and for firms with higher ownership held by transient institutional investors. We then document declines in short-run price impact and return variance during the outage periods, consistent with reduced informed trading. Lastly, we document a positive effect of GenAI-assisted trading on long-run stock price informativeness. Overall, our findings indicate that a significant number of investors use ChatGPT in ways that influence their trading decisions and market outcomes. Future research can investigate the mechanisms underlying these GenAI effects and the potential risks of using GenAI for trading.}
}
@article{OTTO2025105444,
title = {Human-GenAI interaction for active learning in STEM education: State-of-the-art and future directions},
journal = {Computers & Education},
volume = {239},
pages = {105444},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105444},
url = {https://www.sciencedirect.com/science/article/pii/S036013152500212X},
author = {Sofie Otto and Rea Lavi and Lykke {Brogaard Bertel}},
keywords = {Generative artificial intelligence, Active learning, Higher-order thinking skills, Problem-solving, Collaborative learning, STEM education, Literature review},
abstract = {This systematic state-of-the-art review synthesizes findings from 50 studies examining the integration of GenAI into active learning models (such as problem-based learning, collaborative learning, and inquiry-based learning) within STEM education from high school to graduate levels. The analysis identifies five overarching categories of human–GenAI interaction: Tutoring, Co-creating, Processing, Coaching, and Simulating, primarily leveraged to support individual learners in developing problem-solving, critical thinking, and computational thinking skills. While the findings highlight GenAI's potential to support constructivist active learning, its application remains largely individual in scope. Moreover, challenges related to algorithmic bias, information reliability, privacy, and limited domain specificity constrain the orchestration of synergistic human-GenAI interaction, placing significant pedagogical demands on both educators and learners when interacting with GenAI-powered applications. Future research should explore how human-GenAI interactions can be orchestrated to support more active, collaborative, and context-sensitive learning environments. This includes supporting students in developing the competencies necessary to engage, individually and collaboratively, with GenAI tools reflectively, purposefully, and meaningfully in ways that enhance active learning.}
}
@article{MA2025100336,
title = {Systematically visualizing ChatGPT used in higher education: Publication trend, disciplinary domains, research themes, adoption and acceptance},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100336},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100336},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001395},
author = {Ting Ma},
keywords = {Systematic review, Bibliometric analysis, ChatGPT, Generative artificial intelligence, Higher education},
abstract = {Since it was released in November 2022, ChatGPT has been exerting revolutionary influence on the realm of higher education. In order to obtain a comprehensive understanding of the research landscape, we conduct a systematic literature review on the studies of ChatGPT used in higher education. Both quantitative and qualitative methods were adopted to bibliometrically examine the included literature selected from Web of Science and Scopus through the PRISMA protocol. Tools of VOSviewer and CitNetExplorer were employed to visualize the citation information. Our findings showed that the recent two years witnessed an ever-growing popularity of this research theme. Citation information analysis reveals the most influential authors, countries, sources, organizations and four focused topics. The disciplinary distribution of related research indicates a wide range of categories. More importantly, ChatGPT was found to be versatile in assisting teachers, students and researchers with a variety of tasks, and the factors influencing the acceptance of this technology among college students could be investigated through models like TAM, UTAUT and their extensions. We suggest future studies to focus on the ways to address the limitations and ethical issues of ChatGPT through AI literacy cultivation and joint efforts of all stakeholders.}
}
@article{LEE2024100221,
title = {The impact of generative AI on higher education learning and teaching: A study of educators’ perspectives},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100221},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100221},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000225},
author = {Daniel Lee and Matthew Arnold and Amit Srivastava and Katrina Plastow and Peter Strelan and Florian Ploeckl and Dimitra Lekkas and Edward Palmer},
keywords = {Artificial intelligence, Generative artificial intelligence, Higher education, ChatGPT, Learning and teaching},
abstract = {In recent months, Artificial Intelligence (AI) has had, and will continue to have, a dramatic impact on Higher Education (HE). A study conducted by researchers at a leading university in Australia surveyed 30 of their teaching staff, drawn predominantly from their teaching academy, and interviewed eight of them regarding the impact of AI on HE. Data were analyzed using the procedures of Inductive Thematic Analysis and revealed a lack of any homogenous sentiment around AI in HE and much ambiguity regarding best practice regarding recent technological developments. The results indicate concerns exist around concepts relating to academic integrity, however, these concerns may be exaggerated. Almost half of the participants indicated they were using AI within their teaching roles with the most common design change being modifications to assessments. Less than a quarter of staff agreed the university has adequately equipped them for AI, and more than three quarters indicated they would like support. They unanimously assumed the technology will improve. Keeping in mind universities’ obligation to serve students by preparing them for industry, it is vitally important that the HE sector stays informed of developments in AI and commit to ongoing research and discussions regarding best practice in response to AI. However, anything regarding AI and future developments will be extremely difficult to predict.}
}
@article{HAMED2024108782,
title = {Safeguarding authenticity for mitigating the harms of generative AI: Issues, research agenda, and policies for detection, fact-checking, and ethical AI},
journal = {iScience},
volume = {27},
number = {2},
pages = {108782},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.108782},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224000038},
author = {Ahmed Abdeen Hamed and Malgorzata Zachara-Szymanska and Xindong Wu},
keywords = {Biocomputational method, Bioinformatics, Biological sciences, Computational bioinformatics, Natural sciences, Neural networks, Artificial intelligence, Artificial intelligence applications},
abstract = {Summary
As the influence of transformer-based approaches in general and generative artificial intelligence (AI) in particular continues to expand across various domains, concerns regarding authenticity and explainability are on the rise. Here, we share our perspective on the necessity of implementing effective detection, verification, and explainability mechanisms to counteract the potential harms arising from the proliferation of AI-generated inauthentic content and science. We recognize the transformative potential of generative AI, exemplified by ChatGPT, in the scientific landscape. However, we also emphasize the urgency of addressing associated challenges, particularly in light of the risks posed by disinformation, misinformation, and unreproducible science. This perspective serves as a response to the call for concerted efforts to safeguard the authenticity of information in the age of AI. By prioritizing detection, fact-checking, and explainability policies, we aim to foster a climate of trust, uphold ethical standards, and harness the full potential of AI for the betterment of science and society.}
}
@article{SHIMIZU2023,
title = {Developing Medical Education Curriculum Reform Strategies to Address the Impact of Generative AI: Qualitative Study},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/53466},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000818},
author = {Ikuo Shimizu and Hajime Kasai and Kiyoshi Shikino and Nobuyuki Araki and Zaiya Takahashi and Misaki Onodera and Yasuhiko Kimura and Tomoko Tsukamoto and Kazuyo Yamauchi and Mayumi Asahina and Shoichi Ito and Eiryo Kawakami},
keywords = {artificial intelligence, curriculum reform, generative artificial intelligence, large language models, medical education, qualitative analysis, strengths-weaknesses-opportunities-threats (SWOT) framework},
abstract = {Background
Generative artificial intelligence (GAI), represented by large language models, have the potential to transform health care and medical education. In particular, GAI’s impact on higher education has the potential to change students’ learning experience as well as faculty’s teaching. However, concerns have been raised about ethical consideration and decreased reliability of the existing examinations. Furthermore, in medical education, curriculum reform is required to adapt to the revolutionary changes brought about by the integration of GAI into medical practice and research.
Objective
This study analyzes the impact of GAI on medical education curricula and explores strategies for adaptation.
Methods
The study was conducted in the context of faculty development at a medical school in Japan. A workshop involving faculty and students was organized, and participants were divided into groups to address two research questions: (1) How does GAI affect undergraduate medical education curricula? and (2) How should medical school curricula be reformed to address the impact of GAI? The strength, weakness, opportunity, and threat (SWOT) framework was used, and cross-SWOT matrix analysis was used to devise strategies. Further, 4 researchers conducted content analysis on the data generated during the workshop discussions.
Results
The data were collected from 8 groups comprising 55 participants. Further, 5 themes about the impact of GAI on medical education curricula emerged: improvement of teaching and learning, improved access to information, inhibition of existing learning processes, problems in GAI, and changes in physicians’ professionality. Positive impacts included enhanced teaching and learning efficiency and improved access to information, whereas negative impacts included concerns about reduced independent thinking and the adaptability of existing assessment methods. Further, GAI was perceived to change the nature of physicians’ expertise. Three themes emerged from the cross-SWOT analysis for curriculum reform: (1) learning about GAI, (2) learning with GAI, and (3) learning aside from GAI. Participants recommended incorporating GAI literacy, ethical considerations, and compliance into the curriculum. Learning with GAI involved improving learning efficiency, supporting information gathering and dissemination, and facilitating patient involvement. Learning aside from GAI emphasized maintaining GAI-free learning processes, fostering higher cognitive domains of learning, and introducing more communication exercises.
Conclusions
This study highlights the profound impact of GAI on medical education curricula and provides insights into curriculum reform strategies. Participants recognized the need for GAI literacy, ethical education, and adaptive learning. Further, GAI was recognized as a tool that can enhance efficiency and involve patients in education. The study also suggests that medical education should focus on competencies that GAI hardly replaces, such as clinical experience and communication. Notably, involving both faculty and students in curriculum reform discussions fosters a sense of ownership and ensures broader perspectives are encompassed.}
}
@article{NENSA2025100001,
title = {Embracing generative AI: A necessary evolution in professional writing},
journal = {European Journal of Radiology Artificial Intelligence},
volume = {1},
pages = {100001},
year = {2025},
issn = {3050-5771},
doi = {https://doi.org/10.1016/j.ejrai.2024.100001},
url = {https://www.sciencedirect.com/science/article/pii/S305057712400001X},
author = {Felix Nensa},
keywords = {GenAI, LLM, ChatGPT, AI, Writing},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has become an integral part of our professional lives. Despite their transformative potential, many professionals remain cautious about using these tools for drafting and editing manuscripts. While it is reasonable for academic journals to request transparency regarding AI usage, fundamental reservations against employing generative AI (GenAI) are outdated. A useful analogy can be drawn from the film Hidden Figures, which depicts the arrival of IBM computers at NASA, eventually replacing human “computers” for manual calculations. Dorothy Vaughan, the supervisor of these human experts, anticipated the change and adapted proactively by teaching her team programming skills. Today, it is unthinkable for scientific calculations to be done without software, just as it will soon be unthinkable to draft professional texts without AI assistance. GenAI should be seen as a tool that enhances human creativity rather than replacing it. By handling mundane aspects of writing, it allows authors to focus on critical thinking and idea generation. Transparency in AI use fosters trust and maintains ethical standards. Authors are encouraged to use GenAI under supervision and disclose its use openly. This will not only improve manuscript quality but also help authors allocate more time to innovation and creative thinking. Embracing GenAI is not merely an option; it represents an essential evolution in the way we approach writing.}
}