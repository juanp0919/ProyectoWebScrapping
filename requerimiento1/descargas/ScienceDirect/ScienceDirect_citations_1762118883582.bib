@article{BASARAN2025111145,
title = {XAInomaly: Explainable and interpretable Deep Contractive Autoencoder for O-RAN traffic anomaly detection},
journal = {Computer Networks},
volume = {261},
pages = {111145},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111145},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625001136},
author = {Osman Tugay Basaran and Falko Dressler},
keywords = {Explainable and trustworthy AI, Generative AI, O-RAN, Autoencoder, Anomaly detection, Network management},
abstract = {Generative Artificial Intelligence (AI) techniques have become integral part in advancing next generation wireless communication systems by enabling sophisticated data modeling and feature extraction for enhanced network performance. In the realm of open radio access networks (O-RAN), characterized by their disaggregated architecture and heterogeneous components from multiple vendors, the deployment of generative models offers significant advantages for network management such as traffic analysis, traffic forecasting and anomaly detection. However, the complex and dynamic nature of O-RAN introduces challenges that necessitate not only accurate detection mechanisms but also reduced complexity, scalability, and most importantly interpretability to facilitate effective network management. In this study, we introduce the XAInomaly framework, an explainable and interpretable Semi-supervised (SS) Deep Contractive Autoencoder (DeepCAE) design for anomaly detection in O-RAN. Our approach leverages the generative modeling capabilities of our SS-DeepCAE model to learn compressed, robust representations of normal network behavior, which captures essential features, enabling the identification of deviations indicative of anomalies. To address the black-box nature of deep learning models, we propose reactive Explainable AI (XAI) technique called fastshap-C, which is providing transparency into the model’s decision-making process and highlighting the features contributing to anomaly detection.}
}
@article{LI20241581,
title = {Sentiment Analysis Using E-Commerce Review Keyword-Generated Image with a Hybrid Machine Learning-Based Model},
journal = {Computers, Materials and Continua},
volume = {80},
number = {1},
pages = {1581-1599},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.052666},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824005113},
author = {Jiawen Li and Yuesheng Huang and Yayi Lu and Leijun Wang and Yongqi Ren and Rongjun Chen},
keywords = {Sentiment analysis, keyword-generated image, machine learning, Word2Vec-TextRank, CNN-SVM},
abstract = {In the context of the accelerated pace of daily life and the development of e-commerce, online shopping is a mainstream way for consumers to access products and services. To understand their emotional expressions in facing different shopping experience scenarios, this paper presents a sentiment analysis method that combines the e-commerce review keyword-generated image with a hybrid machine learning-based model, in which the Word2Vec-TextRank is used to extract keywords that act as the inputs for generating the related images by generative Artificial Intelligence (AI). Subsequently, a hybrid Convolutional Neural Network and Support Vector Machine (CNN-SVM) model is applied for sentiment classification of those keyword-generated images. For method validation, the data randomly comprised of 5000 reviews from Amazon have been analyzed. With superior keyword extraction capability, the proposed method achieves impressive results on sentiment classification with a remarkable accuracy of up to 97.13%. Such performance demonstrates its advantages by using the text-to-image approach, providing a unique perspective for sentiment analysis in the e-commerce review data compared to the existing works. Thus, the proposed method enhances the reliability and insights of customer feedback surveys, which would also establish a novel direction in similar cases, such as social media monitoring and market trend research.}
}
@article{GROZA2025100057,
title = {Realising the potential impact of artificial intelligence for rare diseases – A framework},
journal = {Rare},
volume = {3},
pages = {100057},
year = {2025},
issn = {2950-0087},
doi = {https://doi.org/10.1016/j.rare.2024.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2950008724000401},
author = {Tudor Groza and Chun-Hung Chan and David A. Pearce and Gareth Baynam},
keywords = {Rare diseases, Patient journey, Generative artificial intelligence, Diagnosis, Care coordination},
abstract = {Rare diseases (RD) are conditions affecting fewer than 1 in 2000 persons, with over 7000 largely genetic RDs affecting 3.5 %-5.9 % of the global population, or approximately 262.9–446.2 million people. The substantial healthcare burden and costs, such as the $1 trillion annual expense in the USA, highlight the urgent need for improved RD management. The International Rare Diseases Research Consortium (IRDiRC) addresses this need through global collaboration, aiming for timely and accurate diagnosis, development of 1000 new therapies, and methodologies to measure impact by 2027. IRDiRC's initiatives include biannual meetings and workshops, like the AI-focused workshop in October 2023. This identified AI as crucial for advancing RD research and proposed a Framework for AI to enhance the RD patient journey by addressing efficiency and quality of life through modular solutions mapped to critical stages. The Framework integrates diverse data sources to improve diagnosis, treatment, and impact assessment, reflecting a holistic, cross-sector approach. By guiding multi-stakeholder efforts, the Framework aims to harness AI’s potential to significantly improve rare disease care.}
}
@article{MUMUNI2025113,
title = {Automated data processing and feature engineering for deep learning and big data applications: A survey},
journal = {Journal of Information and Intelligence},
volume = {3},
number = {2},
pages = {113-153},
year = {2025},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949715924000027},
author = {Alhassan Mumuni and Fuseini Mumuni},
keywords = {AutoML, Automated data preprocessing, Data processing, Automated feature engineering, Generative artificial intelligence, Big data},
abstract = {Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for big data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing – e.g., data cleaning, labeling, missing data imputation, and categorical data encoding – as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering – specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.}
}
@article{CHOWDHURY2025129906,
title = {Handling language prior and compositional reasoning issues in Visual Question Answering system},
journal = {Neurocomputing},
volume = {635},
pages = {129906},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129906},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225005788},
author = {Souvik Chowdhury and Badal Soni},
keywords = {Visual Question Answering, Large language model, In-context learning, Computer vision, Natural language processing, Generative artificial intelligence},
abstract = {Visual Question Answering (VQA) models often suffer from language bias, favoring common but incorrect answers, and struggle with compositional reasoning in complex queries. This paper proposes a unified approach using a multimodal large language model enhanced with adaptive prompts designed for specific tasks. Our method directly addresses these issues by reducing language bias and improving compositional reasoning. Extensive evaluations on benchmark datasets, including VQA v2.0, VQACP, TDIUC, GQA, Visual7 W, TextVQA, and STVQA show that our approach outperforms state-of-the-art models, achieving accuracy improvements of 8% to 9%. These results demonstrate the effectiveness of our method in enhancing VQA accuracy, making it a significant advancement for more reliable and robust applications in real-world scenarios.}
}
@article{SHAYEGAN2025100722,
title = {A hybrid approach to content generation based on user experience using generative AI elements},
journal = {Machine Learning with Applications},
volume = {21},
pages = {100722},
year = {2025},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2025.100722},
url = {https://www.sciencedirect.com/science/article/pii/S2666827025001057},
author = {Mohammad Javad Shayegan and Hossein Hosseinpour},
keywords = {User experience (UX), User-centric, Content generation, Large language models (LLMS), Generative AI, GAI},
abstract = {Understanding and analyzing User Experience (UX) is a critical challenge in e-commerce. This study addresses the integration of UX analysis and Generative Artificial Intelligence (GAI) for content creation, presenting a two-phase approach. In the first phase, UX elements were extracted from user reviews of Amazon digital products and analyzed using clustering algorithms, including K-means, enhanced K-means, and Self-Organizing Maps (SOM). In the second phase, the top UX elements identified were used to generate promotional content with GPT-3.5 Turbo and Claude 3.5 Sonnet language models. The content was evaluated using the Perplexity metric, with three AI models—BERT, GPT-2, and DistilBERT. Results show that the enhanced K-means algorithm paired with GPT-3.5 Turbo achieved the best performance, yielding a Perplexity score of 3.476. This approach demonstrates the potential for leveraging real user data to create targeted and engaging content, providing businesses with actionable insights for improving audience engagement.}
}
@article{CLARKE2025106131,
title = {Principles for the responsible application of Generative AI},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106131},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106131},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000045},
author = {Roger Clarke},
keywords = {Risk assessment, Large language models, GenAI artefact, ChatGPT, Regulation},
abstract = {The quest for Artificial Intelligence (AI) has comprised successive waves of excessive enthusiasm followed by long, dispirited lulls. Most recently, during the first 3–4 years of public access to Generative Artificial Intelligence (GenAI), many authors have bought into the bullish atmosphere, replaying consultancies' predictions about gold mines of process efficiency and innovation. A more balanced approach to the technology is needed. Instances of apparently positive results need calm analysis, firstly to distinguish mirages from genuine contributions; secondly, to identify ways to effectively exploit the new capabilities; and thirdly, to formulate guidance for the avoidance and mitigation of negative consequences. This article's first contribution is to ground the evaluation of GenAI's pathway, applications, impacts, implications and risks in a sufficiently deep appreciation of the technology's nature and key features. A wide range of sources is drawn on, in order to present descriptions of the processes involved in text-based GenAI. From those processes, 20 key characteristics are abstracted that together give rise to the promise and the threats GenAI embodies. The effects of GenAI derive not from the technological features alone, but also from the patterns within which it is put to use. By mapping usage patterns across to domains of application, the phenomenon's impacts and implications can be more reliably delineated. The analysis provides a platform whereby the article's final contribution can be made. Previously-formulated principles for the responsible application of AI of all kinds are applied in the particular context of GenAI.}
}
@article{XIAO2025102835,
title = {Can ChatGPT replace humans in crisis communication? The effects of AI-mediated crisis communication on stakeholder satisfaction and responsibility attribution},
journal = {International Journal of Information Management},
volume = {80},
pages = {102835},
year = {2025},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102835},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000835},
author = {Yi Xiao and Shubin Yu},
keywords = {Chatbot, AI, Crisis communication, Instructing information, Adjusting information},
abstract = {Imagine a world where chatbots are the first responders to crises, efficiently addressing concerns and providing crucial information. ChatGPT has demonstrated the capability of GenAI (Generative Artificial Intelligence)-powered chatbots when deployed to answer crisis-related questions in a timely and cost-efficient manner, thus replacing humans in crisis communication. However, public reactions to such messages remain unknown. To address this problem, this study recruited participants (N1 = 399, N2 = 189, and N3 = 121) and conducted two online vignette experiments and a qualitative survey. The results suggest that, when organizations fail to handle crisis-related requests, stakeholders exhibit higher satisfaction and lower responsibility attribution to chatbots providing instructing (vs. adjusting) information, as they are perceived to be more competent. However, when organizations satisfy requests, chatbots that provide adjusting (vs. instructing information) lead to higher satisfaction and lower responsibility attribution due to higher perceived competence. The second experiment involving a public emergency crisis scenario reveals that, regardless of the information provided (instructing or adjusting), stakeholders exhibit greater satisfaction and positive attitudes toward high-competence (vs. low-competence) chatbots. The qualitative study further confirms the experimental findings and offers insights to improve crisis chatbots. These findings contribute to the literature by extending situational crisis communication theory to nonhuman touchpoints and providing a deeper understanding of using chatbots in crisis communication through the lens of machine heuristics. The study also offers practical guidance for organizations to strategically integrate chatbots and human agents in crisis management based on context.}
}
@article{WANG2024100181,
title = {Comparing ChatGPT and clinical nurses’ performances on tracheostomy care: A cross-sectional study},
journal = {International Journal of Nursing Studies Advances},
volume = {6},
pages = {100181},
year = {2024},
issn = {2666-142X},
doi = {https://doi.org/10.1016/j.ijnsa.2024.100181},
url = {https://www.sciencedirect.com/science/article/pii/S2666142X24000080},
author = {Tongyao Wang and Juan Mu and Jialing Chen and Chia-Chin Lin},
keywords = {Generative artificial intelligence, ChatGPT, Education, Tracheostomy, Nursing},
abstract = {Background
The release of ChatGPT for general use in 2023 by OpenAI has significantly expanded the possible applications of generative artificial intelligence in the healthcare sector, particularly in terms of information retrieval by patients, medical and nursing students, and healthcare personnel.
Objective
To compare the performance of ChatGPT-3.5 and ChatGPT-4.0 to clinical nurses on answering questions about tracheostomy care, as well as to determine whether using different prompts to pre-define the scope of the ChatGPT affects the accuracy of their responses.
Design
Cross-sectional study.
Setting
The data collected from the ChatGPT was collected using the ChatGPT-3.5 and 4.0 using access provided by the University of Hong Kong. The data from the clinical nurses working in mainland China was collected using the Qualtrics survey program.
Participants
No participants were needed for collecting the ChatGPT responses. A total of 272 clinical nurses, with 98.5 % of them working in tertiary care hospitals in mainland China, were recruited using a snowball sampling approach.
Method
We used 43 tracheostomy care-related questions in a multiple-choice format to evaluate the performance of ChatGPT-3.5, ChatGPT-4.0, and clinical nurses. ChatGPT-3.5 and GPT-4.0 were both queried three times with the same questions by different prompts: no prompt, patient-friendly prompt, and act-as-nurse prompt. All responses were independently graded by two qualified otorhinolaryngology nurses on a 3-point accuracy scale (correct, partially correct, and incorrect). The Chi-squared test and Fisher exact test with post-hoc Bonferroni adjustment were used to assess the differences in performance between the three groups, as well as the differences in accuracy between different prompts.
Results
ChatGPT-4.0 showed significantly higher accuracy, with 64.3 % of responses rated as ‘correct’, compared to 60.5 % in ChatGPT-3.5 and 36.7 % in clinical nurses (X 2 = 74.192, p < .001). Except for the ‘care for the tracheostomy stoma and surrounding skin’ domain (X2 = 6.227, p = .156), scores from ChatGPT-3.5 and -4.0 were significantly better than nurses’ on domains related to airway humidification, cuff management, tracheostomy tube care, suction techniques, and management of complications. Overall, ChatGPT-4.0 consistently performed well in all domains, achieving over 50 % accuracy in each domain. Alterations to the prompt had no impact on the performance of ChatGPT-3.5 or -4.0.
Conclusion
ChatGPT may serve as a complementary medical information tool for patients and physicians to improve knowledge in tracheostomy care.
Tweetable abstract
ChatGPT-4.0 can answer tracheostomy care questions better than most clinical nurses. There is no reason nurses should not be using it.}
}
@article{YAU2025130847,
title = {Combinations of generative adversarial network and reinforcement learning: A survey},
journal = {Neurocomputing},
volume = {650},
pages = {130847},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130847},
url = {https://www.sciencedirect.com/science/article/pii/S092523122501519X},
author = {Kok-Lim Alvin Yau and Yung-Wey Chong and Xiumei Fan and Faranak Nejati and Mohammad Kazem Chamran and Shalini Darmaraju},
keywords = {Generative artificial intelligence, Generative adversarial network, GAN, Reinforcement learning, RL, Artificial intelligence},
abstract = {A generative adversarial network (GAN) consists of a generator and a discriminator, which extract features and compete through min–max optimization in a zero-sum two-player game. Reinforcement learning (RL) enables a decision maker (agent) to observe, learn, and select optimal actions within a dynamic environment over time. The combination of these two artificial intelligence approaches, referred to as GAN-RL, presents a powerful synergy that leverages their strengths while addressing their respective limitations. This paper provides the first comprehensive review that systematically examines GAN-RL, offering an in-depth analysis of its theoretical foundations, key methodologies, and diverse applications. Specifically, we categorize GAN-RL approaches based on five primary objectives: (a) generating comprehensive synthetic datasets for training; (b) minimizing the discrepancies between value (or cumulative reward) distributions, where the cumulative reward is defined as the total sum of rewards an agent accumulates over the course of its interactions with the environment; (c) predicting the next scenario; (d) predicting the gradient of the generator in discrete tasks; and (e) learning from demonstrations. Our analysis highlights how GAN-RL enhances system performance, including improvements in cumulative reward, convergence rate, and prediction accuracy. By identifying open challenges and future research directions, this review fills a critical gap in the literature and serves as a valuable resource for researchers exploring the intersection of GANs and RL.}
}
@article{FAN2026111599,
title = {Integrating large language models into manufacturing execution systems: A systematic framework for photoresist manufacturing processes},
journal = {Computers & Industrial Engineering},
volume = {211},
pages = {111599},
year = {2026},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.111599},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225007454},
author = {Shu-Kai S. Fan and Jiun-Tze Wang and Chih-Hung Jen},
keywords = {Manufacturing execution systems (MES), Large Language Models (LLMs), Reinforcement learning (RL)},
abstract = {In the context of an increasingly dynamic and competitive marketplace, traditional manufacturers that fail to adapt face an accelerating trajectory toward obsolescence. Digital transformation, particularly through the implementation of advanced Manufacturing Execution Systems (MES), presents a critical avenue for enhancing operational competitiveness and resilience. Despite the capabilities of MES to facilitate systematic production monitoring and control, these systems continue to rely heavily on human intervention, introducing the potential for operational inefficiencies and human-induced errors. Recent advancements in generative artificial intelligence (Gen AI) offer transformative opportunities to augment MES functionality. This article proposes the integration of large language models (LLMs) within MES architectures to provide real-time alarm detection, production line monitoring, and autonomous control support for the photoresist industry. Additionally, cutting-edge reinforcement learning (RL) algorithms are incorporated to analyze complex operational data streams and to deliver optimized, AI-generated recommendations for decision-makers. The proposed LLMs-based framework aims to significantly enhance decision accuracy, operational efficiency, and adaptive capacity in modern manufacturing environments.}
}
@article{SHIN202340,
title = {Bridging the gap of bibliometric analysis: The evolution, current state, and future directions of tourism research using ChatGPT},
journal = {Journal of Hospitality and Tourism Management},
volume = {57},
pages = {40-47},
year = {2023},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1447677023001596},
author = {Hakseung Shin and Juhyun Kang},
keywords = {Generative artificial intelligence (GAI), ChatGPT, Bibliometric analysis, Tourism research, Knowledge structure, Research agenda},
abstract = {ChatGPT can generate coherent text with unprecedented fluency by processing massive amounts of text data. Given the chatbot's remarkable accuracy in responses to a wide range of topics, this research aims to examine the evolution, present status, and future directions of tourism research using ChatGPT. A total of 15 interview questions were developed and semi-structured interviews were conducted with ChatGPT. The responses were qualitatively analyzed to identify the main themes associated with the issues of tourism research, such as key topics of previous research, forces to influence the evolution, achievement and limitations of research, and under examined areas of research. The use of ChatGPT provided valuable insights into the latest progressions within tourism research. For example, unlike the widely held view adopted by most tourism studies, ChatGPT indicates that the interdisciplinary nature of tourism research strongly contributes to the development of other academic fields, suggesting the maturity of tourism research.}
}
@article{CHOI2024,
title = {Optimizing ChatGPT’s Interpretation and Reporting of Delirium Assessment Outcomes: Exploratory Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/51383},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24005225},
author = {Yong K Choi and Shih-Yin Lin and Donna Marie Fick and Richard W Shulman and Sangil Lee and Priyanka Shrestha and Kate Santoso},
keywords = {generative artificial intelligence, generative AI, large language models, ChatGPT, delirium detection, Sour Seven Questionnaire, prompt engineering, clinical vignettes, medical education, caregiver education},
abstract = {Background
Generative artificial intelligence (AI) and large language models, such as OpenAI’s ChatGPT, have shown promising potential in supporting medical education and clinical decision-making, given their vast knowledge base and natural language processing capabilities. As a general purpose AI system, ChatGPT can complete a wide range of tasks, including differential diagnosis without additional training. However, the specific application of ChatGPT in learning and applying a series of specialized, context-specific tasks mimicking the workflow of a human assessor, such as administering a standardized assessment questionnaire, followed by inputting assessment results in a standardized form, and interpretating assessment results strictly following credible, published scoring criteria, have not been thoroughly studied.
Objective
This exploratory study aims to evaluate and optimize ChatGPT’s capabilities in administering and interpreting the Sour Seven Questionnaire, an informant-based delirium assessment tool. Specifically, the objectives were to train ChatGPT-3.5 and ChatGPT-4 to understand and correctly apply the Sour Seven Questionnaire to clinical vignettes using prompt engineering, assess the performance of these AI models in identifying and scoring delirium symptoms against scores from human experts, and refine and enhance the models’ interpretation and reporting accuracy through iterative prompt optimization.
Methods
We used prompt engineering to train ChatGPT-3.5 and ChatGPT-4 models on the Sour Seven Questionnaire, a tool for assessing delirium through caregiver input. Prompt engineering is a methodology used to enhance the AI’s processing of inputs by meticulously structuring the prompts to improve accuracy and consistency in outputs. In this study, prompt engineering involved creating specific, structured commands that guided the AI models in understanding and applying the assessment tool’s criteria accurately to clinical vignettes. This approach also included designing prompts to explicitly instruct the AI on how to format its responses, ensuring they were consistent with clinical documentation standards.
Results
Both ChatGPT models demonstrated promising proficiency in applying the Sour Seven Questionnaire to the vignettes, despite initial inconsistencies and errors. Performance notably improved through iterative prompt engineering, enhancing the models’ capacity to detect delirium symptoms and assign scores. Prompt optimizations included adjusting the scoring methodology to accept only definitive “Yes” or “No” responses, revising the evaluation prompt to mandate responses in a tabular format, and guiding the models to adhere to the 2 recommended actions specified in the Sour Seven Questionnaire.
Conclusions
Our findings provide preliminary evidence supporting the potential utility of AI models such as ChatGPT in administering standardized clinical assessment tools. The results highlight the significance of context-specific training and prompt engineering in harnessing the full potential of these AI models for health care applications. Despite the encouraging results, broader generalizability and further validation in real-world settings warrant additional research.}
}
@article{LIN202485,
title = {Towards an AI policy framework in scholarly publishing},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {2},
pages = {85-88},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002887},
author = {Zhicheng Lin},
keywords = {generative artificial intelligence, large language models, science, policy, publishing},
abstract = {The rapid adoption of artificial intelligence (AI) tools in academic research raises pressing ethical concerns. I examine major publishing policies in science and medicine, uncovering inconsistencies and limitations in guiding AI usage. To encourage responsible AI integration while upholding transparency, I propose an enabling framework with author and reviewer policy templates.}
}
@article{BAO2025328,
title = {Platform-based task assignment for social manufacturing (PBTA4SM): State-of-the-art review and future directions},
journal = {Journal of Manufacturing Systems},
volume = {78},
pages = {328-350},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524003145},
author = {Yuguang Bao and Xinguo Ming and Xianyu Zhang and Fei Tao and Jiewu Leng and Yang Liu},
keywords = {Platform-based task assignment, Social manufacturing, Supply-demand matching, Collaborative manufacturing, Democratized manufacturing},
abstract = {Mass individualization is calling for a more sustainable manufacturing paradigm which can address the paradoxes of diversity, complexity, and affordability. Social Manufacturing (SM) represents a democratized servitization trend trying to reshape the traditional production relationship between consumers and manufacturers. To achieve the SM visions, new operational mechanisms for SM should be constructed to overcome the challenges of information sharing, accuracy, efficiency, security, sovereignty, etc. The survey found that task assignment (TA) is one of the foundational mechanisms for the implementation of regular autonomous manufacturing systems, as well as the role of TA is further amplified for distributed collaborative environments. Therefore, inspired by the relevant research of management science, Platform-based Task Assignment (PBTA) is proposed to distinguish and conceptualize this different research topic. In SM platforms, the diverse capacities and resources can be shared, so that knowing "who can do” and “select whom to do" is more important than knowing "how to do". Furthermore, the studies on TA for SM present a difference from the previous studies on TA in manufacturing. From a perspective of supply-demand mapping, PBTA illustrates the foundational operational mechanism for SM attracting many researchers’ attention from different fields. Meanwhile, research on PBTA is also required for the platform practices in the era of digital, shared, and platform economy. Given the academic importance and practical value, this survey carefully selects 250 valuable research articles relevant to PBTA for SM. A novel workflow model and knowledge framework, namely PBTA4SM, is proposed to identify and organize the critical issues and challenges. This study shows the state-of-the-art research advancement of PBTA including task design considerations, modelling methods, typical engineering problems, algorithms, decision patterns, key activities, and governance mechanisms. Finally, we complete this holistic survey by highlighting eight potential directions for future research in the Generative Artificial Intelligence (GAI) era.}
}
@article{NTOUMANIS2025102879,
title = {Self-determination theory informed research for promoting physical activity: Contributions, debates, and future directions},
journal = {Psychology of Sport and Exercise},
volume = {80},
pages = {102879},
year = {2025},
issn = {1469-0292},
doi = {https://doi.org/10.1016/j.psychsport.2025.102879},
url = {https://www.sciencedirect.com/science/article/pii/S1469029225000780},
author = {Nikos Ntoumanis and Arlen C. Moller},
keywords = {Narrative review, Tripartite model, Behavioral science, Motivation, Financial incentives, Competition},
abstract = {In this review we evaluate the applications of self-determination theory (SDT) research to promote motivation for physical activity (PA) and exercise. The evidence suggests that SDT-informed interventions are often effective at changing health behaviors, including PA/exercise, and associated health outcomes. The effect sizes are small to moderate and are often mediated by increases in autonomous motivation (primarily), interpersonal support for basic psychological needs, and competence need satisfaction. We also identify conceptual debates within the SDT literature and between SDT and other literatures, and discuss their relevance with respect to PA. We particularly focus on tripartite conceptualizations of interpersonal styles and psychological needs, whether there are more than three basic psychological needs, and the use of financial incentives and competition to promote PA. Our review also provides future conceptual and methodological directions for SDT-based research, building on advances in technology (e.g., generative Artificial Intelligence and Large Language Models) and the broader field of behavioral science (e.g., optimization designs, system-level interventions, behavior change intervention ontologies).}
}
@article{CELIKTUTAN2024496,
title = {Acceptability lies in the eye of the beholder: Self-other biases in GenAI collaborations},
journal = {International Journal of Research in Marketing},
volume = {41},
number = {3},
pages = {496-512},
year = {2024},
issn = {0167-8116},
doi = {https://doi.org/10.1016/j.ijresmar.2024.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167811624000442},
author = {Begum Celiktutan and Anne-Kathrin Klesse and Mirjam A. Tuk},
keywords = {GenAI, ChatGPT, Inferred contribution, Intellectual ownership, Self-other difference, Biased self-evaluation},
abstract = {Since the release of ChatGPT, heated discussions have focused on the acceptable uses of generative artificial intelligence (GenAI) in education, science, and business practices. A salient question in these debates pertains to perceptions of the extent to which creators contribute to the co-produced output. As the current research establishes, the answer to this question depends on the evaluation target. Nine studies (seven preregistered, total N = 4498) document that people evaluate their own contributions to co-produced outputs with ChatGPT as higher than those of others. This systematic self–other difference stems from differential inferences regarding types of GenAI usage behavior: People think that they predominantly use GenAI for inspiration, but others use it to outsource work. These self–other differences in turn have direct ramifications for GenAI acceptability perceptions, such that usage is considered more acceptable for the self than for others. The authors discuss the implications of these findings for science, education, and marketing.}
}
@article{LAI2025,
title = {Roles of AI-Based Synthetic Data in Health Economics and Outcomes Research},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.2157},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525023125},
author = {Tim C. Lai and Surachat Ngorsuraches},
keywords = {data privacy, generative artificial intelligence, privacy enhancing technology, synthetic data},
abstract = {Objectives
We aim to raise awareness of potential applications of synthetic data within the health economics and outcomes research (HEOR) community.
Methods
We provide a concise overview of synthetic data, including data generation and types. We then discuss 3 major data-associated challenges and how synthetic data may be used to address them. Finally, we discuss data utility, privacy protection, potential concerns of its applicability, and future research direction.
Results
The use of synthetic data is an alternative privacy protection technique to enhance data availability, strengthen the robustness of findings for underrepresented populations, and alleviate data insufficiency issues in rare disease research. More studies are needed to explore synthetic data use and address data challenges in HEOR studies. Furthermore, the development of an evaluation framework is encouraged to better support the integration of synthetic data into the HEOR field.
Conclusions
Synthetic data provide a unique opportunity to overcome data-related challenges in HEOR.}
}
@article{YANG2025116061,
title = {A systematic review of building energy performance forecasting approaches},
journal = {Renewable and Sustainable Energy Reviews},
volume = {223},
pages = {116061},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116061},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125007348},
author = {Yizhou Yang and Qiuhua Duan and Forooza Samadi},
keywords = {Building energy performance forecasting (BEPF), Physics-based modeling, Black-box modeling, Hybrid-driven, Thermal properties of materials, Weather impact, Occupant behavior, Real-time adaptability, Artificial intelligence (AI) technique},
abstract = {Building energy performance forecasting (BEPF) is an active area of research with the potential to improve the efficiency of building energy management systems, support global sustainability goals, and mitigate climate change impacts. This systematic review examines three main prediction methods: model-driven, data-driven, and hybrid-driven, each with different principles, basics, advantages, disadvantages, practical applications, challenges, and limitations in addressing the complexities of building energy performance. The review focuses on key influencing factors, including building features, climatic conditions, and occupant behavior, while identifying critical research gaps in current methodologies. Through a bibliometric analysis of 95 relevant publications from 2019 to 2024, this review provides a quantitative overview of research progress and emerging trends. Findings indicate that although BEPF techniques have evolved rapidly, most studies continue to overlook the variability and complexity of occupant behavior, a factor with significantly affects forecast accuracy. To address this, we propose a modular AI-integrated forecasting framework that leverages the strengths of existing approaches, integrates real-time IoT data, and incorporate advanced artificial intelligence techniques, such as generative Artificial Intelligence, reinforcement learning, and Large Language Models (LLMs). A decision-making framework is also introduced to guide method selection based on specific building characteristics, data availability, desired accuracy, and operational goals, offering practical guidance for engineering and policy applications. Additionally, future research should extend beyond individual building dynamics to include a wider range of community-level determinants, such as policy frameworks, economic factors, and social determinants of health considerations (SDOH), aiming for a more comprehensive understanding of building energy consumption patterns. This review not only synthesizes current knowledge but also lays the foundation for future innovations in BEPF. We advocate for moving towards an AI-enhanced, adaptive forecasting model that can integrate different driven methods, capture the variability and unpredictability of occupant behavior, and improve the accuracy and reliability of energy forecasts.}
}
@article{ESPOSITO2026112607,
title = {Generative AI for software architecture. Applications, challenges, and future directions},
journal = {Journal of Systems and Software},
volume = {231},
pages = {112607},
year = {2026},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112607},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002766},
author = {Matteo Esposito and Xiaozhou Li and Sergio Moreschini and Noman Ahmad and Tomas Cerny and Karthik Vaidhyanathan and Valentina Lenarduzzi and Davide Taibi},
keywords = {Generative AI, Software architecture, Multivocal literature review, Large language model, Prompt engineering, Model human interaction, XAI},
abstract = {Context:
Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy.
Aim:
Systematically synthesize the use, rationale, contexts, usability, and challenges of GenAI in software architecture.
Method:
Multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, reported challenges, and extracting themes via open coding.
Results:
This review identifies a significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieval-augmented generation (RAG). GenAI has been applied mostly to the initial stages of the Software Architecture Life Cycle (SALC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the main targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks.
Conclusions:
GenAI shows significant potential in software design, but there are several challenges on its way towards greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to overcome the gap between theoretical possibility and practical use. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{KUO2026105463,
title = {Developing an AI learning companion for mathematics problem solving in elementary schools},
journal = {Computers & Education},
volume = {240},
pages = {105463},
year = {2026},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105463},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002313},
author = {Bor-Chen Kuo and Zong-En Bai and Chia-Hua Lin},
keywords = {Taiwan Adaptive Learning Platform, Generative artificial intelligence, AI learning companion, Large language models, Lag sequential analysis},
abstract = {This study examined the impact of integrating the Taiwan Adaptive Learning Platform (TALP) with generative AI-based learning companion (TALPers) on fifth-grade students' mathematics learning performance. The integration was applied to both self-learning and remedial instruction, with both contexts incorporating Socratic dialogue and Pólya's problem-solving strategy. Results showed that video-based self-learning with TALPer support yielded the highest learning gains. In the remedial setting, students receiving TALPer support also demonstrated significantly better performance. Both approaches were particularly effective for low-achieving students. Lag Sequential Analysis (LSA) further revealed that high-achieving students engaged in more complex interaction patterns with TALPers, sustaining feedback cycles, whereas low-achieving students exhibited simpler interaction patterns. These findings provide empirical support for implementing AI-augmented learning systems in mathematics education and suggest that structured AI support can promote differentiated instruction and student engagement to help bridge achievement gaps.}
}
@article{JIN2025100107,
title = {Deep learning for three-dimensional (3D) plant phenomics},
journal = {Plant Phenomics},
volume = {7},
number = {4},
pages = {100107},
year = {2025},
issn = {2643-6515},
doi = {https://doi.org/10.1016/j.plaphe.2025.100107},
url = {https://www.sciencedirect.com/science/article/pii/S264365152500113X},
author = {Shichao Jin and Dawei Li and Ting Yun and Jianling Tang and Ke Wang and Shaochen Li and Hongyi Yang and Si Yang and Shan Xu and Lin Cao and Haifeng Xia and Qinghua Guo and Yu Zhang and Dong Jiang and Yanfeng Ding},
keywords = {3D phenomics, Deep learning, Dataset, Sampling, Annotation},
abstract = {Plant phenomics, the comprehensive study of plant phenotypes, has gained prominence as a vital tool for understanding the intricate relationships between genotypes and the environment. Image-based plant phenomics has progressed rapidly, and three-dimensional (3D) phenotyping is a valuable extension of traditional 2D phenomics. However, the increased data dimensionality poses challenges to feature extraction and phenotyping. In recent decades, deep learning has led to remarkable progress in revolutionizing 3D phenotyping. Therefore, this review highlights the importance of using deep learning in 3D plant phenomics. It systematically overviews the capabilities of deep learning for 3D computer vision, covering 3D representation, classification, detection and tracking, semantic segmentation, instance segmentation, and generation. Additionally, deep learning techniques for 3D point preprocessing (e.g., annotation, downsampling, and dataset organization) and various plant phenotyping tasks are discussed. Finally, the challenges and perspectives associated with deep learning in 3D plant phenomics are summarized, including (1) benchmark dataset construction by using synthetic datasets and methods such as generative artificial intelligence and unsupervised or weakly supervised learning; (2) accurate and efficient 3D point cloud analysis by leveraging multitask learning, lightweight models, and self-supervised learning; and (3) deep learning for 3D plant phenomics by exploring interpretability, extensibility, and multimodal data utilization. The exploration of deep learning in 3D plant phenomics is poised to spur breakthroughs in a new dimension of plant science.}
}
@article{ABIRAFEH202587,
title = {Can ChatGPT provide parent education for oral immunotherapy?},
journal = {Annals of Allergy, Asthma & Immunology},
volume = {135},
number = {1},
pages = {87-90},
year = {2025},
issn = {1081-1206},
doi = {https://doi.org/10.1016/j.anai.2025.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S1081120625002042},
author = {Jana Abi-Rafeh and Diana Toscano-Rivero and Bruce D. Mazer},
abstract = {Background
Oral Immunotherapy (OIT) has exhibited great potential in the treatment of food allergy. However, there is no global consensus on best practices of OIT. Parents of allergic children often struggle with concerns regarding OIT methodology, safety, and lack of accessible educational resources. ChatGPT is a generative artificial intelligence chatbot from OpenAI recognized for its ability to formulate human-like conversations. Although applications of artificial intelligence in medical settings continue to be explored, the effectiveness of ChatGPT as an educational resource remains unknown for OIT.
Objective
To assess the accuracy of ChatGPT as a self-guided educational resource for parents with children undergoing OIT.
Methods
A total of 14 common questions from parents regarding OIT were entered into ChatGPT version 3.5 and answers were copied verbatim. These responses were then categorized into basic, advanced, or medical, and evaluated by Allergy-Immunology health care practitioners from North America and the United Kingdom using a 10-point Likert scale. Response readability, understandability, and reproducibility were assessed using the Flesch Reading Ease and Flesch-Kincaid Grade level scores, the Patient Education Materials Assessment Tool, and natural language processing tools, respectively.
Results
The average median rankings by the practitioners per category were 8.6, 8.4, and 7.8 for basic, advanced, and medical, respectively. ChatGPT responses exhibited low readability scores, corresponding with a high-grade reading level. Understandability was between 73% to 84%, with scores decreased owing to response complexity. When assessing reproducibility, ChatGPT responses achieved rates between 83% and 93%.
Conclusion
Our results revealed that ChatGPT provides intelligible and comprehensive responses to patient questions. Health care practitioners polled were generally positive but identified important limitations.}
}
@article{MENG2025109974,
title = {A robust unified spoofing audio detection scheme},
journal = {Computers and Electrical Engineering},
volume = {122},
pages = {109974},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109974},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624008991},
author = {Hao Meng and Wei Ou and Ju Huang and Haozhe Liang and Wenbao Han and Qionglu Zhang},
keywords = {Spoofing audio detection, Deepfakes, Self-supervised learning, Multi-task learning},
abstract = {The rapid development of generative artificial intelligence and deepfakes techniques makes it increasingly tough to identify different kinds of spoofing audio, which on one hand weakens the safety of Automatic Speaker Verification (ASV) systems, and on the other hand, negatively affects national security and societal stability. In the face of the emergence of constantly evolving forgery techniques, we need a detection model with strong generalization and high robustness to deal with them. In this work, we propose a Robust and Unified Spoofing Audio Detection (RUSAD) scheme, which is capable of dealing with multiple attacks such as logic attacks, replay attacks and adversarial attacks. We propose an innovative scheme from the perspectives of upstream feature extraction and downstream spoofing classification: the self-supervised upstream learning model based on the Conformer network extracts speech representations, establishes probabilistic spectrum-augmentation events to improve model robustness against adversarial attacks, and formulate multiple decoding tasks for classification and regression; downstream classification of audio spoofing based on inference of the SE-ResNeXt network, supplemented by self-attention pooling and the OC-Softmax angular loss function in order to improve classification performance. We perform detailed experimental evaluations on both the ASVspoof2021 and ADD2023 datasets. The results show that the scheme has improved performance, generalization, and robustness in comparison to the baseline system as well as to most forensic countermeasures, which are capable of achieving the goal of dealing with multiple attacks.}
}
@incollection{MACEDO202583,
title = {Chapter 3 - Automating drug discovery},
editor = {Alberto Pais and Carla Vitorino and Sandra Nunes and Tânia Cova},
booktitle = {Artificial Intelligence for Drug Product Lifecycle Applications},
publisher = {Academic Press},
pages = {83-97},
year = {2025},
isbn = {978-0-323-91819-0},
doi = {https://doi.org/10.1016/B978-0-323-91819-0.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323918190000038},
author = {Bruno Macedo and Tiago Taveira-Gomes},
keywords = {Drug design, Drug discovery, Drug repurposing, Generative artificial intelligence, Graph-based models, Machine learning, Neural networks, Predictive toxicology},
abstract = {The development of new effective medicines has become an urgency. Multiple drug resistant bacteria, tumor heterogeneity, autoimmune disorders or viral mutations emphasizes the urgency for new treatments. Generative Artificial Intelligence is a promising approach to identify new patterns in molecular optimization by effectively exploring the vast chemical space. Graph-based models have emerged as powerful deep learning techniques. These models are capable of processing large datasets and mapping complex correlations more efficiently than traditional methods. This paper explores the technical foundations from graph-based Artificial Intelligence models on training optimization to ensure accuracy and reliable predictions for their purpose in drug discovery, including molecule screening, drug optimization, and understanding molecular interactions.}
}
@article{HUNG2025100151,
title = {The efficacy of incorporating Artificial Intelligence (AI) chatbots in brief gratitude and self-affirmation interventions: Evidence from two exploratory experiments},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100151},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100151},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000350},
author = {Jing Wen Hung and Andree Hartanto and Adalia Y.H. Goh and Zoey K.Y. Eun and K.T.A. Sandeeshwara Kasturiratna and Zhi Xuan Lee and Nadyanna M. Majeed},
keywords = {Positive psychology intervention, Gratitude, Self-affirmation, Artificial intelligence, AI chatbots, Well-being},
abstract = {Numerous studies have demonstrated that positive psychology interventions, including brief interventions, can significantly improve well-being outcomes. These findings are particularly important given that many of these interventions are brief and self-administered, making them both accessible and scalable for large populations. However, the efficacy of positive psychology interventions is often constrained by small effect sizes. In light of advancements in generative Artificial Intelligence (AI), this study explored whether integrating AI chatbots into positive psychology interventions could enhance their efficacy compared to traditional self-administered approaches. Study 1 examined the efficacy of a gratitude intervention delivered through Snapchat's My AI, while Study 2 evaluated a self-affirmation intervention integrated with a customized ChatGPT. Both studies employed within-subject experimental designs. Contrary to our hypotheses, the integration of AI did not yield incremental improvements in gratitude outcomes (Study 1), or self-view outcomes (Study 2) compared to existing non-AI interventions. However, exploratory analyses revealed that the AI-integrated self-affirmation intervention significantly enhanced life satisfaction and medium-arousal positive affect, suggesting potential benefits for selected well-being outcomes. These findings indicate that while AI integration in brief, self-administered positive psychology interventions may enhance certain outcomes, its suitability varies across intervention types. Further research is needed to better understand the contexts in which AI can effectively augment positive psychology interventions.}
}
@article{FENG2024537,
title = {From HAL to GenAI: Optimizing chatbot impacts with CARE},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {537-548},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000570},
author = {Cai (Mitsu) Feng and Elsamari Botha and Leyland Pitt},
keywords = {Generative AI, Chatbots, AI adoption, AI risks, AI ethics, Large language models},
abstract = {This article explores the evolution and prospects of conversational chatbots, specifically the latest generation referred to as generative artificial intelligence (GenAI) chatbots. This article comprehensively examines GenAI chatbots’ business applications and impact across macro, meso, and micro levels of organizations. At the macro level, this article explores how GenAI chatbots reshape industry dynamics. The meso perspective delves into organizational changes, while the micro lens focuses on enhancing individual productivity, learning, and creativity. GenAI chatbots’ immense potential is accompanied by risks in four areas: matching, ethics, technology, and adaptability (META). In response to these challenges, the article introduces a human-centric CARE framework—standing for collaboration, accountability, responsiveness, and empowerment—to mitigate the risks and to optimize the effects of GenAI chatbots. This work provides practical guidelines for navigating the complex landscape of GenAI implementation.}
}
@article{HIROSAWA2024,
title = {Comparative Analysis of Diagnostic Performance: Differential Diagnosis Lists by LLaMA3 Versus LLaMA2 for Case Reports},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/64844},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24006528},
author = {Takanobu Hirosawa and Yukinori Harada and Kazuki Tokumasu and Tatsuya Shiraishi and Tomoharu Suzuki and Taro Shimizu},
keywords = {artificial intelligence, clinical decision support system, generative artificial intelligence, large language models, natural language processing, NLP, AI, clinical decision making, decision support, decision making, LLM: diagnostic, case report, diagnosis, generative AI, LLaMA},
abstract = {Background
Generative artificial intelligence (AI), particularly in the form of large language models, has rapidly developed. The LLaMA series are popular and recently updated from LLaMA2 to LLaMA3. However, the impacts of the update on diagnostic performance have not been well documented.
Objective
We conducted a comparative evaluation of the diagnostic performance in differential diagnosis lists generated by LLaMA3 and LLaMA2 for case reports.
Methods
We analyzed case reports published in the American Journal of Case Reports from 2022 to 2023. After excluding nondiagnostic and pediatric cases, we input the remaining cases into LLaMA3 and LLaMA2 using the same prompt and the same adjustable parameters. Diagnostic performance was defined by whether the differential diagnosis lists included the final diagnosis. Multiple physicians independently evaluated whether the final diagnosis was included in the top 10 differentials generated by LLaMA3 and LLaMA2.
Results
In our comparative evaluation of the diagnostic performance between LLaMA3 and LLaMA2, we analyzed differential diagnosis lists for 392 case reports. The final diagnosis was included in the top 10 differentials generated by LLaMA3 in 79.6% (312/392) of the cases, compared to 49.7% (195/392) for LLaMA2, indicating a statistically significant improvement (P<.001). Additionally, LLaMA3 showed higher performance in including the final diagnosis in the top 5 differentials, observed in 63% (247/392) of cases, compared to LLaMA2’s 38% (149/392, P<.001). Furthermore, the top diagnosis was accurately identified by LLaMA3 in 33.9% (133/392) of cases, significantly higher than the 22.7% (89/392) achieved by LLaMA2 (P<.001). The analysis across various medical specialties revealed variations in diagnostic performance with LLaMA3 consistently outperforming LLaMA2.
Conclusions
The results reveal that the LLaMA3 model significantly outperforms LLaMA2 per diagnostic performance, with a higher percentage of case reports having the final diagnosis listed within the top 10, top 5, and as the top diagnosis. Overall diagnostic performance improved almost 1.5 times from LLaMA2 to LLaMA3. These findings support the rapid development and continuous refinement of generative AI systems to enhance diagnostic processes in medicine. However, these findings should be carefully interpreted for clinical application, as generative AI, including the LLaMA series, has not been approved for medical applications such as AI-enhanced diagnostics.}
}
@article{WU2025691,
title = {Unleashing the power of text for credit default prediction: Comparing human-written and generative AI-refined texts},
journal = {European Journal of Operational Research},
volume = {326},
number = {3},
pages = {691-706},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2025.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0377221725003170},
author = {Zongxiao Wu and Yizhe Dong and Yaoyiran Li and Baofeng Shi},
keywords = {OR in banking, Generative AI, Large language model, Credit risk, Text mining},
abstract = {This study explores the integration of a representative large language model, ChatGPT, into lending decision-making with a focus on credit default prediction. Specifically, we use ChatGPT to analyse and interpret loan assessments written by loan officers and generate refined versions of these texts. Our comparative analysis reveals significant differences between generative artificial intelligence (AI)-refined and human-written texts in terms of text length, semantic similarity, and linguistic representations. Using deep learning techniques, we show that incorporating unstructured text data, particularly ChatGPT-refined texts, alongside conventional structured data significantly enhances credit default predictions. Furthermore, we demonstrate how the contents of both human-written and ChatGPT-refined assessments contribute to the models’ prediction and show that the effect of essential words is highly context-dependent. Moreover, we find that ChatGPT’s analysis of borrower delinquency contributes the most to improving predictive accuracy. We also evaluate the business impact of the models based on human-written and ChatGPT-refined texts, and find that, in most cases, the latter yields higher profitability than the former. This study provides valuable insights into the transformative potential of generative AI in financial services.}
}
@article{KOHNKE2025100371,
title = {Exploring the potential of GenAI for personalised English teaching: Learners' experiences and perceptions},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100371},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100371},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000116},
author = {Lucas Kohnke and Di Zou and Fan Su},
keywords = {Artificial intelligence, Generative artificial intelligence, Personalised learning, English language education, ChatGPT},
abstract = {Artificial intelligence has become seamlessly integrated into personal, professional, and educational spheres. Generative AI (GenAI), in particular, is revolutionising content creation in second language (L2) writing instruction through advanced machine learning models. This study examines the influence of GenAI on L2 learners' language competencies, focusing on tools commonly used by first-year English for Academic Purposes students. Through qualitative and quantitative analysis, including surveys and interviews, this research explored students’ experiences and perceptions of GenAI tools, including Grammarly and Quillbot. The findings revealed that two-thirds of the students (66.7%) regularly used these tools, which they found particularly helpful for improving grammar, writing, vocabulary, and reading skills. Interview insights indicated that the students appreciated the personalised feedback and creative support provided by GenAI tools, although they also acknowledged risks such as irrelevant feedback and potential overreliance. We suggest that while GenAI tools enhance language learning by providing personalised and adaptive support, they should complement rather than replace traditional methods. Our results underscore the need for professional development for educators and the establishment of guidelines to address academic integrity and data privacy.}
}
@article{ZOU2025103940,
title = {Bringing Attention to CAD: Boundary Representation Learning via Transformer},
journal = {Computer-Aided Design},
volume = {189},
pages = {103940},
year = {2025},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2025.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0010448525001010},
author = {Qiang Zou and Lizhen Zhu},
keywords = {Computer-aided design, Boundary representation models, Deep learning, Transformer, B-rep learning},
abstract = {The recent rise of generative artificial intelligence (AI), powered by Transformer networks, has achieved remarkable success in natural language processing, computer vision, and graphics. However, the application of Transformers in computer-aided design (CAD), particularly for processing boundary representation (B-rep) models, remains largely unexplored. To bridge this gap, we propose a novel approach for adapting Transformers to B-rep learning, called the Boundary Representation Transformer (BRT). B-rep models pose unique challenges due to their irregular topology and continuous geometric definitions, which are fundamentally different from the structured and discrete data Transformers are designed for. To address this, BRT proposes a continuous geometric embedding method that encodes B-rep surfaces (trimmed and untrimmed) into Bézier triangles, preserving their shape and continuity without discretization. Additionally, BRT employs a topology-aware embedding method that organizes these geometric embeddings into a sequence of discrete tokens suitable for Transformers, capturing both geometric and topological characteristics within B-rep models. This enables the Transformer’s attention mechanism to effectively learn shape patterns and contextual semantics of boundary elements in a B-rep model. Extensive experiments demonstrate that BRT achieves state-of-the-art performance in part classification and feature recognition tasks.}
}
@article{ISMAILFAWAZ2025104337,
title = {Establishing a unified evaluation framework for human motion generation: A comparative analysis of metrics},
journal = {Computer Vision and Image Understanding},
volume = {254},
pages = {104337},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104337},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225000608},
author = {Ali Ismail-Fawaz and Maxime Devanne and Stefano Berretti and Jonathan Weber and Germain Forestier},
keywords = {Human motion generation, Evaluation of generative models, Generative models metrics, Human motion data},
abstract = {The development of generative artificial intelligence for human motion generation has expanded rapidly, necessitating a unified evaluation framework. This paper presents a detailed review of eight evaluation metrics for human motion generation, highlighting their unique features and shortcomings. We propose standardized practices through a unified evaluation setup to facilitate consistent model comparisons. Additionally, we introduce a novel metric that assesses diversity in temporal distortion by analyzing warping diversity, thereby enhancing the evaluation of temporal data. We also conduct experimental analyses of three generative models using two publicly available datasets, offering insights into the interpretation of each metric in specific case scenarios. Our goal is to offer a clear, user-friendly evaluation framework for newcomers, complemented by publicly accessible code: https://github.com/MSD-IRIMAS/Evaluating-HMG.}
}
@article{SALAH2025101698,
title = {Can generative AI craft scale items? A mixed-method study on AI's capability to adapt and create new scales with recommendations for best practices},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101698},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101698},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125004267},
author = {Mohammed Salah and Fadi Abdelfattah and Hussam {Al Halbusi} and Suaad Jassem and Muna Mohammed and Maria Mohd Ismail and Amira {Al Balghouni}},
keywords = {Generative AI, Scale development, ChatGPT, Trust in AI, AI self-efficacy, AI risk perception},
abstract = {This study explored the potential of generative artificial intelligence (AI), specifically Generative Pre-trained Transformer 4 (GPT-4), in revolutionizing the development and adaptation of research scales, a process traditionally characterized by its time-intensive nature and susceptibility to human bias. This study employed a mixed-method approach and assessed GPT-4's ability to generate reliable and valid scales and compared them with conventional methods. GPT-4 was chosen for its accessibility and accuracy in producing contextually appropriate items. Quantitative analysis confirmed the reliability and validity of the AI-generated scales, while expert evaluations highlighted the model's ability to enhance methodological efficiency and reduce bias. However, this study underscores the importance of combining AI's computational strengths with human expertise to ensure optimal outcomes. This research integrates generative AI into scale development and introduces innovative practices that streamline the process without compromising quality. These findings pave the way for future explorations of AI's role in research methodologies, and offer recommendations for best practices in using AI for scale development. This study contributes to the broader discourse on AI's transformative potential in research, and emphasizes its capacity to enhance the precision and efficiency of data collection tools.}
}
@article{SEO2025,
title = {Performance Assessment of Large Language Models in Medical Consultation: Comparative Study},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/64318},
url = {https://www.sciencedirect.com/science/article/pii/S229196942500033X},
author = {Sujeong Seo and Kyuli Kim and Heyoung Yang},
keywords = {artificial intelligence, biomedical, large language model, depression, similarity measurement, text validity},
abstract = {Background
The recent introduction of generative artificial intelligence (AI) as an interactive consultant has sparked interest in evaluating its applicability in medical discussions and consultations, particularly within the domain of depression.
Objective
This study evaluates the capability of large language models (LLMs) in AI to generate responses to depression-related queries.
Methods
Using the PubMedQA and QuoraQA data sets, we compared various LLMs, including BioGPT, PMC-LLaMA, GPT-3.5, and Llama2, and measured the similarity between the generated and original answers.
Results
The latest general LLMs, GPT-3.5 and Llama2, exhibited superior performance, particularly in generating responses to medical inquiries from the PubMedQA data set.
Conclusions
Considering the rapid advancements in LLM development in recent years, it is hypothesized that version upgrades of general LLMs offer greater potential for enhancing their ability to generate “knowledge text” in the biomedical domain compared with fine-tuning for the biomedical field. These findings are expected to contribute significantly to the evolution of AI-based medical counseling systems.}
}
@article{SHAW2025102495,
title = {Physical artificial intelligence in nursing: Robotics},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102495},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102495},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001484},
author = {Ryan J. Shaw and Boyuan Chen},
keywords = {Nursing, Robotics, Generative artificial intelligence},
abstract = {Background
Robotics, driven by advancements in physical artificial intelligence (AI), offers potential solutions–yet many challenges– to creating innovative care models to meet the needs of the future.
Purpose
To present an overview of robotics across various industries and explain how physical AI is aiding the development and integration of robots into skilled nursing. We discuss the opportunities and challenges of incorporating robots into nursing and offer recommendations for nurses on designing equitable, human-centered care models that include robotics.
Methods
This paper discusses robotics across industries, with a focus on healthcare and nursing. It examines technological capabilities, nursing education needs, and ethical, regulatory, and workforce implications.
Discussion
Robots are increasingly used for logistics, cleaning, and limited direct care tasks. Advancement in physical AI will enable robots to perceive, reason, and act in dynamic environments, supporting human-robot teaming and patient care. Challenges include technical limitations, ethical concerns, disparities in access, and regulatory gaps. Nursing education must evolve to prepare professionals for collaborative practice with robotic systems.
Conclusion
Robotics must be designed to augment care delivery, such as through virtual care models and remote operation. Nurses must lead in designing, implementing, and regulating robotic technologies to ensure they enhance patient outcomes and promote health equity.}
}
@article{DARVIN2025101186,
title = {The need for critical digital literacies in generative AI-mediated L2 writing},
journal = {Journal of Second Language Writing},
volume = {67},
pages = {101186},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101186},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000116},
author = {Ron Darvin},
keywords = {Generative artificial intelligence, Critical digital literacies, Materiality, Indexicality, Ideology, Platform design},
abstract = {This article asserts that the use of generative AI (GenAI) technologies for L2 writing needs to involve critical digital literacies. Drawing on the initial insights from a case study exploring the GenAI practices of secondary school students in Canada, this paper highlights emergent issues surrounding the dispositions of these learners towards these tools, the designs of platforms, and the material differences in the way these tools generate responses and encourage specific practices. Recognizing the inequalities that circumscribe the use of these technologies, this paper proposes materiality, indexicality, and ideology as key constructs that help develop an understanding of critical digital literacies relevant to GenAI-mediated L2 writing and digital multimodal composing. These constructs draw attention to how platform designs and other material processes, together with learner access to resources, can steer learners toward particular interactions and discourses. By understanding how GenAI platforms trained on large datasets can privilege certain ways of thinking and writing, L2 writers can develop a more critical perspective of how these technologies can shape the way we write ourselves into being.}
}
@article{ZHANG2024,
title = {Examining the Role of Large Language Models in Orthopedics: Systematic Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/59607},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007970},
author = {Cheng Zhang and Shanshan Liu and Xingyu Zhou and Siyu Zhou and Yinglun Tian and Shenglin Wang and Nanfang Xu and Weishi Li},
keywords = {large language model, LLM, orthopedics, generative pretrained transformer, GPT, ChatGPT, digital health, clinical practice, artificial intelligence, AI, generative AI, Bard},
abstract = {Background
Large language models (LLMs) can understand natural language and generate corresponding text, images, and even videos based on prompts, which holds great potential in medical scenarios. Orthopedics is a significant branch of medicine, and orthopedic diseases contribute to a significant socioeconomic burden, which could be alleviated by the application of LLMs. Several pioneers in orthopedics have conducted research on LLMs across various subspecialties to explore their performance in addressing different issues. However, there are currently few reviews and summaries of these studies, and a systematic summary of existing research is absent.
Objective
The objective of this review was to comprehensively summarize research findings on the application of LLMs in the field of orthopedics and explore the potential opportunities and challenges.
Methods
PubMed, Embase, and Cochrane Library databases were searched from January 1, 2014, to February 22, 2024, with the language limited to English. The terms, which included variants of “large language model,” “generative artificial intelligence,” “ChatGPT,” and “orthopaedics,” were divided into 2 categories: large language model and orthopedics. After completing the search, the study selection process was conducted according to the inclusion and exclusion criteria. The quality of the included studies was assessed using the revised Cochrane risk-of-bias tool for randomized trials and CONSORT-AI (Consolidated Standards of Reporting Trials–Artificial Intelligence) guidance. Data extraction and synthesis were conducted after the quality assessment.
Results
A total of 68 studies were selected. The application of LLMs in orthopedics involved the fields of clinical practice, education, research, and management. Of these 68 studies, 47 (69%) focused on clinical practice, 12 (18%) addressed orthopedic education, 8 (12%) were related to scientific research, and 1 (1%) pertained to the field of management. Of the 68 studies, only 8 (12%) recruited patients, and only 1 (1%) was a high-quality randomized controlled trial. ChatGPT was the most commonly mentioned LLM tool. There was considerable heterogeneity in the definition, measurement, and evaluation of the LLMs’ performance across the different studies. For diagnostic tasks alone, the accuracy ranged from 55% to 93%. When performing disease classification tasks, ChatGPT with GPT-4’s accuracy ranged from 2% to 100%. With regard to answering questions in orthopedic examinations, the scores ranged from 45% to 73.6% due to differences in models and test selections.
Conclusions
LLMs cannot replace orthopedic professionals in the short term. However, using LLMs as copilots could be a potential approach to effectively enhance work efficiency at present. More high-quality clinical trials are needed in the future, aiming to identify optimal applications of LLMs and advance orthopedics toward higher efficiency and precision.}
}
@article{COPPOLINO2025129406,
title = {The good, the bad, and the algorithm: The impact of generative AI on cybersecurity},
journal = {Neurocomputing},
volume = {623},
pages = {129406},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129406},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225000785},
author = {Luigi Coppolino and Salvatore D’Antonio and Giovanni Mazzeo and Federica Uccello},
keywords = {AI, Artificial intelligence, Generative adversarial network, Web security, Network security, Attack obfuscation, Intrusion detection system},
abstract = {Generative Adversarial Networks (GANs) are emerging as a transformative technology in cybersecurity, presenting both opportunities and challenges in enhancing defensive and offensive strategies. This paper explores the impact that Generative Artificial Intelligence (AI) has on cybersecurity, focusing on its application in the field of network and web security. Current research reveals robust defensive approaches; however, there remains a significant gap in the application of Generative AI to develop advanced attack scenarios capable of bypassing existing defense mechanisms. Our work attempts to fill this gap and spreads awareness regarding a potential exposure of Neural Network (NN)-based Intrusion Detection Systems (IDSs) against AI-enhanced attacks. Unlike conventional approaches that focus on Input Perturbation, Data Poisoning, or Spoofing, we propose a novel offensive strategy called Attack Obfuscation. This strategy leverages Conditional GANs (CGANs) to conceal genuine attacks by injecting synthetic traffic designed to deceive NN-based IDS. The experimental investigation validates the proposed approach against three distinct datasets and different typologies of attacks, managing to successfully deceive the IDS.}
}
@article{MOORHOUSE2024103399,
title = {Developing language teachers’ professional generative AI competence: An intervention study in an initial language teacher education course},
journal = {System},
volume = {125},
pages = {103399},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103399},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24001817},
author = {Benjamin Luke Moorhouse and Yuwei Wan and Chenze Wu and Lucas Kohnke and Tsz Ying Ho and Theresa Kwong},
abstract = {Generative Artificial Intelligence (GenAI) tools have been argued to have transformative potential in education; yet existing literature suggests that language teachers generally lack the abilities to leverage these tools effectively and critically. Conducted in an initial language teacher education programme at a Hong Kong university, this mixed-method intervention study aims to explore the effects of explicit training for using GenAI tools for language teaching in rising pre-service language teachers’ professional GenAI competence (P-GenAI-C). 54 M.Ed students took part in an 11-week course intervention aiming to enhance the five aspects in the P-GenAI-C framework. Analysis of pre- and post-intervention questionnaires, which encompassed a mix of open and closed items to gather participants’ knowledge and perceptions of utilising GenAI tools, as well as the follow-up interviews, revealed that the intervention was effective in stretching all aspects of pre-service teachers’ P-GenAI-C. While there was greater evidence of improvement in participants’ pedagogical competence and critical awareness of GenAI tools deployment, there was less evidence of development in other aspects, such as teachers’ capacity to guide their students to use GenAI tools effectively and responsibly. This discrepancy might be attributed to the lack of such content in the course intervention. Implications for incorporating elements of P-GenAI-C into teacher preparation courses and programmes are discussed.}
}
@article{LEE2024103690,
title = {Human vs. AI: The battle for authenticity in fashion design and consumer response},
journal = {Journal of Retailing and Consumer Services},
volume = {77},
pages = {103690},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2023.103690},
url = {https://www.sciencedirect.com/science/article/pii/S0969698923004411},
author = {Garim Lee and Hye-Young Kim},
keywords = {Generative AI, AI-Assisted design, Schema theory, Authenticity, AI customization},
abstract = {Generative Artificial Intelligence (AI) empowers the AI design process. Then, how do consumers respond to AI-designed fashion products? Building on schema theory, this research investigated the extent to which AI-designed clothing is perceived as authentic through three online experiments. Study 1 (n = 121) and Study 2 (n = 161) showed consumers generally respond more favorably to human-designed (vs. AI-designed) clothing, which is driven by perceived authenticity and expected product quality. Study 3 (n = 156) confirmed that negative responses toward AI-designed clothing can be mitigated when consumers have the option to provide input to customize the design because it enhances perceived authenticity. Study findings offer a theoretical understanding of how and why consumers respond to AI-designed products and practical guidelines for retailers.}
}
@article{AHMED2025,
title = {Parallel Corpus Analysis of Text and Audio Comprehension to Evaluate Readability Formula Effectiveness: Quantitative Analysis},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/69772},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125013275},
author = {Arif Ahmed and Gondy Leroy and David Kauchak and Prosanta Barai and Philip Harber and Stephen Rains},
keywords = {health literacy, parallel corpora, generative AI, user evaluation, text and audio readability, comprehension, retention, actual difficulty, perceived difficulty.},
abstract = {Background
Health literacy, the ability to understand and act on health information, is critical for patient outcomes and health care system effectiveness. While plain language guidelines enhance text-based communication, audio-based health information remains underexplored, despite the growing use of digital assistants and smart devices in health care. Traditional readability formulas, such as Flesch-Kincaid, provide limited insights into the complexity of health-related texts and fail to address challenges specific to audio formats. Factors like syntax and semantic features significantly influence comprehension and retention across modalities.
Objective
This study investigates features that affect comprehension of medical information delivered via text or audio formats. We also examine existing readability formulas and their correlation with perceived and actual difficulty of health information for both modalities.
Method
We developed a parallel corpus of health-related information that differed in delivery format: text or audio. We used text from the British Medical Journal (BMJ) Lay Summary (n=193), WebMD (n=40), Patient Instruction (n=40), Simple Wikipedia (n=243), and BMJ journal (n=200). Participants (n=487) read or listened to a health text and then completed a questionnaire evaluating perceived difficulty of the text, measured using a 5-point Likert scale, and actual difficulty measured using multiple-choice and true-false questions (comprehension) as well as free recall of information (retention). Questions were generated by generative artificial intelligence (ChatGPT-4.0). Underlying syntactic, semantic, and domain-specific features, as well as common readability formulas, were evaluated for their relation to information difficulty.
Results
Text versions were perceived as easier than audio, with BMJ Lay Summary scoring 1.76 versus 2.1 and BMJ journal 2.59 versus 2.83 (lower is easier). Comprehension accuracy was higher for text across all sources (eg, BMJ journal: 76% vs 58%; Patient Instructions: 86% vs 66%). Retention was better for text, with significant differences in exact word matching for Patient Instructions and BMJ journal. Longer texts increased perceived difficulty in text but reduced free recall in both modalities (−0.23,−0.25 in audio). Higher content word frequency improved retention (0.23, 0.21) and lowered perceived difficulty (−0.20 in audio). Verb-heavy content eased comprehension (−0.29 in audio), while nouns and adjectives increased difficulty (0.20, 0.18). Readability formulas’ outcomes were unrelated to comprehension or retention, but correlated with perceived difficulty in text (eg, Smog Index: 0.334 correlation).
Conclusions
Text was more effective for conveying complex health information, but audio can be suitable for easier content. In addition, several textual features affect information comprehension and retention for both modalities. Finally, existing readability formulas did not explain actual difficulty. This study highlighted the importance of tailoring health information delivery to content complexity by using appropriate style and modality.}
}
@article{RIZOS2025101969,
title = {The impact of LLMs on mathematics education and research at the university},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101969},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101969},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125006977},
author = {Ioannis Rizos and Nikolaos Gkrekas},
keywords = {LLMs, ChatGPT, Mathematics education, Tertiary education, AI},
abstract = {This study examines the impact of generative Artificial Intelligence and Large Language Models on the academic community, with a specific focus on the Greek math community during the spring semester of 2023–2024. The study involved 81 undergraduate students, 10 university teaching personnel, and 8 researchers. The study used questionnaires, interviews, and work samples to investigate the use and perceptions of Large Language Models in three academic domains: mathematics education, applied mathematics, and machine learning. The environment and the conditions in which the student interview data were collected were in the form of an original type of Mathematics workshop section, encouraging an experimental process that may be adopted in future seminars, conferences, or colloquia. The findings imply cautious usage of Large Language Models with moderate satisfaction among students, modest use by teaching staff, and limited use in research. While Large Language Models have potential in educational contexts, their existing limits in dealing with sophisticated mathematical issues, proofs/justification, and developing unique answers underscore the importance of cautious integration into academic processes. This study highlights the necessity for further exploration of Artificial Intelligence capabilities and their implications for future academic environments. Moreover, it underscores a novel trend in mathematics-focused academia that may bear resemblance to practices observed in other sciences. This area merits further investigation by future research.}
}
@article{STEELE2023100160,
title = {To GPT or not GPT? Empowering our students to learn with AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100160},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100160},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000395},
author = {Jennifer L. Steele},
keywords = {ChatGPT, Artificial intelligence, Pedagogy, Educational technology, Academic integrity},
abstract = {I argue that ChatGPT and other generative artificial intelligence tools pose three main threats to our current education systems, creating problems of measurement, information accuracy, and skill devaluation. But when we place these threats into historical context, we see that AI tools can also empower students and level the educational playing field. In classrooms from primary to tertiary and spanning all content areas, we can help our students become critical thinkers by using ChatGPT to comprehend texts, aggregate knowledge, and understand genre conventions in prose as well as programming. The aim is to help students leverage AI as a tool that they question and critique, advancing their own comprehension, research, and composition skills in the process.}
}
@article{ARFAIE2024110815,
title = {ChatGPT and neurosurgical education: A crossroads of innovation and opportunity},
journal = {Journal of Clinical Neuroscience},
volume = {129},
pages = {110815},
year = {2024},
issn = {0967-5868},
doi = {https://doi.org/10.1016/j.jocn.2024.110815},
url = {https://www.sciencedirect.com/science/article/pii/S0967586824003540},
author = {Saman Arfaie and Mohammad {Sadegh Mashayekhi} and Mohammad Mofatteh and Crystal Ma and Richard Ruan and Mark A. MacLean and Rena Far and Jasleen Saini and Irene E. Harmsen and Taylor Duda and Alwyn Gomez and Alexander D. Rebchuk and Alick {Pingbei Wang} and Neilen Rasiah and Eddie Guo and Ali M. Fazlollahi and Emma {Rose Swan} and Pouya Amin and Safraz Mohammed and Jeffrey D. Atkinson and Rolando F. {Del Maestro} and Fady Girgis and Ashish Kumar and Sunit Das},
keywords = {ChatGPT, Clinical neuroscience, Generative artificial intelligence, Large Language Model, Medical education, Neural networks, Open AI},
abstract = {Large language models (LLM) have been promising recently in the medical field, with numerous applications in clinical neuroscience. OpenAI’s launch of Generative Pre-trained Transformer 3.5 (GPT-3.5) in November 2022 and its successor, Generative Pre-trained Transformer 4 (GPT 4) in March 2023 have garnered widespread attention and debate surrounding natural language processing (NLP) and LLM advancements. Transformer models are trained on natural language datasets to predict and generate sequences of characters. Using internal weights from training, they produce tokens that align with their understanding of the initial input. This paper delves into ChatGPT’s potential as a learning tool in neurosurgery while contextualizing its abilities for passing medical licensing exams and neurosurgery written boards. Additionally, possibilities for creating personalized case presentations and study material are discussed alongside ChatGPT’s capacity to optimize the research workflow and perform a concise literature review. However, such tools need to be used with caution, given the possibility of artificial intelligence hallucinations and other concerns such as user overreliance, and complacency. Overall, this opinion paper raises key points surrounding ChatGPT’s role in neurosurgical education.}
}
@article{SILVA2025101680,
title = {Cloud removal with compact diffusion models: A residual block-based approach},
journal = {Remote Sensing Applications: Society and Environment},
volume = {39},
pages = {101680},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101680},
url = {https://www.sciencedirect.com/science/article/pii/S2352938525002332},
author = {Leandro Henrique Furtado Pinto Silva and João Fernando Mari and Mauricio Cunha Escarpinati and André Ricardo Backes},
keywords = {Cloud removal, Remote sensing, Satellite images, Diffusion models},
abstract = {Satellites are powerful tools for remote sensing, as they enable the imaging of large areas with high quality. However, satellites can be prone to artifacts such as clouds, which can negatively influence the analysis of these images. Thus, researchers have widely investigated cloud removal techniques to mitigate these artifacts, leveraging the rise of generative artificial intelligence methods. These techniques, although powerful, require a high computational cost, which limits their use in real-time applications, embedded devices, and environmental monitoring systems, where computational resources are often limited. Therefore, this work presents an approach based on compact latent diffusion, where the denoising model uses attention channels and residual block operations. In addition, we evaluated different training loss functions, which help the model perform cloud removal across various land cover types. Considering a resource-constrained approach, we investigated different experimental configurations using Pareto Front to optimize the most promising experiments. Our results demonstrate a balance between reconstruction quality and computational cost compared to baseline. Our approaches have between 48% and 82% fewer parameters while presenting competitive results for similarity, noise, and perceptual metrics.}
}
@article{JO2025124326,
title = {The fear of being replaced by generative AI: An examination of influential factors among office workers},
journal = {Technological Forecasting and Social Change},
volume = {220},
pages = {124326},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124326},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003579},
author = {Hyeon Jo and Do-Hyung Park},
keywords = {Artificial intelligence, Job replacement anxiety, Anthropomorphism, Personalization, Skepticism},
abstract = {As advancements in generative artificial intelligence (GAI) permeate the modern workplace, anxieties about job replacement become increasingly prevalent. This study utilized partial least squares structural equation modeling on a sample of Korean office workers from various industries to explore the correlations between various factors and job replacement anxiety in the context of GAI. Memorability and self-learning characteristics of GAI were found to not significantly influence job replacement concerns. On the other hand, personalization and anthropomorphism—AI's human-like characteristics and adaptability—were found to be significantly associated with increased job replacement anxiety. Additionally, skepticism was found to significantly moderate the relationships between these GAI characteristics and job replacement anxiety. This research pioneers a nuanced exploration of how personalization and anthropomorphism, as dimensions of GAI, directly contribute to job replacement anxiety, providing an informed perspective by integrating skepticism as a moderating factor in a culturally specific context. The findings from this study provide new insights into how perceptions of GAI characteristics and demographics influence job replacement concerns.}
}
@incollection{JAGANATHAN2026241,
title = {Chapter 11 - Federated learning for predictive modeling of disease prevention in metaverse},
editor = {Shubham Mahajan and Jyotir Moy Chatterjee},
booktitle = {Federated Learning in Metaverse Healthcare},
publisher = {Academic Press},
pages = {241-264},
year = {2026},
isbn = {978-0-443-33789-5},
doi = {https://doi.org/10.1016/B978-0-443-33789-5.00013-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443337895000133},
author = {Dharani Jaganathan and A. Vadivel and S. {Jansi Rani} and Vaishnavi Thangamuthu},
keywords = {Data security, cardiovascular disease, metaverse, federated learning, healthcare},
abstract = {The Indian healthcare system, serving 1.4 billion people through a complicated public-private system, faces significant challenges such as a lack of proper infrastructure and healthcare providers, an imbalance of cities-villages and an increasing difficulty of noncommunicable diseases. The metaverse is a combined virtual space, developed by combining the virtual reality with augmented physical reality revolutionizing clinical care by improving patient care, decision making and health care operations. Virtual assistants and chatbots support clinicians in providing treatment advice and assisting patients with care-related queries. While generative artificial intelligence (AI) enables synthetic records for algorithms. Telemetry and observation of sick people can be done with IoT-powered virtual hospitals. Augmented Reality enhances clinical care by providing real-time digital information, promoting treatments for age-related diseases. Along with these advantages there is a possibility of security concerns such as Identity Theft and data privacy concerns since the metaverse collects a lot of user data, device vulnerabilities. Here, federated learning (FL) a new form of training the AI model for handling and storing private data in a decentralized model without sharing the confidential record. This chapter will explore metaverse in healthcare and the impact of FL in predictive modeling for disease prevention.}
}
@article{JANG2025106174,
title = {Generative AI in architectural design: Application, data, and evaluation methods},
journal = {Automation in Construction},
volume = {174},
pages = {106174},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106174},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525002146},
author = {Suhyung Jang and Hyunsung Roh and Ghang Lee},
keywords = {Artificial intelligence (AI), Architectural design, Design generation, Neural network (NN), Deep learning},
abstract = {This paper presents a systematic review of generative artificial intelligence (AI) use in architectural design from 2014 to 2024, focusing on 1) AI models and theory-application gaps, 2) design phases, tasks, and objectives, 3) data types and contents, and 4) evaluation methods. Based on 161 journal papers selected using preferred reporting items for systematic reviews and meta-analysis (PRISMA), the analysis reveals the theory-application gap has been reduced by 96.09 %, from 62 to 2.5 years, highlighting rapid AI adoption since 2021 with generative adversarial networks (GANs) leading, and transformers and diffusion models gaining traction. For its application, AI is employed in schematic design phases in 68.94 %, while later phases remain underexplored. Regarding types of data used, images dominate at both input (52.8 %) and output (68.32 %), with multimodal and graph data showing promise. For evaluation, comparative evaluation was most utilized (60.9 %) supported by subjective assessment by authors (34.2 %) and third parties (17.4 %).}
}
@article{NEGRON2025194,
title = {OP0233-PARE UNDERSTANDING SEXUALITY IN RHEUMATIC AND MUSCULOSKELETAL DISEASES: EXPANDING THE REUMASUTRA PROJECT TO THE GENERAL POPULATION},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {194-195},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.244},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725012774},
author = {J.B.J.B. Negrón and R. {(Lliga Reumatològica Catalana)}},
keywords = {Diversity, Equity, and Inclusion (DEI), Education, Quality of life},
abstract = {Background:
In EULAR 2020, the results of our ongoing project Reumasutra were presented. The aims were to (i) understand the complexities and the difficulties of sexuality in people with rheumatic and musculoskeletal diseases (RMDs), (ii) offer a solution to the problems previously identified, and (iii) (un)validate the proposed solution using feedback of people with RMDs [1]. However, we were forced to pause the last phase of the project due to diverse challenges been the most influential the development of generative artificial intelligence and its potential use for creating deepfakes. This technology brought with it ethical challenges. Therefore, we wanted to be sure how we could best protect the dignity of the individuals who trusted us by participating in the explicit audiovisual shorts, which involved recreating adapted sexual positions for people with RMDs. While considering the best options available, we decided that the topic of sexuality and sex in RMDs was too important to be put on hold for an extended period. Therefore, we chose to expand Reumasutra by creating a documentary for people of all ages, aimed at making the taboo topic of sexuality and sex in RMDs visible and accessible to the general population.
Objectives:
To create a documentary for the general population on sexuality and sex in RMDs in order to raise awareness of this taboo topic.
Methods:
For this work, our ontological and epistemological assumptions stand by the constructivist/interpretivist paradigm which establishes that there are multiple subjective realities, each of which is socially constructed by and between individuals. The creation of the documentary was approached using qualitative research methodology and methods. Narrative interviews were used as the method of data collection. Interviews were moderated by the same researcher which was assisted by an audiovisual team in charge of recording the interviews and subsequent audiovisual editing of the final piece. A total of 10 interviews (eight with women), conducted in Catalan, Spanish, and English, took place in February 2024 in Barcelona, Spain. Seven of the interviews were with individuals with RMDs (such as axial spondylarthritis, fibromyalgia, rheumatoid arthritis, and pulmonary sarcoidosis, among others), and the remaining interviews were with health professionals or patient advocates. It is important to note that some of the individuals interviewed held more than one role, being both people with RMDs and healthcare professionals or patient advocates. After data collection, a qualitative content analysis was performed.
Results:
Our main result is the documentary (approximate duration of 50 minutes) in which four main topics were generated and could be appreciated in more depth. Although sexuality and sex were the primary focus of our work, the narrative interviews revealed important issues that we were previously unaware of, which may also be invisible to the general population. The four main topics are: (i) structural violence and microaggressions against women, (ii) lack of education on diversity, equity, and inclusion (DEI) within the medical community, (iii) the formation of a new identity after diagnosis, and (iv) women's bodies as factories for producing life.
Conclusion:
There is an invisibility of women in medicine. Just as sexuality and sex in RMDs are not a local problem but a global one, we believe this invisibility is also a global issue. Sociocultural variables and dynamics (e.g., religious practices) play a role in the magnitude of this issue across different countries. Structural violence and various types of aggression were identified in the experiences of the women who participated, which was not the case for the men interviewed. DEI education is needed in medical training to counterbalance this violence. New meaning in the lives of the participants was found through collective activities that created bonds with different communities. However, there is a reproductive reductionism in rheumatology when the topic of sexuality and sex is addressed with women. Our results serve as an invitation for everyone involved in the diagnosis and treatment of RMDs to reflect on our practices, their origins, and ask ourselves: Are there better ways?
REFERENCES:
[1] Negrón JB, Ponce L, Galega LLR, Catalana LLR. OP0309-PARE REUMASUTRA: Rethinking Sexuality in Rheumatic and Musculoskeletal Diseases. BMJ Publishing Group Ltd; 2020.
Acknowledgements:
To all those who shared intimate aspects of their experience with the disease. Thank you for your vulnerability and for teaching us lessons that are not taught in textbooks or classrooms.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{SZCZESNIEWSKI2024398,
title = {Quality of information about urologic pathology in English and Spanish from ChatGPT, BARD, and Copilot},
journal = {Actas Urológicas Españolas (English Edition)},
volume = {48},
number = {5},
pages = {398-403},
year = {2024},
issn = {2173-5786},
doi = {https://doi.org/10.1016/j.acuroe.2024.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S2173578624000167},
author = {J.J. Szczesniewski and A. {Ramos Alba} and P.M. {Rodríguez Castro} and M.F. {Lorenzo Gómez} and J. {Sainz González} and L. {Llanes González}},
keywords = {Artificial intelligence, Information quality, ChatGPT, Copilot, BARD, Urology, Inteligencia artificial, Calidad de información, ChatGPT, Copilot, BARD, Urología},
abstract = {Introduction and objective
Generative artificial intelligence makes it possible to ask about medical pathologies in dialog boxes. Our objective was to analyze the quality of information about the most common urological pathologies provided by ChatGPT (OpenIA), BARD (Google), and Copilot (Microsoft).
Methods
We analyzed information on the following pathologies and their treatments as provided by AI: prostate cancer, kidney cancer, bladder cancer, urinary lithiasis, and benign prostatic hypertrophy (BPH). Questions in English and Spanish were posed in dialog boxes; the answers were collected and analyzed with DISCERN questionnaires and the overall appropriateness of the response. Surgical procedures were performed with an informed consent questionnaire.
Results
The responses from the three chatbots explained the pathology, detailed risk factors, and described treatments. The difference is that BARD and Copilot provide external information citations, which ChatGPT does not. The highest DISCERN scores, in absolute numbers, were obtained in Copilot; however, on the appropriacy scale it was noted that their responses were not the most appropriate. The best surgical treatment scores were obtained by BARD, followed by ChatGPT, and finally Copilot.
Conclusions
The answers obtained from generative AI on urological diseases depended on the formulation of the question. The information provided had significant biases, depending on pathology, language, and above all, the dialog box consulted.
Resumen
Introducción y objetivo
La inteligencia artificial (IA) generativa permite preguntar, a través de los cuadros de diálogo, sobre patologías médicas. Nuestro objetivo fue analizar la calidad de la información acerca de las patologías urológicas más comunes en los chatbots ChatGPT de OpenIA, BARD de Google y Copilot de Microsoft.
Material y método
Se realizó un análisis de la información aportada por IA sobre las siguientes patologías y sus tratamientos: cáncer de próstata, cáncer renal, cáncer de vejiga, litiasis urinarias e hipertrofia benigna de próstata (HBP). A través de cuadros de diálogo se formularon preguntas estructuradas en inglés y en español, recopilando las respuestas para analizarlas posteriormente con cuestionarios DISCERN y sobre la idoneidad global de la respuesta. Los tratamientos quirúrgicos se realizaron con cuestionario de consentimiento informado.
Resultados
Las respuestas obtenidas a través de los tres chatbots explicaron la patología, detallaron los factores de riesgo y describieron los tratamientos. La diferencia radica en que BARD y Copilot aportan citas de información externa, algo que ChatGPT no realiza. Las puntuaciones DISCERN más altas, en números absolutos, se obtuvieron en Copilot; sin embargo, en la escala de idoneidad se objetivó que sus respuestas no fueron las más apropiadas. Las mejores puntuaciones de tratamientos quirúrgicos fueron obtenidas por BARD, seguido de ChatGPT y finalmente de Copilot.
Conclusiones
Las respuestas obtenidas de la IA generativa sobre enfermedades urológicas dependieron de la formulación de la pregunta. La información proporcionada presentó sesgos importantes, dependiendo de la patología, del idioma y, sobre todo, del cuadro de diálogo consultado.}
}
@article{XIA2025106024,
title = {Intelligent co-design of shear wall and beam layouts using a graph neural network},
journal = {Automation in Construction},
volume = {172},
pages = {106024},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106024},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525000640},
author = {Jikang Xia and Wenjie Liao and Bo Han and Shulu Zhang and Xinzheng Lu},
keywords = {Shear wall structure, Graph neural network, Graph co-representation of wall and beam, Intelligent co-design, Feature engineering},
abstract = {Generative artificial intelligence-driven design of shear wall structures is crucial for the intelligent design of buildings, but current methods arrange shear walls and then beams successively, overlooking their interdependence. This paper constructed a graph representation of the coupled potential positions for shear walls and beams and proposed a co-design method driven by a graph neural network (GNN). Feature engineering was used to represent shear wall and beam layouts as graph data enhanced through data augmentation to improve GNN model generalization. The GraphSAGE algorithm analyzed the graph to simultaneously generate the shear wall and beam layouts followed by postprocessing for extraction and optimization based on encoded design rules. A case study validated the method, showing that intersections over union for GNN-generated layouts were 14.9 % and 35.6 % higher than those from the conventional approach. This method offers a reference for the coupled design of multiple structural attributes.}
}
@article{DONG2024102397,
title = {Exploring the integration of IoT and Generative AI in English language education: Smart tools for personalized learning experiences},
journal = {Journal of Computational Science},
volume = {82},
pages = {102397},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102397},
url = {https://www.sciencedirect.com/science/article/pii/S187775032400190X},
author = {Wanjin Dong and Daohua Pan and Soonbae Kim},
keywords = {IoT, Generative AI, Smart tools, Adaptive learning environment},
abstract = {English language education is undergoing a transformative shift, propelled by advancements in technology. This research explores the integration of the Internet of Things (IoT) and Generative Artificial Intelligence (Generative AI) in the context of English language education, with a focus on developing a personalized oral assessment method. The proposed method leverages real-time data collection from IoT devices and Generative AI's language generation capabilities to create a dynamic and adaptive learning environment. The study addresses historical challenges in traditional teaching methodologies, emphasizing the need for AI approaches. The research objectives encompass a comprehensive exploration of the historical context, challenges, and existing technological interventions in English language education. A novel, technology-driven oral assessment method is designed, implemented, and rigorously evaluated using datasets such as Librispeech and L2Arctic. The ablation study investigates the impact of training dataset proportions and model learning rates on the method's performance. Results from the study highlight the importance of maintaining a balance in dataset proportions, selecting an optimal learning rate, and considering model depth in achieving optimal performance.}
}
@article{WANG2026116467,
title = {Data-driven diffusion generative design of energy-absorbing metamaterials using implicit surface representation},
journal = {Applied Mathematical Modelling},
volume = {151},
pages = {116467},
year = {2026},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2025.116467},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X25005414},
author = {Haoyu Wang and Haisen Xu and Hanlin Xiao and Shan Tang},
keywords = {Data-driven, Diffusion model, Implicit surface representation, Energy-absorbing metamaterial, Deep learning, Nonlinear design},
abstract = {Currently, the design of energy-absorbing materials and structures primarily relies on empirical or heuristic methods. Motivated by advances in generative artificial intelligence techniques, a data-driven diffusion generative approach using implicit surface representation for energy-absorbing metamaterial design is proposed. This approach utilizes the diffusion model to learn the conditional distribution of metamaterial based on specified mechanical properties, converting target properties into potential metamaterial topologies. Additionally, level set-based implicit surface representation ensures that the generated metamaterials have high-quality geometric shapes and clear boundary definitions, enhancing design flexibility while requiring fewer design variables. Numerical simulations and experimental results consistently verify that the proposed approach enables rapid and accurate design of metamaterials tailored to target mechanical performance. This method offers an innovative and efficient solution for the accelerated design of energy-absorbing metamaterials, providing a new perspective and approach to address complex engineering design challenges.}
}
@article{HELD2024,
title = {A Novel Cognitive Behavioral Therapy–Based Generative AI Tool (Socrates 2.0) to Facilitate Socratic Dialogue: Protocol for a Mixed Methods Feasibility Study},
journal = {JMIR Research Protocols},
volume = {13},
year = {2024},
issn = {1929-0748},
doi = {https://doi.org/10.2196/58195},
url = {https://www.sciencedirect.com/science/article/pii/S1929074824006164},
author = {Philip Held and Sarah A Pridgen and Yaozhong Chen and Zuhaib Akhtar and Darpan Amin and Sean Pohorence},
keywords = {generative artificial intelligence, mental health, feasibility, cognitive restructuring, Socratic dialogue, mobile phone},
abstract = {Background
Digital mental health tools, designed to augment traditional mental health treatments, are becoming increasingly important due to a wide range of barriers to accessing mental health care, including a growing shortage of clinicians. Most existing tools use rule-based algorithms, often leading to interactions that feel unnatural compared with human therapists. Large language models (LLMs) offer a solution for the development of more natural, engaging digital tools. In this paper, we detail the development of Socrates 2.0, which was designed to engage users in Socratic dialogue surrounding unrealistic or unhelpful beliefs, a core technique in cognitive behavioral therapies. The multiagent LLM-based tool features an artificial intelligence (AI) therapist, Socrates, which receives automated feedback from an AI supervisor and an AI rater. The combination of multiple agents appeared to help address common LLM issues such as looping, and it improved the overall dialogue experience. Initial user feedback from individuals with lived experiences of mental health problems as well as cognitive behavioral therapists has been positive. Moreover, tests in approximately 500 scenarios showed that Socrates 2.0 engaged in harmful responses in under 1% of cases, with the AI supervisor promptly correcting the dialogue each time. However, formal feasibility studies with potential end users are needed.
Objective
This mixed methods study examines the feasibility of Socrates 2.0.
Methods
On the basis of the initial data, we devised a formal feasibility study of Socrates 2.0 to gather qualitative and quantitative data about users’ and clinicians’ experience of interacting with the tool. Using a mixed method approach, the goal is to gather feasibility and acceptability data from 100 users and 50 clinicians to inform the eventual implementation of generative AI tools, such as Socrates 2.0, in mental health treatment. We designed this study to better understand how users and clinicians interact with the tool, including the frequency, length, and time of interactions, users’ satisfaction with the tool overall, quality of each dialogue and individual responses, as well as ways in which the tool should be improved before it is used in efficacy trials. Descriptive and inferential analyses will be performed on data from validated usability measures. Thematic analysis will be performed on the qualitative data.
Results
Recruitment will begin in February 2024 and is expected to conclude by February 2025. As of September 25, 2024, overall, 55 participants have been recruited.
Conclusions
The development of Socrates 2.0 and the outlined feasibility study are important first steps in applying generative AI to mental health treatment delivery and lay the foundation for formal feasibility studies.
International Registered Report Identifier (IRRID)
DERR1-10.2196/58195}
}
@article{WEN2025,
title = {EdgeAIGC: Model caching and resource allocation for Edge Artificial Intelligence Generated Content},
journal = {Digital Communications and Networks},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864825001142},
author = {Wu Wen and Yibin Huang and Xinxin Zhao and Peiying Zhang and Kai Liu and Guowei Shi},
keywords = {Generative AI, Edge Model Caching, Resource Allocation, Edge Intelligence},
abstract = {With the rapid development of Generative Artificial Intelligence technology, the traditional cloud-based centralized model training and inference face significant limitations due to high transmission latency and costs, which restrict user-side in-situ Artificial Intelligence Generated Content (AIGC) service requests. To this end, we propose the Edge Artificial Intelligence Generated Content (EdgeAIGC) framework, which can effectively solve the problems brought by cloud computing by implementing in-situ processing of services close to the data source through edge computing. However, AIGC models usually have a large parameter scale and complex computing requirements, which poses a huge challenge to the storage and computing resources of edge devices. This paper focuses on the edge intelligence model caching and resource allocation problems in the EdgeAIGC framework, aiming to improve the cache hit rate and resource utilization of edge devices for models by optimizing the model caching strategy and resource allocation scheme, and realize in-situ AIGC service processing. With the optimization objectives of minimizing service request response time and execution cost in resource-constrained environments, we employ the Twin Delayed Deep Deterministic Policy Gradient algorithm for optimization. Experimental results show that, compared with other methods, our model caching and resource allocation strategies can effectively improve the cache hit rate by at least 41.06% and reduce the response cost.}
}
@article{LIM2025,
title = {The art of medical synthesis: Where Chinese medical wisdom intersects with artificial intelligence},
journal = {Journal of Traditional Chinese Medical Sciences},
year = {2025},
issn = {2095-7548},
doi = {https://doi.org/10.1016/j.jtcms.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S209575482500078X},
author = {Enoch Chi Ngai Lim and Nga Chong Lisa Cheng and Chi Eung Danforn Lim},
keywords = {Artificial intelligence, Chinese medicine, Western medicine, Regulation, Ethics},
abstract = {Generative artificial intelligence (AI), specifically large language models, such as DeepSeek, has accelerated the digital transformation of healthcare systems in both developing and developed countries. The use of AI in diagnostics, image processing and interpretation, treatment personalization, clinical documentation, and drug discovery is an example of the implementation of AI in Western medicine. The need for evidence-based studies and a standardized approach to scientific medicine aligns well with these applications. AI can leave a lasting impact on the Chinese medicine (CM) landscape by increasing expectations and presenting new challenges. The analogy between the CM-specific diagnostic methods and syndrome differentiation, which is holistic, pattern-oriented, patient-centered, and clinical data analysis, is significant at multiple levels. These qualities pose challenges for AI usage in CM, which heavily relies on structured data and pattern recognition. Despite these adversities, AI can still be used in CM through data standardization, prediction formulation, and treatment planning, provided that the integration of this tool considers the primary principles of CM and adheres to ethical and regulatory considerations. This review examines the dichotomous approach to health and medicine in the contexts of AI and CM, highlighting the evolving potential, inherent limitations, and ethical and regulatory issues associated with the application of AI to CM. It provides a foundation for developing technologically progressive yet culturally and philosophically sensitive strategies that are in harmony with traditional clinical values.}
}
@article{WEUTHEN2025,
title = {Comparison of ChatGPT and Internet Research for Clinical Research and Decision-Making in Occupational Medicine: Randomized Controlled Trial},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/63857},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25003555},
author = {Felix A Weuthen and Nelly Otte and Hanif Krabbe and Thomas Kraus and Julia Krabbe},
keywords = {occupational diseases, artificial intelligence, internet research, medicine, occupational medicine, ChatGPT, AI, decision-making, algorithms, algorithm, large language models, LLMs, physicians, medical students, occupational lung diseases, occupational lung disease},
abstract = {Background
Artificial intelligence is becoming a part of daily life and the medical field. Generative artificial intelligence models, such as GPT-4 and ChatGPT, are experiencing a surge in popularity due to their enhanced performance and reliability. However, the application of these models in specialized domains, such as occupational medicine, remains largely unexplored.
Objective
This study aims to assess the potential suitability of a generative large language model, such as ChatGPT, as a support tool for medical research and even clinical decisions in occupational medicine in Germany.
Methods
In this randomized controlled study, the usability of ChatGPT for medical research and clinical decision-making was investigated using a web application developed for this purpose. Eligibility criteria were being a physician or medical student. Participants (N=56) were asked to work on 3 cases of occupational lung diseases and answer case-related questions. They were allocated via coin weighted for proportions of physicians in each group into 2 groups. One group researched the cases using an integrated chat application similar to ChatGPT based on the latest GPT-4-Turbo model, while the other used their usual research methods, such as Google, Amboss, or DocCheck. The primary outcome was case performance based on correct answers, while secondary outcomes included changes in specific question accuracy and self-assessed occupational medicine expertise before and after case processing. Group assignment was not traditionally blinded, as the chat window indicated membership; participants only knew the study examined web-based research, not group specifics.
Results
Participants of the ChatGPT group (n=27) showed better performance in specific research, for example, for potentially hazardous substances or activities (eg, case 1: ChatGPT group 2.5 hazardous substances that cause pleural changes versus 1.8 in a group with own research; P=.01; Cohen r=–0.38), and led to an increase in self-assessment with regard to specialist knowledge (from 3.9 to 3.4 in the ChatGPT group vs from 3.5 to 3.4 in the own research group; German school grades between 1=very good and 6=unsatisfactory; P=.047). However, clinical decisions, for example, whether an occupational disease report should be filed, were more often made correctly as a result of the participant’s own research (n=29; eg, case 1: Should an occupational disease report be filed? Yes for 7 participants in the ChatGPT group vs 14 in their own research group; P=.007; odds ratio 6.00, 95% CI 1.54‐23.36).
Conclusions
ChatGPT can be a useful tool for targeted medical research, even for rather specific questions in occupational medicine regarding occupational diseases. However, clinical decisions should currently only be supported and not made by the large language model. Future systems should be critically assessed, even if the initial results are promising.
Trial Registration
German Clinical Trials Registry DRKS00036492; https://drks.de/search/en/trial/DRKS00036492/entails}
}
@article{LI2024,
title = {Impact of Artificial Intelligence–Generated Content Labels On Perceived Accuracy, Message Credibility, and Sharing Intentions for Misinformation: Web-Based, Randomized, Controlled Experiment},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/60024},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24007443},
author = {Fan Li and Ya Yang},
keywords = {generative AI, artificial intelligence, ChatGPT, AIGC label, misinformation, perceived accuracy, message credibility, sharing intention, social media, health information},
abstract = {Background
The proliferation of generative artificial intelligence (AI), such as ChatGPT, has added complexity and richness to the virtual environment by increasing the presence of AI-generated content (AIGC). Although social media platforms such as TikTok have begun labeling AIGC to facilitate the ability for users to distinguish it from human-generated content, little research has been performed to examine the effect of these AIGC labels.
Objective
This study investigated the impact of AIGC labels on perceived accuracy, message credibility, and sharing intention for misinformation through a web-based experimental design, aiming to refine the strategic application of AIGC labels.
Methods
The study conducted a 2×2×2 mixed experimental design, using the AIGC labels (presence vs absence) as the between-subjects factor and information type (accurate vs inaccurate) and content category (for-profit vs not-for-profit) as within-subjects factors. Participants, recruited via the Credamo platform, were randomly assigned to either an experimental group (with labels) or a control group (without labels). Each participant evaluated 4 sets of content, providing feedback on perceived accuracy, message credibility, and sharing intention for misinformation. Statistical analyses were performed using SPSS version 29 and included repeated-measures ANOVA and simple effects analysis, with significance set at P<.05.
Results
As of April 2024, this study recruited a total of 957 participants, and after screening, 400 participants each were allocated to the experimental and control groups. The main effects of AIGC labels were not significant for perceived accuracy, message credibility, or sharing intention. However, the main effects of information type were significant for all 3 dependent variables (P<.001), as were the effects of content category (P<.001). There were significant differences in interaction effects among the 3 variables. For perceived accuracy, the interaction between information type and content category was significant (P=.005). For message credibility, the interaction between information type and content category was significant (P<.001). Regarding sharing intention, both the interaction between information type and content category (P<.001) and the interaction between information type and AIGC labels (P=.008) were significant.
Conclusions
This study found that AIGC labels minimally affect perceived accuracy, message credibility, or sharing intention but help distinguish AIGC from human-generated content. The labels do not negatively impact users’ perceptions of platform content, indicating their potential for fact-checking and governance. However, AIGC labeling applications should vary by information type; they can slightly enhance sharing intention and perceived accuracy for misinformation. This highlights the need for more nuanced strategies for AIGC labels, necessitating further research.}
}
@article{FAKFARE2025104070,
title = {Customer word-of-mouth for generative AI: Innovation and adoption in hospitality and tourism},
journal = {International Journal of Hospitality Management},
volume = {126},
pages = {104070},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.104070},
url = {https://www.sciencedirect.com/science/article/pii/S0278431924003827},
author = {Pipatpong Fakfare and Noppadol Manosuthi and Jin-Soo Lee and Heesup Han and Minkyoung Jin},
keywords = {Generative AI, Word-of-mouth (WOM), Five-state customer adoption, Innovation, Hospitality and tourism},
abstract = {Generative artificial intelligence (AI), such as ChatGPT, is increasingly utilized to facilitate decision-making processes in various aspects of our lives, including travel activities. Despite its growing adoption in the travel service industry, a research gap focusing on the innovation characteristics of ChatGPT, customer adoption, and word-of-mouth (WOM) remains. By utilizing stringent methodologies through variable- and case-based approaches, this study explores the influence of ChatGPT innovation characteristics and customer adoption factors in inducing WOM. The formal set-theoretic approach further explores the intersections between the empirical model, theory, and outcome (WOM). The results provide novel insights into customer WOM for generative AI, examining whether innovation attributes, such as relative benefits, complexity and compatibility, and/or states of customer adoption factors -- particularly in terms of cognitive, affective, and behavioral response individually or in combination -- contribute to WOM, thereby leading to theoretical and practical implications in the hospitality and tourism industry.}
}
@article{ARISTEIDOU202421,
title = {Generative AI and neural networks towards advanced robot cognition},
journal = {CIRP Annals},
volume = {73},
number = {1},
pages = {21-24},
year = {2024},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2024.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0007850624000271},
author = {Christoforos Aristeidou and Nikos Dimitropoulos and George Michalos},
keywords = {Cognitive robotics, Neural networks, Generative artificial intelligence},
abstract = {Enhancing autonomy and applicability of robotic systems across diverse scenarios, requires efficient environment perception. Conventional vision systems are highly performing but limited to simple tasks, while AI based ones require extensive data collection, processing and training. This paper presents a framework leveraging generative AI and Neural Networks to implement a dynamically updateable perception system. A multimodal conditional Generative Adversarial Network generates large image datasets which are automatically annotated by a Large Multimodal Model. A Convolutional Neural Network performs further dataset augmentation. A case study on the inspection of aircraft fuel tanks is used to showcase the potential of the approach.}
}
@article{MIZUMOTO2025100210,
title = {Large language models fall short in classifying learners’ open-ended responses},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {2},
pages = {100210},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100210},
url = {https://www.sciencedirect.com/science/article/pii/S277276612500031X},
author = {Atsushi Mizumoto and Mark Feng Teng},
keywords = {Research methods, Generative AI, Large language models (LLM), Qualitative analysis, Coding and classification},
abstract = {Generative Artificial Intelligence (GenAI), based on large language models (LLMs), excels in various language comprehension tasks and is increasingly utilized in applied linguistics research. This study examines the accuracy and methodological implications of using LLMs to classify open-ended responses from learners. We surveyed 143 Japanese university students studying English as a foreign language (EFL) about their essay-writing process. Two human evaluators independently classified the students’ responses based on self-regulated learning processes: planning, monitoring, and evaluation. At the same time, several LLMs performed the same classification task, and their results were compared with those of the human evaluators using Cohen’s kappa coefficient. We established κ ≥ 0.8 as the threshold for strong agreement based on rigorous methodological standards. Our findings revealed that even the best-performing model (DeepSeek-V3) achieved only moderate agreement (κ = 0.68), while other models demonstrated fair-to-moderate agreement (κ = 0.37–0.61). Surprisingly, open-source models outperformed several commercial counterparts. These results highlight the necessity of expert oversight when integrating GenAI as a support tool in qualitative data analysis. The paper concludes by discussing the methodological implications for using LLMs in qualitative research and proposing specific prompt engineering strategies to enhance their reliability in applied linguistics.}
}
@article{PUJOL2025,
title = {ChatGPT Frente a un Examen Teórico de Cirugía Ortopédica y Traumatología: Valor Clínico y Educativo},
journal = {Revista Española de Cirugía Ortopédica y Traumatología},
year = {2025},
issn = {1888-4415},
doi = {https://doi.org/10.1016/j.recot.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1888441525001791},
author = {Oriol Pujol and María Guzmán and Clara Álvaro and Joan Leal and Joan Minguell and Nayana Joshi},
keywords = {Inteligencia artificial, Aprendizaje automático, ChatGPT, Cirugía ortopédica y traumatología, educación, Imágenes médicas},
abstract = {Resumen
Introducción: ChatGPT, un chatbot de inteligencia artificial (IA) generativa, es una herramienta prometedora de apoyo en el diagnóstico, toma de decisiones y educación en Cirugía Ortopédica y Traumatología (COT). El objetivo principal de este estudio es evaluar la capacidad de ChatGPT-4o para responder las preguntas de un examen teórico dirigido a residentes de COT. El objetivo secundario es comparar la tasa de aciertos y patrón de respuestas obtenidos por este chatbot con los de los residentes, categorizados según sus años de experiencia. Métodos: Es un estudio observacional retrospectivo. Se ha analizado el examen teórico de COT realizado por residentes de un hospital terciario español en 2024. El examen incluyó 48 preguntas tipo test (10 con imagen), distribuidas entre distintas subespecialidades. Se registraron las respuestas de ChatGPT-4o y de los residentes para comparar las tasas de aciertos. Además, se analizó la capacidad de acertar preguntas en función de la temática y vinculación a imagen. Resultados: ChatGPT-4o respondió correctamente 34 de 48 preguntas (71%). La tasa de respuestas correctas de ChatGPT fue superior a la media de los residentes de COT (67%), obteniendo una puntuación similar a la de los residentes de quinto año (70%). Sin embargo, mostró una tasa de acierto mucho menor en las preguntas vinculadas a imagen clínica o radiológica (30%). Conclusiones: ChatGPT-4o es capaz de responder preguntas de un examen teórico sobre COT, obteniendo una tasa de aciertos superior a la media de los residentes de COT y similar a la de los residentes de quinto año. No obstante, la tasa de errores fue del 29.2% y destacó una capacidad más limitada para acertar preguntas vinculadas a imágenes, así como cuestiones que exijan razonamiento clínico complejo. El uso de este modelo de IA no puede sustituir la experiencia y razonamiento del profesional médico.
Introduction: ChatGPT, a generative artificial intelligence (AI) chatbot, represents a potential tool to support diagnosis, decision-making, and education in Orthopaedic Surgery and Traumatology (OST). The primary aim of this study was to evaluate the ability of ChatGPT-4o to answer questions from a theoretical exam designed for OST residents. The secondary aim was to compare the chatbot’s score and response patterns with those of residents, stratified by years of training. Methods: This was a retrospective observational study. A theoretical OST exam administered in 2024 to residents at a Spanish tertiary hospital was analyzed. The exam comprised 48 multiple-choice questions (10 including images) across different subspecialties. The responses of ChatGPT-4o and the residents were recorded to compare accuracy rates. In addition, the ability to correctly answer questions was analyzed according to topic and association with images. Results: ChatGPT-4o correctly answered 34 out of 48 questions (71%). Its accuracy rate was higher than the average of OST residents (67%), achieving a score comparable to fifth-year residents (70%). However, its performance was notably lower in image-based clinical or radiological questions (30% accuracy). Conclusion: ChatGPT-4o is capable of answering questions from a theoretical OST examination, achieving a score higher than the average of OST residents and comparable to that of the most experienced residents (fifth-year). However, the error rate was 29.2%, with a notably lower accuracy in questions involving images and those requiring complex clinical reasoning. The use of this AI model cannot replace the expertise and reasoning of medical professionals.}
}
@article{ANTIA2025100243,
title = {Healthy Heart Assistant, a WhatsApp-Based Generative Pretrained Transformer Technology, for Self-Care in Hypertensive Patients},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {3},
pages = {100243},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100243},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000501},
author = {Samuel E. Antia and Collins N. Ugwu and Vishal Ghodka and Babangida S. Chori and Muhammad S. Nazir and Chizoba A. Odili and Godsent C. Isiguzo and Sri Vasireddy and Augustine N. Odili},
abstract = {Objective
To evaluate the feasibility, usability, and efficacy of innovative generative pretrained transformer chatbot in improving self-care in hypertensive patients in a resource-limited setting.
Patients and Methods
A single-arm nonblinded clinical trial was deployed in a busy cardiology clinic in a low-resource setting. Artificial intelligence–enabled chatbot (Healthy Heart Assistant) was activated in smartphones of 50 adults on treatment for hypertension. Participants were trained on how to use the Healthy Heart Assistant including setting medication and appointment reminders. Baseline questionnaires were administered at enrollment and 30 days later to explore acceptability, feasibility and usability of the bot. We used chatbot usability questionnaire and self-made Healthy Heart Assistant satisfaction questionnaire to assess bot usability and patients’ satisfaction, respectively. The study began on April 5, 2024, through July 15, 2024.
Results
Of 200 hypertensive clinic attendees, 70 (35%) had internet-enabled bot-compatible cell phones, of which 50 hypertensive patients were recruited to participate in the study. Among 50 participants, 2 (4%) were lost to follow-up; 19 (39.6%) were women; and 40 (83.3%) had attained tertiary level of education. Mean time of training to use bot was 5.7 minutes, with 35 (70.8%) of participants being able to use the bot within 5 minutes. The median frequency of chats for participants within the timeframe was an average of 1.5 chats/day. Chatbot usability questionnaire score was 69.5%, whereas self-made Healthy Heart Assistant satisfaction questionnaire score was 90%.
Conclusion
This proof-of-concept study shows that generative artificial intelligence can be applied with reasonable success in hypertension self-care in low-resource settings and has potential for being effective.}
}
@article{THOMAS2024102619,
title = {ChatGPT appropriation: A catalyst for creative performance, innovation orientation, and agile leadership},
journal = {Technology in Society},
volume = {78},
pages = {102619},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102619},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001672},
author = {Asha Thomas and Harshleen Kaur Duggal and Puja Khatri and Vincenzo Corvello},
keywords = {ChatGPT appropriation, Creative performance, Generative AI, Innovation orientation, Agile leadership},
abstract = {Appropriation of generative artificial intelligence is a burgeoning area in the realm of technological advancements and holds significant promise for organizational dynamics and creative performance. This study seeks to clarify its relationship with Individual Creative Performance, understand the influences of Innovation Orientation and Agile Leadership on Appropriation, with particular reference with ChatGPT and propose a framework for its comprehension. Drawing from a targeted sample of 671 responses across prominent industries in Poland, we uncover a marked empirical gap. Our results underscore the instrumental role of Innovation Orientation in molding both ChatGPT Appropriation and Individual Creative Performance, while also emphasizing the mediating roles of Innovation Orientation and ChatGPT Appropriation in the nexus between Agile Leadership and Individual Creative Performance.}
}
@article{GAO2025100472,
title = {Do AI chatbot-integrated writing tasks influence writing self-efficacy and critical thinking ability? An exploratory study},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100472},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100472},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001122},
author = {Jie Gao and Jing Zhang and Yalin Li},
keywords = {AI chatbot-integrated writing tasks, Critical thinking ability, Writing self-efficacy, Vocational college students, Quasi-experimental design},
abstract = {Emerging discussions have boomed in relation to recent trends and applications of generative artificial intelligence in education, but few attention were paid to AI chatbots in terms of critical thinking ability and second language (L2) writing self-efficacy. To address such research gap, this study aims to delve into effectiveness of AI chatbot-integrated writing tasks on critical thinking ability and writing self-efficacy among vocational college students. Followed the quasi-experiment design, this study recruited 80 first-year vocational college students from two intact class. Throughout seven-week's instruction, quantitative data were collected with pre- and post-questionnaires of writing self-efficacy and critical thinking ability. The results revealed no statistical difference in terms of both critical thinking ability and writing self-efficacy even with greater increase among the experimental group than that of the control peers. Further analysis of each dimension demonstrated the statistical difference of language construction, indicating that vocational college students with limited language proficiency strive to promote language organization in their writings in terms of critical thinking ability development. The research contributes valuable empirical evidence of incorporating generative AI chatbots into L2 writing by extending the Cognitive Load Theory and Social Cognitive Theory. It also underscores the need to leveraging AI chatbots as tools for cognitive transformation rather than mere procedural assistance, and relevant training programs are essential to optimize the educational benefits of AI tools and cultivate digital literacy among vocational college learners.}
}
@article{PRINZ2025105515,
title = {Codes across (life)sciences},
journal = {BioSystems},
volume = {254},
pages = {105515},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2025.105515},
url = {https://www.sciencedirect.com/science/article/pii/S030326472500125X},
author = {Robert Prinz and Philipp Bucher and Ádám Kun and Omar Paredes and Anna Aragno and Candice Shelby and Markus Gumbel and Elena Fimmel and Lutz Strüngmann},
keywords = {Code biology, Mathematics, Computer science, Synthetic biology, Ecological codes, Psychology, Psychoanalysis, Cultural codes, Cyborgism, Transhumanism},
abstract = {The concept of “code” connotes different meanings, intentions, and formalizations. From mathematics and computer sciences to psychology and culture, the term becomes less formal, more diverse, and sometimes appears ambiguous. In biology a growing number of codes ignite a debate about their role in evolution, biocomplexity, and agency, to name just a few. Here, a transdisciplinary group of code scientists attempts to capture the big picture of code research across their fields of interest. In this cross-sectional overview commonalities emerge that may pave the way towards a unified theory of life-based-on-codes. Codes underly cellular processes, perception, cognition, and communication. From ecosystems to human language, codes influence how individuals behave in groups, memorize, learn, and take part in cultural practices. Emotions like aggression, fear, anger, frustration, are important motivators of behaviour modulating mutual communication and sculpting individual experience. The inheritance of experience in form of innate release mechanisms, stereotyped behaviour, or archetypes may have phylogenetic and ontogenetic roots that rely on codes and impact our conscious decision making. Unconsciously, even our dreams draw on codes. In the future, conflation of different coding systems, e.g., from synthetic biology and generative artificial intelligence, will merge biological codes with machine logic and computer language to promote next-level transhumanism. Codes emerge as a currency converter between systems of life and between different scientific disciplines.}
}
@article{HUSSAIN2025100707,
title = {Humanizing generative AI Brands: How brand anthropomorphism converts customers into brand heroes},
journal = {Computers in Human Behavior Reports},
volume = {19},
pages = {100707},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100707},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825001228},
author = {Khalid Hussain},
keywords = {Brand anthropomorphism, Brand respect, Brand hero, Generative AI, Branding},
abstract = {The recent surge in research on generative artificial intelligence (GenAI) can be attributed to the unparalleled success of ChatGPT. This success has fueled the development of new GenAI applications that are rapidly transforming the business landscape. Academic research largely focuses on exploring how GenAI can be utilized to enhance the effectiveness of business processes and everyday life of consumers. However, limited attention has been paid to understanding how GenAI brands can sustain their business in this highly dynamic and fiercely competitive GenAI market. To fill this gap, the present study investigated the role of brand anthropomorphism attributes in influencing brand respect and brand heroes. A sample of 315 consumers of GenAI applications was recruited from two countries: the United States of America (n = 167) and the United Kingdom (n = 148). Psychometric properties were validated via confirmatory factor analysis, and hypotheses were tested using PLS-SEM with SmartPLS 4.0. In addition, the present study conducted an importance-performance map analysis to complement the structural analysis. Findings revealed that moral virtue, cognitive experience and appearance attributes of brand anthropomorphism enhance brand respect. Whereas moral virtue, appearance and conscious emotionality attributes of brand anthropomorphism positively influence brand hero. Respondents’ age significantly moderates some of the proposed relationships while gender does not exhibit a significant influence. Theoretical contributions and managerial implications are also discussed.}
}
@article{DUAN2025103221,
title = {Inverse design of lattice structures with target mechanical performance via generative adversarial networks considering the effect of process parameters},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103221},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103221},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625001144},
author = {Chenglong Duan and Dazhong Wu},
keywords = {Inverse design, Additive manufacturing, Lattice structures, Machine learning, Generative adversarial networks},
abstract = {While generative artificial intelligence has been used to design materials and structures for additive manufacturing, current techniques can only generate design parameters. However, not only design parameters but also additive manufacturing (AM) process parameters affect the mechanical properties of additively manufactured materials. To address this issue, we introduce an auxiliary classifier generative adversarial network (ACGAN)-based computational framework that generates both design and AM process parameters to fabricate lattice structures with target mechanical performance. The computational framework consists of two ACGAN models, including a generative model called InverseACGAN and a forward predictive model called ForwardACGAN. The generative model generates critical design parameters of the lattice structures, including line distance, layer height, and infill pattern, as well as AM process parameters, including print speed and print temperature, based on target mechanical properties (i.e., porosity and compressive modulus). The forward predictive model predicts the mechanical properties of the lattice structures generated by the generative model. The experimental results show that the porosity and compressive modulus of the lattice structures designed by ACGAN are in good agreement with the target porosity and compressive modulus. The average mean absolute percentage errors between target and actual porosity, and target and actual compressive modulus are 6.481% and 10.208%, respectively.}
}
@article{ZHAO2025102829,
title = {Generative AI: The transformative impact of ChatGPT on systemic financial risk in Chinese banks},
journal = {Pacific-Basin Finance Journal},
volume = {93},
pages = {102829},
year = {2025},
issn = {0927-538X},
doi = {https://doi.org/10.1016/j.pacfin.2025.102829},
url = {https://www.sciencedirect.com/science/article/pii/S0927538X25001660},
author = {Yikai Zhao and Runyu Dai and Jun Nagayasu},
keywords = {AI, ChatGPT, Systemic financial risk, Chinese banks},
abstract = {We investigate the impact of ChatGPT, a generative artificial intelligence (GenAI) application, on the systemic financial risk of Chinese banks. Using a sample of 42 publicly traded banks and employing regression discontinuity (RD) and regression discontinuity difference-in-differences (RD-DID) methodologies, we assess the immediate effects following the launch of ChatGPT on November 30, 2022. Our findings reveal an immediate and significant increase in systemic financial risk, measured by ΔCoVaR. Robustness checks, including placebo tests, alternative risk measures, and varying sample windows, confirm the reliability of these results. Mechanism analysis highlights that transitional challenges during GenAI adoption exacerbate systemic vulnerabilities. Smaller banks, rural commercial banks, and banks with higher nonperforming loan ratios (NPL) face heightened risks, while large state-owned banks remain relatively insulated. These findings underscore the double-edged nature of disruptive innovations such that GenAI integration poses short-term risks to financial stability even if GenAI has transformative potential.}
}
@article{AKYON2024,
title = {Evaluating the Capabilities of Generative AI Tools in Understanding Medical Papers: Qualitative Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/59258},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001133},
author = {Seyma Handan Akyon and Fatih Cagatay Akyon and Ahmet Sefa Camyar and Fatih Hızlı and Talha Sari and Şamil Hızlı},
keywords = {large language models, LLM, LLMs, ChatGPT, artificial intelligence, AI, natural language processing, medicine, health care, GPT, machine learning, language model, language models, generative, research paper, research papers, scientific research, answer, answers, response, responses, comprehension, STROBE, Strengthening the Reporting of Observational Studies in Epidemiology},
abstract = {Background
Reading medical papers is a challenging and time-consuming task for doctors, especially when the papers are long and complex. A tool that can help doctors efficiently process and understand medical papers is needed.
Objective
This study aims to critically assess and compare the comprehension capabilities of large language models (LLMs) in accurately and efficiently understanding medical research papers using the STROBE (Strengthening the Reporting of Observational Studies in Epidemiology) checklist, which provides a standardized framework for evaluating key elements of observational study.
Methods
The study is a methodological type of research. The study aims to evaluate the understanding capabilities of new generative artificial intelligence tools in medical papers. A novel benchmark pipeline processed 50 medical research papers from PubMed, comparing the answers of 6 LLMs (GPT-3.5-Turbo, GPT-4-0613, GPT-4-1106, PaLM 2, Claude v1, and Gemini Pro) to the benchmark established by expert medical professors. Fifteen questions, derived from the STROBE checklist, assessed LLMs’ understanding of different sections of a research paper.
Results
LLMs exhibited varying performance, with GPT-3.5-Turbo achieving the highest percentage of correct answers (n=3916, 66.9%), followed by GPT-4-1106 (n=3837, 65.6%), PaLM 2 (n=3632, 62.1%), Claude v1 (n=2887, 58.3%), Gemini Pro (n=2878, 49.2%), and GPT-4-0613 (n=2580, 44.1%). Statistical analysis revealed statistically significant differences between LLMs (P<.001), with older models showing inconsistent performance compared to newer versions. LLMs showcased distinct performances for each question across different parts of a scholarly paper—with certain models like PaLM 2 and GPT-3.5 showing remarkable versatility and depth in understanding.
Conclusions
This study is the first to evaluate the performance of different LLMs in understanding medical papers using the retrieval augmented generation method. The findings highlight the potential of LLMs to enhance medical research by improving efficiency and facilitating evidence-based decision-making. Further research is needed to address limitations such as the influence of question formats, potential biases, and the rapid evolution of LLM models.}
}
@article{FRAILENARVAEZ2025100466,
title = {Between machines and art: The impact of CNC technology on artistic creation},
journal = {Array},
volume = {27},
pages = {100466},
year = {2025},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2025.100466},
url = {https://www.sciencedirect.com/science/article/pii/S2590005625000931},
author = {Marcelo Fraile-Narváez and Mihaela I. Chidean},
keywords = {Development of low-cost CNC machine, Generative artificial intelligence, Human–machine creative - collaboration, Digital art materialisation, Material variability in digital fabrication},
abstract = {This study shows how a hybrid workflow based on a Style-GAN-3 (with 256 × 256 pixel resolution) together with a €185 open-hardware plotter reframes authorship by uniting algorithmic invention with material execution. Specifically, it focuses on the development of a low-cost CNC machine, named ‘Gorosito’, which includes various customisation elements, such as the ability to interchange drawing tools to suit the operator/artist. Experimental validation of Gorosito is performed using images generated with generative AI and also including a comparison of the results with those produced by a commercial CNC machine. Results reveal precision of 0.045 mm and a 34% cost saving comparing with other commercial solutions. Our findings also show that each artwork, derived from the same digital file, acquires a unique expression, which leads to a redefinition of authenticity in digital art and provides a renewed perspective on the interplay between technology, artistic creation and cultural perception. The study thus positions Gorosito as an open and reproducible framework that any creative-code laboratory can adopt, bridging machine learning research with low-cost digital fabrication.}
}
@incollection{DIMAURO202515,
title = {Chapter 2 - Diagnosing the future: The role of artificial intelligence in the forthcoming medical epoch},
editor = {Dipu Patel},
booktitle = {Digital Health},
publisher = {Academic Press},
pages = {15-26},
year = {2025},
isbn = {978-0-443-23901-4},
doi = {https://doi.org/10.1016/B978-0-443-23901-4.00002-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443239014000027},
author = {Mark DiMauro},
keywords = {AGI, AI, AI ethics, Artificial intelligence, Augmented workforces, Computer in society, Delivery of healthcare, Generative AI, Human–computer interaction, Information management, Information systems, Machine learning, Medical education},
abstract = {Although artificial intelligence systems and neural networks have been around for nearly half a century, newer technologies like ChatGPT have thrust their capabilities into the limelight as Generative Artificial Intelligence systems take the media and academia by storm. This chapter examines the onset of Generative AI within the medical space, speculating at use cases, hesitation, and trust issues on the part of providers and/or patients, and touches upon what the future of AI-equipped healthcare might look like. Ultimately, as we work toward the future of healthcare and what many consider the AI's ultimate form—Artificial General Intelligence or AGI—questions of ethics, agency, applicability, privacy, efficiency, and capability all rise to the surface. It behooves us to engage with these questions now, while Generative AI is still in its relative infancy, especially within the context of an industry like healthcare.}
}
@article{OMAR2024e595,
title = {ChatGPT for digital pathology research},
journal = {The Lancet Digital Health},
volume = {6},
number = {8},
pages = {e595-e600},
year = {2024},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(24)00114-6},
url = {https://www.sciencedirect.com/science/article/pii/S2589750024001146},
author = {Mohamed Omar and Varun Ullanat and Massimo Loda and Luigi Marchionni and Renato Umeton},
abstract = {Summary
The rapid evolution of generative artificial intelligence (AI) models including OpenAI's ChatGPT signals a promising era for medical research. In this Viewpoint, we explore the integration and challenges of large language models (LLMs) in digital pathology, a rapidly evolving domain demanding intricate contextual understanding. The restricted domain-specific efficiency of LLMs necessitates the advent of tailored AI tools, as illustrated by advancements seen in the last few years including FrugalGPT and BioBERT. Our initiative in digital pathology emphasises the potential of domain-specific AI tools, where a curated literature database coupled with a user-interactive web application facilitates precise, referenced information retrieval. Motivated by the success of this initiative, we discuss how domain-specific approaches substantially minimise the risk of inaccurate responses, enhancing the reliability and accuracy of information extraction. We also highlight the broader implications of such tools, particularly in streamlining access to scientific research and democratising access to computational pathology techniques for scientists with little coding experience. This Viewpoint calls for an enhanced integration of domain-specific text-generation AI tools in academic settings to facilitate continuous learning and adaptation to the dynamically evolving landscape of medical research.}
}
@article{GIANNAKOPOULOS2023,
title = {Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/51580},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123009949},
author = {Kostis Giannakopoulos and Argyro Kavadella and Anas {Aaqel Salim} and Vassilis Stamatopoulos and Eleftherios G Kaklamanos},
keywords = {artificial intelligence, AI, large language models, generative pretrained transformers, evidence-based dentistry, ChatGPT, Google Bard, Microsoft Bing, clinical practice, dental professional, dental practice, clinical decision-making, clinical practice guidelines},
abstract = {Background
The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy.
Objective
This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry.
Methods
The LLMs were queried with 20 open-type, clinical dentistry–related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs’ answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs’ answers.
Results
Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate.
Conclusions
This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist’s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.}
}
@article{CALLEJA2025237,
title = {Primary school teachers’ perceptions towards the use of generative AI in teaching using lesson study},
journal = {International Journal for Lesson and Learning Studies},
volume = {14},
number = {3},
pages = {237-252},
year = {2025},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-11-2024-0268},
url = {https://www.sciencedirect.com/science/article/pii/S2046825325000125},
author = {James Calleja and Patrick Camilleri},
keywords = {Generative AI, Lesson study, Primary school teachers, Professional development, Teachers’ perceptions, Technology acceptance model},
abstract = {Purpose
The research, carried out with three lesson study teams in two primary schools in Malta, focuses on teachers’ changing perceptions of using Generative Artificial Intelligence (GenAI) in teaching using lesson study. The study seeks to discern how teachers’ interpretation and judgement towards the use of AI may lead them to its future integration in teaching.
Design/methodology/approach
This paper presents a multiple-case case study for an in-depth analysis of teachers’ perceptions towards the employment of AI in formal educational settings. Data, from email interviews with the three teachers teaching the lessons and detailed reports of each lesson study group, are analysed using the Technology Acceptance Model (TAM) as a theoretical lens.
Findings
Teachers’ use of GenAI in teaching using lesson study positively enhanced their perceptions and attitudes towards AI. It boosted their agency instigating them to intentionally see how to learn more about its employment to improve students’ learning experiences.
Originality/value
Using the TAM to examine teachers’ perceptions of using GenAI in teaching using lesson study, this research offers insights into teachers’ attitudes towards emerging technologies. It also provides implications for the design of professional development programmes through the integration of GenAI for teacher support.}
}
@article{CENGIZ2025103837,
title = {Exploring second language writers’ engagement with ChatGPT feedback: Revision behaviors and perceptions},
journal = {System},
volume = {134},
pages = {103837},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103837},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002477},
author = {Behice Ceyda Cengiz and Zeynep Bilki and Amine Hatun Ataş and Berkan Celik},
keywords = {Second language (L2) writing, Writing feedback, Generative artificial intelligence (GenAI), ChatGPT feedback, Feedback prompt},
abstract = {While recent research underlines ChatGPT's potential as a second language (L2) writing feedback tool, its effectiveness and role in engaging L2 writers require further investigation. This study explores how English as a Foreign Language (EFL) writers engage with ChatGPT feedback by analyzing their revision behaviors and perceptions of its effectiveness in revising their opinion essays. Using a convergent parallel mixed methods design, the study involved 25 B1-level EFL students from a university in Türkiye. Data were collected through essay drafts, change tracker sheets, a questionnaire, and interviews. The descriptive and thematic analysis of essays, change tracker sheets, and interviews revealed that most content and language feedback was accepted, while organization feedback received mixed engagement of acceptance and rejection. Students were more likely to accept language use feedback than content or organization feedback, often incorporating ChatGPT's revisions directly. For content feedback, the most common revision operations were additions and substitutions while more than a third of the revisions in response to organization feedback involved no corrections. Correction was the most frequent revision operation for language use feedback. Questionnaire and interview analyses further revealed that while ChatGPT feedback was generally well-received and considered beneficial for writing improvement, students faced challenges related to feedback length, specificity, advanced language, and misunderstandings. This study provides valuable insights into how EFL students interact with ChatGPT-generated feedback, highlighting both its potential to support L2 writing development and the challenges that may limit its effectiveness.}
}
@article{ANAND2025101069,
title = {Algorithms in the orchard: An embedding-based expert answering system for apple rust},
journal = {Smart Agricultural Technology},
volume = {12},
pages = {101069},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101069},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525003028},
author = {Astha Anand and Jian Shen and Armin Bernd Cremers and Marc Jacobs},
keywords = {Embeddings, Retrieval-augmented generation, Knowledge graph, Apple rust, Large language model, Generative artificial intelligence, Agricultural pest control},
abstract = {As sustainable agricultural practices gain importance, the need for intelligent pest control decision-making has grown. This paper introduces SEEDS: Similarity-based Expert Embedding Decision System, a Retrieval-Augmented Generation (RAG) based agricultural question-answering (QA) system. It is built upon a domain-specific knowledge graph (KG), representing Cedar Apple Rust disease, its host and causative agents, plant defense molecules against apple rust infection, and various pesticides. Utilizing the OpenAI embedding model, the system generates embeddings for user queries and KG data, employing similarity metrics to rank KG entries, facilitating accurate and relevant pest control recommendations. SEEDS is a promising niche AI tool in plant protection, setting the stage for scalable, extensible QA frameworks in precision agriculture. The results signify not only a step forward in agricultural expert systems but also highlight the potential for expanding this approach to other crops and pests, marking a substantial advancement in the use of AI for agricultural pest control.}
}
@incollection{OZCAN2025137,
title = {Chapter 6 - Dynamic relationalities of relational dynamics},
editor = {Kerimcan Ozcan and Venkat Ramaswamy},
booktitle = {Dynamic Relationality Theory of Creative Transformation},
publisher = {Elsevier},
pages = {137-155},
year = {2025},
isbn = {978-0-443-30159-9},
doi = {https://doi.org/10.1016/B978-0-443-30159-9.00006-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443301599000062},
author = {Kerimcan Ozcan and Venkat Ramaswamy},
keywords = {Artificial general intelligence, Becoming, Differential forms, Differential transformation, Homotopy, Monad, Singularity},
abstract = {Chapter 6 delves into the continuous transformation of identities and structures within Dynamic Relationality Theory employing category theory and differential topology to explore the fluid concept of “becoming.” It highlights significant shifts in relational dynamics, particularly with the advent of generative artificial intelligence (AI), emphasizing the role of natural transformation in guiding the evolution of categories and their interrelationships amid profound changes. The chapter employs differential topological concepts like smooth manifolds, vector fields, Lie derivatives, differential forms, and de Rham cohomology to model transformations within and across categories, providing a holistic view of relational dynamics, especially relevant to Artificial General Intelligence (AGI). It introduces a new monadology to encapsulate category dynamics and applies homotopy theory to model gradual and controlled transformations. The discussion culminates in the exploration of singularity in AGI as a differential transformation, underlining the impact of emerging technologies on categorical transformations and their implications for immersive, AI-driven interaction.}
}
@article{DENG2025118467,
title = {Becoming a cognitive miser? Antecedents and consequences of addictive ChatGPT use},
journal = {Social Science & Medicine},
volume = {383},
pages = {118467},
year = {2025},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2025.118467},
url = {https://www.sciencedirect.com/science/article/pii/S0277953625007981},
author = {Zihao Deng and Zhaohua Deng},
keywords = {Addictive use, Dual-system theory, Self-construal, Cognitive miserliness},
abstract = {Generative Artificial Intelligence (GenAI) has significantly enhanced productivity across diverse domains, however, growing concerns persist regarding its addictive use and potential cognitive ramifications. This study employed dual-system theory to examine the cognitive-behavioral mechanisms underpinning addictive ChatGPT use, positioning self-construal as a key antecedent and cognitive miserliness as a critical consequence. We adopted a mixed-methods approach for both exploratory and confirmatory analysis. Three cross-sectional surveys revealed that heightened activity in the impulsive cognitive system was a significant predictor of addictive ChatGPT use. Moreover, a dysregulation between the impulsive and reflective cognitive systems exacerbated compulsive tendencies and facilitated cognitive miserliness. Self-construal also affected these effects: individuals with an independent orientation were more likely to rely on the impulsive cognitive system, while those with an interdependent orientation engaged the reflective cognitive system more frequently. Notably, the reflective cognitive system often failed to adequately inhibit addictive ChatGPT use. Qualitative insights supported these findings and offered a deeper understanding of users’ behavioral patterns. This study contributes to theoretical discourse on the adverse cognitive impact of GenAI use, and informs managers seeking to design interventions that promote healthier digital engagement.}
}
@article{HE2025103020,
title = {Beyond simple interaction: Uncovering the perception-interaction intrinsic mechanism of generative AI agents—A multi-modal big data analysis with PLS-SEM and fsQCA},
journal = {Technology in Society},
volume = {83},
pages = {103020},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103020},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002106},
author = {Hao He and Shizhen Bai and Chunjia Han and Mu Yang and Weijia Fan and Brij B. Gupta},
keywords = {Human-AI interaction, Generative AI agent, Interactive willingness, Perceived characteristics, Empathy, Multi-modal big data analysis},
abstract = {Generative Artificial Intelligence (GenAI) is increasingly being adopted across industries, yet existing literature has not fully explored the unique traits and the complex mechanism it introduces. To address this gap, this study investigates the unique characteristics of GenAI agents and their impact on user interaction behaviors. By analyzing user-generated text and AI-generated images from the Character.AI platform, we examine three key perceptual characteristics: social personalization, functional customization, and emotional affordance. Through multi-modal machine learning approaches combining Structural Topic Modeling (STM) and Facial Action Coding System (FACS), we propose the “perceived characteristics of GenAI agent-empathy-interactive willingness” (PCoGenAI-E-IW) theoretical model to explore how user perceptions transform into interactive behaviors. Furthermore, the PLS-SEM analysis and configurational approach identify 10 distinct variable combinations that influence users’ interaction willingness. The findings validate our multi-modal analytical framework while providing valuable empirical evidence for marketing strategy formulation, service experience optimization, and theoretical advancement in human-AI interaction research.}
}
@article{OZMEN2025105215,
title = {“Whom do we educate? Uncertainties and inexplicable ecstasy of the GenAI era in foreign language teacher education”},
journal = {Teaching and Teacher Education},
volume = {167},
pages = {105215},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105215},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002926},
author = {Kemal Sinan Özmen and Hale Ülkü Aydın},
keywords = {GenAI, English language teacher education, Teacher educators, Student teacher competences},
abstract = {This study examines the implications of Generative Artificial Intelligence (GenAI) in English language teacher education, focusing on how teacher educators perceive and respond to its integration. Framed by Schön's reflective model and the TPACK framework, it advances the conceptualization of GenAI as a core element of teacher competence rather than a peripheral technological skill. Using qualitative interviews with six ELT professors and document analysis of 22 curricula in Türkiye, the study identifies four themes: (1) a gap between student digital readiness and institutional inertia, (2) pedagogical and ethical challenges, (3) time constraints in methodology courses, and (4) a role exchange where GenAI assumes cognitively demanding tasks. Participants proposed five strategies, including curriculum-wide integration, professional development for educators, and AI detection tools. The study contributes an ethically grounded, context-sensitive perspective, urging SLTE programs to embed reflective and learner-centered approaches in preparing future teachers for the pedagogical realities of AI-mediated education.}
}
@article{YAU2024,
title = {Accuracy of Prospective Assessments of 4 Large Language Model Chatbot Responses to Patient Questions About Emergency Care: Experimental Comparative Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/60291},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007404},
author = {Jonathan Yi-Shin Yau and Soheil Saadat and Edmund Hsu and Linda Suk-Ling Murphy and Jennifer S Roh and Jeffrey Suchard and Antonio Tapia and Warren Wiechmann and Mark I Langdorf},
keywords = {artificial intelligence, AI, chatbots, generative AI, natural language processing, consumer health information, patient education, literacy, emergency care information, chatbot, misinformation, health care, medical consultation},
abstract = {Background
Recent surveys indicate that 48% of consumers actively use generative artificial intelligence (AI) for health-related inquiries. Despite widespread adoption and the potential to improve health care access, scant research examines the performance of AI chatbot responses regarding emergency care advice.
Objective
We assessed the quality of AI chatbot responses to common emergency care questions. We sought to determine qualitative differences in responses from 4 free-access AI chatbots, for 10 different serious and benign emergency conditions.
Methods
We created 10 emergency care questions that we fed into the free-access versions of ChatGPT 3.5 (OpenAI), Google Bard, Bing AI Chat (Microsoft), and Claude AI (Anthropic) on November 26, 2023. Each response was graded by 5 board-certified emergency medicine (EM) faculty for 8 domains of percentage accuracy, presence of dangerous information, factual accuracy, clarity, completeness, understandability, source reliability, and source relevancy. We determined the correct, complete response to the 10 questions from reputable and scholarly emergency medical references. These were compiled by an EM resident physician. For the readability of the chatbot responses, we used the Flesch-Kincaid Grade Level of each response from readability statistics embedded in Microsoft Word. Differences between chatbots were determined by the chi-square test.
Results
Each of the 4 chatbots’ responses to the 10 clinical questions were scored across 8 domains by 5 EM faculty, for 400 assessments for each chatbot. Together, the 4 chatbots had the best performance in clarity and understandability (both 85%), intermediate performance in accuracy and completeness (both 50%), and poor performance (10%) for source relevance and reliability (mostly unreported). Chatbots contained dangerous information in 5% to 35% of responses, with no statistical difference between chatbots on this metric (P=.24). ChatGPT, Google Bard, and Claud AI had similar performances across 6 out of 8 domains. Only Bing AI performed better with more identified or relevant sources (40%; the others had 0%-10%). Flesch-Kincaid Reading level was 7.7-8.9 grade for all chatbots, except ChatGPT at 10.8, which were all too advanced for average emergency patients. Responses included both dangerous (eg, starting cardiopulmonary resuscitation with no pulse check) and generally inappropriate advice (eg, loosening the collar to improve breathing without evidence of airway compromise).
Conclusions
AI chatbots, though ubiquitous, have significant deficiencies in EM patient advice, despite relatively consistent performance. Information for when to seek urgent or emergent care is frequently incomplete and inaccurate, and patients may be unaware of misinformation. Sources are not generally provided. Patients who use AI to guide health care decisions assume potential risks. AI chatbots for health should be subject to further research, refinement, and regulation. We strongly recommend proper medical consultation to prevent potential adverse outcomes.}
}
@article{DERE2026130134,
title = {Motor-intent decoding from synthetic EEG data using denoising diffusion probabilistic models},
journal = {Expert Systems with Applications},
volume = {299},
pages = {130134},
year = {2026},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.130134},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425037492},
author = {Mustapha Deji Dere and Ji-Hun Jo and Boreom Lee},
keywords = {Electroencephalograph (EEG), Electromyogram (EMG), Deep learning, Diffusion model, Generative artificial intelligence},
abstract = {Decoding motor-intent directly from electroencephalogram (EEG) signals presents significant opportunities for advancing bio-inspired rehabilitation strategies and developing sophisticated human-computer interfaces. Despite the historical dominance of discriminative deep learning decoders, limitations in data availability and the development of effective decoding pipelines remain key obstacles to realizing this potential. This study introduces a novel framework predicated on electromyogram (EMG)-prompted diffusion models for the direct decoding of motor-intent from EMG and EEG signals. We demonstrate that this approach reduces classification error by 12.70 % relative to recent discriminative decoders. Furthermore, our results surpassed conventional positive pair augmentation techniques, such as jittering, exhibiting a 3.41 % improvement in performance. These findings underscore the transformative potential of generative models for generating synthetic training data and optimizing decoding pipelines in neuro-signal processing. We anticipate that this work will stimulate further investigation into the application of these techniques to improve the efficacy of rehabilitation interventions and facilitate more intuitive human-computer interactions, ultimately contributing to advancements in neuro-assistive device development and personalized rehabilitation strategies.}
}
@article{LAI2025100266,
title = {Designing and validating an AI-supported tool for enhancing critical inquiry in EFL education},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100266},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100266},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000874},
author = {Wan Yee Winsy Lai and Paul Kim and Ju Seong Lee},
keywords = {Critical inquiry skills, AI-powered learning, Generative artificial intelligence, EFL education, Bloom’s Taxonomy},
abstract = {As Generative AI (GenAI) technologies advance rapidly, educational settings face an urgent need for targeted interventions to cultivate learners’ critical, higher-order inquiry skills, so they can effectively navigate, assess, and apply AI-generated content. The urgency of this imperative is magnified for EFL learners in test-driven educational contexts that foster passive learning behaviors, discourage questioning, and inhibit critical thinking. To address these issues, we developed an AI-powered tool designed to evaluate questions based on Bloom’s Taxonomy, a six-level framework of cognitive processes, ranging from basic recall questions (Level 1) to advanced questions that trigger creative and evaluative thinking (Level 5). In study 1, the reliability of the tool was confirmed through multiple inter-rater tests with strong agreement. In study 2, we implemented an intervention program that integrated Bloom’s Taxonomy, targeted readings, group discussions, and sharing to enhance inquiry skills among EFL undergraduate students. Four statistical analyses in SPSS 29.0—including ICC for inter-rater reliability, Pearson correlation, and regression—were conducted to validate the AI-powered inquiry evaluation tool. Across 174 questions, students’ average inquiry level improved from 3.3 to 4.1 (on a five-level scale), showing a significant 0.8-level increase and meaningful enhancement in question quality. The study provides solid evidence of the reliability and validity of the AI-powered inquiry evaluation tool as an objective, real-time method that enhances the efficiency, consistency, and scalability of assessments, offering valuable guidance for EFL practitioners, curriculum designers, researchers, educators, and institutions in integrating evidence-based, inquiry-driven tools into EFL programs.}
}
@article{YILMAZ2023100005,
title = {Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100005},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Generative artificial intelligence, ChatGPT, Programming, Programming learning, Student opinions},
abstract = {With the diversification of generative artificial intelligence (AI) applications, the interest in their use in every segment and field of society in recent years has been increasing rapidly. One of these areas is programming learning and program writing processes. One of the generative AI tools used for this purpose is ChatGPT. The use of ChatGPT in program writing processes has become widespread, and this tool has a certain potential in the programming process. However, when the literature is examined, research results related to using ChatGPT for this purpose have yet to be found. The existing literature has a gap that requires exploration. This study aims to analyze the students' perspectives on using ChatGPT in the field of programming and programming learning. The study encompassed a cohort of 41 undergraduate students enrolled in a public university's Computer Technology and Information Systems department. The research was carried out within the scope of the Object-Oriented Programming II course for eight weeks. Throughout the research process, students were given project assignments related to the course every week, and they were asked to use ChatGPT while solving them. The research data was collected using a form consisting of open-ended questions and analyzed through content analysis. The research findings revealed both the advantages and disadvantages of ChatGPT usage, as perceived by the students. The students stated that the main benefits of using ChatGPT in programming learning are providing fast and mostly correct answers to questions, improving thinking skills, facilitating debugging, and increasing self-confidence. On the other hand, the main limitations of using ChatGPT in programming education were getting students used to laziness, being unable to answer some questions, or giving incomplete/incorrect answers, causing professional anxiety in students. Based on the results of the research, it can be said that it would be useful to integrate generative AI tools into programming courses considering the advantages they provide in programming teaching. However, appropriate measures should be taken regarding the limitations it brings. Based on the research findings, several recommendations were proposed regarding the integration of ChatGPT into lessons.}
}
@article{SHI2025124328,
title = {Toward open-source foundation model ecosystem: Impact evaluation framework and promotion mechanism},
journal = {Technological Forecasting and Social Change},
volume = {221},
pages = {124328},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124328},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003592},
author = {Jincheng Shi and Shan Jiang},
keywords = {Artificial intelligence, Open source, Foundation model, Generative artificial intelligence, Impact evaluation},
abstract = {Open-source foundation models cultivate complex innovation ecosystems that render traditional, project-centric evaluation frameworks inadequate. To address this gap, our study develops and validates a three-level framework for assessing ecosystem-level impact and identifying its enhancement mechanisms. Grounded in technology diffusion theory, we conduct a mixed-methods analysis of 14 leading models, using data from Hugging Face, GitHub, and X (formerly Twitter). Our findings reveal that while the initial impact of these models is balanced, significant gaps emerge at the secondary (derivative innovation) and tertiary (global influence) levels. We term this challenge the “climbing effect”—the difficulty of transitioning impact across these levels—and identify specific technical and strategic control points that facilitate this progression. Theoretically, this study shifts the unit of analysis from individual projects to broader ecosystems, challenges the assumption of “smooth diffusion,” and introduces control point theory to the open-source context. Practically, our findings offer actionable strategies for developers and an evidence-based framework for policymakers to foster a more prosperous open-source AI landscape.}
}
@article{DONG2025102582,
title = {Revisiting PR professionalism and ethics in the generative AI era through PR practitioners’ insights},
journal = {Public Relations Review},
volume = {51},
number = {3},
pages = {102582},
year = {2025},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2025.102582},
url = {https://www.sciencedirect.com/science/article/pii/S036381112500044X},
author = {Chuqing Dong and Morgan {van den Berg}},
keywords = {Ethics, Generative artificial intelligence (GAI), Professional code of ethics, PR practitioners},
abstract = {Recent breakthroughs in artificial intelligence (AI) continue to redefine strategic communication practices, provoking serious consideration for ethical implications, guidelines, and contextualizing areas of integration. Based on interviews with 21 PR professionals, this study examined perspectives on AI, particularly Generative AI (GAI), in PR practices and related ethical implications. Results highlight key benefits and commonly shared challenges of GAI use in PR practices. Additionally, the study reveals various ethical concerns identified by professionals in GAI use and the moral values held by professionals in guiding their ethical GAI use. This study contributes to an ongoing discussion on developing PR ethics theories pertinent to professionals that address PR practitioners’ timely ethical concerns around GAI. Practically, this study helps PR scholars and educators understand how professionals navigate rapidly advancing GAI technologies while maintaining high ethical standards and social responsibility.}
}
@article{BETZLER2023e917,
title = {Large language models and their impact in ophthalmology},
journal = {The Lancet Digital Health},
volume = {5},
number = {12},
pages = {e917-e924},
year = {2023},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(23)00201-7},
url = {https://www.sciencedirect.com/science/article/pii/S2589750023002017},
author = {Bjorn Kaijun Betzler and Haichao Chen and Ching-Yu Cheng and Cecilia S Lee and Guochen Ning and Su Jeong Song and Aaron Y Lee and Ryo Kawasaki and Peter {van Wijngaarden} and Andrzej Grzybowski and Mingguang He and Dawei Li and An {Ran Ran} and Daniel Shu Wei Ting and Kelvin Teo and Paisan Ruamviboonsuk and Sobha Sivaprasad and Varun Chaudhary and Ramin Tadayoni and Xiaofei Wang and Carol Y Cheung and Yingfeng Zheng and Ya Xing Wang and Yih Chung Tham and Tien Yin Wong},
abstract = {Summary
The advent of generative artificial intelligence and large language models has ushered in transformative applications within medicine. Specifically in ophthalmology, large language models offer unique opportunities to revolutionise digital eye care, address clinical workflow inefficiencies, and enhance patient experiences across diverse global eye care landscapes. Yet alongside these prospects lie tangible and ethical challenges, encompassing data privacy, security, and the intricacies of embedding large language models into clinical routines. This Viewpoint highlights the promising applications of large language models in ophthalmology, while weighing up the practical and ethical barriers towards their real-world implementation. This Viewpoint seeks to stimulate broader discourse on the potential of large language models in ophthalmology and to galvanise both clinicians and researchers into tackling the prevailing challenges and optimising the benefits of large language models while curtailing the associated risks.}
}
@article{FARRELLY2025358,
title = {The application of generative AI to healthcare regulation},
journal = {International Journal of Health Care Quality Assurance},
volume = {38},
number = {4},
pages = {358-369},
year = {2025},
issn = {0952-6862},
doi = {https://doi.org/10.1108/IJHCQA-07-2025-0093},
url = {https://www.sciencedirect.com/science/article/pii/S0952686225000120},
author = {John Farrelly and James V. Lucey and Gary Kiernan and Laura McQuaid and Pawel Stepala and Sandra Conroy and Stephen {O' Rourke} and Cathal James White and Cathal Leahy and Niall Clarke and Hector Chavez Hernandez and Louis Keyes and Stephen Neville},
keywords = {Generative AI, Healthcare regulation, Microsoft Copilot 365, Regulatory reporting, Automation, Operational efficiency, Regulation, Quality},
abstract = {Purpose
The article investigates the application of generative artificial intelligence (GenAI), specifically Microsoft Copilot 365, in automating the drafting of regulatory reports for a national healthcare regulator. The initiative aimed to assess the feasibility and effectiveness of AI technologies in reducing manual effort, maintaining quality and accuracy of report and enhancing operational efficiency in the regulatory reporting processes.
Design/methodology/approach
A proof of concept (PoC) was conducted to evaluate Microsoft Copilot 365’s capabilities in generating high-quality draft reports. Sample data were extracted and structured from a data repository to train AI prompts. Test cases were selected to simulate real-world scenarios. AI-generated documents were compared with human-authored reports. Accuracy, completeness and overall quality was compared using standardised BERTScore and ROUGE-L metrics.
Findings
AI-generated reports closely matched human-authored documents in terms of accuracy, completeness and quality. BERTScore and ROUGE-L metrics indicated high alignment, with Copilot outputs showing strong consistency across various regulations. Feedback from stakeholders highlighted the AI’s performance and its potential impact on time reduction.
Practical implications
The successful implementation of this PoC underscores the transformative potential of AI technologies in regulatory environments. Automating routine tasks may allow regulators to reallocate human resources to onsite inspection activities, enhancing overall operational effectiveness. The findings support the integration of AI in regulatory reporting, paving the way for future advancements in this domain.
Originality/value
This is the first paper to our knowledge that investigates the application of GenAI, specifically Microsoft Copilot 365, in automating the drafting of regulatory reports for a healthcare regulator.}
}
@article{WHITE2024S83,
title = {CAN AI BE USEFUL AS A CLINICAL TOOL FOR RISK STRATIFYING LOCALIZED PROSTATE CANCER PATIENTS?},
journal = {Urologic Oncology: Seminars and Original Investigations},
volume = {42},
pages = {S83},
year = {2024},
issn = {1078-1439},
doi = {https://doi.org/10.1016/j.urolonc.2024.01.233},
url = {https://www.sciencedirect.com/science/article/pii/S1078143924002497},
author = {Randie White and Stephen Ryan},
abstract = {Introduction
Generative Artificial Intelligence (AI) has become prominent in healthcare, particularly as an oncology aid in clinical documentation, which has implications for treatment decisions.1 National guidelines favor synoptic reporting of prostate biopsy specimens to aid in proper risk stratification of prostate cancer (PCa).2;Thus, AI is a potential tool to analyze synoptic reports and reduce the variation in algorithmic risk stratification. We questioned whether a trained AI model could review pathology reports, along with clinical vignettes, for PCa to provide an accurate risk assessment and recommendations.1. Sorin, V, Barash, Y, Konin, E., et al.. Deep-learning natural language processing for oncological applications. The Lancet Oncology. 2020 Dec 2020;21(12)doi:10.1016/S1470-2045(20)30615-X2. https://www.nccn.org/professionals/physician_gls/pdf/prostate_blocks.pdf
Methods
Retrospective review of localized PCa patients from January 2022 – January 2023 was performed. Following initial prostate biopsy, all patients were consulted and risk stratified based on NCCN guidelines by a urologic oncologist. We provided a generative AI model, ChatGPT3, the PCa risk stratification algorithm from NCCN Version 1.2023. Then queried the model to ensure accurate recall of the algorithm rules. Clinical features (PSA, cT stage) and histologic features (synoptic path report) from each case were provided and the model was prompted to “risk stratify the following patient.” In addition, we requested additional evaluation (ex: imaging) and initial therapy recommendations were also queried. 10 patients from each NCCN risk category were reviewed.3. ChatGPT. https://chat.openai.com
Results
60 patients were reviewed. The generative AI model correctly risk stratified 39/60 patients (65.0%). The AI model incorrectly risk stratified 21/60 patients, however, it did assign them to an adjacent risk group (Figure 1).; Notably, 14/20 patients were correctly assigned as intermediate risk group, but the model required further prompting for categorization into favorable or unfavorable risk. Once prompted, only 12/20 were correctly risk stratified (Figure 1). Finally, when queried, the model was able to recommend treatment and imaging modalities appropriate to the stated risk group (ex: very low risk favor active surveillance, and high risk required imaging).
Conclusions
Generative AI demonstrated poor performance in algorithmic risk stratification using standardized synoptic reports. The implications of inaccurate assessments need to be considered as more healthcare professionals and systems look to incorporating generative AI into clinical tools. A healthy amount of skepticism and close review is needed to vet any clinical tool. Ultimately when it comes to the nuance of the PCa, a trained provider is still needed to interpret the information and recommendations in line with the patient's goals and preferences.}
}
@incollection{GAUR2026197,
title = {Chapter 11 - Health equity and generative AI: Role, impact, and challenges},
editor = {Loveleen Gaur and Ajith Abraham},
booktitle = {Generative Artificial Intelligence and Ethics for Healthcare},
publisher = {Academic Press},
pages = {197-210},
year = {2026},
isbn = {978-0-443-33124-4},
doi = {https://doi.org/10.1016/B978-0-443-33124-4.00006-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443331244000060},
author = {Loveleen Gaur and Ajith Abraham},
keywords = {Algorithm bias, Ethical issues, Fairness, Generative AI, Health disparities, Health equity, Inclusive healthcare, Public health},
abstract = {This chapter explores the intersection of health equity and generative artificial intelligence (AI), emphasizing the role of AI in addressing health disparities while recognizing the challenges it presents. Health equity refers to the principle of fairness in healthcare, ensuring that all individuals have access to necessary resources and opportunities for optimal health. Generative AI has emerged as a transformative tool in healthcare, aiding in diagnosis, treatment planning, and patient management. However, algorithmic bias poses significant risks, exacerbating existing disparities and potentially leading to inequitable healthcare outcomes. The chapter examines how biases in AI algorithms can contribute to health disparities, illustrated through case studies showcasing real-world implications. Ethical concerns surrounding distributive justice, patient autonomy, and resource allocation are also addressed, highlighting the importance of equitable AI integration in healthcare systems. Strategies for developing fair algorithms, implementing ethical guidelines, and engaging with affected communities are discussed as essential components for promoting health equity. Additionally, the chapter presents case studies that demonstrate successful initiatives aimed at mitigating bias and enhancing equity through AI applications. Looking ahead, it identifies future directions for fair AI development, the need for policy and regulatory measures, and the vision for an inclusive healthcare system where generative AI serves to bridge health equity gaps.}
}
@article{XIAO2024105874,
title = {Automated daily report generation from construction videos using ChatGPT and computer vision},
journal = {Automation in Construction},
volume = {168},
pages = {105874},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105874},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006101},
author = {Bo Xiao and Yifan Wang and Yongpan Zhang and Chen Chen and Amos Darko},
keywords = {Construction daily report generation, Computer vision, ChatGPT, Construction management, Project documentation},
abstract = {Daily reports are important in construction management, informing project teams about status, enabling timely resolutions of delays and budget issues, and serving as official records for disputes and litigation. However, current practices are manual and time-consuming, requiring engineers to physically visit sites for observations. To fill this gap, this paper proposes an automated framework to generate daily construction reports from on-site videos by integrating ChatGPT and computer vision (CV)-based methods. The framework utilizes CV methods to analyze video footage and extract relevant productivity and activity information, which is then fed into ChatGPT using proper prompts to generate daily reports. A web application is developed to implement and validate the framework on a real construction site in Hong Kong, generating daily reports over a month. This research enhances construction management by significantly reducing documentation efforts through generative artificial intelligence, with potential applications in jobsite safety management, quality reporting, and stakeholder communication.}
}
@article{GUTIERREZMAQUILON2024,
title = {Integrating GPT-Based AI into Virtual Patients to Facilitate Communication Training Among Medical First Responders: Usability Study of Mixed Reality Simulation},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/58623},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24007133},
author = {Rodrigo {Gutiérrez Maquilón} and Jakob Uhl and Helmut Schrom-Feiertag and Manfred Tscheligi},
keywords = {medical first responders, verbal communication skills, training, virtual patient, generative artificial intelligence, GPT, large language models, prompt engineering, mixed reality},
abstract = {Background
Training in social-verbal interactions is crucial for medical first responders (MFRs) to assess a patient’s condition and perform urgent treatment during emergency medical service administration. Integrating conversational agents (CAs) in virtual patients (VPs), that is, digital simulations, is a cost-effective alternative to resource-intensive human role-playing. There is moderate evidence that CAs improve communication skills more effectively when used with instructional interventions. However, more recent GPT-based artificial intelligence (AI) produces richer, more diverse, and more natural responses than previous CAs and has control of prosodic voice qualities like pitch and duration. These functionalities have the potential to better match the interaction expectations of MFRs regarding habitability.
Objective
We aimed to study how the integration of GPT-based AI in a mixed reality (MR)–VP could support communication training of MFRs.
Methods
We developed an MR simulation of a traffic accident with a VP. ChatGPT (OpenAI) was integrated into the VP and prompted with verified characteristics of accident victims. MFRs (N=24) were instructed on how to interact with the MR scenario. After assessing and treating the VP, the MFRs were administered the Mean Opinion Scale-Expanded, version 2, and the Subjective Assessment of Speech System Interfaces questionnaires to study their perception of the voice quality and the usability of the voice interactions, respectively. Open-ended questions were asked after completing the questionnaires. The observed and logged interactions with the VP, descriptive statistics of the questionnaires, and the output of the open-ended questions are reported.
Results
The usability assessment of the VP resulted in moderate positive ratings, especially in habitability (median 4.25, IQR 4-4.81) and likeability (median 4.50, IQR 3.97-5.91). Interactions were negatively affected by the approximately 3-second latency of the responses. MFRs acknowledged the naturalness of determining the physiological states of the VP through verbal communication, for example, with questions such as “Where does it hurt?” However, the question-answer dynamic in the verbal exchange with the VP and the lack of the VP’s ability to start the verbal exchange were noticed. Noteworthy insights highlighted the potential of domain-knowledge prompt engineering to steer the actions of MFRs for effective training.
Conclusions
Generative AI in VPs facilitates MFRs’ training but continues to rely on instructions for effective verbal interactions. Therefore, the capabilities of the GPT-VP and a training protocol need to be communicated to trainees. Future interactions should implement triggers based on keyword recognition, the VP pointing to the hurting area, conversational turn-taking techniques, and add the ability for the VP to start a verbal exchange. Furthermore, a local AI server, chunk processing, and lowering the audio resolution of the VP’s voice could ameliorate the delay in response and allay privacy concerns. Prompting could be used in future studies to create a virtual MFR capable of assisting trainees.}
}
@article{YEOH2025102647,
title = {Trends and applications of variational autoencoders in medical imaging analysis},
journal = {Computerized Medical Imaging and Graphics},
volume = {126},
pages = {102647},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102647},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001569},
author = {Pauline Shan Qing Yeoh and Khairunnisa Hasikin and Xiang Wu and Siew Li Goh and Khin Wee Lai},
keywords = {Deep learning, Generative AI, Healthcare, Medical imaging analysis, Variational autoencoders},
abstract = {Automated medical imaging analysis plays a crucial role in modern healthcare, with deep learning emerging as a widely adopted solution. However, traditional supervised learning methods often struggle to achieve optimal performance due to increasing challenges such as data scarcity and variability. In response, generative artificial intelligence has gained significant attention, particularly Variational Autoencoders (VAEs), which have been extensively utilized to address various challenges in medical imaging. This review analyzed 118 articles published in the Web of Science database between 2018 and 2024. Bibliometric analysis was conducted to map research trends, while a curated compilation of datasets and evaluation metrics were extracted to underscore the importance of standardization in deep learning workflows. VAEs have been applied across multiple healthcare applications, including anomaly detection, segmentation, classification, synthesis, registration, harmonization, and clustering. Findings suggest that VAE-based models are increasingly applied in medical imaging, with Magnetic Resonance Imaging emerging as the dominant modality and image synthesis as a primary application. The growing interest in this field highlights the potential of VAEs to enhance medical imaging analysis by overcoming existing limitations in data-driven healthcare solutions. This review serves as a valuable resource for researchers looking to integrate VAE models into healthcare applications, offering an overview of current advancements.}
}
@article{DALVIESFAHANI2025124291,
title = {Stimulus-organism-response framework of decision-makers intention to adopt generative AI to replace entry-level jobs: The moderating impact of personality traits},
journal = {Technological Forecasting and Social Change},
volume = {219},
pages = {124291},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124291},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525003221},
author = {Mohammad Dalvi-Esfahani and Hajar Barati-Ahmadabadi and T. Ramayah and Jason J. Turner and Noorminshah {A. Iahad} and Nasrin Azar},
keywords = {Generative AI, Entry-level jobs, Stimulus-Organism-Response (S-O-R), Theory of Effective Use (TEU)},
abstract = {This study was motivated by the limited research on the adoption of Generative Artificial Intelligence (GenAI) in the workplace. Based on the Stimulus-Organism-Response (S-O-R) framework, we developed a model to assess the factors influencing decision-makers' intention to adopt GenAI as a substitute for entry-level jobs in financial institutions. To test the hypotheses, we collected survey data from 335 respondents in Malaysian financial institutions and analyzed it using partial least squares structural equation modeling. The findings indicate that trust in GenAI significantly affects decision-makers' intention to adopt it as an alternative solution to human positions. Trust, in turn, was found to be positively influenced by constructs from the Theory of Effective Use (transparent interaction, informed action, and representational fidelity) as well as AI literacy, which reflects users' ability to evaluate and interact with AI. The results also show that personality traits, particularly conscientiousness, moderate the relationship between trust and adoption intention, highlighting the importance of individual differences in GenAI usage. Collectively, our findings extend the S-O-R framework by revealing how both cognitive and affective factors shape GenAI adoption behavior. The study also offers practical implications for GenAI stakeholders, especially about the vital role of trust-building strategies in fostering AI adoption.}
}
@article{MIRTAHERI2025114406,
title = {Automated vulnerability score prediction through lightweight generative AI},
journal = {Knowledge-Based Systems},
volume = {329},
pages = {114406},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114406},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125014455},
author = {Seyedeh Leili Mirtaheri and Andrea Pugliese and Valerio Pascucci},
keywords = {Generative AI, Vulnerability scoring, LLM, BERT, Transformer},
abstract = {Given the constantly increasing number of newly published vulnerabilities, manually assessing their scores (e.g., under the Common Vulnerability Scoring System) has become unfeasible. Recently, learning-based systems have been proposed to automatically predict vulnerability scores. Such systems use vulnerability indexing databases to train deep learning algorithms. However, their practical applicability has important limitations, including a high dependency on the quality and diversity of training data, and high computational requirements. In addition, vulnerability descriptions often do not follow the standard templates and are not rich enough with respect to the expected features. In this paper, we propose a novel architecture that takes advantage of both generative artificial intelligence and lightweight deep learning techniques to provide an efficient and effective solution for automated vulnerability scoring. Data extracted from the National Vulnerability Dataset is fed into a large language model layer, whose output (i.e., an augmented dataset) is then used in a lightweight fine-tuned BERTsmall layer. We provide the results of an extensive experimental assessment of the effect of both each layer of the architecture and end-to-end performances. The results suggest that the combination of GPT3.5-Turbo and BERTsmall provides the most effective accuracy-time trade-off. We also compare the performance of the proposed architecture with other LLMs, BERT models, and cutting-edge approaches. The results show good improvements in prediction quality also when compared to a recent technique that incorporates data from 66 different sources, including the NVD.}
}
@article{COEN2025,
title = {Chatbot for the Return of Positive Genetic Screening Results for Hereditary Cancer Syndromes: Prompt Engineering Project},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/65848},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000680},
author = {Emma Coen and Guilherme {Del Fiol} and Kimberly A Kaphingst and Emerson Borsato and Jackilen Shannon and Hadley Smith and Aaron Masino and Caitlin G Allen},
keywords = {prompt engineering, few-shot learning, retrieval-augmented generation, population screening program, cancer, genetics, screening, syndrome, genomic, counseling, large language model, LLM, engineering, chatbot, prompt, RAG, mobile phone},
abstract = {The increasing demand for population-wide genomic screening and the limited availability of genetic counseling resources have created a pressing need for innovative service delivery models. Chatbots powered by large language models (LLMs) have shown potential in genomic services, particularly in pretest counseling, but their application in returning positive population-wide genomic screening results remains underexplored. Leveraging advanced LLMs like GPT-4 offers an opportunity to address this gap by delivering accurate, contextual, and user-centered communication to individuals receiving positive genetic test results. This project aimed to design, implement, and evaluate a chatbot integrated with GPT-4, tailored to support the return of positive genomic screening results in the context of South Carolina’s In Our DNA SC program. This initiative offers free genetic screening to 100,000 individuals, with over 33,000 results returned and numerous positive findings for conditions such as Lynch syndrome, hereditary breast and ovarian cancer syndrome, and familial hypercholesterolemia. A 3-step prompt engineering process using retrieval-augmented generation and few-shot techniques was used to create the chatbot. Training materials included patient frequently asked questions, genetic counseling scripts, and patient-derived queries. The chatbot underwent iterative refinement based on 13 training questions, while performance was evaluated through expert ratings on responses to 2 hypothetical patient scenarios. The 2 scenarios were intended to represent common but distinct patient profiles in terms of gender, race, ethnicity, age, and background knowledge. Domain experts rated the chatbot using a 5-point Likert scale across 8 predefined criteria: tone, clarity, program accuracy, domain accuracy, robustness, efficiency, boundaries, and usability. The chatbot achieved an average score of 3.86 (SD 0.89) across all evaluation metrics. The highest-rated criteria were tone (mean 4.25, SD 0.71) and usability (mean 4.25, SD 0.58), reflecting the chatbot’s ability to communicate effectively and provide a seamless user experience. Boundary management (mean 4.0, SD 0.76) and efficiency (mean 3.88, SD 1.08) also scored well, while clarity and robustness received ratings of 3.81 (SD 1.05) and 3.81 (SD 0.66), respectively. Domain accuracy was rated 3.63 (SD 0.96), indicating satisfactory performance in delivering genetic information, whereas program accuracy received the lowest score of 3.25 (SD 1.39), highlighting the need for improvements in delivering program-specific details. This project demonstrates the feasibility of using LLM-powered chatbots to support the return of positive genomic screening results. The chatbot effectively handled open-ended patient queries, maintained conversational boundaries, and delivered user-friendly responses. However, enhancements in program-specific accuracy are essential to maximize its utility. Future research will explore hybrid chatbot designs that combine the strengths of LLMs with rule-based components to improve scalability, accuracy, and accessibility in genomic service delivery. The findings underscore the potential of generative artificial intelligence tools to address resource limitations and improve the accessibility of genomic health care services.}
}
@article{LI2025103015,
title = {The psychological mechanism of value co-creation with human-centred generative AI robot assistants},
journal = {Technology in Society},
volume = {83},
pages = {103015},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103015},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002052},
author = {Zhaotong Li and Kum Fai Yuen and Chee-Chong Teo},
keywords = {Human-centred generative AI, Robot assistant, Value co-creation, Autonomy competence relatedness model, Mind perception theory},
abstract = {Human-Generative Artificial Intelligence (GAI) interactions are receiving increasing attention in both society and academia, and GAI integration makes robot assistants more human-centred to better serve consumers. Understanding the value co-creation process between human consumers and GAI robot assistants is critical for the broader adoption of such technologies. This study seeks to investigate the psychological mechanisms and antecedent factors that underlie the human–AI value co-creation process, which has received limited attention in the literature. Accordingly, a theoretical model based on the Autonomy Competence Relatedness (ACR) model and Mind Perception Theory (MPT) is developed to examine the technological features and psychological factors that promote value co-creation. A survey was conducted in Singapore and collected 607 responses, which were analysed through covariance-based structural equation modelling. Survey results reveal that GAI robot assistant features (i.e., sensing autonomy, thought autonomy, action autonomy, personalisation, anthropomorphism, and interactivity) positively impact value co-creation through the mediation of consumers' psychological motivations, including perceived autonomy, competence, warmth, and relatedness satisfactions. By extending the ACR model with MPT, this study enhances the literature on human-GAI interactions, offering a novel understanding of the psychological factors driving value co-creation in human-centred GAI applications.}
}
@article{MOROSKY20254,
title = {Practical applications of artificial intelligence chatbots in obstetrics and gynecology medical education},
journal = {American Journal of Obstetrics and Gynecology},
volume = {233},
number = {1},
pages = {4-11},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825002285},
author = {Christopher M. Morosky and Laura Baecher-Lind and Katherine T. Chen and Angela Fleming and Shireen Madani Sims and Helen Kang Morgan and Celeste S. Royce and Tammy Sonn and Alyssa Stephenson-Famy and Jill Sutton and Jonathan Schaffir and Rashmi Bhargava},
keywords = {artificial intelligence, biases, chatbot, ChatGPT, data privacy, faculty development, feedback, hallucinations, informed approach, integration, large language models, learning objectives, medical education, mentorship, responsible use, teaching},
abstract = {Generative artificial intelligence chatbots are sophisticated conversational artificial intelligence tools that have the capability to interpret natural language inputs and produce responses that closely resemble human speech. Artificial intelligence chatbots hold significant promise in revolutionizing medical education by offering invaluable support across various educational domains, including teaching, learning, and assessment. Their practical applications span a wide spectrum, from aligning learning objectives and simplifying administrative tasks to facilitating feedback, aiding faculty development, and supporting mentorship initiatives. However, alongside their potential benefits, concerns exist regarding data privacy, inherent biases, and occasional errors termed “hallucinations,” underscoring the imperative for a cautious and informed approach to their integration within educational settings. It therefore becomes essential for medical educators and academic institutions to proactively engage with artificial intelligence technologies like chatbots, not only to leverage their benefits but also to critically assess and address associated challenges such as bias, privacy, and misinformation. By thoughtfully integrating artificial intelligence tools, medical educators can determine where these technologies are most beneficial, implement safeguards against potential harms, and explore innovative applications to enhance medical education.}
}
@article{WANG2024104133,
title = {Audio–visual deepfake detection using articulatory representation learning},
journal = {Computer Vision and Image Understanding},
volume = {248},
pages = {104133},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104133},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002145},
author = {Yujia Wang and Hua Huang},
keywords = {Deepfake detection, Audio–visual, Articulatory representation},
abstract = {Advancements in generative artificial intelligence have made it easier to manipulate auditory and visual elements, highlighting the critical need for robust audio–visual deepfake detection methods. In this paper, we propose an articulatory representation-based audio–visual deepfake detection approach, ART-AVDF. First, we devise an audio encoder to extract articulatory features that capture the physical significance of articulation movement, integrating with a lip encoder to explore audio–visual articulatory correspondences in a self-supervised learning manner. Then, we design a multimodal joint fusion module to further explore inherent audio–visual consistency using the articulatory embeddings. Extensive experiments on the DFDC, FakeAVCeleb, and DefakeAVMiT datasets demonstrate that ART-AVDF obtains a significant performance improvement compared to many deepfake detection models.}
}